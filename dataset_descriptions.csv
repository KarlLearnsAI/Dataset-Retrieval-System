Dataset ID,Name,Description
2,anneal,"**Author**: Unknown. Donated by David Sterling and Wray Buntine  

**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Annealing) - 1990  

**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  



The original Annealing dataset from UCI. The exact meaning of the features and classes is largely unknown. Annealing, in metallurgy and materials science, is a heat treatment that alters the physical and sometimes chemical properties of a material to increase its ductility and reduce its hardness, making it more workable. It involves heating a material to above its recrystallization temperature, maintaining a suitable temperature, and then cooling. (Wikipedia)



### Attribute Information:

     1. family:          --,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS

     2. product-type:    C, H, G

     3. steel:           -,R,A,U,K,M,S,W,V

     4. carbon:          continuous

     5. hardness:        continuous

     6. temper_rolling:  -,T

     7. condition:       -,S,A,X

     8. formability:     -,1,2,3,4,5

     9. strength:        continuous

    10. non-ageing:      -,N

    11. surface-finish:  P,M,-

    12. surface-quality: -,D,E,F,G

    13. enamelability:   -,1,2,3,4,5

    14. bc:              Y,-

    15. bf:              Y,-

    16. bt:              Y,-

    17. bw/me:           B,M,-

    18. bl:              Y,-

    19. m:               Y,-

    20. chrom:           C,-

    21. phos:            P,-

    22. cbond:           Y,-

    23. marvi:           Y,-

    24. exptl:           Y,-

    25. ferro:           Y,-

    26. corr:            Y,-

    27. blue/bright/varn/clean:          B,R,V,C,-

    28. lustre:          Y,-

    29. jurofm:          Y,-

    30. s:               Y,-

    31. p:               Y,-

    32. shape:           COIL, SHEET

    33. thick:           continuous

    34. width:           continuous

    35. len:             continuous

    36. oil:             -,Y,N

    37. bore:            0000,0500,0600,0760

    38. packing: -,1,2,3

    classes:        1,2,3,4,5,U

  

    -- The '-' values are actually 'not_applicable' values rather than

       'missing_values' (and so can be treated as legal discrete

       values rather than as showing the absence of a discrete value)."
3,kr-vs-kp,"Author: Alen Shapiro
Source: [UCI](https://archive.ics.uci.edu/ml/datasets/Chess+(King-Rook+vs.+King-Pawn))
Please cite: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)

1. Title: Chess End-Game -- King+Rook versus King+Pawn on a7
(usually abbreviated KRKPA7). The pawn on a7 means it is one square
away from queening. It is the King+Rook's side (white) to move.

2. Sources:
(a) Database originally generated and described by Alen Shapiro.
(b) Donor/Coder: Rob Holte (holte@uottawa.bitnet). The database
was supplied to Holte by Peter Clark of the Turing Institute
in Glasgow (pete@turing.ac.uk).
(c) Date: 1 August 1989

3. Past Usage:
- Alen D. Shapiro (1983,1987), ""Structured Induction in Expert Systems"",
Addison-Wesley. This book is based on Shapiro's Ph.D. thesis (1983)
at the University of Edinburgh entitled ""The Role of Structured
Induction in Expert Systems"".
- Stephen Muggleton (1987), ""Structuring Knowledge by Asking Questions"",
pp.218-229 in ""Progress in Machine Learning"", edited by I. Bratko
and Nada Lavrac, Sigma Press, Wilmslow, England SK9 5BB.
- Robert C. Holte, Liane Acker, and Bruce W. Porter (1989),
""Concept Learning and the Problem of Small Disjuncts"",
Proceedings of IJCAI. Also available as technical report AI89-106,
Computer Sciences Department, University of Texas at Austin,
Austin, Texas 78712.

4. Relevant Information:
The dataset format is described below. Note: the format of this
database was modified on 2/26/90 to conform with the format of all
the other databases in the UCI repository of machine learning databases.

5. Number of Instances: 3196 total

6. Number of Attributes: 36

7. Attribute Summaries:
Classes (2): -- White-can-win (""won"") and White-cannot-win (""nowin"").
I believe that White is deemed to be unable to win if the Black pawn
can safely advance.
Attributes: see Shapiro's book.

8. Missing Attributes: -- none

9. Class Distribution:
In 1669 of the positions (52%), White can win.
In 1527 of the positions (48%), White cannot win.

The format for instances in this database is a sequence of 37 attribute values.
Each instance is a board-descriptions for this chess endgame. The first
36 attributes describe the board. The last (37th) attribute is the
classification: ""win"" or ""nowin"". There are 0 missing values.
A typical board-description is

f,f,f,f,f,f,f,f,f,f,f,f,l,f,n,f,f,t,f,f,f,f,f,f,f,t,f,f,f,f,f,f,f,t,t,n,won

The names of the features do not appear in the board-descriptions.
Instead, each feature correponds to a particular position in the
feature-value list. For example, the head of this list is the value
for the feature ""bkblk"". The following is the list of features, in
the order in which their values appear in the feature-value list:

[bkblk,bknwy,bkon8,bkona,bkspr,bkxbq,bkxcr,bkxwp,blxwp,bxqsq,cntxt,dsopp,dwipd,
hdchk,katri,mulch,qxmsq,r2ar8,reskd,reskr,rimmx,rkxwp,rxmsq,simpl,skach,skewr,
skrxp,spcop,stlmt,thrsk,wkcti,wkna8,wknck,wkovl,wkpos,wtoeg]

In the file, there is one instance (board position) per line.


Num Instances: 3196
Num Attributes: 37
Num Continuous: 0 (Int 0 / Real 0)
Num Discrete: 37
Missing values: 0 / 0.0%"
4,labor,"**Author**: Unknown
**Source**: Collective Barganing Review, Labour Canada
**Please cite**: https://archive.ics.uci.edu/ml/citation_policy.html

Date: Tue, 15 Nov 88 15:44:08 EST
 From: stan <stan@csi2.UofO.EDU>
 To: aha@ICS.UCI.EDU
 
 1. Title: Final settlements in labor negotitions in Canadian industry
 
 2. Source Information
    -- Creators: Collective Barganing Review, montly publication,
       Labour Canada, Industrial Relations Information Service,
         Ottawa, Ontario, K1A 0J2, Canada, (819) 997-3117
         The data includes all collective agreements reached
         in the business and personal services sector for locals
         with at least 500 members (teachers, nurses, university
         staff, police, etc) in Canada in 87 and first quarter of 88.   
    -- Donor: Stan Matwin, Computer Science Dept, University of Ottawa,
                 34 Somerset East, K1N 9B4, (stan@uotcsi2.bitnet)
    -- Date: November 1988
  
 3. Past Usage:
    -- testing concept learning software, in particular
       an experimental method to learn two-tiered concept descriptions.
       The data was used to learn the description of an acceptable
       and unacceptable contract.
       The unacceptable contracts were either obtained by interviewing
       experts, or by inventing near misses.
       Examples of use are described in:
         Bergadano, F., Matwin, S., Michalski, R.,
         Zhang, J., Measuring Quality of Concept Descriptions, 
         Procs. of the 3rd European Working Sessions on Learning,
         Glasgow, October 1988.
         Bergadano, F., Matwin, S., Michalski, R., Zhang, J.,
         Representing and Acquiring Imprecise and Context-dependent
         Concepts in Knowledge-based Systems, Procs. of ISMIS'88,
         North Holland, 1988.
 4. Relevant Information:
    -- data was used to test 2tier approach with learning
 from positive and negative examples
 
 5. Number of Instances: 57 
 
 6. Number of Attributes: 16 
 
 7. Attribute Information:
    1.  dur: duration of agreement 
        [1..7]
    2   wage1.wage : wage increase in first year of contract 
        [2.0 .. 7.0]
    3   wage2.wage : wage increase in second year of contract
        [2.0 .. 7.0]
    4   wage3.wage : wage increase in third year of contract
        [2.0 .. 7.0]
    5   cola : cost of living allowance 
        [none, tcf, tc]
    6   hours.hrs : number of working hours during week
        [35 .. 40]
    7   pension : employer contributions to pension plan
        [none, ret_allw, empl_contr]
    8   stby_pay : standby pay
        [2 .. 25]
    9   shift_diff : shift differencial : supplement for work on II and III shift
        [1 .. 25]
   10   educ_allw.boolean : education allowance 
        [true false]
   11   holidays : number of statutory holidays 
        [9 .. 15]
   12   vacation : number of paid vacation days
        [ba, avg, gnr]
   13   lngtrm_disabil.boolean : 
        employer's help during employee longterm disabil
        ity [true , false]
   14   dntl_ins : employers contribution towards the dental plan
        [none, half, full]
   15   bereavement.boolean : employer's financial contribution towards the 
        covering the costs of bereavement
        [true , false]
   16   empl_hplan : employer's contribution towards the health plan
        [none, half, full]
 
 8. Missing Attribute Values: None
 
 9. Class Distribution:
 
 10. Exceptions from format instructions: no commas between attribute values."
5,arrhythmia,"**Author**: H. Altay Guvenir, Burak Acar, Haldun Muderrisoglu  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/arrhythmia)   
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)

**Cardiac Arrhythmia Database**  
The aim is to determine the type of arrhythmia from the ECG recordings. This database contains 279 attributes, 206 of which are linear valued and the rest are nominal. 

Concerning the study of H. Altay Guvenir: ""The aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in one of the 16 groups. Class 01 refers to 'normal' ECG classes, 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones. For the time being, there exists a computer program that makes such a classification. However, there are differences between the cardiologist's and the program's classification. Taking the cardiologist's as a gold standard we aim to minimize this difference by means of machine learning tools.
 
The names and id numbers of the patients were recently removed from the database.
 
### Attribute Information  
 
       1 Age: Age in years , linear
       2 Sex: Sex (0 = male; 1 = female) , nominal
       3 Height: Height in centimeters , linear
       4 Weight: Weight in kilograms , linear
       5 QRS duration: Average of QRS duration in msec., linear
       6 P-R interval: Average duration between onset of P and Q waves
         in msec., linear
       7 Q-T interval: Average duration between onset of Q and offset
         of T waves in msec., linear
       8 T interval: Average duration of T wave in msec., linear
       9 P interval: Average duration of P wave in msec., linear
      Vector angles in degrees on front plane of:, linear
      10 QRS
      11 T
      12 P
      13 QRST
      14 J
      15 Heart rate: Number of heart beats per minute ,linear
      Of channel DI:
       Average width, in msec., of: linear
       16 Q wave
       17 R wave
       18 S wave
       19 R' wave, small peak just after R
       20 S' wave
       21 Number of intrinsic deflections, linear
       22 Existence of ragged R wave, nominal
       23 Existence of diphasic derivation of R wave, nominal
       24 Existence of ragged P wave, nominal
       25 Existence of diphasic derivation of P wave, nominal
       26 Existence of ragged T wave, nominal
       27 Existence of diphasic derivation of T wave, nominal
      Of channel DII: 
       28 .. 39 (similar to 16 .. 27 of channel DI)
      Of channels DIII:
       40 .. 51
      Of channel AVR:
       52 .. 63
      Of channel AVL:
       64 .. 75
      Of channel AVF:
       76 .. 87
      Of channel V1:
       88 .. 99
      Of channel V2:
       100 .. 111
      Of channel V3:
       112 .. 123
      Of channel V4:
       124 .. 135
      Of channel V5:
       136 .. 147
      Of channel V6:
       148 .. 159
      Of channel DI:
       Amplitude , * 0.1 milivolt, of
       160 JJ wave, linear
       161 Q wave, linear
       162 R wave, linear
       163 S wave, linear
       164 R' wave, linear
       165 S' wave, linear
       166 P wave, linear
       167 T wave, linear
       168 QRSA , Sum of areas of all segments divided by 10,
           ( Area= width * height / 2 ), linear
       169 QRSTA = QRSA + 0.5 * width of T wave * 0.1 * height of T
           wave. (If T is diphasic then the bigger segment is
           considered), linear
      Of channel DII:
       170 .. 179
      Of channel DIII:
       180 .. 189
      Of channel AVR:
       190 .. 199
      Of channel AVL:
       200 .. 209
      Of channel AVF:
       210 .. 219
      Of channel V1:
       220 .. 229
      Of channel V2:
       230 .. 239
      Of channel V3:
       240 .. 249
      Of channel V4:
       250 .. 259
      Of channel V5:
       260 .. 269
      Of channel V6:
       270 .. 279
        
Class code - class - number of instances:
> 
        01             Normal                245
        02             Ischemic changes (Coronary Artery Disease)   44
        03             Old Anterior Myocardial Infarction           15
        04             Old Inferior Myocardial Infarction           15
        05             Sinus tachycardy        13
        06             Sinus bradycardy        25
        07             Ventricular Premature Contraction (PVC)       3
        08             Supraventricular Premature Contraction       2
        09             Left bundle branch block         9 
        10             Right bundle branch block       50
        11             1. degree AtrioVentricular block       0 
        12             2. degree AV block                0
        13             3. degree AV block                0
        14             Left ventricule hypertrophy                4
        15             Atrial Fibrillation or Flutter               5
        16             Others                 22"
6,letter,"**Author**: David J. Slate  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Letter+Recognition) - 01-01-1991  
**Please cite**: P. W. Frey and D. J. Slate. ""Letter Recognition Using Holland-style Adaptive Classifiers"". Machine Learning 6(2), 1991  

1. TITLE: 
  Letter Image Recognition Data 
 
    The objective is to identify each of a large number of black-and-white
    rectangular pixel displays as one of the 26 capital letters in the English
    alphabet.  The character images were based on 20 different fonts and each
    letter within these 20 fonts was randomly distorted to produce a file of
    20,000 unique stimuli.  Each stimulus was converted into 16 primitive
    numerical attributes (statistical moments and edge counts) which were then
    scaled to fit into a range of integer values from 0 through 15.  We
    typically train on the first 16000 items and then use the resulting model
    to predict the letter category for the remaining 4000.  See the article
    cited above for more details."
7,audiology,"**Author**: Professor Jergen at Baylor College of Medicine
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Audiology+(Standardized))
**Please cite**: Bareiss, E. Ray, & Porter, Bruce (1987). Protos: An Exemplar-Based Learning Apprentice. In the Proceedings of the 4th International Workshop on Machine Learning, 12-23, Irvine, CA: Morgan Kaufmann

**Audiology Database**
This database is a standardized version of the original audiology database (see audiology.* in this directory). The non-standard set of attributes have been converted to a standard set of attributes according to the rules that follow.

* Each property that appears anywhere in the original .data or .test file has been represented as a separate attribute in this file.

* A property such as age_gt_60 is represented as a boolean attribute with values f and t.

* In most cases, a property of the form x(y) is represented as a discrete attribute x() whose possible values are the various y's; air() is an example. There are two exceptions:
** when only one value of y appears anywhere, e.g. static(normal). In this case, x_y appears as a boolean attribute.
** when one case can have two or more values of x, e.g. history(..). All possible values of history are treated as separate boolean attributes.

* Since boolean attributes only appear as positive conditions, each boolean attribute is assumed to be false unless noted as true. The value of multi-value discrete attributes taken as unknown (""?"") unless a value is specified.

* The original case identifications, p1 to p200 in the .data file and t1 to t26 in the .test file, have been added as a unique identifier attribute.

[Note: in the original .data file, p165 has a repeated specification of o_ar_c(normal); p166 has repeated specification of speech(normal) and conflicting values air(moderate) and air(mild). No other problems with the original data were noted.]


### Attribute Information:

age_gt_60: f, t.
air(): mild,moderate,severe,normal,profound.
airBoneGap: f, t.
ar_c(): normal,elevated,absent.
ar_u(): normal,absent,elevated.
bone(): mild,moderate,normal,unmeasured.
boneAbnormal: f, t.
bser(): normal,degraded.
history_buzzing: f, t.
history_dizziness: f, t.
history_fluctuating: f, t.
history_fullness: f, t.
history_heredity: f, t.
history_nausea: f, t.
history_noise: f, t.
history_recruitment: f, t.
history_ringing: f, t.
history_roaring: f, t.
history_vomiting: f, t.
late_wave_poor: f, t.
m_at_2k: f, t.
m_cond_lt_1k: f, t.
m_gt_1k: f, t.
m_m_gt_2k: f, t.
m_m_sn: f, t.
m_m_sn_gt_1k: f, t.
m_m_sn_gt_2k: f, t.
m_m_sn_gt_500: f, t.
m_p_sn_gt_2k: f, t.
m_s_gt_500: f, t.
m_s_sn: f, t.
m_s_sn_gt_1k: f, t.
m_s_sn_gt_2k: f, t.
m_s_sn_gt_3k: f, t.
m_s_sn_gt_4k: f, t.
m_sn_2_3k: f, t.
m_sn_gt_1k: f, t.
m_sn_gt_2k: f, t.
m_sn_gt_3k: f, t.
m_sn_gt_4k: f, t.
m_sn_gt_500: f, t.
m_sn_gt_6k: f, t.
m_sn_lt_1k: f, t.
m_sn_lt_2k: f, t.
m_sn_lt_3k: f, t.
middle_wave_poor: f, t.
mod_gt_4k: f, t.
mod_mixed: f, t.
mod_s_mixed: f, t.
mod_s_sn_gt_500: f, t.
mod_sn: f, t.
mod_sn_gt_1k: f, t.
mod_sn_gt_2k: f, t.
mod_sn_gt_3k: f, t.
mod_sn_gt_4k: f, t.
mod_sn_gt_500: f, t.
notch_4k: f, t.
notch_at_4k: f, t.
o_ar_c(): normal,elevated,absent.
o_ar_u(): normal,absent,elevated.
s_sn_gt_1k: f, t.
s_sn_gt_2k: f, t.
s_sn_gt_4k: f, t.
speech(): normal,good,very_good,very_poor,poor,unmeasured.
static_normal: f, t.
tymp(): a,as,b,ad,c.
viith_nerve_signs: f, t.
wave_V_delayed: f, t.
waveform_ItoV_prolonged: f, t.
indentifier (unique for each instance)

class:
cochlear_unknown,mixed_cochlear_age_fixation,poss_central
mixed_cochlear_age_otitis_media,mixed_poss_noise_om,
cochlear_age,normal_ear,cochlear_poss_noise,cochlear_age_and_noise,
acoustic_neuroma,mixed_cochlear_unk_ser_om,conductive_discontinuity,
retrocochlear_unknown,conductive_fixation,bells_palsy,
cochlear_noise_and_heredity,mixed_cochlear_unk_fixation,
otitis_media,possible_menieres,possible_brainstem_disorder,
cochlear_age_plus_poss_menieres,mixed_cochlear_age_s_om,
mixed_cochlear_unk_discontinuity,mixed_poss_central_om"
8,liver-disorders,"**Author**: BUPA Medical Research Ltd. Donor: Richard S. Forsyth   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Liver+Disorders) - 5/15/1990  
**Please cite**: 

**BUPA liver disorders**
 
The first 5 variables are all blood tests which are thought to be sensitive to liver disorders that might arise from excessive alcohol consumption.  Each line in the dataset constitutes the record of a single male individual. 

**Important note:** The 7th field (selector) has been widely misinterpreted in the past as a dependent variable representing presence or absence of a liver disorder. This is incorrect [1]. The 7th field was created by BUPA researchers as a train/test selector. It is not suitable as a dependent variable for classification. The dataset does not contain any variable representing presence or absence of a liver disorder. Researchers who wish to use this dataset as a classification benchmark should follow the method used in experiments by the donor (Forsyth & Rada, 1986, Machine learning: applications in expert systems and information retrieval) and others (e.g. Turney, 1995, Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm), who used the 6th field (drinks), after dichotomising, as a dependent variable for classification. Because of widespread misinterpretation in the past, researchers should take care to state their method clearly.
 
**Attribute information**  
    1. mcv mean corpuscular volume  
    2. alkphos alkaline phosphotase  
    3. sgpt alanine aminotransferase  
    4. sgot  aspartate aminotransferase  
    5. gammagt gamma-glutamyl transpeptidase  
    6. drinks number of half-pint equivalents of alcoholic beverages drunk per day  
    7. selector field created by the BUPA researchers to split the data into train/test sets  

[1] McDermott & Forsyth 2016, Diagnosing a disorder in a classification benchmark, Pattern Recognition Letters, Volume 73. Note Forsyth is named on the UCI page as the original donor of the dataset."
9,autos,"**Author**: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Automobile) - 1987  
**Please cite**:   

**1985 Auto Imports Database**  
This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars.  The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price.   Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale.  Actuarians call this process ""symboling"".  A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.
 
The third factor is the relative average loss payment per insured vehicle year.  This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.
 
Several of the attributes in the database could be used as a ""class"" attribute.

Sources:  
1) 1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook.
2) Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038 
3) Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037
 
Past Usage:  
Kibler,~D., Aha,~D.~W., & Albert,~M. (1989).  Instance-based prediction of real-valued attributes.  {it Computational Intelligence}, {it 5}, 51--57.

 
Attribute Information:
>
   1. symboling:                -3, -2, -1, 0, 1, 2, 3.
   2. normalized-losses:        continuous from 65 to 256.
   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,
                                isuzu, jaguar, mazda, mercedes-benz, mercury,
                                mitsubishi, nissan, peugot, plymouth, porsche,
                                renault, saab, subaru, toyota, volkswagen, volvo
   4. fuel-type:                diesel, gas.
   5. aspiration:               std, turbo.
   6. num-of-doors:             four, two.
   7. body-style:               hardtop, wagon, sedan, hatchback, convertible.
   8. drive-wheels:             4wd, fwd, rwd.
   9. engine-location:          front, rear.
  10. wheel-base:               continuous from 86.6 120.9.
  11. length:                   continuous from 141.1 to 208.1.
  12. width:                    continuous from 60.3 to 72.3.
  13. height:                   continuous from 47.8 to 59.8.
  14. curb-weight:              continuous from 1488 to 4066.
  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.
  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.
  17. engine-size:              continuous from 61 to 326.
  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.
  19. bore:                     continuous from 2.54 to 3.94.
  20. stroke:                   continuous from 2.07 to 4.17.
  21. compression-ratio:        continuous from 7 to 23.
  22. horsepower:               continuous from 48 to 288.
  23. peak-rpm:                 continuous from 4150 to 6600.
  24. city-mpg:                 continuous from 13 to 49.
  25. highway-mpg:              continuous from 16 to 54.
  26. price:                    continuous from 5118 to 45400."
10,lymph,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Citation Request:
    This lymphography domain was obtained from the University Medical Centre,
    Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and 
    M. Soklic for providing the data.  Please include this citation if you plan
    to use this database.
 
 1. Title: Lymphography Domain
 
 2. Sources: 
     (a) See Above.
     (b) Donors: Igor Kononenko, 
                 University E.Kardelj
                 Faculty for electrical engineering
                 Trzaska 25
                 61000 Ljubljana (tel.: (38)(+61) 265-161
 
                 Bojan Cestnik
                 Jozef Stefan Institute
                 Jamova 39
                 61000 Ljubljana
                 Yugoslavia (tel.: (38)(+61) 214-399 ext.287) 
    (c) Date: November 1988
 
 3. Past Usage: (sveral)
     1. Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A
        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko
        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.
        -- Assistant-86: 76% accuracy
     2. Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In
        I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 11-30,
        Sigma Press.
        -- Simple Bayes: 83% accuracy
        -- CN2 (99% threshold): 82%
     3. Michalski,R., Mozetic,I. Hong,J., & Lavrac,N. (1986).  The Multi-Purpose
        Incremental Learning System AQ15 and its Testing Applications to Three
        Medical Domains.  In Proceedings of the Fifth National Conference on
        Artificial Intelligence, 1041-1045. Philadelphia, PA: Morgan Kaufmann.
        -- Experts: 85% accuracy (estimate)
        -- AQ15: 80-82%
 
 4. Relevant Information:
      This is one of three domains provided by the Oncology Institute
      that has repeatedly appeared in the machine learning literature.
      (See also breast-cancer and primary-tumor.)
 
 5. Number of Instances: 148
 
 6. Number of Attributes: 19 including the class attribute
 
 7. Attribute information:
     --- NOTE: All attribute values in the database have been entered as
               numeric values corresponding to their index in the list
               of attribute values for that attribute domain as given below.
     1. class: normal find, metastases, malign lymph, fibrosis
     2. lymphatics: normal, arched, deformed, displaced
     3. block of affere: no, yes
     4. bl. of lymph. c: no, yes
     5. bl. of lymph. s: no, yes
     6. by pass: no, yes
     7. extravasates: no, yes
     8. regeneration of: no, yes
     9. early uptake in: no, yes
    10. lym.nodes dimin: 0-3
    11. lym.nodes enlar: 1-4
    12. changes in lym.: bean, oval, round
    13. defect in node: no, lacunar, lac. marginal, lac. central
    14. changes in node: no, lacunar, lac. margin, lac. central
    15. changes in stru: no, grainy, drop-like, coarse, diluted, reticular, 
                         stripped, faint, 
    16. special forms: no, chalices, vesicles
    17. dislocation of: no, yes
    18. exclusion of no: no, yes
    19. no. of nodes in: 0-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, >=70
 
 8. Missing Attribute Values: None
 
 9. Class Distribution: 
     Class:        Number of Instances:
     normal find:  2
     metastases:   81
     malign lymph: 61
     fibrosis:     4
 
 




 Relabeled values in attribute 'lymphatics'
    From: '1'                     To: normal              
    From: '2'                     To: arched              
    From: '3'                     To: deformed            
    From: '4'                     To: displaced           


 Relabeled values in attribute 'block_of_affere'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'bl_of_lymph_c'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'bl_of_lymph_s'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'by_pass'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'extravasates'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'regeneration_of'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'early_uptake_in'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'changes_in_lym'
    From: '1'                     To: bean                
    From: '2'                     To: oval                
    From: '3'                     To: round               


 Relabeled values in attribute 'defect_in_node'
    From: '1'                     To: no                  
    From: '2'                     To: lacunar             
    From: '3'                     To: lac_margin          
    From: '4'                     To: lac_central         


 Relabeled values in attribute 'changes_in_node'
    From: '1'                     To: no                  
    From: '2'                     To: lacunar             
    From: '3'                     To: lac_margin          
    From: '4'                     To: lac_central         


 Relabeled values in attribute 'changes_in_stru'
    From: '1'                     To: no                  
    From: '2'                     To: grainy              
    From: '3'                     To: drop_like           
    From: '4'                     To: coarse              
    From: '5'                     To: diluted             
    From: '6'                     To: reticular           
    From: '7'                     To: stripped            
    From: '8'                     To: faint               


 Relabeled values in attribute 'special_forms'
    From: '1'                     To: no                  
    From: '2'                     To: chalices            
    From: '3'                     To: vesicles            


 Relabeled values in attribute 'dislocation_of'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'exclusion_of_no'
    From: '1'                     To: no                  
    From: '2'                     To: yes                 


 Relabeled values in attribute 'class'
    From: '1'                     To: normal              
    From: '2'                     To: metastases          
    From: '3'                     To: malign_lymph        
    From: '4'                     To: fibrosis"
11,balance-scale,"**Author**: Siegler, R. S. (donated by Tim Hume)  
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/balance+scale) - 1994  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Balance Scale Weight & Distance Database**  
This data set was generated to model psychological experimental results.  Each example is classified as having the balance scale tip to the right, tip to the left, or be balanced. The attributes are the left weight, the left distance, the right weight, and the right distance. The correct way to find the class is the greater of (left-distance * left-weight) and (right-distance * right-weight). If they are equal, it is balanced.

### Attribute description  
The attributes are the left weight, the left distance, the right weight, and the right distance.

### Relevant papers  
Shultz, T., Mareschal, D., & Schmidt, W. (1994). Modeling Cognitive Development on Balance Scale Phenomena. Machine Learning, Vol. 16, pp. 59-88."
12,mfeat-factors,"**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Multiple Features Dataset: Factors**  
One of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. 

### Attribute Information  
The attributes represent 216 profile correlations. No more information is known.

### Relevant Papers  
A slightly different version of the database is used in  
M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.
 
The database as is is used in:  
A.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000"
13,breast-cancer,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Citation Request:
    This breast cancer domain was obtained from the University Medical Centre,
    Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and 
    M. Soklic for providing the data.  Please include this citation if you plan
    to use this database.
 
 1. Title: Breast cancer data (Michalski has used this)
 
 2. Sources: 
    -- Matjaz Zwitter & Milan Soklic (physicians)
       Institute of Oncology 
       University Medical Center
       Ljubljana, Yugoslavia
    -- Donors: Ming Tan and Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
    -- Date: 11 July 1988
 
 3. Past Usage: (Several: here are some)
      -- Michalski,R.S., Mozetic,I., Hong,J., & Lavrac,N. (1986). The 
         Multi-Purpose Incremental Learning System AQ15 and its Testing 
         Application to Three Medical Domains.  In Proceedings of the 
         Fifth National Conference on Artificial Intelligence, 1041-1045,
         Philadelphia, PA: Morgan Kaufmann.
         -- accuracy range: 66%-72%
      -- Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In 
         Progress in Machine Learning (from the Proceedings of the 2nd
         European Working Session on Learning), 11-30, Bled, 
         Yugoslavia: Sigma Press.
         -- 8 test results given: 65%-72% accuracy range
      -- Tan, M., & Eshelman, L. (1988). Using weighted networks to 
         represent classification knowledge in noisy domains.  Proceedings 
         of the Fifth International Conference on Machine Learning, 121-134,
         Ann Arbor, MI.
         -- 4 systems tested: accuracy range was 68%-73.5%
     -- Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A
        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko
        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.
        -- Assistant-86: 78% accuracy
 
 4. Relevant Information:
      This is one of three domains provided by the Oncology Institute
      that has repeatedly appeared in the machine learning literature.
      (See also lymphography and primary-tumor.)
 
      This data set includes 201 instances of one class and 85 instances of
      another class.  The instances are described by 9 attributes, some of
      which are linear and some are nominal.
 
 5. Number of Instances: 286
 
 6. Number of Attributes: 9 + the class attribute
 
 7. Attribute Information:
    1. Class: no-recurrence-events, recurrence-events
    2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.
    3. menopause: lt40, ge40, premeno.
    4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44,
                   45-49, 50-54, 55-59.
    5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26,
                  27-29, 30-32, 33-35, 36-39.
    6. node-caps: yes, no.
    7. deg-malig: 1, 2, 3.
    8. breast: left, right.
    9. breast-quad: left-up, left-low, right-up, right-low, central.
   10. irradiat: yes, no.
 
 8. Missing Attribute Values: (denoted by ""?"")
    Attribute #:  Number of instances with missing values:
    6.             8
    9.             1.
 
 9. Class Distribution:
     1. no-recurrence-events: 201 instances
     2. recurrence-events: 85 instances

 Num Instances:     286
 Num Attributes:    10
 Num Continuous:    0 (Int 0 / Real 0)
 Num Discrete:      10
 Missing values:    9 /  0.3%

     name                      type enum ints real     missing    distinct  (1)
   1 'age'                     Enum 100%   0%   0%     0 /  0%     6 /  2%   0% 
   2 'menopause'               Enum 100%   0%   0%     0 /  0%     3 /  1%   0% 
   3 'tumor-size'              Enum 100%   0%   0%     0 /  0%    11 /  4%   0% 
   4 'inv-nodes'               Enum 100%   0%   0%     0 /  0%     7 /  2%   0% 
   5 'node-caps'               Enum  97%   0%   0%     8 /  3%     2 /  1%   0% 
   6 'deg-malig'               Enum 100%   0%   0%     0 /  0%     3 /  1%   0% 
   7 'breast'                  Enum 100%   0%   0%     0 /  0%     2 /  1%   0% 
   8 'breast-quad'             Enum 100%   0%   0%     1 /  0%     5 /  2%   0% 
   9 'irradiat'                Enum 100%   0%   0%     0 /  0%     2 /  1%   0% 
  10 'Class'                   Enum 100%   0%   0%     0 /  0%     2 /  1%   0%"
14,mfeat-fourier,"**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Multiple Features Dataset: Fourier**  
One of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images.

### Attribute Information  
The attributes represent 76 Fourier coefficients of the character shapes.

### Relevant Papers  
A slightly different version of the database is used in  
M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.
 
The database as is is used in:  
A.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000"
15,breast-w,"**Author**: Dr. William H. Wolberg, University of Wisconsin  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)), [University of Wisconsin](http://pages.cs.wisc.edu/~olvi/uwmp/cancer.html) - 1995  
**Please cite**: See below, plus [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  

**Breast Cancer Wisconsin (Original) Data Set.** Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The target feature records the prognosis (malignant or benign). [Original data available here](ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/)  

Current dataset was adapted to ARFF format from the UCI version. Sample code ID's were removed.  

! Note that there is also a related Breast Cancer Wisconsin (Diagnosis) Data Set with a different set of features, better known as [wdbc](https://www.openml.org/d/1510).

### Relevant Papers  

W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. 

O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.  

### Citation request  

This breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.  If you publish results when using this database, then please include this information in your acknowledgments.  Also, please cite one or more of:

   1. O. L. Mangasarian and W. H. Wolberg: ""Cancer diagnosis via linear 
      programming"", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.

   2. William H. Wolberg and O.L. Mangasarian: ""Multisurface method of 
      pattern separation for medical diagnosis applied to breast cytology"", 
      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, 
      December 1990, pp 9193-9196.

   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: ""Pattern recognition 
      via linear programming: Theory and application to medical diagnosis"", 
      in: ""Large-scale numerical optimization"", Thomas F. Coleman and Yuying
      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.

   4. K. P. Bennett & O. L. Mangasarian: ""Robust linear programming 
      discrimination of two linearly inseparable sets"", Optimization Methods
      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers)."
16,mfeat-karhunen,"**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Multiple Features Dataset: Karhunen**  
One of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. 

### Attribute Information  
The attributes represent 64 descriptors from the Karhunen-Loeve Transform, a linear transform that corresponds to the projection of the images on the eigenvectors of a covariant matrix. Also see:  
M.D. Garris et al: NIST Form-Based Handprint Recognition System. Internal Report. National Institute of Standards and Technology, NISTIR 5469, 1994.

### Relevant Papers  
A slightly different version of the database is used in  
M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.
 
The database as is is used in:  
A.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000"
18,mfeat-morphological,"**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Multiple Features Dataset: Morphological**  
One of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. 

In this dataset, these digits are represented in terms of 6 morphological features. 

### Attribute Information  
The meaning of the features is mostly unknown. They are never named in the original files, and the paper only talks about 'morphological features, such as the number of endpoints'.

### Relevant Papers  
A slightly different version of the database is used in  
M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.
 
The database as is is used in:  
A.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000"
20,mfeat-pixel,"**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Multiple Features Dataset: Pixel**  
One of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. The maps were scanned in 8 bit grey value at density of 400dpi, scanned, sharpened, and thresholded. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images.  

Using this dataset, sampled versions of the original images may be obtained (15 x 16 pixels).  

### Attribute Information  
The mfeatures represent 240 (15 x 16) pixel averages in 2 x 3 windows. 

### Relevant Papers  
A slightly different version of the database is used in  
M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.
 
The database as is is used in:  
A.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000"
22,mfeat-zernike,"**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**Multiple Features Dataset: Zernike**  
One of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. 

In this dataset, these digits are represented in terms of 47 Zernike moments. 

### Attribute Information  
The attributes represent 47 rotation invariant Zernike moments. They can't distinguish samples of class '6' from those of class '9'. More information on Zernike moments can be found in:  
A. Khotanzad and Y.H. Hong: Rotation invariant pattern recognition using Zernike moments. Int. Conf. on Pattern Recognition, Rome 1998, pp. 326-328.

### Relevant Papers  
A slightly different version of the database is used in  
M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.
 
The database as is is used in:  
A.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000"
23,cmc,"**Author**: [Tjen-Sien Lim](limt@stat.wisc.edu) 
**Source**: [As obtained from UCI](https://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice)
**Please cite**: [UCI citation](https://archive.ics.uci.edu/ml/citation_policy.html)

1. Title: Contraceptive Method Choice
 
 2. Sources:
    (a) Origin:  This dataset is a subset of the 1987 National Indonesia
                 Contraceptive Prevalence Survey
    (b) Creator: Tjen-Sien Lim (limt@stat.wisc.edu)
    (c) Donor:   Tjen-Sien Lim (limt@stat.wisc.edu)
    (c) Date:    June 7, 1997
 
 3. Past Usage:
    Lim, T.-S., Loh, W.-Y. & Shih, Y.-S. (1999). A Comparison of
    Prediction Accuracy, Complexity, and Training Time of Thirty-three
    Old and New Classification Algorithms. Machine Learning. Forthcoming.
    (ftp://ftp.stat.wisc.edu/pub/loh/treeprogs/quest1.7/mach1317.pdf or
    (http://www.stat.wisc.edu/~limt/mach1317.pdf)
 
 4. Relevant Information:
    This dataset is a subset of the 1987 National Indonesia Contraceptive
    Prevalence Survey. The samples are married women who were either not 
    pregnant or do not know if they were at the time of interview. The 
    problem is to predict the current contraceptive method choice 
    (no use, long-term methods, or short-term methods) of a woman based 
    on her demographic and socio-economic characteristics.
 
 5. Number of Instances: 1473
 
 6. Number of Attributes: 10 (including the class attribute)
 
 7. Attribute Information:
 
    1. Wife's age                     (numerical)
    2. Wife's education               (categorical)      1=low, 2, 3, 4=high
    3. Husband's education            (categorical)      1=low, 2, 3, 4=high
    4. Number of children ever born   (numerical)
    5. Wife's religion                (binary)           0=Non-Islam, 1=Islam
    6. Wife's now working?            (binary)           0=Yes, 1=No
    7. Husband's occupation           (categorical)      1, 2, 3, 4
    8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high
    9. Media exposure                 (binary)           0=Good, 1=Not good
    10. Contraceptive method used     (class attribute)  1=No-use 
                                                         2=Long-term
                                                         3=Short-term
 
 8. Missing Attribute Values: None

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
24,mushroom,"**Author**: [Jeff Schlimmer](Jeffrey.Schlimmer@a.gp.cs.cmu.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/mushroom) - 1981     
**Please cite**:  The Audubon Society Field Guide to North American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred A. Knopf 


### Description

This dataset describes mushrooms in terms of their physical characteristics. They are classified into: poisonous or edible.

### Source
```
(a) Origin: 
Mushroom records are drawn from The Audubon Society Field Guide to North American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred A. Knopf 

(b) Donor: 
Jeff Schlimmer (Jeffrey.Schlimmer '@' a.gp.cs.cmu.edu)
```

### Dataset description

This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.

### Attributes Information
```
1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s 
2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s 
3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y 
4. bruises?: bruises=t,no=f 
5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s 
6. gill-attachment: attached=a,descending=d,free=f,notched=n 
7. gill-spacing: close=c,crowded=w,distant=d 
8. gill-size: broad=b,narrow=n 
9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y 
10. stalk-shape: enlarging=e,tapering=t 
11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=? 
12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s 
13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s 
14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y 
15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y 
16. veil-type: partial=p,universal=u 
17. veil-color: brown=n,orange=o,white=w,yellow=y 
18. ring-number: none=n,one=o,two=t 
19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z 
20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y 
21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y 
22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d
```

### Relevant papers

Schlimmer,J.S. (1987). Concept Acquisition Through Representational Adjustment (Technical Report 87-19). Doctoral disseration, Department of Information and Computer Science, University of California, Irvine. 

Iba,W., Wogulis,J., & Langley,P. (1988). Trading off Simplicity and Coverage in Incremental Concept Learning. In Proceedings of the 5th International Conference on Machine Learning, 73-79. Ann Arbor, Michigan: Morgan Kaufmann. 

Duch W, Adamczak R, Grabczewski K (1996) Extraction of logical rules from training data using backpropagation networks, in: Proc. of the The 1st Online Workshop on Soft Computing, 19-30.Aug.1996, pp. 25-30, [Web Link] 

Duch W, Adamczak R, Grabczewski K, Ishikawa M, Ueda H, Extraction of crisp logical rules using constrained backpropagation networks - comparison of two new approaches, in: Proc. of the European Symposium on Artificial Neural Networks (ESANN'97), Bruge, Belgium 16-18.4.1997."
25,colic,"**Author**: Mary McLeish & Matt Cecile, University of Guelph  
Donor: Will Taylor (taylor@pluto.arc.nasa.gov)   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Horse+Colic) - 8/6/89   

**Horse Colic database**  
Database of surgeries on horses. Possible class attributes: 24 (whether lesion is surgical), others include: 23, 25, 26, and 27

Notes:
* Hospital_Number is an identifier and should be ignored when modelling

Attribute Information:
> 
   1:  surgery?
           1 = Yes, it had surgery
           2 = It was treated without surgery  
   2:  Age 
           1 = Adult horse
           2 = Young (< 6 months)  
   3:  Hospital Number 
           - numeric id
           - the case number assigned to the horse
             (may not be unique if the horse is treated > 1 time)  
   4:  rectal temperature
           - linear
           - in degrees celsius.
           - An elevated temp may occur due to infection.
           - temperature may be reduced when the animal is in late shock
           - normal temp is 37.8
           - this parameter will usually change as the problem progresses
                eg. may start out normal, then become elevated because of
                    the lesion, passing back through the normal range as the
                    horse goes into shock  
   5:  pulse 
           - linear
           - the heart rate in beats per minute
           - is a reflection of the heart condition: 30 -40 is normal for adults
           - rare to have a lower than normal rate although athletic horses
             may have a rate of 20-25
           - animals with painful lesions or suffering from circulatory shock
             may have an elevated heart rate  
   6:  respiratory rate
           - linear
           - normal rate is 8 to 10
           - usefulness is doubtful due to the great fluctuations  
   7:  temperature of extremities
           - a subjective indication of peripheral circulation
           - possible values:
                1 = Normal
                2 = Warm
                3 = Cool
                4 = Cold
           - cool to cold extremities indicate possible shock
           - hot extremities should correlate with an elevated rectal temp.  
   8:  peripheral pulse
           - subjective
           - possible values are:
                1 = normal
                2 = increased
                3 = reduced
                4 = absent
           - normal or increased p.p. are indicative of adequate circulation
             while reduced or absent indicate poor perfusion  
   9:  mucous membranes
           - a subjective measurement of colour
           - possible values are:
                1 = normal pink
                2 = bright pink
                3 = pale pink
                4 = pale cyanotic
                5 = bright red / injected
                6 = dark cyanotic
           - 1 and 2 probably indicate a normal or slightly increased
             circulation
           - 3 may occur in early shock
           - 4 and 6 are indicative of serious circulatory compromise
           - 5 is more indicative of a septicemia  
  10: capillary refill time
           - a clinical judgement. The longer the refill, the poorer the
             circulation
           - possible values
                1 = < 3 seconds
                2 = >= 3 seconds  
  11: pain - a subjective judgement of the horse's pain level
           - possible values:
                1 = alert, no pain
                2 = depressed
                3 = intermittent mild pain
                4 = intermittent severe pain
                5 = continuous severe pain
           - should NOT be treated as a ordered or discrete variable!
           - In general, the more painful, the more likely it is to require
             surgery
           - prior treatment of pain may mask the pain level to some extent  
  12: peristalsis                              
           - an indication of the activity in the horse's gut. As the gut
             becomes more distended or the horse becomes more toxic, the
             activity decreases
           - possible values:
                1 = hypermotile
                2 = normal
                3 = hypomotile
                4 = absent  
  13: abdominal distension
           - An IMPORTANT parameter.
           - possible values
                1 = none
                2 = slight
                3 = moderate
                4 = severe
           - an animal with abdominal distension is likely to be painful and
             have reduced gut motility.
           - a horse with severe abdominal distension is likely to require
             surgery just tio relieve the pressure  
  14: nasogastric tube
           - this refers to any gas coming out of the tube
           - possible values:
                1 = none
                2 = slight
                3 = significant
           - a large gas cap in the stomach is likely to give the horse
             discomfort  
  15: nasogastric reflux
           - possible values
                1 = none
                2 = > 1 liter
                3 = < 1 liter
           - the greater amount of reflux, the more likelihood that there is
             some serious obstruction to the fluid passage from the rest of
             the intestine  
  16: nasogastric reflux PH
           - linear
           - scale is from 0 to 14 with 7 being neutral
           - normal values are in the 3 to 4 range  
  17: rectal examination - feces
           - possible values
                1 = normal
                2 = increased
                3 = decreased
                4 = absent
           - absent feces probably indicates an obstruction  
  18: abdomen
           - possible values
                1 = normal
                2 = other
                3 = firm feces in the large intestine
                4 = distended small intestine
                5 = distended large intestine
           - 3 is probably an obstruction caused by a mechanical impaction
             and is normally treated medically
           - 4 and 5 indicate a surgical lesion  
  19: packed cell volume
           - linear
           - the # of red cells by volume in the blood
           - normal range is 30 to 50. The level rises as the circulation
             becomes compromised or as the animal becomes dehydrated.  
  20: total protein
           - linear
           - normal values lie in the 6-7.5 (gms/dL) range
           - the higher the value the greater the dehydration  
  21: abdominocentesis appearance
           - a needle is put in the horse's abdomen and fluid is obtained from
             the abdominal cavity
           - possible values:
                1 = clear
                2 = cloudy
                3 = serosanguinous
           - normal fluid is clear while cloudy or serosanguinous indicates
             a compromised gut  
  22: abdomcentesis total protein
           - linear
           - the higher the level of protein the more likely it is to have a
             compromised gut. Values are in gms/dL  
  23: outcome
           - what eventually happened to the horse?
           - possible values:
                1 = lived
                2 = died
                3 = was euthanized  
  24: surgical lesion?
           - retrospectively, was the problem (lesion) surgical?
           - all cases are either operated upon or autopsied so that
             this value and the lesion type are always known
           - possible values:
                1 = Yes
                2 = No  
  25, 26, 27: type of lesion
           - first number is site of lesion
                1 = gastric
                2 = sm intestine
                3 = lg colon
                4 = lg colon and cecum
                5 = cecum
                6 = transverse colon
                7 = retum/descending colon
                8 = uterus
                9 = bladder
                11 = all intestinal sites
                00 = none
           - second number is type
                1 = simple
                2 = strangulation
                3 = inflammation
                4 = other
           - third number is subtype
                1 = mechanical
                2 = paralytic
                0 = n/a
           - fourth number is specific code
                1 = obturation
                2 = intrinsic
                3 = extrinsic
                4 = adynamic
                5 = volvulus/torsion
                6 = intussuption
                7 = thromboembolic
                8 = hernia
                9 = lipoma/slenic incarceration
                10 = displacement
                0 = n/a
  28: cp_data
           - is pathology data present for this case?
                1 = Yes
                2 = No
           - this variable is of no significance since pathology data
             is not included or collected for these cases"
26,nursery,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Nursery Database
 
 2. Sources:
    (a) Creator: Vladislav Rajkovic et al. (13 experts)
    (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)
                Blaz Zupan      (blaz.zupan@ijs.si)
    (c) Date: June, 1997
 
 3. Past Usage:
 
    The hierarchical decision model, from which this dataset is
    derived, was first presented in 
 
    M. Olave, V. Rajkovic, M. Bohanec: An application for admission in
    public school systems. In (I. Th. M. Snellen and W. B. H. J. van de
    Donk and J.-P. Baquiast, editors) Expert Systems in Public
    Administration, pages 145-160. Elsevier Science Publishers (North
    Holland)}, 1989.
 
    Within machine-learning, this dataset was used for the evaluation
    of HINT (Hierarchy INduction Tool), which was proved to be able to
    completely reconstruct the original hierarchical model. This,
    together with a comparison with C4.5, is presented in
 
    B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by
    function decomposition. ICML-97, Nashville, TN. 1997 (to appear)
 
 4. Relevant Information Paragraph:
 
    Nursery Database was derived from a hierarchical decision model
    originally developed to rank applications for nursery schools. It
    was used during several years in 1980's when there was excessive
    enrollment to these schools in Ljubljana, Slovenia, and the
    rejected applications frequently needed an objective
    explanation. The final decision depended on three subproblems:
    occupation of parents and child's nursery, family structure and
    financial standing, and social and health picture of the family.
    The model was developed within expert system shell for decision
    making DEX (M. Bohanec, V. Rajkovic: Expert system for decision
    making. Sistemica 1(1), pp. 145-157, 1990.).
 
    The hierarchical model ranks nursery-school applications according
    to the following concept structure:
 
    NURSERY            Evaluation of applications for nursery schools
    . EMPLOY           Employment of parents and child's nursery
    . . parents        Parents' occupation
    . . has_nurs       Child's nursery
    . STRUCT_FINAN     Family structure and financial standings
    . . STRUCTURE      Family structure
    . . . form         Form of the family
    . . . children     Number of children
    . . housing        Housing conditions
    . . finance        Financial standing of the family
    . SOC_HEALTH       Social and health picture of the family
    . . social         Social conditions
    . . health         Health conditions
 
    Input attributes are printed in lowercase. Besides the target
    concept (NURSERY) the model includes four intermediate concepts:
    EMPLOY, STRUCT_FINAN, STRUCTURE, SOC_HEALTH. Every concept is in
    the original model related to its lower level descendants by a set
    of examples (for these examples sets see 
    http://www-ai.ijs.si/BlazZupan/nursery.html).
 
    The Nursery Database contains examples with the structural
    information removed, i.e., directly relates NURSERY to the eight input
    attributes: parents, has_nurs, form, children, housing, finance,
    social, health.
 
    Because of known underlying concept structure, this database may be
    particularly useful for testing constructive induction and
    structure discovery methods.
 
 5. Number of Instances: 12960
    (instances completely cover the attribute space)
 
 6. Number of Attributes: 8
 
 7. Attribute Values:
 
    parents        usual, pretentious, great_pret
    has_nurs       proper, less_proper, improper, critical, very_crit
    form           complete, completed, incomplete, foster
    children       1, 2, 3, more
    housing        convenient, less_conv, critical
    finance        convenient, inconv
    social         non-prob, slightly_prob, problematic
    health         recommended, priority, not_recom
 
 8. Missing Attribute Values: none
 
 9. Class Distribution (number of instances per class)
 
    class        N         N[%]
    ------------------------------
    not_recom    4320   (33.333 %)
    recommend       2   ( 0.015 %)
    very_recom    328   ( 2.531 %)
    priority     4266   (32.917 %)
    spec_prior   4044   (31.204 %)

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
27,colic,"**Author**: Mary McLeish & Matt Cecile, University of Guelph
Donor: Will Taylor (taylor@pluto.arc.nasa.gov)   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Horse+Colic) - 8/6/89  
**Please cite**:   

**Horse Colic database**
In this version (version 2), some features were removed. It is unclear why of how this was done."
28,optdigits,"**Author**: E. Alpaydin, C. Kaynak  
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits)  
**Please cite**: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)  

1. Title of Database: Optical Recognition of Handwritten Digits
 
 2. Source:
  E. Alpaydin, C. Kaynak
  Department of Computer Engineering
  Bogazici University, 80815 Istanbul Turkey
  alpaydin@boun.edu.tr
  July 1998
 
 3. Past Usage:
  C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their
  Applications to Handwritten Digit Recognition, 
  MSc Thesis, Institute of Graduate Studies in Science and 
  Engineering, Bogazici University.
 
  E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika,
  to appear. ftp://ftp.icsi.berkeley.edu/pub/ai/ethem/kyb.ps.Z
 
 4. Relevant Information:
  We used preprocessing programs made available by NIST to extract
  normalized bitmaps of handwritten digits from a preprinted form. From
  a total of 43 people, 30 contributed to the training set and different
  13 to the test set. 32x32 bitmaps are divided into nonoverlapping 
  blocks of 4x4 and the number of on pixels are counted in each block.
  This generates an input matrix of 8x8 where each element is an 
  integer in the range 0..16. This reduces dimensionality and gives 
  invariance to small distortions.
 
  For info on NIST preprocessing routines, see 
  M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, 
  P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based 
  Handprint Recognition System, NISTIR 5469, 1994.
 
 5. Number of Instances
  optdigits.tra Training 3823
  optdigits.tes Testing  1797
  
  The way we used the dataset was to use half of training for 
  actual training, one-fourth for validation and one-fourth
  for writer-dependent testing. The test set was used for 
  writer-independent testing and is the actual quality measure.
 
 6. Number of Attributes
  64 input+1 class attribute
 
 7. For Each Attribute:
  All input attributes are integers in the range 0..16.
  The last attribute is the class code 0..9
 
 8. Missing Attribute Values
  None
 
 9. Class Distribution
  Class: No of examples in training set
  0:  376
  1:  389
  2:  380
  3:  389
  4:  387
  5:  376
  6:  377
  7:  387
  8:  380
  9:  382
 
  Class: No of examples in testing set
  0:  178
  1:  182
  2:  177
  3:  183
  4:  181
  5:  182
  6:  181
  7:  179
  8:  174
  9:  180
 
 Accuracy on the testing set with k-nn 
 using Euclidean distance as the metric
 
  k =  1   : 98.00
  k =  2   : 97.38
  k =  3   : 97.83
  k =  4   : 97.61
  k =  5   : 97.89
  k =  6   : 97.77
  k =  7   : 97.66
  k =  8   : 97.66
  k =  9   : 97.72
  k = 10   : 97.55
  k = 11   : 97.89"
29,credit-approval,"**Author**: Confidential - Donated by Ross Quinlan   
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/credit+approval) - 1987  
**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  

**Credit Approval**
This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data.  
   
This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values."
30,page-blocks,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title of Database: Blocks Classification
 2. Sources:
    (a) Donato Malerba
        Dipartimento di Informatica
        University of Bari
        via Orabona 4
        70126 Bari - Italy
        phone: +39 - 80 - 5443269
        fax: +39 - 80 - 5443196
        malerbad@vm.csata.it
    (b) Donor: Donato Malerba
    (c) Date: July 1995
 3. Past Usage:
    This data set have been used to try different simplification methods
    for decision trees. A summary of the results can be found in:
 
    Malerba, D., Esposito, F., and Semeraro, G.
    ""A Further Comparison of Simplification Methods for Decision-Tree Induction.""
    In D. Fisher and H. Lenz (Eds.), ""Learning  from Data: 
    Artificial Intelligence and Statistics V"", Lecture Notes in Statistics,
    Springer Verlag, Berlin, 1995.
 
    The problem consists in classifying all the blocks of the page
    layout of a document that has been detected by a segmentation
    process. This is an essential step in document analysis
    in order to separate text from graphic areas. Indeed, 
    the five classes are: text (1), horizontal line (2),
    picture (3), vertical line (4) and graphic (5).
    For a detailed presentation of the problem see:
 
     Esposito F., Malerba D., & Semeraro G.
   Multistrategy Learning for Document Recognition
          Applied Artificial Intelligence, 8, pp. 33-84, 1994
 
    All instances have been personally checked so that
    low noise is present in the data.
 
 4. Relevant Information Paragraph:
 
    The 5473 examples comes from 54 distinct documents. 
    Each observation concerns one block. 
    All attributes are numeric.
    Data are in a format readable by C4.5.
 
 5. Number of Instances: 5473.
 
 6. Number of Attributes 
 
    height:   integer.         | Height of the block.
    lenght:   integer.     | Length of the block. 
    area:     integer.    | Area of the block (height * lenght);
    eccen:    continuous.  | Eccentricity of the block (lenght / height);
    p_black:  continuous.  | Percentage of black pixels within the block (blackpix / area);
    p_and:    continuous.        | Percentage of black pixels after the application of the Run Length Smoothing Algorithm (RLSA) (blackand / area);
    mean_tr:  continuous.      | Mean number of white-black transitions (blackpix / wb_trans);
    blackpix: integer.    | Total number of black pixels in the original bitmap of the block.
    blackand: integer.        | Total number of black pixels in the bitmap of the block after the RLSA.
    wb_trans: integer.          | Number of white-black transitions in the original bitmap of the block.
 
 
 
 7. Missing Attribute Values:  No missing value.
 
 8. Class Distribution: 
 
                                            Valid    Cum
    Class               Frequency  Percent  Percent  Percent
  
 text                      4913     89.8     89.8     89.8
 horiz. line                329      6.0      6.0     95.8
 graphic                     28       .5       .5     96.3
 vert. line                  88      1.6      1.6     97.9
 picture                    115      2.1      2.1    100.0
                                 -------  -------  -------
                         TOTAL      5473    100.0    100.0
 
 Summary Statistics:
 
 Variable      Mean    Std Dev   Minimum   Maximum   Correlation 
 
 HEIGHT       10.47      18.96         1       804         .3510
 LENGTH       89.57     114.72         1       553        -.0045
 AREA       1198.41    4849.38         7    143993         .2343
 ECCEN        13.75      30.70      .007    537.00         .0992
 P_BLACK        .37        .18      .052      1.00         .2130
 P_AND          .79        .17      .062      1.00        -.1771
 MEAN_TR       6.22      69.08      1.00   4955.00         .0723
 BLACKPIX    365.93    1270.33         7     33017         .1656
 BLACKAND    741.11    1881.50         7     46133         .1565
 WB_TRANS    106.66     167.31         1      3212         .0337
 

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
31,credit-g,"**Author**: Dr. Hans Hofmann  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)

**German Credit dataset**  
This dataset classifies people described by a set of attributes as good or bad credit risks.

This dataset comes with a cost matrix: 
``` 
Good  Bad (predicted)  
Good   0    1   (actual)  
Bad    5    0  
```

It is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  

### Attribute description  

1. Status of existing checking account, in Deutsche Mark.  
2. Duration in months  
3. Credit history (credits taken, paid back duly, delays, critical accounts)  
4. Purpose of the credit (car, television,...)  
5. Credit amount  
6. Status of savings account/bonds, in Deutsche Mark.  
7. Present employment, in number of years.  
8. Installment rate in percentage of disposable income  
9. Personal status (married, single,...) and sex  
10. Other debtors / guarantors  
11. Present residence since X years  
12. Property (e.g. real estate)  
13. Age in years  
14. Other installment plans (banks, stores)  
15. Housing (rent, own,...)  
16. Number of existing credits at this bank  
17. Job  
18. Number of people being liable to provide maintenance for  
19. Telephone (yes,no)  
20. Foreign worker (yes,no)"
32,pendigits,"**Author**: E. Alpaydin, Fevzi. Alimoglu  
**Source**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits)  
**Please cite**:  [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)

**Pen-Based Recognition of Handwritten Digits**  
We create a digit database by collecting 250 samples from 44 writers. The samples, written by 30 writers, are used for training, cross-validation and writer dependent testing, and the digits written by the other 14 are used for writer independent testing. This database is also available in the UNIPEN format.

We use a WACOM PL-100V pressure sensitive tablet with an integrated LCD display and a cordless stylus. The input and display areas are located in the same place. Attached to the serial port of an Intel 486 based PC, it allows us to collect handwriting samples. The tablet
sends $x$ and $y$ tablet coordinates and pressure level values of the pen at fixed time intervals (sampling rate) of 100 miliseconds. 
 
These writers are asked to write 250 digits in random order inside boxes of 500 by 500 tablet pixel resolution.  Subject are monitored only during the first entry screens. Each screen contains five boxes with the digits to be written displayed above. Subjects are told to write only inside these boxes.  If they make a mistake or are unhappy with their writing, they are instructed to clear the content of a box by using an on-screen button. The first ten digits are ignored because most writers are not familiar with this type of input devices, but subjects are not aware of this. 
 
In our study, we use only ($x, y$) coordinate information. The stylus pressure level values are ignored. First we apply normalization to make our representation invariant to translations and scale distortions. The raw data that we capture from the tablet consist of integer values between 0 and 500 (tablet input box resolution). The new coordinates are such that the coordinate which has the maximum range varies between 0 and 100. Usually $x$ stays in this range, since most characters are taller than they are wide.  

### Attribute information  

In order to train and test our classifiers, we need to represent digits as constant length feature vectors. A commonly used technique leading to good results is resampling the ( x_t, y_t) points. Temporal resampling (points regularly spaced in time) or spatial resampling (points regularly spaced in arc length) can be used here. Raw point data are already regularly spaced in time but the distance between them is variable. Previous research showed that spatial resampling to obtain a constant number of regularly spaced points on the trajectory yields much better performance, because it provides a better alignment between points. Our resampling algorithm uses simple linear interpolation between pairs of points. The resampled digits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T, regularly spaced in arc length, as opposed to the input sequence, which is regularly spaced in time.
 
So, the input vector size is 2*T, two times the number of points resampled. We considered spatial resampling to T=8,12,16 points in our experiments and found that T=8 gave the best trade-off between accuracy and complexity.
 
The way we used the dataset was to use first half of training for actual training, one-fourth for validation and one-fourth for writer-dependent testing. The test set was used for writer-independent testing and is the actual quality measure."
34,postoperative-patient-data,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Postoperative Patient Data
 
 2. Source Information:
    -- Creators: Sharon Summers, School of Nursing, University of Kansas
                 Medical Center, Kansas City, KS 66160
                 Linda Woolery, School of Nursing, University of Missouri,
                 Columbia, MO 65211
    -- Donor:    Jerzy W. Grzymala-Busse (jerzy@cs.ukans.edu) (913)864-4488
    -- Date:     June 1993
 
 3. Past Usage:
    1. A. Budihardjo, J. Grzymala-Busse, L. Woolery (1991). Program LERS_LB 2.5
       as a tool for knowledge acquisition in nursing, Proceedings of the 4th
       Int. Conference on Industrial & Engineering Applications of AI & Expert
       Systems, pp. 735-740.
 
    2. L. Woolery, J. Grzymala-Busse, S. Summers, A. Budihardjo (1991). The use
       of machine learning program LERS_LB 2.5 in knowledge acquisition for 
       expert system development in nursing. Computers in Nursing 9, pp. 227-234.
 
 4. Relevant Information:
       The classification task of this database is to determine where
       patients in a postoperative recovery area should be sent to next.  
       Because hypothermia is a significant concern after surgery
       (Woolery, L. et. al. 1991), the attributes correspond roughly to body 
       temperature measurements.
 
       Results:
       -- LERS (LEM2): 48% accuracy
 
 5. Number of Instances: 90
 
 6. Number of Attributes: 9 including the decision (class attribute)
 
 7. Attribute Information:
      1. L-CORE (patient's internal temperature in C):
               high (> 37), mid (>= 36 and <= 37), low (< 36)
      2. L-SURF (patient's surface temperature in C):
               high (> 36.5), mid (>= 36.5 and <= 35), low (< 35)
      3. L-O2 (oxygen saturation in %):
               excellent (>= 98), good (>= 90 and < 98),
               fair (>= 80 and < 90), poor (< 80)
      4. L-BP (last measurement of blood pressure):
               high (> 130/90), mid (<= 130/90 and >= 90/70), low (< 90/70)
      5. SURF-STBL (stability of patient's surface temperature):
               stable, mod-stable, unstable
      6. CORE-STBL (stability of patient's core temperature)
               stable, mod-stable, unstable
      7. BP-STBL (stability of patient's blood pressure)
               stable, mod-stable, unstable
      8. COMFORT (patient's perceived comfort at discharge, measured as
               an integer between 0 and 20)
      9. decision ADM-DECS (discharge decision):
               I (patient sent to Intensive Care Unit),
               S (patient prepared to go home),
               A (patient sent to general hospital floor)
 
 8. Missing Attribute Values:
      Attribute 8 has 3 missing values
 
 9. Class Distribution:
      I (2)
      S (24)
      A (64)
 
 
 
 

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
35,dermatology,"1. Title: Dermatology Database

2. Source Information:
   (a) Original owners:
       -- 1. Nilsel Ilter, M.D., Ph.D., 
             Gazi University, 
             School of Medicine
             06510 Ankara, Turkey
             Phone: +90 (312) 214 1080

       -- 2. H. Altay Guvenir, PhD., 
             Bilkent University,
             Department of Computer Engineering and Information Science,
             06533 Ankara, Turkey
             Phone: +90 (312) 266 4133
             Email: guvenir@cs.bilkent.edu.tr

   (b) Donor: H. Altay Guvenir,
              Bilkent University,
              Department of Computer Engineering and Information Science,
              06533 Ankara, Turkey
              Phone: +90 (312) 266 4133
              Email: guvenir@cs.bilkent.edu.tr

   (c) Date:  January, 1998

3. Past Usage:
   1. G. Demiroz, H. A. Govenir, and N. Ilter, 
      ""Learning Differential Diagnosis of Eryhemato-Squamous Diseases using
       Voting Feature Intervals"", Aritificial Intelligence in Medicine,

      The aim is to determine the type of Eryhemato-Squamous Disease.

4. Relevant Information:
     This database contains 34 attributes, 33 of which are linear
     valued and one of them is nominal. 

     The differential diagnosis of erythemato-squamous diseases is a real
     problem in dermatology. They all share the clinical features of
     erythema and scaling, with very little differences. The diseases in
     this group are psoriasis, seboreic dermatitis, lichen planus, 
     pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris.
     Usually a biopsy is necessary for the diagnosis but unfortunately
     these diseases share many histopathological features as
     well. Another difficulty for the differential diagnosis is that a
     disease may show the features of another disease at the beginning
     stage and may have the characteristic features at the following stages. 
     Patients were first evaluated clinically with 12 features.
     Afterwards, skin samples were taken for the evaluation of 22
     histopathological features. The values of the histopathological features
     are determined by an analysis of the samples under a microscope. 

     In the dataset constructed for this domain, the family history feature
     has the value 1 if any of these diseases has been observed in the
     family, and 0 otherwise. The age feature simply represents the age of
     the patient. Every other feature (clinical and histopathological) was
     given a degree in the range of 0 to 3. Here, 0 indicates that the
     feature was not present, 3 indicates the largest amount possible,
     and 1, 2 indicate the relative intermediate values.

     The names and id numbers of the patients were recently 
     removed from the database.

5. Number of Instances: 366

6. Number of Attributes: 34

7. Attribute Information:
   -- Complete attribute documentation:
      Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)
      1: erythema
      2: scaling
      3: definite borders
      4: itching
      5: koebner phenomenon
      6: polygonal papules
      7: follicular papules
      8: oral mucosal involvement
      9: knee and elbow involvement
     10: scalp involvement
     11: family history, (0 or 1)
     34: Age (linear)

     Histopathological Attributes: (take values 0, 1, 2, 3)
     12: melanin incontinence
     13: eosinophils in the infiltrate
     14: PNL infiltrate
     15: fibrosis of the papillary dermis
     16: exocytosis
     17: acanthosis
     18: hyperkeratosis
     19: parakeratosis
     20: clubbing of the rete ridges
     21: elongation of the rete ridges
     22: thinning of the suprapapillary epidermis
     23: spongiform pustule
     24: munro microabcess
     25: focal hypergranulosis
     26: disappearance of the granular layer
     27: vacuolisation and damage of basal layer
     28: spongiosis
     29: saw-tooth appearance of retes
     30: follicular horn plug
     31: perifollicular parakeratosis
     32: inflammatory monoluclear inflitrate
     33: band-like infiltrate
      
8. Missing Attribute Values: 8 (in Age attribute). Distinguished with '?'.

9. Class Distribution:
       Database:  Dermatology
       
       Class code:   Class:                  Number of instances:
       1             psoriasis			    112
       2             seboreic dermatitis             61
       3             lichen planus                   72
       4             pityriasis rosea                49
       5             cronic dermatitis               52    
       6             pityriasis rubra pilaris        20"
36,segment,"**Author**: University of Massachusetts Vision Group, Carla Brodley  
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/image+segmentation) - 1990  
**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  

**Image Segmentation Data Set**
The instances were drawn randomly from a database of 7 outdoor images. The images were hand-segmented to create a classification for every pixel. Each instance is a 3x3 region.
 
### Attribute Information  

1.  region-centroid-col:  the column of the center pixel of the region.
2.  region-centroid-row:  the row of the center pixel of the region.
3.  region-pixel-count:  the number of pixels in a region = 9.
4.  short-line-density-5:  the results of a line extractoin algorithm that 
          counts how many lines of length 5 (any orientation) with
          low contrast, less than or equal to 5, go through the region.
5.  short-line-density-2:  same as short-line-density-5 but counts lines
          of high contrast, greater than 5.
6.  vedge-mean:  measure the contrast of horizontally
          adjacent pixels in the region.  There are 6, the mean and 
          standard deviation are given.  This attribute is used as
         a vertical edge detector.
7.  vegde-sd:  (see 6)
8.  hedge-mean:  measures the contrast of vertically adjacent
           pixels. Used for horizontal line detection. 
9.  hedge-sd: (see 8).
10. intensity-mean:  the average over the region of (R + G + B)/3
11. rawred-mean: the average over the region of the R value.
12. rawblue-mean: the average over the region of the B value.
13. rawgreen-mean: the average over the region of the G value.
14. exred-mean: measure the excess red:  (2R - (G + B))
15. exblue-mean: measure the excess blue:  (2B - (G + R))
16. exgreen-mean: measure the excess green:  (2G - (R + B))
17. value-mean:  3-d nonlinear transformation
          of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals
          of Interactive Computer Graphics)
18. saturatoin-mean:  (see 17)
19. hue-mean:  (see 17)"
37,diabetes,"**Author**: [Vincent Sigillito](vgs@aplcen.apl.jhu.edu)  

**Source**: [Obtained from UCI](https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes) 

**Please cite**: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)  

1. Title: Pima Indians Diabetes Database
 
 2. Sources:
    (a) Original owners: National Institute of Diabetes and Digestive and
                         Kidney Diseases
    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)
                           Research Center, RMI Group Leader
                           Applied Physics Laboratory
                           The Johns Hopkins University
                           Johns Hopkins Road
                           Laurel, MD 20707
                           (301) 953-6231
    (c) Date received: 9 May 1990
 
 3. Past Usage:
     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., &
        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast
        the onset of diabetes mellitus.  In {it Proceedings of the Symposium
        on Computer Applications and Medical Care} (pp. 261--265).  IEEE
        Computer Society Press.
 
        The diagnostic, binary-valued variable investigated is whether the
        patient shows signs of diabetes according to World Health Organization
        criteria (i.e., if the 2 hour post-load plasma glucose was at least 
        200 mg/dl at any survey  examination or if found during routine medical
        care).   The population lives near Phoenix, Arizona, USA.
 
        Results: Their ADAP algorithm makes a real-valued prediction between
        0 and 1.  This was transformed into a binary decision using a cutoff of 
        0.448.  Using 576 training instances, the sensitivity and specificity
        of their algorithm was 76% on the remaining 192 instances.
 
 4. Relevant Information:
       Several constraints were placed on the selection of these instances from
       a larger database.  In particular, all patients here are females at
       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning
       routine that generates and executes digital analogs of perceptron-like
       devices.  It is a unique algorithm; see the paper for details.
 
 5. Number of Instances: 768
 
 6. Number of Attributes: 8 plus class 
 
 7. For Each Attribute: (all numeric-valued)
    1. Number of times pregnant
    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test
    3. Diastolic blood pressure (mm Hg)
    4. Triceps skin fold thickness (mm)
    5. 2-Hour serum insulin (mu U/ml)
    6. Body mass index (weight in kg/(height in m)^2)
    7. Diabetes pedigree function
    8. Age (years)
    9. Class variable (0 or 1)
 
 8. Missing Attribute Values: None
 
 9. Class Distribution: (class value 1 is interpreted as ""tested positive for
    diabetes"")
 
    Class Value  Number of instances
    0            500
    1            268
 
 10. Brief statistical analysis:
 
     Attribute number:    Mean:   Standard Deviation:
     1.                     3.8     3.4
     2.                   120.9    32.0
     3.                    69.1    19.4
     4.                    20.5    16.0
     5.                    79.8   115.2
     6.                    32.0     7.9
     7.                     0.5     0.3
     8.                    33.2    11.8
 
 




 Relabeled values in attribute 'class'
    From: 0                       To: tested_negative     
    From: 1                       To: tested_positive"
38,sick,"**Author**: Ross Quinlan
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/thyroid+disease)   
**Please cite**: Thyroid disease records supplied by the Garavan Institute and J. Ross Quinlan, New South Wales Institute, Syndney, Australia. 1987.

Attribute information:

```
sick, negative.   |  classes

age:    continuous.
sex:    M, F.
on thyroxine:   f, t.
query on thyroxine:  f, t.
on antithyroid medication: f, t.
sick:    f, t.
pregnant:   f, t.
thyroid surgery:  f, t.
I131 treatment:   f, t.
query hypothyroid:  f, t.
query hyperthyroid:  f, t.
lithium:   f, t.
goitre:    f, t.
tumor:    f, t.
hypopituitary:   f, t.
psych:    f, t.
TSH measured:   f, t.
TSH:    continuous.
T3 measured:   f, t.
T3:    continuous.
TT4 measured:   f, t.
TT4:    continuous.
T4U measured:   f, t.
T4U:    continuous.
FTI measured:   f, t.
FTI:    continuous.
TBG measured:   f, t.
TBG:    continuous.
referral source:  WEST, STMW, SVHC, SVI, SVHD, other.
```

``` 
 Num Instances:     3772
 Num Attributes:    30
 Num Continuous:    7 (Int 1 / Real 6)
 Num Discrete:      23
 Missing values:    6064 /  5.4%
```

```
     name                      type enum ints real     missing    distinct  (1)
   1 'age'                     Int    0% 100%   0%     1 /  0%    93 /  2%   0% 
   2 'sex'                     Enum  96%   0%   0%   150 /  4%     2 /  0%   0% 
   3 'on thyroxine'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   4 'query on thyroxine'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   5 'on antithyroid medicati  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   6 'sick'                    Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   7 'pregnant'                Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   8 'thyroid surgery'         Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   9 'I131 treatment'          Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  10 'query hypothyroid'       Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  11 'query hyperthyroid'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  12 'lithium'                 Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  13 'goitre'                  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  14 'tumor'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  15 'hypopituitary'           Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  16 'psych'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  17 'TSH measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  18 'TSH'                     Real   0%  11%  79%   369 / 10%   287 /  8%   2% 
  19 'T3 measured'             Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  20 'T3'                      Real   0%   9%  71%   769 / 20%    69 /  2%   0% 
  21 'TT4 measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  22 'TT4'                     Real   0%  94%   0%   231 /  6%   241 /  6%   1% 
  23 'T4U measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  24 'T4U'                     Real   0%   2%  87%   387 / 10%   146 /  4%   1% 
  25 'FTI measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  26 'FTI'                     Real   0%  90%   0%   385 / 10%   234 /  6%   2% 
  27 'TBG measured'            Enum 100%   0%   0%     0 /  0%     1 /  0%   0% 
  28 'TBG'                     Real   0%   0%   0%  3772 /100%     0 /  0%   0% 
  29 'referral source'         Enum 100%   0%   0%     0 /  0%     5 /  0%   0% 
  30 'Class'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0%
```"
39,ecoli,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Protein Localization Sites
 
 
 2. Creator and Maintainer:
 	     Kenta Nakai
              Institue of Molecular and Cellular Biology
 	     Osaka, University
 	     1-3 Yamada-oka, Suita 565 Japan
 	     nakai@imcb.osaka-u.ac.jp
              http://www.imcb.osaka-u.ac.jp/nakai/psort.html
    Donor: Paul Horton (paulh@cs.berkeley.edu)
    Date:  September, 1996
    See also: yeast database
 
 3. Past Usage.
 Reference: ""A Probablistic Classification System for Predicting the Cellular 
            Localization Sites of Proteins"", Paul Horton & Kenta Nakai,
            Intelligent Systems in Molecular Biology, 109-115.
 	   St. Louis, USA 1996.
 Results: 81% for E.coli with an ad hoc structured
 	 probability model. Also similar accuracy for Binary Decision Tree and
 	 Bayesian Classifier methods applied by the same authors in
 	 unpublished results.
 
 Predicted Attribute: Localization site of protein. ( non-numeric ).
 
 
 4. The references below describe a predecessor to this dataset and its 
 development. They also give results (not cross-validated) for classification 
 by a rule-based expert system with that version of the dataset.
 
 Reference: ""Expert Sytem for Predicting Protein Localization Sites in 
            Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  
            PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.
 
 Reference: ""A Knowledge Base for Predicting Protein Localization Sites in
 	   Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, 
 	   Genomics 14:897-911, 1992.
 
 
 5. Number of Instances:  336 for the E.coli dataset and 
 
 
 6. Number of Attributes.
          for E.coli dataset:  8 ( 7 predictive, 1 name )
 	     
 7. Attribute Information.
 
   1.  Sequence Name: Accession number for the SWISS-PROT database
   2.  mcg: McGeoch's method for signal sequence recognition.
   3.  gvh: von Heijne's method for signal sequence recognition.
   4.  lip: von Heijne's Signal Peptidase II consensus sequence score.
            Binary attribute.
   5.  chg: Presence of charge on N-terminus of predicted lipoproteins.
 	   Binary attribute.
   6.  aac: score of discriminant analysis of the amino acid content of
 	   outer membrane and periplasmic proteins.
   7. alm1: score of the ALOM membrane spanning region prediction program.
   8. alm2: score of ALOM program after excluding putative cleavable signal
 	   regions from the sequence.
 
 NOTE - the sequence name has been removed
 
 8. Missing Attribute Values: None.
 
 
 9. Class Distribution. The class is the localization site. Please see Nakai &
 		       Kanehisa referenced above for more details.
 
   cp  (cytoplasm)                                    143
   im  (inner membrane without signal sequence)        77               
   pp  (perisplasm)                                    52
   imU (inner membrane, uncleavable signal sequence)   35
   om  (outer membrane)                                20
   omL (outer membrane lipoprotein)                     5
   imL (inner membrane lipoprotein)                     2
   imS (inner membrane, cleavable signal sequence)      2"
40,sonar,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

NAME: Sonar, Mines vs. Rocks
 
 SUMMARY: This is the data set used by Gorman and Sejnowski in their study
 of the classification of sonar signals using a neural network [1].  The
 task is to train a network to discriminate between sonar signals bounced
 off a metal cylinder and those bounced off a roughly cylindrical rock.
 
 SOURCE: The data set was contributed to the benchmark collection by Terry
 Sejnowski, now at the Salk Institute and the University of California at
 San Deigo.  The data set was developed in collaboration with R. Paul
 Gorman of Allied-Signal Aerospace Technology Center.
 
 MAINTAINER: Scott E. Fahlman
 
 PROBLEM DESCRIPTION:
 
 The file ""sonar.mines"" contains 111 patterns obtained by bouncing sonar
 signals off a metal cylinder at various angles and under various
 conditions.  The file ""sonar.rocks"" contains 97 patterns obtained from
 rocks under similar conditions.  The transmitted sonar signal is a
 frequency-modulated chirp, rising in frequency.  The data set contains
 signals obtained from a variety of different aspect angles, spanning 90
 degrees for the cylinder and 180 degrees for the rock.
 
 Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number
 represents the energy within a particular frequency band, integrated over
 a certain period of time.  The integration aperture for higher frequencies
 occur later in time, since these frequencies are transmitted later during
 the chirp.
 
 The label associated with each record contains the letter ""R"" if the object
 is a rock and ""M"" if it is a mine (metal cylinder).  The numbers in the
 labels are in increasing order of aspect angle, but they do not encode the
 angle directly.
 
 METHODOLOGY: 
 
 This data set can be used in a number of different ways to test learning
 speed, quality of ultimate learning, ability to generalize, or combinations
 of these factors.
 
 In [1], Gorman and Sejnowski report two series of experiments: an
 ""aspect-angle independent"" series, in which the whole data set is used
 without controlling for aspect angle, and an ""aspect-angle dependent""
 series in which the training and testing sets were carefully controlled to
 ensure that each set contained cases from each aspect angle in
 appropriate proportions.
 
 For the aspect-angle independent experiments the combined set of 208 cases
 is divided randomly into 13 disjoint sets with 16 cases in each.  For each
 experiment, 12 of these sets are used as training data, while the 13th is
 reserved for testing.  The experiment is repeated 13 times so that every
 case appears once as part of a test set.  The reported performance is an
 average over the entire set of 13 different test sets, each run 10 times.
 
 It was observed that this random division of the sample set led to rather
 uneven performance.  A few of the splits gave poor results, presumably
 because the test set contains some samples from aspect angles that are
 under-represented in the corresponding training set.  This motivated Gorman
 and Sejnowski to devise a different set of experiments in which an attempt
 was made to balance the training and test sets so that each would have a
 representative number of samples from all aspect angles.  Since detailed
 aspect angle information was not present in the data base of samples, the
 208 samples were first divided into clusters, using a 60-dimensional
 Euclidian metric; each of these clusters was then divided between the
 104-member training set and the 104-member test set.  
 
 The actual training and testing samples used for the ""aspect angle
 dependent"" experiments are marked in the data files.  The reported
 performance is an average over 10 runs with this single division of the
 data set.
 
 A standard back-propagation network was used for all experiments.  The
 network had 60 inputs and 2 output units, one indicating a cylinder and the
 other a rock.  Experiments were run with no hidden units (direct
 connections from each input to each output) and with a single hidden layer
 with 2, 3, 6, 12, or 24 units.  Each network was trained by 300 epochs over
 the entire training set.
 
 The weight-update formulas used in this study were slightly different from
 the standard form.  A learning rate of 2.0 and momentum of 0.0 was used.
 Errors less than 0.2 were treated as zero.  Initial weights were uniform
 random values in the range -0.3 to +0.3.
 
 RESULTS: 
 
 For the angle independent experiments, Gorman and Sejnowski report the
 following results for networks with different numbers of hidden units:
 
 Hidden	% Right on	Std.	% Right on	Std.
 Units	Training set	Dev.	Test Set	Dev.
 ------	------------	----	----------	----
 0	89.4		2.1	77.1		8.3
 2	96.5		0.7	81.9		6.2
 3	98.8		0.4	82.0		7.3
 6	99.7		0.2	83.5		5.6
 12	99.8		0.1	84.7		5.7
 24	99.8		0.1	84.5		5.7
 
 For the angle-dependent experiments Gorman and Sejnowski report the
 following results:
 
 Hidden	% Right on	Std.	% Right on	Std.
 Units	Training set	Dev.	Test Set	Dev.
 ------	------------	----	----------	----
 0	79.3		3.4	73.1		4.8
 2	96.2		2.2	85.7		6.3
 3	98.1		1.5	87.6		3.0
 6	99.4		0.9	89.3		2.4
 12	99.8		0.6	90.4		1.8
 24     100.0		0.0	89.2		1.4
 
 Not surprisingly, the network's performance on the test set was somewhat
 better when the aspect angles in the training and test sets were balanced.
 
 Gorman and Sejnowski further report that a nearest neighbor classifier on
 the same data gave an 82.7% probability of correct classification.
 
 Three trained human subjects were each tested on 100 signals, chosen at
 random from the set of 208 returns used to create this data set.  Their
 responses ranged between 88% and 97% correct.  However, they may have been
 using information from the raw sonar signal that is not preserved in the
 processed data sets presented here.
 
 REFERENCES: 
 
 1. Gorman, R. P., and Sejnowski, T. J. (1988).  ""Analysis of Hidden Units
 in a Layered Network Trained to Classify Sonar Targets"" in Neural Networks,
 Vol. 1, pp. 75-89.




 Relabeled values in attribute 'Class'
    From: R                       To: Rock                
    From: M                       To: Mine"
41,glass,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Glass Identification Database
 
 2. Sources:
     (a) Creator: B. German
         -- Central Research Establishment
            Home Office Forensic Science Service
            Aldermaston, Reading, Berkshire RG7 4PN
     (b) Donor: Vina Spiehler, Ph.D., DABFT
                Diagnostic Products Corporation
                (213) 776-0180 (ext 3014)
     (c) Date: September, 1987
 
 3. Past Usage:
     -- Rule Induction in Forensic Science
        -- Ian W. Evett and Ernest J. Spiehler
        -- Central Research Establishment
           Home Office Forensic Science Service
           Aldermaston, Reading, Berkshire RG7 4PN
        -- Unknown technical note number (sorry, not listed here)
        -- General Results: nearest neighbor held its own with respect to the
              rule-based system
 
 4. Relevant Information:n
       Vina conducted a comparison test of her rule-based system, BEAGLE, the
       nearest-neighbor algorithm, and discriminant analysis.  BEAGLE is 
       a product available through VRS Consulting, Inc.; 4676 Admiralty Way,
       Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189.
       In determining whether the glass was a type of ""float"" glass or not,
       the following results were obtained (# incorrect answers):
 
              Type of Sample                            Beagle   NN    DA
              Windows that were float processed (87)     10      12    21
              Windows that were not:            (76)     19      16    22
 
       The study of classification of types of glass was motivated by 
       criminological investigation.  At the scene of the crime, the glass left
       can be used as evidence...if it is correctly identified!
 
 5. Number of Instances: 214
 
 6. Number of Attributes: 10 (including an Id#) plus the class attribute
    -- all attributes are continuously valued
 
 7. Attribute Information:
    1. Id number: 1 to 214
    2. RI: refractive index
    3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as 
                   are attributes 4-10)
    4. Mg: Magnesium
    5. Al: Aluminum
    6. Si: Silicon
    7. K: Potassium
    8. Ca: Calcium
    9. Ba: Barium
   10. Fe: Iron
   11. Type of glass: (class attribute)
       -- 1 building_windows_float_processed
       -- 2 building_windows_non_float_processed
       -- 3 vehicle_windows_float_processed
       -- 4 vehicle_windows_non_float_processed (none in this database)
       -- 5 containers
       -- 6 tableware
       -- 7 headlamps
 
 8. Missing Attribute Values: None
 
 Summary Statistics:
 Attribute:   Min     Max      Mean     SD      Correlation with class
  2. RI:       1.5112  1.5339   1.5184  0.0030  -0.1642
  3. Na:      10.73   17.38    13.4079  0.8166   0.5030
  4. Mg:       0       4.49     2.6845  1.4424  -0.7447
  5. Al:       0.29    3.5      1.4449  0.4993   0.5988
  6. Si:      69.81   75.41    72.6509  0.7745   0.1515
  7. K:        0       6.21     0.4971  0.6522  -0.0100
  8. Ca:       5.43   16.19     8.9570  1.4232   0.0007
  9. Ba:       0       3.15     0.1750  0.4972   0.5751
 10. Fe:       0       0.51     0.0570  0.0974  -0.1879
 
 9. Class Distribution: (out of 214 total instances)
     -- 163 Window glass (building windows and vehicle windows)
        -- 87 float processed  
           -- 70 building windows
           -- 17 vehicle windows
        -- 76 non-float processed
           -- 76 building windows
           -- 0 vehicle windows
     -- 51 Non-window glass
        -- 13 containers
        -- 9 tableware
        -- 29 headlamps
 
 
 




 Relabeled values in attribute 'Type'
    From: '1'                     To: 'build wind float'    
    From: '2'                     To: 'build wind non-float'
    From: '3'                     To: 'vehic wind float'    
    From: '4'                     To: 'vehic wind non-float'
    From: '5'                     To: containers          
    From: '6'                     To: tableware           
    From: '7'                     To: headlamps"
42,soybean,"**Author**: R.S. Michalski and R.L. Chilausky (Donors: Ming Tan & Jeff Schlimmer)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Soybean+(Large)) - 1988  
**Please cite**: R.S. Michalski and R.L. Chilausky ""Learning by Being Told and Learning from Examples: An Experimental Comparison of the Two Methods of Knowledge Acquisition in the Context of Developing an Expert System for Soybean Disease Diagnosis"", International Journal of Policy Analysis and Information Systems, Vol. 4, No. 2, 1980.  

**Large Soybean Database**  
This is the large soybean database from the UCI repository, with its training and test database combined into a single file. 

There are 19 classes, only the first 15 of which have been used in prior work. The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered. The value 'dna' means does not apply. The values for attributes are encoded numerically, with the first value encoded as ""0,'' the second as ""1,'' and so forth. An unknown value is encoded as ""?''.

### Attribute Information

1. date: april,may,june,july,august,september,october,?. 
2. plant-stand: normal,lt-normal,?. 
3. precip: lt-norm,norm,gt-norm,?. 
4. temp: lt-norm,norm,gt-norm,?. 
5. hail: yes,no,?. 
6. crop-hist: diff-lst-year,same-lst-yr,same-lst-two-yrs, 
same-lst-sev-yrs,?. 
7. area-damaged: scattered,low-areas,upper-areas,whole-field,?. 
8. severity: minor,pot-severe,severe,?. 
9. seed-tmt: none,fungicide,other,?. 
10. germination: 90-100%,80-89%,lt-80%,?. 
11. plant-growth: norm,abnorm,?. 
12. leaves: norm,abnorm. 
13. leafspots-halo: absent,yellow-halos,no-yellow-halos,?. 
14. leafspots-marg: w-s-marg,no-w-s-marg,dna,?. 
15. leafspot-size: lt-1/8,gt-1/8,dna,?. 
16. leaf-shread: absent,present,?. 
17. leaf-malf: absent,present,?. 
18. leaf-mild: absent,upper-surf,lower-surf,?. 
19. stem: norm,abnorm,?. 
20. lodging: yes,no,?. 
21. stem-cankers: absent,below-soil,above-soil,above-sec-nde,?. 
22. canker-lesion: dna,brown,dk-brown-blk,tan,?. 
23. fruiting-bodies: absent,present,?. 
24. external decay: absent,firm-and-dry,watery,?. 
25. mycelium: absent,present,?. 
26. int-discolor: none,brown,black,?. 
27. sclerotia: absent,present,?. 
28. fruit-pods: norm,diseased,few-present,dna,?. 
29. fruit spots: absent,colored,brown-w/blk-specks,distort,dna,?. 
30. seed: norm,abnorm,?. 
31. mold-growth: absent,present,?. 
32. seed-discolor: absent,present,?. 
33. seed-size: norm,lt-norm,?. 
34. shriveling: absent,present,?. 
35. roots: norm,rotted,galls-cysts,?.

### Classes 

-- 19 Classes = {diaporthe-stem-canker, charcoal-rot, rhizoctonia-root-rot, phytophthora-rot, brown-stem-rot, powdery-mildew, downy-mildew, brown-spot, bacterial-blight, bacterial-pustule, purple-seed-stain, anthracnose, phyllosticta-leaf-spot, alternarialeaf-spot, frog-eye-leaf-spot, diaporthe-pod-&-stem-blight, cyst-nematode, 2-4-d-injury, herbicide-injury} 

### Revelant papers

Tan, M., & Eshelman, L. (1988). Using weighted networks to represent classification knowledge in noisy domains. Proceedings of the Fifth International Conference on Machine Learning (pp. 121-134). Ann Arbor, Michigan: Morgan Kaufmann. 

Fisher,D.H. & Schlimmer,J.C. (1988). Concept Simplification and Predictive Accuracy. Proceedings of the Fifth International Conference on Machine Learning (pp. 22-28). Ann Arbor, Michigan: Morgan Kaufmann."
43,haberman,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Haberman's Survival Data
 
 2. Sources:
    (a) Donor:   Tjen-Sien Lim (limt@stat.wisc.edu)
    (b) Date:    March 4, 1999
 
 3. Past Usage:
    1. Haberman, S. J. (1976). Generalized Residuals for Log-Linear
       Models, Proceedings of the 9th International Biometrics
       Conference, Boston, pp. 104-122.
    2. Landwehr, J. M., Pregibon, D., and Shoemaker, A. C. (1984),
       Graphical Models for Assessing Logistic Regression Models (with
       discussion), Journal of the American Statistical Association 79:
       61-83.
    3. Lo, W.-D. (1993). Logistic Regression Trees, PhD thesis,
       Department of Statistics, University of Wisconsin, Madison, WI.
 
 4. Relevant Information:
    The dataset contains cases from a study that was conducted between
    1958 and 1970 at the University of Chicago's Billings Hospital on
    the survival of patients who had undergone surgery for breast
    cancer.
 
 5. Number of Instances: 306
 
 6. Number of Attributes: 4 (including the class attribute)
 
 7. Attribute Information:
    1. Age of patient at time of operation (numerical)
    2. Patient's year of operation (year - 1900, numerical)
    3. Number of positive axillary nodes detected (numerical)
    4. Survival status (class attribute)
          1 = the patient survived 5 years or longer
          2 = the patient died within 5 year
 
 8. Missing Attribute Values: None

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
44,spambase,"**Author**: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt    
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/spambase)   
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)

SPAM E-mail Database  
The ""spam"" concept is diverse: advertisements for products/websites, make money fast schemes, chain letters, pornography... Our collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.
 
For background on spam:  
Cranor, Lorrie F., LaMacchia, Brian A.  Spam! Communications of the ACM, 41(8):74-83, 1998.  

### Attribute Information:  
The last column denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occurring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  

For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes:  

48 continuous real [0,100] attributes of type  
word_freq_WORD = percentage of words in the e-mail that match WORD,  i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A ""word"" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.
 
6 continuous real [0,100] attributes of type char_freq_CHAR = percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail
 
1 continuous real [1,...] attribute of type capital_run_length_average
 = average length of uninterrupted sequences of capital letters
 
1 continuous integer [1,...] attribute of type capital_run_length_longest
 = length of longest uninterrupted sequence of capital letters
 
1 continuous integer [1,...] attribute of type capital_run_length_total
 = sum of length of uninterrupted sequences of capital letters
 = total number of capital letters in the e-mail
 
1 nominal {0,1} class attribute of type spam
 = denotes whether the e-mail was considered spam (1) or not (0), 
 i.e. unsolicited commercial e-mail."
46,splice,"**Author**: Genbank. Donated by G. Towell, M. Noordewier, and J. Shavlik  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+(Splice-junction+Gene+Sequences))   
**Please cite**:  None  

Primate splice-junction gene sequences (DNA) with associated imperfect domain theory.
Splice junctions are points on a DNA sequence at which 'superfluous' DNA is removed during the process of protein creation in higher organisms. The problem posed in this dataset is to recognize, given a sequence of DNA, the boundaries between exons (the parts of the DNA sequence retained after splicing) and introns (the parts of the DNA sequence that are spliced out). This problem consists of two subtasks: recognizing exon/intron boundaries (referred to as EI sites), and recognizing intron/exon boundaries (IE sites). (In the biological community, IE borders are referred to a ''acceptors'' while EI borders are referred to as ''donors''.)

All examples taken from Genbank 64.1. Categories ""ei"" and ""ie"" include every ""split-gene"" for primates in Genbank 64.1. Non-splice examples taken from sequences known not to include a splicing site.
         
### Attribute Information 
>
              1   One of {n ei ie}, indicating the class.
              2   The instance name.
           3-62   The remaining 60 fields are the sequence, starting at 
                  position -30 and ending at position +30. Each of
                  these fields is almost always filled by one of 
                  {a, g, t, c}. Other characters indicate ambiguity among
                  the standard characters according to the following table:
    character: meaning
        D: A or G or T
        N: A or G or C or T
        S: C or G
        R: A or G

Notes:  
* Instance_name is an identifier and should be ignored for modelling"
48,tae,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Teaching Assistant Evaluation
 
 2. Sources:
    (a) Collector: Wei-Yin Loh (Department of Statistics, UW-Madison)
    (b) Donor:     Tjen-Sien Lim (limt@stat.wisc.edu)
    (b) Date:      June 7, 1997
 
 3. Past Usage:
    1. Loh, W.-Y. & Shih, Y.-S. (1997). Split Selection Methods for 
       Classification Trees, Statistica Sinica 7: 815-840.
    2. Lim, T.-S., Loh, W.-Y. & Shih, Y.-S. (1999). A Comparison of
       Prediction Accuracy, Complexity, and Training Time of
       Thirty-three Old and New Classification Algorithms. Machine
       Learning. Forthcoming.
       (ftp://ftp.stat.wisc.edu/pub/loh/treeprogs/quest1.7/mach1317.pdf or
       (http://www.stat.wisc.edu/~limt/mach1317.pdf)
 
 4. Relevant Information:
    The data consist of evaluations of teaching performance over three
    regular semesters and two summer semesters of 151 teaching assistant
    (TA) assignments at the Statistics Department of the University of
    Wisconsin-Madison. The scores were divided into 3 roughly equal-sized
    categories (""low"", ""medium"", and ""high"") to form the class variable.
 
 5. Number of Instances: 151
 
 6. Number of Attributes: 6 (including the class attribute)
 
 7. Attribute Information:
   
    1. Whether of not the TA is a native English speaker (binary)
       1=English speaker, 2=non-English speaker
    2. Course instructor (categorical, 25 categories)
    3. Course (categorical, 26 categories)
    4. Summer or regular semester (binary) 1=Summer, 2=Regular
    5. Class size (numerical)
    6. Class attribute (categorical) 1=Low, 2=Medium, 3=High
 
 8. Missing Attribute Values: None

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
49,heart-c,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Publication Request: 
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    This file describes the contents of the heart-disease directory.
 
    This directory contains 4 databases concerning heart disease diagnosis.
    All attributes are numeric-valued.  The data was collected from the
    four following locations:
 
      1. Cleveland Clinic Foundation (cleveland.data)
      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)
      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)
      4. University Hospital, Zurich, Switzerland (switzerland.data)
 
    Each database has the same instance format.  While the databases have 76
    raw attributes, only 14 of them are actually used.  Thus I've taken the
    liberty of making 2 copies of each database: one with all the attributes
    and 1 with the 14 attributes actually used in past experiments.
 
    The authors of the databases have requested:
 
       ...that any publications resulting from the use of the data include the 
       names of the principal investigator responsible for the data collection
       at each institution.  They would be:
 
        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
           Robert Detrano, M.D., Ph.D.
 
    Thanks in advance for abiding by this request.
 
    David Aha
    July 22, 1988
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
 
 1. Title: Heart Disease Databases
 
 2. Source Information:
    (a) Creators: 
        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
              Robert Detrano, M.D., Ph.D.
    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   
    (c) Date: July, 1988
 
 3. Past Usage:
     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,
        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it 
        International application of a new probability algorithm for the 
        diagnosis of coronary artery disease.}  {it American Journal of 
        Cardiology}, {it 64},304--310.
        -- International Probability Analysis 
        -- Address: Robert Detrano, M.D.
                    Cardiology 111-C
                    V.A. Medical Center
                    5901 E. 7th Street
                    Long Beach, CA 90028
        -- Results in percent accuracy: (for 0.5 probability threshold)
              Data Name:  CDF    CADENZA
           -- Hungarian   77     74
              Long beach  79     77
              Swiss       81     81
           -- Approximately a 77% correct classification accuracy with a
              logistic-regression-derived discriminant function
     2. David W. Aha & Dennis Kibler
        -- 
           
           
           -- Instance-based prediction of heart-disease presence with the 
              Cleveland database
              -- NTgrowth: 77.0% accuracy
              --       C4: 74.8% accuracy
     3. John Gennari
        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of
           incremental concept formation. {it Artificial Intelligence, 40},
           11--61.
        -- Results: 
           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy
              on the Cleveland database.
 
 4. Relevant Information:
      This database contains 76 attributes, but all published experiments
      refer to using a subset of 14 of them.  In particular, the Cleveland
      database is the only one that has been used by ML researchers to 
      this date.  The ""goal"" field refers to the presence of heart disease
      in the patient.  It is integer valued from 0 (no presence) to 4.
      Experiments with the Cleveland database have concentrated on simply
      attempting to distinguish presence (values 1,2,3,4) from absence (value
      0).  
    
      The names and social security numbers of the patients were recently 
      removed from the database, replaced with dummy values.
 
      One file has been ""processed"", that one containing the Cleveland 
      database.  All four unprocessed files also exist in this directory.
     
 5. Number of Instances: 
         Database:    # of instances:
           Cleveland: 303
           Hungarian: 294
         Switzerland: 123
       Long Beach VA: 200
 
 6. Number of Attributes: 76 (including the predicted attribute)
 
 7. Attribute Information:
    -- Only 14 used
       -- 1. #3  (age)       
       -- 2. #4  (sex)       
       -- 3. #9  (cp)        
       -- 4. #10 (trestbps)  
       -- 5. #12 (chol)      
       -- 6. #16 (fbs)       
       -- 7. #19 (restecg)   
       -- 8. #32 (thalach)   
       -- 9. #38 (exang)     
       -- 10. #40 (oldpeak)   
       -- 11. #41 (slope)     
       -- 12. #44 (ca)        
       -- 13. #51 (thal)      
       -- 14. #58 (num)       (the predicted attribute)
 
    -- Complete attribute documentation:
       1 id: patient identification number
       2 ccf: social security number (I replaced this with a dummy value of 0)
       3 age: age in years
       4 sex: sex (1 = male; 0 = female)
       5 painloc: chest pain location (1 = substernal; 0 = otherwise)
       6 painexer (1 = provoked by exertion; 0 = otherwise)
       7 relrest (1 = relieved after rest; 0 = otherwise)
       8 pncaden (sum of 5, 6, and 7)
       9 cp: chest pain type
         -- Value 1: typical angina
         -- Value 2: atypical angina
         -- Value 3: non-anginal pain
         -- Value 4: asymptomatic
      10 trestbps: resting blood pressure (in mm Hg on admission to the 
         hospital)
      11 htn
      12 chol: serum cholestoral in mg/dl
      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
      14 cigs (cigarettes per day)
      15 years (number of years as a smoker)
      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)
      17 dm (1 = history of diabetes; 0 = no such history)
      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
      19 restecg: resting electrocardiographic results
         -- Value 0: normal
         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST 
                     elevation or depression of > 0.05 mV)
         -- Value 2: showing probable or definite left ventricular hypertrophy
                     by Estes' criteria
      20 ekgmo (month of exercise ECG reading)
      21 ekgday(day of exercise ECG reading)
      22 ekgyr (year of exercise ECG reading)
      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
      28 proto: exercise protocol
           1 = Bruce     
           2 = Kottus
           3 = McHenry
           4 = fast Balke
           5 = Balke
           6 = Noughton 
           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was 
               written!)
           8 = bike 125 kpa min/min  
           9 = bike 100 kpa min/min
          10 = bike 75 kpa min/min
          11 = bike 50 kpa min/min
          12 = arm ergometer
      29 thaldur: duration of exercise test in minutes
      30 thaltime: time when ST measure depression was noted
      31 met: mets achieved
      32 thalach: maximum heart rate achieved
      33 thalrest: resting heart rate
      34 tpeakbps: peak exercise blood pressure (first of 2 parts)
      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
      36 dummy
      37 trestbpd: resting blood pressure
      38 exang: exercise induced angina (1 = yes; 0 = no)
      39 xhypo: (1 = yes; 0 = no)
      40 oldpeak = ST depression induced by exercise relative to rest
      41 slope: the slope of the peak exercise ST segment
         -- Value 1: upsloping
         -- Value 2: flat
         -- Value 3: downsloping
      42 rldv5: height at rest
      43 rldv5e: height at peak exercise
      44 ca: number of major vessels (0-3) colored by flourosopy
      45 restckm: irrelevant
      46 exerckm: irrelevant
      47 restef: rest raidonuclid (sp?) ejection fraction
      48 restwm: rest wall (sp?) motion abnormality
         0 = none
         1 = mild or moderate
         2 = moderate or severe
         3 = akinesis or dyskmem (sp?)
      49 exeref: exercise radinalid (sp?) ejection fraction
      50 exerwm: exercise wall (sp?) motion 
      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
      52 thalsev: not used
      53 thalpul: not used
      54 earlobe: not used
      55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")
      56 cday: day of cardiac cath (sp?)
      57 cyr: year of cardiac cath (sp?)
      58 num: diagnosis of heart disease (angiographic disease status)
         -- Value 0: < 50% diameter narrowing
         -- Value 1: > 50% diameter narrowing
         (in any major vessel: attributes 59 through 68 are vessels)
      59 lmt
      60 ladprox
      61 laddist
      62 diag
      63 cxmain
      64 ramus
      65 om1
      66 om2
      67 rcaprox
      68 rcadist
      69 lvx1: not used
      70 lvx2: not used
      71 lvx3: not used
      72 lvx4: not used
      73 lvf: not used
      74 cathef: not used
      75 junk: not used
      76 name: last name of patient 
         (I replaced this with the dummy string ""name"")
 
 9. Missing Attribute Values: Several.  Distinguished with value -9.0.
 
 10. Class Distribution:
         Database:      0   1   2   3   4 Total
           Cleveland: 164  55  36  35  13   303
           Hungarian: 188  37  26  28  15   294
         Switzerland:   8  48  32  30   5   123
       Long Beach VA:  51  56  41  42  10   200

 'slope' is ordered




 Relabeled values in attribute 'sex'
    From: 0                       To: female              
    From: 1                       To: male                


 Relabeled values in attribute 'cp'
    From: 1                       To: typ_angina          
    From: 4                       To: asympt              
    From: 3                       To: non_anginal         
    From: 2                       To: atyp_angina         


 Relabeled values in attribute 'fbs'
    From: 1                       To: t                   
    From: 0                       To: f                   


 Relabeled values in attribute 'restecg'
    From: 2                       To: left_vent_hyper     
    From: 0                       To: normal              
    From: 1                       To: st_t_wave_abnormality


 Relabeled values in attribute 'exang'
    From: 0                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute 'slope'
    From: 1                       To: up                  
    From: 2                       To: flat                
    From: 3                       To: down                


 Relabeled values in attribute 'thal'
    From: 6                       To: fixed_defect        
    From: 3                       To: normal              
    From: 7                       To: reversable_defect   


 Relabeled values in attribute 'num'
    From: '0'                     To: '<50'               
    From: '1'                     To: '>50_1'             
    From: '2'                     To: '>50_2'             
    From: '3'                     To: '>50_3'             
    From: '4'                     To: '>50_4'"
50,tic-tac-toe,"**Author**: David W. Aha    
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) - 1991   
**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)

**Tic-Tac-Toe Endgame database**  
This database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where ""x"" is assumed to have played first.  The target concept is ""win for x"" (i.e., true when ""x"" has one of 8 possible ways to create a ""three-in-a-row"").  

### Attribute Information  

     (x=player x has taken, o=player o has taken, b=blank)
     1. top-left-square: {x,o,b}
     2. top-middle-square: {x,o,b}
     3. top-right-square: {x,o,b}
     4. middle-left-square: {x,o,b}
     5. middle-middle-square: {x,o,b}
     6. middle-right-square: {x,o,b}
     7. bottom-left-square: {x,o,b}
     8. bottom-middle-square: {x,o,b}
     9. bottom-right-square: {x,o,b}
    10. Class: {positive,negative}"
51,heart-h,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Publication Request: 
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    This file describes the contents of the heart-disease directory.
 
    This directory contains 4 databases concerning heart disease diagnosis.
    All attributes are numeric-valued.  The data was collected from the
    four following locations:
 
      1. Cleveland Clinic Foundation (cleveland.data)
      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)
      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)
      4. University Hospital, Zurich, Switzerland (switzerland.data)
 
    Each database has the same instance format.  While the databases have 76
    raw attributes, only 14 of them are actually used.  Thus I've taken the
    liberty of making 2 copies of each database: one with all the attributes
    and 1 with the 14 attributes actually used in past experiments.
 
    The authors of the databases have requested:
 
       ...that any publications resulting from the use of the data include the 
       names of the principal investigator responsible for the data collection
       at each institution.  They would be:
 
        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
           Robert Detrano, M.D., Ph.D.
 
    Thanks in advance for abiding by this request.
 
    David Aha
    July 22, 1988
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
 
 1. Title: Heart Disease Databases
 
 2. Source Information:
    (a) Creators: 
        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
              Robert Detrano, M.D., Ph.D.
    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   
    (c) Date: July, 1988
 
 3. Past Usage:
     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,
        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it 
        International application of a new probability algorithm for the 
        diagnosis of coronary artery disease.}  {it American Journal of 
        Cardiology}, {it 64},304--310.
        -- International Probability Analysis 
        -- Address: Robert Detrano, M.D.
                    Cardiology 111-C
                    V.A. Medical Center
                    5901 E. 7th Street
                    Long Beach, CA 90028
        -- Results in percent accuracy: (for 0.5 probability threshold)
              Data Name:  CDF    CADENZA
           -- Hungarian   77     74
              Long beach  79     77
              Swiss       81     81
           -- Approximately a 77% correct classification accuracy with a
              logistic-regression-derived discriminant function
     2. David W. Aha & Dennis Kibler
        -- 
           
           
           -- Instance-based prediction of heart-disease presence with the 
              Cleveland database
              -- NTgrowth: 77.0% accuracy
              --       C4: 74.8% accuracy
     3. John Gennari
        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of
           incremental concept formation. {it Artificial Intelligence, 40},
           11--61.
        -- Results: 
           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy
              on the Cleveland database.
 
 4. Relevant Information:
      This database contains 76 attributes, but all published experiments
      refer to using a subset of 14 of them.  In particular, the Cleveland
      database is the only one that has been used by ML researchers to 
      this date.  The ""goal"" field refers to the presence of heart disease
      in the patient.  It is integer valued from 0 (no presence) to 4.
      Experiments with the Cleveland database have concentrated on simply
      attempting to distinguish presence (values 1,2,3,4) from absence (value
      0).  
    
      The names and social security numbers of the patients were recently 
      removed from the database, replaced with dummy values.
 
      One file has been ""processed"", that one containing the Cleveland 
      database.  All four unprocessed files also exist in this directory.
     
 5. Number of Instances: 
         Database:    # of instances:
           Cleveland: 303
           Hungarian: 294
         Switzerland: 123
       Long Beach VA: 200
 
 6. Number of Attributes: 76 (including the predicted attribute)
 
 7. Attribute Information:
    -- Only 14 used
       -- 1. #3  (age)       
       -- 2. #4  (sex)       
       -- 3. #9  (chest_pain)        
       -- 4. #10 (trestbps)  
       -- 5. #12 (chol)      
       -- 6. #16 (fbs)       
       -- 7. #19 (restecg)   
       -- 8. #32 (thalach)   
       -- 9. #38 (exang)     
       -- 10. #40 (oldpeak)   
       -- 11. #41 (slope)     
       -- 12. #44 (ca)        
       -- 13. #51 (thal)      
       -- 14. #58 (num)       (the predicted attribute)
 
    -- Complete attribute documentation:
       1 id: patient identification number
       2 ccf: social security number (I replaced this with a dummy value of 0)
       3 age: age in years
       4 sex: sex (1 = male; 0 = female)
       5 painloc: chest pain location (1 = substernal; 0 = otherwise)
       6 painexer (1 = provoked by exertion; 0 = otherwise)
       7 relrest (1 = relieved after rest; 0 = otherwise)
       8 pncaden (sum of 5, 6, and 7)
       9 chest_pain: chest pain type
         -- Value 1: typical angina
         -- Value 2: atypical angina
         -- Value 3: non-anginal pain
         -- Value 4: asymptomatic
      10 trestbps: resting blood pressure (in mm Hg on admission to the 
         hospital)
      11 htn
      12 chol: serum cholestoral in mg/dl
      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
      14 cigs (cigarettes per day)
      15 years (number of years as a smoker)
      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)
      17 dm (1 = history of diabetes; 0 = no such history)
      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
      19 restecg: resting electrocardiographic results
         -- Value 0: normal
         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST 
                     elevation or depression of > 0.05 mV)
         -- Value 2: showing probable or definite left ventricular hypertrophy
                     by Estes' criteria
      20 ekgmo (month of exercise ECG reading)
      21 ekgday(day of exercise ECG reading)
      22 ekgyr (year of exercise ECG reading)
      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
      28 proto: exercise protocol
           1 = Bruce     
           2 = Kottus
           3 = McHenry
           4 = fast Balke
           5 = Balke
           6 = Noughton 
           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was 
               written!)
           8 = bike 125 kpa min/min  
           9 = bike 100 kpa min/min
          10 = bike 75 kpa min/min
          11 = bike 50 kpa min/min
          12 = arm ergometer
      29 thaldur: duration of exercise test in minutes
      30 thaltime: time when ST measure depression was noted
      31 met: mets achieved
      32 thalach: maximum heart rate achieved
      33 thalrest: resting heart rate
      34 tpeakbps: peak exercise blood pressure (first of 2 parts)
      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
      36 dummy
      37 trestbpd: resting blood pressure
      38 exang: exercise induced angina (1 = yes; 0 = no)
      39 xhypo: (1 = yes; 0 = no)
      40 oldpeak = ST depression induced by exercise relative to rest
      41 slope: the slope of the peak exercise ST segment
         -- Value 1: upsloping
         -- Value 2: flat
         -- Value 3: downsloping
      42 rldv5: height at rest
      43 rldv5e: height at peak exercise
      44 ca: number of major vessels (0-3) colored by flourosopy
      45 restckm: irrelevant
      46 exerckm: irrelevant
      47 restef: rest raidonuclid (sp?) ejection fraction
      48 restwm: rest wall (sp?) motion abnormality
         0 = none
         1 = mild or moderate
         2 = moderate or severe
         3 = akinesis or dyskmem (sp?)
      49 exeref: exercise radinalid (sp?) ejection fraction
      50 exerwm: exercise wall (sp?) motion 
      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
      52 thalsev: not used
      53 thalpul: not used
      54 earlobe: not used
      55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")
      56 cday: day of cardiac cath (sp?)
      57 cyr: year of cardiac cath (sp?)
      58 num: diagnosis of heart disease (angiographic disease status)
         -- Value 0: < 50% diameter narrowing
         -- Value 1: > 50% diameter narrowing
         (in any major vessel: attributes 59 through 68 are vessels)
      59 lmt
      60 ladprox
      61 laddist
      62 diag
      63 cxmain
      64 ramus
      65 om1
      66 om2
      67 rcaprox
      68 rcadist
      69 lvx1: not used
      70 lvx2: not used
      71 lvx3: not used
      72 lvx4: not used
      73 lvf: not used
      74 cathef: not used
      75 junk: not used
      76 name: last name of patient 
         (I replaced this with the dummy string ""name"")
 
 9. Missing Attribute Values: Several.  Distinguished with value -9.0.
 
 10. Class Distribution:
         Database:      0   1   2   3   4 Total
           Cleveland: 164  55  36  35  13   303
           Hungarian: 188  37  26  28  15   294
         Switzerland:   8  48  32  30   5   123
       Long Beach VA:  51  56  41  42  10   200





 Relabeled values in attribute 'sex'
    From: 0                       To: female              
    From: 1                       To: male                


 Relabeled values in attribute 'chest_pain'
    From: 1                       To: typ_angina          
    From: 4                       To: asympt              
    From: 3                       To: non_anginal         
    From: 2                       To: atyp_angina         


 Relabeled values in attribute 'fbs'
    From: 1                       To: t                   
    From: 0                       To: f                   


 Relabeled values in attribute 'restecg'
    From: 2                       To: left_vent_hyper     
    From: 0                       To: normal              
    From: 1                       To: st_t_wave_abnormality


 Relabeled values in attribute 'exang'
    From: 0                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute 'slope'
    From: 3                       To: down                
    From: 2                       To: flat                
    From: 1                       To: up                  


 Relabeled values in attribute 'thal'
    From: 6                       To: fixed_defect        
    From: 3                       To: normal              
    From: 7                       To: reversable_defect   


 Relabeled values in attribute 'num'
    From: '0'                     To: '<50'               
    From: '1'                     To: '>50_1'             
    From: '2'                     To: '>50_2'             
    From: '3'                     To: '>50_3'             
    From: '4'                     To: '>50_4'"
52,trains,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: INDUCE Trains Data set
 
 2. Sources:
    - Donor: GMU, Center for AI, Software Librarian,
             Eric E. Bloedorn (bloedorn@aic.gmu.edu)
    - Original owners: Ryszard S. Michalski (michalski@aic.gmu.edu)
      and Robert Stepp
    - Date received: 1 June 1994
    - Date updated: 24 June 1994 (Thanks to Larry Holder (UT Arlington)
      for noticing a translation error)
 
 3. Past usage:
    - This set most closely resembles the data sets described in the following
      two publications:
       1. R.S. Michalski and  J.B. Larson ""Inductive Inference of VL
          Decision Rules"" In Proceedings of the Workshop in Pattern-Directed 
          Inference Systems, Hawaii, May 1977.  Also published in SIGART
          Newsletter, ACM No. 63, pp. 38-44, June 1977.
       2. Stepp, R.E. and Michalski, R.S. ""Conceptual Clustering: Inventing 
          Goal-Oriented Classifications of Structured Objects""  In 
          R.S. Michalski, J.G. Carbonell, and T.M. Mitchell (Eds.) ""Machine
          Learning: An Artificial Intelligence Approach, Volume II"".  Los
          Altos, Ca: Morgan Kaufmann.  
   
    Both of these papers describe a set of 10 trains, 5 east-bound and 5 west
    bound.  Both refer to the same 10 trains as seen by the figures in these
    publications.   The differences are:
      1) This dataset has 10 attributes, no wheel, or load color attributes
      2) Reference 2 (Stepp, Michalski): does not completely list the 
         attributes used, but does mention wheel color - an attribute not 
         present in this dataset.
      3) Reference 1 (Michalski, Larson): 12 attributes mentioned, but only 6
         are explicitly described. These 6 are included in the dataset below 
         and the Stepp and Michalski set.
 
    Results:
     [1] Michalski and Larson found the following decision rules:
       (1) There exists car1, car2, lod1 and lod2 such that
           [infront(car1, car2)][lcont(car1, lod1)][lcont(car2,lod2)]
           [load-shape(lod1)=triangle][load-shape(lod2)=polygon]=>[dir=east]
       (2) There exists a car1 such that
           [ln(car1)=short][car-shape(car1)=closed-top]=>[dir=east]
       (3) [ncar=3]v There exists car1 such that [car1(car-shape(car1)=jagged-
           top] =>[dir=west]
           There exists car1 such that 
       (4) [#cars(ln=long)=2][cshape(car1)=open,trapezoind,u-shaped] v
           [location(car1)=2][cshape(car1)=closed, rectangle]=>[dir=west]
        (The first selector in rule 4 uses a meta descriptor generated by
         the program that counts the number of long cars in a train)
     [2] The goal of the cluster research is to develop a general method
         for clustering structured objects that can generate conjunctive
         descriptions that occur in human classifications or invent new
         concepts that have similar appeal. CLUSTER/S was able to find the
         following cognitively appealing clusters: 1) a) ""There are two 
         different car shapes in the train"" b) ""There are three or more
         different car shapes in the train"" 2) a) Wheels on all cars have 
         the same color, b) wheels on all cars do not have the same color.""
 
 4. Relevant information:
    - Additional ""background"" knowledge is supplied that provides a partial
      ordering on some of the attribute values.
    - We are providing this dataset both in its original form and in a form
      similar to the more typical propositional datasets in our repository.
      Since the trains dataset records relations between attributes, this
      transformation was somewhat challenging.  However, it may shed some
      insight on this problem for people who are more familiar with the simple
      one-instance-per-line dataset format.
    - Hierarchy of values:
      if (cshape is one of {openrect,opentrap,ushaped,dblopnrect}
        then cshape is opentop
      if (cshape is one of {hexagon,ellipse,closedrect,jaggedtop,slopetop,
                            engine}
        then cshape closedtop
    - Prediction task: Determine concise decision rules distinguishing 
                       trains traveling east from those traveling west.
 
 5. Number of instances: 10
 
 6. Number of attributes:
    - 10, not including the class attribute
   1.   ccont(train idx1, car idx2): car idx is contained in train idx
   2.             ncar(train idx): # of trains in car train idx (int)
   3. infront(car idx1, car idx2): relative positions of cars in train
   4.                loc(car idx): absolute position of car in train (int)
   5.               nwhl(car idx): # of wheels of car idx (int)
   6.                 ln(car idx): length of car idx (long, short)
   7.             cshape(car idx): shape of car (engine, dblopenrect, 
                                   closedrect, openrect, opentrap, ushaped,
                                   hexagon, ellipse, jaggedtop, slopetop,
                                   opentop, closedtop) 
   8.                npl(car idx): number of loads in car idx
   9.    lcont(car idx, load idx): description of which cars hold which loads
  10.           lhshape(load idx): description of load shape (trianglod, 
                                   rectanglod, circlelod, hexagonlod)
  Class: direction (east, west)
 
  The following format was used for the ""transformed"" dataset representation
  as found in trains.transformed.data (one instance per line):
 
  Attributes: 33
   1. Number_of_cars (integer in [3-5])
   2. Number_of_different_loads (integer in [1-4])
   3-22: 5 attributes for each of cars 2 through 5: (20 attributes total)
     - num_wheels (integer in [2-3])
     - length (short or long)    
     - shape (closedrect, dblopnrect, ellipse, engine, hexagon,
              jaggedtop, openrect, opentrap, slopetop, ushaped)
     - num_loads (integer in [0-3])
     - load_shape (circlelod, hexagonlod, rectanglod, trianglod)
   23-32: 10 Boolean attributes describing whether 2 types of loads are on
          adjacent cars of the train
     - Rectangle_next_to_rectangle (0 if false, 1 if true)
     - Rectangle_next_to_triangle (0 if false, 1 if true)
     - Rectangle_next_to_hexagon (0 if false, 1 if true)
     - Rectangle_next_to_circle (0 if false, 1 if true)
     - Triangle_next_to_triangle (0 if false, 1 if true)
     - Triangle_next_to_hexagon (0 if false, 1 if true)
     - Triangle_next_to_circle (0 if false, 1 if true)
     - Hexagon_next_to_hexagon (0 if false, 1 if true)
     - Hexagon_next_to_circle (0 if false, 1 if true)
     - Circle_next_to_circle (0 if false, 1 if true)
   33. Class attribute (east or west)
   
   The number of cars vary between 3 and 5.  Therefore, attributes referring
   to properties of cars that do not exist (such as the 5 attriubutes for
   the ""5th"" car when the train has fewer than 5 cars) are assigned a value
   of ""-"".
 
 7. Distribution of classes:
    - There are 5 east-bound trains and 5 west-bound trains 
      (i.e., 50% east, 50% west)
 

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last"
53,heart-statlog,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This database contains 13 attributes (which have been extracted from
 a larger set of 75)       
   
 
 
 Attribute Information:
 ------------------------
       -- 1. age       
       -- 2. sex       
       -- 3. chest pain type  (4 values)       
       -- 4. resting blood pressure  
       -- 5. serum cholestoral in mg/dl      
       -- 6. fasting blood sugar > 120 mg/dl       
       -- 7. resting electrocardiographic results  (values 0,1,2) 
       -- 8. maximum heart rate achieved  
       -- 9. exercise induced angina    
       -- 10. oldpeak = ST depression induced by exercise relative to rest   
       -- 11. the slope of the peak exercise ST segment     
       -- 12. number of major vessels (0-3) colored by flourosopy        
       -- 13.  thal: 3 = normal; 6 = fixed defect; 7 = reversable defect     
 
 Attributes types
 -----------------
 
 Real: 1,4,5,8,10,12
 Ordered:11,
 Binary: 2,6,9
 Nominal:7,3,13
 
 Variable to be predicted
 ------------------------
 Absence (1) or presence (2) of heart disease
 
 Cost Matrix
 
          abse  pres
 absence   0     1
 presence  5     0
 
 where the rows represent the true values and the columns the predicted.
 
 No missing values.
 
 270 observations




 Relabeled values in attribute class
    From: 1                       To: absent              
    From: 2                       To: present"
54,vehicle,"**Author**: Dr. Pete Mowforth and Dr. Barry Shepherd  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Vehicle+Silhouettes))
**Please cite**: Siebert,JP. Turing Institute Research Memorandum TIRM-87-018 ""Vehicle Recognition Using Rule Based Methods"" (March 1987)  

 NAME
         vehicle silhouettes
 
 PURPOSE
         to classify a given silhouette as one of four types of vehicle,
         using  a set of features extracted from the silhouette. The
         vehicle may be viewed from one of many different angles.  
 
 PROBLEM TYPE
         classification
         
 SOURCE
         Drs.Pete Mowforth and Barry Shepherd
         Turing Institute
         George House
         36 North Hanover St.
         Glasgow
         G1 2AD
 
 CONTACT
         Alistair Sutherland
         Statistics Dept.
         Strathclyde University
         Livingstone Tower
         26 Richmond St.
         GLASGOW G1 1XH
         Great Britain
         
         Tel: 041 552 4400 x3033
         
         Fax: 041 552 4711 
         
         e-mail: alistair@uk.ac.strathclyde.stams
 
 HISTORY
         This data was originally gathered at the TI in 1986-87 by
         JP Siebert. It was partially financed by Barr and Stroud Ltd.
         The original purpose was to find a method of distinguishing
         3D objects within a 2D image by application of an ensemble of
         shape feature extractors to the 2D silhouettes of the objects.
         Measures of shape features extracted from example silhouettes
         of objects to be discriminated were used to generate a class-
         ification rule tree by means of computer induction.
          This object recognition strategy was successfully used to 
         discriminate between silhouettes of model cars, vans and buses
         viewed from constrained elevation but all angles of rotation.
          The rule tree classification performance compared favourably
         to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neigh-
         bour) statistical classifiers in terms of both error rate and
         computational efficiency. An investigation of these rule trees
         generated by example indicated that the tree structure was 
         heavily influenced by the orientation of the objects, and grouped
         similar object views into single decisions.
 
 DESCRIPTION
          The features were extracted from the silhouettes by the HIPS
         (Hierarchical Image Processing System) extension BINATTS, which 
         extracts a combination of scale independent features utilising
         both classical moments based measures such as scaled variance,
         skewness and kurtosis about the major/minor axes and heuristic
         measures such as hollows, circularity, rectangularity and
         compactness.
          Four ""Corgie"" model vehicles were used for the experiment:
         a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400.
         This particular combination of vehicles was chosen with the 
         expectation that the bus, van and either one of the cars would
         be readily distinguishable, but it would be more difficult to
         distinguish between the cars.
          The images were acquired by a camera looking downwards at the
         model vehicle from a fixed angle of elevation (34.2 degrees
         to the horizontal). The vehicles were placed on a diffuse
         backlit surface (lightbox). The vehicles were painted matte black
         to minimise highlights. The images were captured using a CRS4000
         framestore connected to a vax 750. All images were captured with
         a spatial resolution of 128x128 pixels quantised to 64 greylevels.
         These images were thresholded to produce binary vehicle silhouettes,
         negated (to comply with the processing requirements of BINATTS) and
         thereafter subjected to shrink-expand-expand-shrink HIPS modules to
         remove ""salt and pepper"" image noise.
          The vehicles were rotated and their angle of orientation was measured
         using a radial graticule beneath the vehicle. 0 and 180 degrees
         corresponded to ""head on"" and ""rear"" views respectively while 90 and
         270 corresponded to profiles in opposite directions. Two sets of
         60 images, each set covering a full 360 degree rotation, were captured
         for each vehicle. The vehicle was rotated by a fixed angle between 
         images. These datasets are known as e2 and e3 respectively.
          A further two sets of images, e4 and e5, were captured with the camera 
         at elevations of 37.5 degs and 30.8 degs respectively. These sets
         also contain 60 images per vehicle apart from e4.van which contains
         only 46 owing to the difficulty of containing the van in the image
         at some orientations.
 
 ATTRIBUTES
         
         COMPACTNESS     (average perim)**2/area
         
         CIRCULARITY     (average radius)**2/area
         
         DISTANCE CIRCULARITY    area/(av.distance from border)**2
         
         RADIUS RATIO    (max.rad-min.rad)/av.radius
         
         PR.AXIS ASPECT RATIO    (minor axis)/(major axis)
         
         MAX.LENGTH ASPECT RATIO (length perp. max length)/(max length)
         
         SCATTER RATIO   (inertia about minor axis)/(inertia about major axis)
         
         ELONGATEDNESS           area/(shrink width)**2
         
         PR.AXIS RECTANGULARITY  area/(pr.axis length*pr.axis width)
         
         MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this)
         
         SCALED VARIANCE         (2nd order moment about minor axis)/area
         ALONG MAJOR AXIS
         
         SCALED VARIANCE         (2nd order moment about major axis)/area
         ALONG MINOR AXIS 
         
         SCALED RADIUS OF GYRATION       (mavar+mivar)/area
         
         SKEWNESS ABOUT  (3rd order moment about major axis)/sigma_min**3
         MAJOR AXIS
         
         SKEWNESS ABOUT  (3rd order moment about minor axis)/sigma_maj**3
         MINOR AXIS
                 
         KURTOSIS ABOUT  (4th order moment about major axis)/sigma_min**4
         MINOR AXIS  
                 
         KURTOSIS ABOUT  (4th order moment about minor axis)/sigma_maj**4
         MAJOR AXIS
         
         HOLLOWS RATIO   (area of hollows)/(area of bounding polygon)
         
          Where sigma_maj**2 is the variance along the major axis and
         sigma_min**2 is the variance along the minor axis, and
         
         area of hollows= area of bounding poly-area of object 
         
          The area of the bounding polygon is found as a side result of
         the computation to find the maximum length. Each individual
         length computation yields a pair of calipers to the object
         orientated at every 5 degrees. The object is propagated into
         an image containing the union of these calipers to obtain an
         image of the bounding polygon. 
         
 NUMBER OF CLASSES
 
         4       OPEL, SAAB, BUS, VAN
 
 NUMBER OF EXAMPLES
 
                 Total no. = 946
                 
                 No. in each class
                 
                   opel 240
                   saab 240
                   bus  240
                   van  226
                 
                 
                 100 examples are being kept by Strathclyde for validation.
                 So StatLog partners will receive 846 examples.
 
 NUMBER OF ATTRIBUTES
 
                 No. of atts. = 18"
55,hepatitis,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Hepatitis Domain
 
 2. Sources:
      (a) unknown
      (b) Donor: G.Gong  (Carnegie-Mellon University) via 
                    Bojan Cestnik
                    Jozef Stefan Institute
                    Jamova 39
                    61000 Ljubljana
                    Yugoslavia (tel.: (38)(+61) 214-399 ext.287) }
      (c) Date: November, 1988
 
 3. Past Usage:
     1. Diaconis,P. & Efron,B. (1983).  Computer-Intensive Methods in 
        Statistics.  Scientific American, Volume 248.
        -- Gail Gong reported a 80% classfication accuracy
     2. Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A
        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko
        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.
        -- Assistant-86: 83% accuracy
 
 4. Relevant Information:
     Please ask Gail Gong for further information on this database.
 
 5. Number of Instances: 155
 
 6. Number of Attributes: 20 (including the class attribute)
 
 7. Attribute information: 
      1. Class: DIE, LIVE
      2. AGE: 10, 20, 30, 40, 50, 60, 70, 80
      3. SEX: male, female
      4. STEROID: no, yes
      5. ANTIVIRALS: no, yes
      6. FATIGUE: no, yes
      7. MALAISE: no, yes
      8. ANOREXIA: no, yes
      9. LIVER BIG: no, yes
     10. LIVER FIRM: no, yes
     11. SPLEEN PALPABLE: no, yes
     12. SPIDERS: no, yes
     13. ASCITES: no, yes
     14. VARICES: no, yes
     15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00
         -- see the note below
     16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250
     17. SGOT: 13, 100, 200, 300, 400, 500, 
     18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0
     19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90
     20. HISTOLOGY: no, yes
 
     The BILIRUBIN attribute appears to be continuously-valued.  I checked
     this with the donater, Bojan Cestnik, who replied:
 
       About the hepatitis database and BILIRUBIN problem I would like to say
       the following: BILIRUBIN is continuous attribute (= the number of it's
       ""values"" in the ASDOHEPA.DAT file is negative!!!); ""values"" are quoted
       because when speaking about the continuous attribute there is no such 
       thing as all possible values. However, they represent so called
       ""boundary"" values; according to these ""boundary"" values the attribute
       can be discretized. At the same time, because of the continious
       attribute, one can perform some other test since the continuous
       information is preserved. I hope that these lines have at least roughly 
       answered your question. 
 
 8. Missing Attribute Values: (indicated by ""?"")
      Attribute Number:    Number of Missing Values:
                     1:    0
                     2:    0
                     3:    0
                     4:    1
                     5:    0
                     6:    1
                     7:    1
                     8:    1
                     9:    10
                    10:    11
                    11:    5
                    12:    5
                    13:    5
                    14:    5
                    15:    6
                    16:    29
                    17:    4
                    18:    16
                    19:    67
                    20:    0
 
 9. Class Distribution:
      DIE: 32
     LIVE: 123
 
 




 Relabeled values in attribute SEX
    From: 2                       To: male                
    From: 1                       To: female              


 Relabeled values in attribute STEROID
    From: 1                       To: no                  
    From: 2                       To: yes                 


 Relabeled values in attribute ANTIVIRALS
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute FATIGUE
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute MALAISE
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute ANOREXIA
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute LIVER_BIG
    From: 1                       To: no                  
    From: 2                       To: yes                 


 Relabeled values in attribute LIVER_FIRM
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute SPLEEN_PALPABLE
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute SPIDERS
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute ASCITES
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute VARICES
    From: 2                       To: no                  
    From: 1                       To: yes                 


 Relabeled values in attribute HISTOLOGY
    From: 1                       To: no                  
    From: 2                       To: yes"
56,vote,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: 1984 United States Congressional Voting Records Database
 
 2. Source Information:
     (a) Source:  Congressional Quarterly Almanac, 98th Congress, 
                  2nd session 1984, Volume XL: Congressional Quarterly Inc. 
                  Washington, D.C., 1985.
     (b) Donor: Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
     (c) Date: 27 April 1987 
 
 3. Past Usage
    - Publications
      1. Schlimmer, J. C. (1987).  Concept acquisition through 
         representational adjustment.  Doctoral dissertation, Department of 
         Information and Computer Science, University of California, Irvine, CA.
         -- Results: about 90%-95% accuracy appears to be STAGGER's asymptote
      - Predicted attribute: party affiliation (2 classes)
 
 4. Relevant Information:
       This data set includes votes for each of the U.S. House of
       Representatives Congressmen on the 16 key votes identified by the
       CQA.  The CQA lists nine different types of votes: voted for, paired
       for, and announced for (these three simplified to yea), voted
       against, paired against, and announced against (these three
       simplified to nay), voted present, voted present to avoid conflict
       of interest, and did not vote or otherwise make a position known
       (these three simplified to an unknown disposition).
 
 5. Number of Instances: 435 (267 democrats, 168 republicans)
 
 6. Number of Attributes: 16 + class name = 17 (all Boolean valued)
 
 7. Attribute Information:
    1. Class Name: 2 (democrat, republican)
    2. handicapped-infants: 2 (y,n)
    3. water-project-cost-sharing: 2 (y,n)
    4. adoption-of-the-budget-resolution: 2 (y,n)
    5. physician-fee-freeze: 2 (y,n)
    6. el-salvador-aid: 2 (y,n)
    7. religious-groups-in-schools: 2 (y,n)
    8. anti-satellite-test-ban: 2 (y,n)
    9. aid-to-nicaraguan-contras: 2 (y,n)
   10. mx-missile: 2 (y,n)
   11. immigration: 2 (y,n)
   12. synfuels-corporation-cutback: 2 (y,n)
   13. education-spending: 2 (y,n)
   14. superfund-right-to-sue: 2 (y,n)
   15. crime: 2 (y,n)
   16. duty-free-exports: 2 (y,n)
   17. export-administration-act-south-africa: 2 (y,n)
 
 8. Missing Attribute Values: Denoted by ""?""
 
    NOTE: It is important to recognize that ""?"" in this database does 
          not mean that the value of the attribute is unknown.  It 
          means simply, that the value is not ""yea"" or ""nay"" (see 
          ""Relevant Information"" section above).
 
    Attribute:  #Missing Values:
            1:  0
            2:  0
            3:  12
            4:  48
            5:  11
            6:  11
            7:  15
            8:  11
            9:  14
           10:  15
           11:  22
           12:  7
           13:  21
           14:  31
           15:  25
           16:  17
           17:  28
 
 9. Class Distribution: (2 classes)
    1. 45.2 percent are democrat
    2. 54.8 percent are republican
 
 Class predictiveness and predictability: Pr(C|A=V) and Pr(A=V|C)
  Attribute 1: (A = handicapped-infants)
   0.91;  1.21  (C=democrat; V=y)
   0.09;  0.10  (C=republican; V=y)
   0.43;  0.38  (C=democrat; V=n)
   0.57;  0.41  (C=republican; V=n)
   0.75;  0.03  (C=democrat; V=?)
   0.25;  0.01  (C=republican; V=?)
  Attribute 2: (A = water-project-cost-sharing)
   0.62;  0.45  (C=democrat; V=y)
   0.38;  0.23  (C=republican; V=y)
   0.62;  0.45  (C=democrat; V=n)
   0.38;  0.23  (C=republican; V=n)
   0.58;  0.10  (C=democrat; V=?)
   0.42;  0.06  (C=republican; V=?)
  Attribute 3: (A = adoption-of-the-budget-resolution)
   0.91;  0.87  (C=democrat; V=y)
   0.09;  0.07  (C=republican; V=y)
   0.17;  0.11  (C=democrat; V=n)
   0.83;  0.44  (C=republican; V=n)
   0.64;  0.03  (C=democrat; V=?)
   0.36;  0.01  (C=republican; V=?)
  Attribute 4: (A = physician-fee-freeze)
   0.08;  0.05  (C=democrat; V=y)
   0.92;  0.50  (C=republican; V=y)
   0.99;  0.92  (C=democrat; V=n)
   0.01;  0.01  (C=republican; V=n)
   0.73;  0.03  (C=democrat; V=?)
   0.27;  0.01  (C=republican; V=?)
  Attribute 5: (A = el-salvador-aid)
   0.26;  0.21  (C=democrat; V=y)
   0.74;  0.48  (C=republican; V=y)
   0.96;  0.75  (C=democrat; V=n)
   0.04;  0.02  (C=republican; V=n)
   0.80;  0.04  (C=democrat; V=?)
   0.20;  0.01  (C=republican; V=?)
  Attribute 6: (A = religious-groups-in-schools)
   0.45;  0.46  (C=democrat; V=y)
   0.55;  0.46  (C=republican; V=y)
   0.89;  0.51  (C=democrat; V=n)
   0.11;  0.05  (C=republican; V=n)
   0.82;  0.03  (C=democrat; V=?)
   0.18;  0.01  (C=republican; V=?)
  Attribute 7: (A = anti-satellite-test-ban)
   0.84;  0.75  (C=democrat; V=y)
   0.16;  0.12  (C=republican; V=y)
   0.32;  0.22  (C=democrat; V=n)
   0.68;  0.38  (C=republican; V=n)
   0.57;  0.03  (C=democrat; V=?)
   0.43;  0.02  (C=republican; V=?)
  Attribute 8: (A = aid-to-nicaraguan-contras)
   0.90;  0.82  (C=democrat; V=y)
   0.10;  0.07  (C=republican; V=y)
   0.25;  0.17  (C=democrat; V=n)
   0.75;  0.41  (C=republican; V=n)
   0.27;  0.01  (C=democrat; V=?)
   0.73;  0.03  (C=republican; V=?)
  Attribute 9: (A = mx-missile)
   0.91;  0.70  (C=democrat; V=y)
   0.09;  0.06  (C=republican; V=y)
   0.29;  0.22  (C=democrat; V=n)
   0.71;  0.45  (C=republican; V=n)
   0.86;  0.07  (C=democrat; V=?)
   0.14;  0.01  (C=republican; V=?)
  Attribute 10: (A = immigration)
   0.57;  0.46  (C=democrat; V=y)
   0.43;  0.28  (C=republican; V=y)
   0.66;  0.52  (C=democrat; V=n)
   0.34;  0.23  (C=republican; V=n)
   0.57;  0.01  (C=democrat; V=?)
   0.43;  0.01  (C=republican; V=?)
  Attribute 11: (A = synfuels-corporation-cutback)
   0.86;  0.48  (C=democrat; V=y)
   0.14;  0.06  (C=republican; V=y)
   0.48;  0.47  (C=democrat; V=n)
   0.52;  0.43  (C=republican; V=n)
   0.57;  0.04  (C=democrat; V=?)
   0.43;  0.03  (C=republican; V=?)
  Attribute 12: (A = education-spending)
   0.21;  0.13  (C=democrat; V=y)
   0.79;  0.42  (C=republican; V=y)
   0.91;  0.80  (C=democrat; V=n)
   0.09;  0.06  (C=republican; V=n)
   0.58;  0.07  (C=democrat; V=?)
   0.42;  0.04  (C=republican; V=?)
  Attribute 13: (A = superfund-right-to-sue)
   0.35;  0.27  (C=democrat; V=y)
   0.65;  0.42  (C=republican; V=y)
   0.89;  0.67  (C=democrat; V=n)
   0.11;  0.07  (C=republican; V=n)
   0.60;  0.06  (C=democrat; V=?)
   0.40;  0.03  (C=republican; V=?)
  Attribute 14: (A = crime)
   0.36;  0.34  (C=democrat; V=y)
   0.64;  0.49  (C=republican; V=y)
   0.98;  0.63  (C=democrat; V=n)
   0.02;  0.01  (C=republican; V=n)
   0.59;  0.04  (C=democrat; V=?)
   0.41;  0.02  (C=republican; V=?)
  Attribute 15: (A = duty-free-exports)
   0.92;  0.60  (C=democrat; V=y)
   0.08;  0.04  (C=republican; V=y)
   0.39;  0.34  (C=democrat; V=n)
   0.61;  0.44  (C=republican; V=n)
   0.57;  0.06  (C=democrat; V=?)
   0.43;  0.04  (C=republican; V=?)
  Attribute 16: (A = export-administration-act-south-africa)
   0.64;  0.65  (C=democrat; V=y)
   0.36;  0.30  (C=republican; V=y)
   0.19;  0.04  (C=democrat; V=n)
   0.81;  0.15  (C=republican; V=n)
   0.79;  0.31  (C=democrat; V=?)
   0.21;  0.07  (C=republican; V=?)"
57,hypothyroid,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

;
 ; Thyroid disease records supplied by the Garavan Institute and J. Ross
 ; Quinlan, New South Wales Institute, Syndney, Australia.
 ;
 ; 1987.
 ;
 
 hypothyroid, primary hypothyroid, compensated hypothyroid,
 secondary hypothyroid,
 negative.			|  classes
 
 age:				continuous.
 sex:				M, F.
 on thyroxine:			f, t.
 query on thyroxine:		f, t.
 on antithyroid medication:	f, t.
 sick:				f, t.
 pregnant:			f, t.
 thyroid surgery:		f, t.
 I131 treatment:			f, t.
 query hypothyroid:		f, t.
 query hyperthyroid:		f, t.
 lithium:			f, t.
 goitre:				f, t.
 tumor:				f, t.
 hypopituitary:			f, t.
 psych:				f, t.
 TSH measured:			f, t.
 TSH:				continuous.
 T3 measured:			f, t.
 T3:				continuous.
 TT4 measured:			f, t.
 TT4:				continuous.
 T4U measured:			f, t.
 T4U:				continuous.
 FTI measured:			f, t.
 FTI:				continuous.
 TBG measured:			f, t.
 TBG:				continuous.
 referral source:		WEST, STMW, SVHC, SVI, SVHD, other.


 Num Instances:     3772
 Num Attributes:    30
 Num Continuous:    7 (Int 1 / Real 6)
 Num Discrete:      23
 Missing values:    6064 /  5.4%

     name                      type enum ints real     missing    distinct  (1)
   1 'age'                     Int    0% 100%   0%     1 /  0%    93 /  2%   0% 
   2 'sex'                     Enum  96%   0%   0%   150 /  4%     2 /  0%   0% 
   3 'on thyroxine'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   4 'query on thyroxine'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   5 'on antithyroid medicati  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   6 'sick'                    Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   7 'pregnant'                Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   8 'thyroid surgery'         Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
   9 'I131 treatment'          Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  10 'query hypothyroid'       Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  11 'query hyperthyroid'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  12 'lithium'                 Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  13 'goitre'                  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  14 'tumor'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  15 'hypopituitary'           Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  16 'psych'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  17 'TSH measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  18 'TSH'                     Real   0%  11%  79%   369 / 10%   287 /  8%   2% 
  19 'T3 measured'             Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  20 'T3'                      Real   0%   9%  71%   769 / 20%    69 /  2%   0% 
  21 'TT4 measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  22 'TT4'                     Real   0%  94%   0%   231 /  6%   241 /  6%   1% 
  23 'T4U measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  24 'T4U'                     Real   0%   2%  87%   387 / 10%   146 /  4%   1% 
  25 'FTI measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% 
  26 'FTI'                     Real   0%  90%   0%   385 / 10%   234 /  6%   2% 
  27 'TBG measured'            Enum 100%   0%   0%     0 /  0%     1 /  0%   0% 
  28 'TBG'                     Real   0%   0%   0%  3772 /100%     0 /  0%   0% 
  29 'referral source'         Enum 100%   0%   0%     0 /  0%     5 /  0%   0% 
  30 'Class'                   Enum 100%   0%   0%     0 /  0%     4 /  0%   0%"
59,ionosphere,"**Author**: Space Physics Group, Applied Physics Laboratory, Johns Hopkins University. Donated by Vince Sigillito.  
**Source**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/ionosphere)  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html) 

**Johns Hopkins University Ionosphere database**  
This radar data was collected by a system in Goose Bay, Labrador.  This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.  See the paper for more details.  

### Attribute information
Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number.  There were 17 pulse numbers for the Goose Bay system.  Instances in this database are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.

The targets were free electrons in the ionosphere.  ""Good"" (g) radar returns are those showing evidence of some type of structure in the ionosphere.  ""Bad"" (b) returns are those that do not; their signals pass through the ionosphere.  

### Relevant papers  
Sigillito, V. G., Wing, S. P., Hutton, L. V., & Baker, K. B. (1989). Classification of radar returns from the ionosphere using neural networks. Johns Hopkins APL Technical Digest, 10, 262-266."
60,waveform-5000,"**Author**: Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J.  
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/waveform+database+generator+(version+2)) - 1988  
**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)    

**Waveform Database Generator**  
Generator generating 3 classes of waves. Each class is generated from a combination of 2 of 3 ""base"" waves.  

For details, see Breiman,L., Friedman,J.H., Olshen,R.A., and Stone,C.J. (1984). 
Classification and Regression Trees. Wadsworth International, pp 49-55, 169. 

Note: There is [an earlier version](http://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+(Version+1)) of this dataset that only has 21 attributes (it does not add the 19 noise features).

### Attribute Information

40 attributes describing the waveform, all of which include noise. The latter 19 attributes are all noise attributes with mean 0 and variance 1."
61,iris,"**Author**: R.A. Fisher  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Iris) - 1936 - Donated by Michael Marshall  
**Please cite**:   

**Iris Plants Database**  
This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is     linearly separable from the other 2; the latter are NOT linearly separable from each other.

Predicted attribute: class of iris plant.  
This is an exceedingly simple domain.  
 
### Attribute Information:
    1. sepal length in cm
    2. sepal width in cm
    3. petal length in cm
    4. petal width in cm
    5. class: 
       -- Iris Setosa
       -- Iris Versicolour
       -- Iris Virginica"
62,zoo,"**Author**: Richard S. Forsyth   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Zoo) - 5/15/1990   
**Please cite**:  

**Zoo database**  
A simple database containing 17 Boolean-valued attributes describing animals.  The ""type"" attribute appears to be the class attribute. 

Notes:  
* I find it unusual that there are 2 instances of ""frog"" and one of ""girl""!
* feature 'animal' is an identifier (though not unique) and should be ignored when modeling"
70,"BNG(anneal,nominal,1000000)",
71,"BNG(anneal.ORIG,nominal,1000000)",
72,BNG(kr-vs-kp),
73,"BNG(labor,nominal,1000000)",
74,"BNG(letter,nominal,1000000)",
75,"BNG(autos,nominal,1000000)",
76,"BNG(lymph,nominal,1000000)",
77,"BNG(breast-cancer,nominal,1000000)",
78,"BNG(mfeat-fourier,nominal,1000000)",
115,"BNG(mfeat-karhunen,nominal,1000000)",
116,"BNG(bridges_version1,nominal,1000000)",
117,"BNG(bridges_version2,nominal,1000000)",
118,"BNG(mfeat-zernike,nominal,1000000)",
119,"BNG(cmc,nominal,55296)",
120,BNG(mushroom),
121,"BNG(colic.ORIG,nominal,1000000)",
122,"BNG(colic,nominal,1000000)",
123,BNG(optdigits),
124,"BNG(credit-a,nominal,1000000)",
125,"BNG(page-blocks,nominal,295245)",
126,"BNG(credit-g,nominal,1000000)",
127,"BNG(pendigits,nominal,1000000)",
128,"BNG(cylinder-bands,nominal,1000000)","This data sets consists of 3 different types of irises' (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray"
129,"BNG(dermatology,nominal,1000000)",
130,BNG(segment),
131,"BNG(sick,nominal,1000000)",
132,"BNG(sonar,nominal,1000000)",
133,"BNG(glass,nominal,137781)",
134,BNG(soybean),
135,BNG(spambase),
136,"BNG(heart-c,nominal,1000000)",
137,BNG(tic-tac-toe),
138,"BNG(heart-h,nominal,1000000)",
139,BNG(trains),
140,"BNG(heart-statlog,nominal,1000000)",
141,"BNG(vehicle,nominal,1000000)",
142,"BNG(hepatitis,nominal,1000000)",
143,BNG(vote),
144,"BNG(hypothyroid,nominal,1000000)",
146,BNG(ionosphere),
147,"BNG(waveform-5000,nominal,1000000)",
148,"BNG(zoo,nominal,1000000)",
149,CovPokElec,"**Author**: Albert Bifet  
**Source**: [MOA](http://moa.cms.waikato.ac.nz/datasets/) - 2009  
**Please cite**:   

Dataset created to study concept drift in stream mining. It is constructed by combining the Covertype, Poker-Hand, and Electricity datasets. More details can be found in:
Albert Bifet, Geoff Holmes, Bernhard Pfahringer, Richard Kirkby, and Ricard Gavaldà. 2009. New ensemble methods for evolving data streams. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '09)."
150,covertype,"**Author**: Albert Bifet  
**Source**: [MOA](http://moa.cms.waikato.ac.nz/datasets/) - 2009  
**Please cite**:   

Normalized version of the Forest Covertype dataset (see version 1), so that the numerical values are between 0 and 1. Contains the forest cover type for 30 x 30 meter cells obtained from US Forest Service (USFS) Region 2 Resource Information System &#40;RIS&#41; data. It contains 581,012 instances and 54 attributes, and it has been used in several papers on data stream classification."
151,electricity,"**Author**: M. Harries, J. Gama, A. Bifet  
**Source**: [Joao Gama](http://www.inescporto.pt/~jgama/ales/ales_5.html) - 2009  
**Please cite**: None  

**Electricity** is a widely used dataset described by M. Harries and analyzed by J. Gama (see papers below). This data was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. Electricity transfers to/from the neighboring state of Victoria were done to alleviate fluctuations.

The dataset (originally named ELEC2) contains 45,312 instances dated from 7 May 1996 to 5 December 1998. Each example of the dataset refers to a period of 30 minutes, i.e. there are 48 instances for each time period of one day. Each example on the dataset has 5 fields, the day of week, the time stamp, the New South Wales electricity demand, the Victoria electricity demand, the scheduled electricity transfer between states and the class label. The class label identifies the change of the price (UP or DOWN) in New South Wales relative to a moving average of the last 24 hours (and removes the impact of longer term price trends). 

The data was normalized by A. Bifet.

### Attribute information  
* Date: date between 7 May 1996 to 5 December 1998. Here normalized between 0 and 1
* Day: day of the week (1-7)
* Period: time of the measurement (1-48) in half hour intervals over 24 hours. Here normalized between 0 and 1
* NSWprice: New South Wales electricity price, normalized between 0 and 1
* NSWdemand: New South Wales electricity demand, normalized between 0 and 1
* VICprice: Victoria electricity price, normalized between 0 and 1
* VICdemand: Victoria electricity demand, normalized between 0 and 1
* transfer: scheduled electricity transfer between both states, normalized between 0 and 1

### Relevant papers  
M. Harries. Splice-2 comparative evaluation: Electricity pricing. Technical report, The University of South Wales, 1999.  
J. Gama, P. Medas, G. Castillo, and P. Rodrigues. Learning with drift detection. In SBIA Brazilian Symposium on Artificial Intelligence, pages 286–295, 2004."
152,Hyperplane_10_1E-3,
153,Hyperplane_10_1E-4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Synthetic dataset. Almost identical to [dataset 152](https://www.openml.org/d/153/edit)"
154,LED(50000),
155,pokerhand,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Normalized version of the pokerhand data set.

Automated file upload of pokerhand-normalized.arff"
156,RandomRBF_0_0,
157,RandomRBF_10_1E-3,
158,RandomRBF_10_1E-4,
159,RandomRBF_50_1E-3,
160,RandomRBF_50_1E-4,
161,SEA(50),
162,SEA(50000),
163,lung-cancer,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Lung Cancer Data
 
 2. Source Information:
 	- Data was published in : 
 	  Hong, Z.Q. and Yang, J.Y. ""Optimal Discriminant Plane for a Small
 	  Number of Samples and Design Method of Classifier on the Plane"",
 	  Pattern Recognition, Vol. 24, No. 4, pp. 317-324, 1991.
 	- Donor: Stefan Aeberhard, stefan@coral.cs.jcu.edu.au
 	- Date : May, 1992
 
 3. Past Usage:
 	- Hong, Z.Q. and Yang, J.Y. ""Optimal Discriminant Plane for a Small
           Number of Samples and Design Method of Classifier on the Plane"",
           Pattern Recognition, Vol. 24, No. 4, pp. 317-324, 1991.
 	- Aeberhard, S., Coomans, D, De Vel, O. ""Comparisons of 
 	  Classification Methods in High Dimensional Settings"", 
 	  submitted to Technometrics.
 	- Aeberhard, S., Coomans, D, De Vel, O. ""The Dangers of 
 	  Bias in High Dimensional Settings"", submitted to
 	  pattern Recognition.
 
 4. Relevant Information:
 	- This data was used by Hong and Young to illustrate the 
 	  power of the optimal discriminant plane even in ill-posed
 	  settings. Applying the KNN method in the resulting plane	
 	  gave 77% accuracy. However, these results are strongly
 	  biased (See Aeberhard's second ref. above, or email to
 	  stefan@coral.cs.jcu.edu.au). Results obtained by
 	  Aeberhard et al. are : 
 	  RDA : 62.5%, KNN 53.1%, Opt. Disc. Plane 59.4%
 
 	  The data described 3 types of pathological lung cancers.
 	  The Authors give no information on the individual
 	  variables nor on where the data was originally used.
 
        -  In the original data 4 values for the fifth attribute were -1.
           These values have been changed to ? (unknown). (*)
        -  In the original data 1 value for the 39 attribute was 4.  This
           value has been changed to ? (unknown). (*)
     
 	  
 5. Number of Instances: 32
 
 6. Number of Attributes: 57 (1 class attribute, 56 predictive)
 
 7. Attribute Information:
 
 	attribute 1 is the class label.
 	
 	- All predictive attributes are nominal, taking on integer 
 	  values 0-3
 
 8. Missing Attribute Values: Attributes 5 and 39 (*)
 
 9. Class Distribution:
 	- 3 classes, 
 		1.)	9 observations
 		2.)	13     ""
 		3.)	10     ""
 

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: first"
164,molecular-biology_promoters,"**Author**: C. Harley, R. Reynolds, M. Noordewier, J. Shavlik.  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+(Promoter+Gene+Sequences)) - 1990  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  

**E. coli promoter gene sequences (DNA)**  
Compilation of promoters with known transcriptional start points for E. coli genes. The task is to recognize promoters in strings that represent nucleotides (one of A, G, T, or C). A promoter is a genetic region which initiates the first step in the expression of an adjacent gene (transcription).  

The input features are 57 sequential DNA nucleotides. Fifty-three sample promoters and 53 nonpromoter sequences were used. The 53 sample promoters were obtained from a compilation
produced by Hawley and McClure (1983). Negative training examples were thus derived by selecting contiguous substrings from a 1.5 kilobase sequence provided by Prof. T. Record of the Univ. of Wisconsin’s Chemistry Dept. This sequence is a fragment from E. coli bacteriophage T7 isolated with the restriction enzyme HaeIII. By virtue of the fact that the fragment does not bind RNA polymerase, it is believed to not contain any promoter sites.

This dataset has been developed to help evaluate a ""hybrid"" learning algorithm (""KBANN"") that uses examples to inductively refine preexisting knowledge.

### Attribute Description  

* 1. One of {+/-}, indicating the class (""+"" = promoter).
* 2. The instance name (non-promoters named by position in the 1500-long nucleotide sequence provided by T. Record).
* 3-59. The remaining 57 fields are the sequence, starting at position -50 (p-50) and ending at position +7 (p7). Each of these fields is filled by one of {a, g, t, c}.
 
### Relevant papers  

* Harley, C. and Reynolds, R. 1987. ""Analysis of E. Coli Promoter Sequences."" Nucleic Acids Research, 15:2343-2361.  
* Towell, G., Shavlik, J. and Noordewier, M. 1990. ""Refinement of Approximate Domain Theories by Knowledge-Based Artificial Neural Networks."" In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90)."
171,primary-tumor,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Citation Request:
    This primary tumor domain was obtained from the University Medical Centre,
    Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and 
    M. Soklic for providing the data.  Please include this citation if you plan
    to use this database.
 
 1. Title: Primary Tumor Domain
 
 2. Sources:
      (a) Source:
      (b) Donors: Igor Kononenko, 
                  University E.Kardelj
                  Faculty for electrical engineering
                  Trzaska 25
                  61000 Ljubljana (tel.: (38)(+61) 265-161
 
                  Bojan Cestnik
                  Jozef Stefan Institute
                  Jamova 39
                  61000 Ljubljana
                  Yugoslavia (tel.: (38)(+61) 214-399 ext.287) 
      (c) Date: November 1988
 
 3. Past Usage: (sveral)
     1. Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A
        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko
        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.
        -- Assistant-86: 44% accuracy
     2. Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In
        I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 11-30,
        Sigma Press.
        -- Simple Bayes: 48% accuracy
        -- CN2 (95% threshold): 45%
     3. Michalski,R., Mozetic,I. Hong,J., & Lavrac,N. (1986).  The Multi-Purpose
        Incremental Learning System AQ15 and its Testing Applications to Three
        Medical Domains.  In Proceedings of the Fifth National Conference on
        Artificial Intelligence, 1041-1045. Philadelphia, PA: Morgan Kaufmann.
        -- Experts: 42% accuracy 
        -- AQ15: 29-41%
 
 4. Relevant Information:
      This is one of three domains provided by the Oncology Institute
      that has repeatedly appeared in the machine learning literature.
      (See also breast-cancer and lymphography.)
 
 5. Number of Instances: 339
 
 6. Number of Attributes: 18 including the class attribute
 
 7. Attribute Information: (class is location of tumor)
     --- NOTE: All attribute values in the database have been entered as
               numeric values corresponding to their index in the list
               of attribute values for that attribute domain as given below.
     1. class: lung, head & neck, esophasus, thyroid, stomach, duoden & sm.int,
               colon, rectum, anus, salivary glands, pancreas, gallblader,
               liver, kidney, bladder, testis, prostate, ovary, corpus uteri, 
               cervix uteri, vagina, breast
     2. age:   <30, 30-59, >=60
     3. sex:   male, female
     4. histologic-type: epidermoid, adeno, anaplastic
     5. degree-of-diffe: well, fairly, poorly
     6. bone: yes, no
     7. bone-marrow: yes, no
     8. lung: yes, no
     9. pleura: yes, no
    10. peritoneum: yes, no
    11. liver: yes, no
    12. brain: yes, no
    13. skin: yes, no
    14. neck: yes, no
    15. supraclavicular: yes, no
    16. axillar: yes, no
    17. mediastinum: yes, no
    18. abdominal: yes, no
 
 8. Missing Attribute Values: (? indicates unknown value)
     Attribute#: Number of missing values
     1: 0
     2: 0
     3: 1
     4: 67
     5: 155
     6: 0
     7: 0
     8: 0
     9: 0
     10: 0
     11: 0
     12: 0
     13: 1
     14: 0
     15: 0
     16: 1
     17: 0
     18: 0
 
 9. Class Distribution: 
     Class Index:   Number of instances in class:
               1:   84
               2:   20
               3:   9
               4:   14
               5:   39
               6:   1
               7:   14
               8:   6
               9:   0
              10:   2
              11:   28
              12:   16
              13:   7
              14:   24
              15:   2
              16:   1
              17:   10
              18:   29
              19:   6
              20:   2
              21:   1
              22:   24





 Relabeled values in attribute age
    From: 1                       To: '<30'               
    From: 2                       To: '30-59'             
    From: 3                       To: '>=60'              


 Relabeled values in attribute sex
    From: 1                       To: male                
    From: 2                       To: female              


 Relabeled values in attribute histologic-type
    From: 1                       To: epidermoid          
    From: 2                       To: adeno               
    From: 3                       To: anaplastic          


 Relabeled values in attribute degree-of-diffe
    From: 1                       To: well                
    From: 2                       To: fairly              
    From: 3                       To: poorly              


 Relabeled values in attribute bone
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute bone-marrow
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute lung
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute pleura
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute peritoneum
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute liver
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute brain
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute skin
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute neck
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute supraclavicular
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute axillar
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute mediastinum
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute abdominal
    From: 1                       To: yes                 
    From: 2                       To: no                  


 Relabeled values in attribute class
    From: 1                       To: lung                
    From: 2                       To: 'head and neck'     
    From: 3                       To: esophagus           
    From: 4                       To: thyroid             
    From: 5                       To: stomach             
    From: 6                       To: 'duoden and sm.int' 
    From: 7                       To: colon               
    From: 8                       To: rectum              
    From: 9                       To: anus                
    From: 10                      To: 'salivary glands'   
    From: 11                      To: pancreas            
    From: 12                      To: gallbladder         
    From: 13                      To: liver               
    From: 14                      To: kidney              
    From: 15                      To: bladder             
    From: 16                      To: testis              
    From: 17                      To: prostate            
    From: 18                      To: ovary               
    From: 19                      To: 'corpus uteri'      
    From: 20                      To: 'cervix uteri'      
    From: 21                      To: vagina              
    From: 22                      To: breast"
172,shuttle-landing-control,"# Space Shuttle Autolanding Domain
 
NASA: Mr. Roger Burke's autolander design team

##### Past Usage: (several, it appears)
      Example: Michie,D. (1988).  The Fifth Generation's Unbridged Gap.
               In Rolf Herken (Ed.) The Universal Turing Machine: A
               Half-Century Survey, 466-489, Oxford University Press.
 
##### Relevant Information:
      This is a tiny database.  Michie reports that Burke's group used
      RULEMASTER to generate comprehendable rules for determining
      the conditions under which an autolanding would be preferable to
      manual control of the spacecraft.
 
##### Number of Instances:
15
 
##### Number of Attributes: 
7 (including the class attribute)
 
##### Attribute Information:
     1. Class: noauto, auto
        -- that is, advise using manual/automatic control
     2. STABILITY: stab, xstab
     3. ERROR: XL, LX, MM, SS
     4. SIGN: pp, nn
     5. WIND: head, tail
     6. MAGNITUDE: Low, Medium, Strong, OutOfRange
     7. VISIBILITY: yes, no
 
##### Missing Attribute Values:
    -- none
    -- but several ""don't care"" values: (denoted by ""*"")
          Attribute Number:   Number of Don't Care Values:
                         2:   2
                         3:   3
                         4:   8
                         5:   8
                         6:   5
                         7:   0
 
##### Class Distribution:
     1. Use noauto control: 6
     2. Use automatic control: 9%
 Information about the dataset\
 CLASSTYPE: nominal\
 CLASSINDEX: first"
179,adult,"**Author**: Ronny Kohavi and Barry Becker  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Adult) - 1996-05-01  
**Please cite**: Ron Kohavi, ""Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  

**Note: This dataset is not the original UCI dataset. It has some discretized features. See version 2 for the original.**

Prediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))

Ronny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.  
e-mail: ronnyk '@' live.com for questions."
180,covertype,"**Covertype**  
Predicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types). 

This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. 

Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. 

As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4). 

The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.) Cache la Poudre would probably be more unique than the others, due to its relatively low elevation range and species composition.

Attribute Information:  
Given is the attribute name, attribute type, the measurement unit and a brief description. The forest cover type is the classification problem. The order of this listing corresponds to the order of numerals along the rows of the database. 
```
Name / Data Type / Measurement / Description  
Elevation / quantitative /meters / Elevation in meters  
Aspect / quantitative / azimuth / Aspect in degrees azimuth  
Slope / quantitative / degrees / Slope in degrees  
Horizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features  
Vertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features  
Horizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway  
Hillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice  
Hillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer solstice  
Hillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice  
Horizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points  
Wilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation  
Soil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation  
Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation 
```

Relevant Papers:  
- Blackard, Jock A. and Denis J. Dean. 2000. ""Comparative Accuracies of Artificial Neural Networks and Discriminant Analysis in Predicting Forest Cover Types from Cartographic Variables."" Computers and Electronics in Agriculture 24(3):131-151. 
- Blackard, Jock A. and Denis J. Dean. 1998. ""Comparative Accuracies of Neural Networks and Discriminant Analysis in Predicting Forest Cover Types from Cartographic Variables."" Second Southern Forestry GIS Conference. University of Georgia. Athens, GA. Pages 189-199. 
- Blackard, Jock A. 1998. ""Comparison of Neural Networks and Discriminant Analysis in Predicting Forest Cover Types."" Ph.D. dissertation. Department of Forest Sciences. Colorado State University. Fort Collins, Colorado. 165 pages."
181,yeast,"**Author**:   
**Source**: Unknown -   
**Please cite**:"
182,satimage,"**Author**: Ashwin Srinivasan, Department of Statistics and Data Modeling, University of Strathclyde  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)) - 1993  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  

The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. 

One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels. 

The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. 

Each pixel is categorized as one of the following classes:  
1 red soil  
2 cotton crop  
3 grey soil  
4 damp grey soil  
5 soil with vegetation stubble  
6 mixture class (all types present)  
7 very damp grey soil  

NB. There are no examples with class 6 in this dataset.  

The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset.  

### Attribute information  
There are 36 predictive attributes (= 4 spectral bands x 9 pixels in neighborhood).
In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary. 

In this version, the pixel values 0..255 are normalized around 0.

**Note: it is unclear why the attributes are named Aattr - Fattr in this version, since there are only 4 bands and 9 pixels, naming them A1, B1, C1, D1, A2, B2, C2, D2, ... would have made more sense.**"
183,abalone,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title of Database: Abalone data
 
 2. Sources:
 
    (a) Original owners of database:
 	Marine Resources Division
 	Marine Research Laboratories - Taroona
 	Department of Primary Industry and Fisheries, Tasmania
 	GPO Box 619F, Hobart, Tasmania 7001, Australia
 	(contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)
 
    (b) Donor of database:
 	Sam Waugh (Sam.Waugh@cs.utas.edu.au)
 	Department of Computer Science, University of Tasmania
 	GPO Box 252C, Hobart, Tasmania 7001, Australia
 
    (c) Date received: December 1995
 
 
 3. Past Usage:
 
    Sam Waugh (1995) ""Extending and benchmarking Cascade-Correlation"", PhD
    thesis, Computer Science Department, University of Tasmania.
 
    -- Test set performance (final 1044 examples, first 3133 used for training):
 	24.86% Cascade-Correlation (no hidden nodes)
 	26.25% Cascade-Correlation (5 hidden nodes)
 	21.5%  C4.5
 	 0.0%  Linear Discriminate Analysis
 	 3.57% k=5 Nearest Neighbour
       (Problem encoded as a classification task)
 
    -- Data set samples are highly overlapped.  Further information is required
 	to separate completely using affine combinations.  Other restrictions
 	to data set examined.
 
    David Clark, Zoltan Schreter, Anthony Adams ""A Quantitative Comparison of
    Dystal and Backpropagation"", submitted to the Australian Conference on
    Neural Networks (ACNN'96). Data set treated as a 3-category classification
    problem (grouping ring classes 1-8, 9 and 10, and 11 on).
 
    -- Test set performance (3133 training, 1044 testing as above):
 	64%    Backprop
 	55%    Dystal
    -- Previous work (Waugh, 1995) on same data set:
 	61.40% Cascade-Correlation (no hidden nodes)
 	65.61% Cascade-Correlation (5 hidden nodes)
 	59.2%  C4.5
 	32.57% Linear Discriminate Analysis
 	62.46% k=5 Nearest Neighbour
 
 
 4. Relevant Information Paragraph:
 
    Predicting the age of abalone from physical measurements.  The age of
    abalone is determined by cutting the shell through the cone, staining it,
    and counting the number of rings through a microscope -- a boring and
    time-consuming task.  Other measurements, which are easier to obtain, are
    used to predict the age.  Further information, such as weather patterns
    and location (hence food availability) may be required to solve the problem.
 
    From the original data examples with missing values were removed (the
    majority having the predicted value missing), and the ranges of the
    continuous values have been scaled for use with an ANN (by dividing by 200).
 
    Data comes from an original (non-machine-learning) study:
 
 	Warwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and
 	Wes B Ford (1994) ""The Population Biology of Abalone (_Haliotis_
 	species) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North
 	Coast and Islands of Bass Strait"", Sea Fisheries Division, Technical
 	Report No. 48 (ISSN 1034-3288)
 
 
 5. Number of Instances: 4177
 
 
 6. Number of Attributes: 8
 
 
 7. Attribute information:
 
    Given is the attribute name, attribute type, the measurement unit and a
    brief description.  The number of rings is the value to predict: either
    as a continuous value or as a classification problem.
 
 	Name		Data Type	Meas.	Description
 	----		---------	-----	-----------
 	Sex		nominal			M, F, and I (infant)
 	Length		continuous	mm	Longest shell measurement
 	Diameter	continuous	mm	perpendicular to length
 	Height		continuous	mm	with meat in shell
 	Whole weight	continuous	grams	whole abalone
 	Shucked weight	continuous	grams	weight of meat
 	Viscera weight	continuous	grams	gut weight (after bleeding)
 	Shell weight	continuous	grams	after being dried
 	Rings		integer			+1.5 gives the age in years
 
    Statistics for numeric domains:
 
 		Length	Diam	Height	Whole	Shucked	Viscera	Shell	Rings
 	Min	0.075	0.055	0.000	0.002	0.001	0.001	0.002	    1
 	Max	0.815	0.650	1.130	2.826	1.488	0.760	1.005	   29
 	Mean	0.524	0.408	0.140	0.829	0.359	0.181	0.239	9.934
 	SD	0.120	0.099	0.042	0.490	0.222	0.110	0.139	3.224
 	Correl	0.557	0.575	0.557	0.540	0.421	0.504	0.628	  1.0
 
 
 8. Missing Attribute Values: None
 
 
 9. Class Distribution:
 
 	Class	Examples
 	-----	--------
 	1	1
 	2	1
 	3	15
 	4	57
 	5	115
 	6	259
 	7	391
 	8	568
 	9	689
 	10	634
 	11	487
 	12	267
 	13	203
 	14	126
 	15	103
 	16	67
 	17	58
 	18	42
 	19	32
 	20	26
 	21	14
 	22	6
 	23	9
 	24	2
 	25	1
 	26	1
 	27	2
 	29	1
 	-----	----
 	Total	4177
 
 Num Instances:     4177
 Num Attributes:    9
 Num Continuous:    8 (Int 1 / Real 7)
 Num Discrete:      1
 Missing values:    0 /  0.0%

     name                      type enum ints real     missing    distinct  (1)
   1 'Sex'                     Enum 100%   0%   0%     0 /  0%     3 /  0%   0% 
   2 'Length'                  Real   0%   0% 100%     0 /  0%   134 /  3%   0% 
   3 'Diameter'                Real   0%   0% 100%     0 /  0%   111 /  3%   0% 
   4 'Height'                  Real   0%   0% 100%     0 /  0%    51 /  1%   0% 
   5 'Whole weight'            Real   0%   0% 100%     0 /  0%  2429 / 58%  31% 
   6 'Shucked weight'          Real   0%   0% 100%     0 /  0%  1515 / 36%  10% 
   7 'Viscera weight'          Real   0%   0% 100%     0 /  0%   880 / 21%   3% 
   8 'Shell weight'            Real   0%   0% 100%     0 /  0%   926 / 22%   8% 
   9 'Class_Rings'             Int    0% 100%   0%     0 /  0%    28 /  1%   0%"
184,kropt,"Classify a chess game based on the position of the white king, the white rook and the black king."
185,baseball,"Database of baseball players and play statistics, including 'Games_played', 'At_bats', 'Runs', 'Hits', 'Doubles', 'Triples', 'Home_runs', 'RBIs', 'Walks', 'Strikeouts', 'Batting_average', 'On_base_pct', 'Slugging_pct' and 'Fielding_ave' 

Notes:  
* Quotes, Single-Quotes and Backslashes were removed, Blanks replaced with Underscores
* Player is an identifier that should be ignored when modelling the data"
186,braziltourism,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
                by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
                consists of a zip file containing two versions of each of 84 data sets, 
                plus this README file. Each data set is given in comma-delimited ASCII
                (.csv) form, and Microsoft Excel (.xls) form.
 
 NOTICE: These data sets may be used freely for scientific, educational and/or
         noncommercial purposes, provided suitable acknowledgment is given (by citing
         the above-named reference).
 
 Further details concerning the book, including information on statistical software
 (including sample S-PLUS/R and SAS code), are available at the web site
 
             http://www.stern.nyu.edu/~jsimonof/AnalCatData


 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: last


 Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
       with Underscores"
187,wine,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title of Database: Wine recognition data
 	Updated Sept 21, 1998 by C.Blake : Added attribute information
 
 2. Sources:
    (a) Forina, M. et al, PARVUS - An Extendible Package for Data
        Exploration, Classification and Correlation. Institute of Pharmaceutical
        and Food Analysis and Technologies, Via Brigata Salerno, 
        16147 Genoa, Italy.
 
    (b) Stefan Aeberhard, email: stefan@coral.cs.jcu.edu.au
    (c) July 1991
 3. Past Usage:
 
    (1)
    S. Aeberhard, D. Coomans and O. de Vel,
    Comparison of Classifiers in High Dimensional Settings,
    Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of
    Mathematics and Statistics, James Cook University of North Queensland.
    (Also submitted to Technometrics).
 
    The data was used with many others for comparing various 
    classifiers. The classes are separable, though only RDA 
    has achieved 100% correct classification.
    (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))
    (All results using the leave-one-out technique)
 
    In a classification context, this is a well posed problem 
    with ""well behaved"" class structures. A good data set 
    for first testing of a new classifier, but not very 
    challenging.
 
    (2) 
    S. Aeberhard, D. Coomans and O. de Vel,
    ""THE CLASSIFICATION PERFORMANCE OF RDA""
    Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of
    Mathematics and Statistics, James Cook University of North Queensland.
    (Also submitted to Journal of Chemometrics).
 
    Here, the data was used to illustrate the superior performance of
    the use of a new appreciation function with RDA. 
 
 4. Relevant Information:
 
    -- These data are the results of a chemical analysis of
       wines grown in the same region in Italy but derived from three
       different cultivars.
       The analysis determined the quantities of 13 constituents
       found in each of the three types of wines. 
 
    -- I think that the initial data set had around 30 variables, but 
       for some reason I only have the 13 dimensional version. 
       I had a list of what the 30 or so variables were, but a.) 
       I lost it, and b.), I would not know which 13 variables
       are included in the set.
 
    -- The attributes are (dontated by Riccardo Leardi, 
 	riclea@anchem.unige.it )
  	1) Alcohol
  	2) Malic acid
  	3) Ash
 	4) Alcalinity of ash  
  	5) Magnesium
 	6) Total phenols
  	7) Flavanoids
  	8) Nonflavanoid phenols
  	9) Proanthocyanins
 	10)Color intensity
  	11)Hue
  	12)OD280/OD315 of diluted wines
  	13)Proline            
 
 5. Number of Instances
 
       	class 1 59
 	class 2 71
 	class 3 48
 
 6. Number of Attributes 
 	
 	13
 
 7. For Each Attribute:
 
 	All attributes are continuous
 	
 	No statistics available, but suggest to standardise
 	variables for certain uses (e.g. for us with classifiers
 	which are NOT scale invariant)
 
 	NOTE: 1st attribute is class identifier (1-3)
 
 8. Missing Attribute Values:
 
 	None
 
 9. Class Distribution: number of instances per class
 
       	class 1 59
 	class 2 71
 	class 3 48

 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: first"
188,eucalyptus,"**Author**: Bruce Bulloch    
**Source**: [WEKA Dataset Collection](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) - part of the agridatasets archive. [This is the true source](http://tunedit.org/repo/Data/Agricultural/eucalyptus.arff)  
**Please cite**: None  

**Eucalyptus Soil Conservation**  
The objective was to determine which seedlots in a species are best for soil conservation in seasonally dry hill country. Determination is found by measurement of height, diameter by height, survival, and other contributing factors. 
 
It is important to note that eucalypt trial methods changed over time; earlier trials included mostly 15 - 30cm tall seedling grown in peat plots and the later trials have included mostly three replications of eight trees grown. This change may contribute to less significant results.

Experimental data recording procedures which require noting include:
 - instances with no data recorded due to experimental recording procedures
   require that the absence of a species from one replicate at a site was
   treated as a missing value, but if absent from two or more replicates at a
   site the species was excluded from the site's analyses.
 - missing data for survival, vigour, insect resistance, stem form, crown form
   and utility especially for the data recorded at the Morea Station; this 
   could indicate the death of species in these areas or a lack in collection
   of data.  

### Attribute Information  
 
  1.  Abbrev - site abbreviation - enumerated
  2.  Rep - site rep - integer
  3.  Locality - site locality in the North Island - enumerated
  4.  Map_Ref - map location in the North Island - enumerated
  5.  Latitude - latitude approximation - enumerated
  6.  Altitude - altitude approximation - integer
  7.  Rainfall - rainfall (mm pa) - integer
  8.  Frosts - frosts (deg. c) - integer
  9.  Year - year of planting - integer
  10. Sp - species code - enumerated
  11. PMCno - seedlot number - integer
  12. DBH - best diameter base height (cm) - real
  13. Ht - height (m) - real
  14. Surv - survival - integer
  15. Vig - vigour - real
  16. Ins_res - insect resistance - real
  17. Stem_Fm - stem form - real
  18. Crown_Fm - crown form - real
  19. Brnch_Fm - branch form - real
  Class:
  20. Utility - utility rating - enumerated

### Relevant papers

Bulluch B. T., (1992) Eucalyptus Species Selection for Soil Conservation in Seasonally Dry Hill Country - Twelfth Year Assessment  New Zealand Journal of Forestry Science 21(1): 10 - 31 (1991)  

Kirsten Thomson and Robert J. McQueen (1996) Machine Learning Applied to Fourteen Agricultural Datasets. University of Waikato Research Report  
https://www.cs.waikato.ac.nz/ml/publications/1996/Thomson-McQueen-96.pdf + the original publication:"
189,kin8nm,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This is data set is concerned with the forward kinematics of an 8 link
 robot arm. Among the existing variants of this data set we have used
 the variant 8nm, which is known to be highly non-linear and medium
 noisy.

 Original source: DELVE repository of data. 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 8192 cases, 9 attributes (0 nominal, 9 continuous)."
190,mbagrade,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Dataset from Smoothing Methods in Statistics 
 (ftp stat.cmu.edu/datasets)

 Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag."
191,wisconsin,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Wisconsin Prognostic Breast Cancer (WPBC)
 
 2. Source Information
 
 a) Creators: 
 
 	Dr. William H. Wolberg, General Surgery Dept., University of
 	Wisconsin,  Clinical Sciences Center, Madison, WI 53792
 	wolberg@eagle.surgery.wisc.edu
 
 	W. Nick Street, Computer Sciences Dept., University of
 	Wisconsin, 1210 West Dayton St., Madison, WI 53706
 	street@cs.wisc.edu  608-262-6619
 
 	Olvi L. Mangasarian, Computer Sciences Dept., University of
 	Wisconsin, 1210 West Dayton St., Madison, WI 53706
 	olvi@cs.wisc.edu 
 
 b) Donor: Nick Street
 
 c) Date: December 1995
 
 3. Past Usage:
 
 	Various versions of this data have been used in the following
 	publications: 
 
 	(i) W. N. Street, O. L. Mangasarian, and W.H. Wolberg. 
 	An inductive learning approach to prognostic prediction. 
 	In A. Prieditis and S. Russell, editors, Proceedings of the
 	Twelfth International Conference on Machine Learning, pages
 	522--530, San Francisco, 1995. Morgan Kaufmann.
 
 	(ii) O.L. Mangasarian, W.N. Street and W.H. Wolberg. 
 	Breast cancer diagnosis and prognosis via linear programming. 
 	Operations Research, 43(4), pages 570-577, July-August 1995. 
 
 	(iii) W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. 
 	Computerized breast cancer diagnosis and prognosis from fine
 	needle aspirates.  Archives of Surgery 1995;130:511-516. 
 
 	(iv) W.H. Wolberg, W.N. Street, and O.L. Mangasarian. 
 	Image analysis and machine learning applied to breast cancer
 	diagnosis and prognosis. Analytical and Quantitative Cytology
 	and Histology, Vol. 17 No. 2, pages 77-87, April 1995.
 
 	(v) W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. 
 	Computer-derived nuclear ``grade'' and breast cancer prognosis. 
 	Analytical and Quantitative Cytology and Histology, Vol. 17,
 	pages 257-264, 1995. 
 
 See also:
 	http://www.cs.wisc.edu/~olvi/uwmp/mpml.html
 	http://www.cs.wisc.edu/~olvi/uwmp/cancer.html
 
 Results:
 
 	Two possible learning problems:
 
 	1) Predicting field 2, outcome: R = recurrent, N = nonrecurrent
 	- Dataset should first be filtered to reflect a particular
 	endpoint; e.g., recurrences before 24 months = positive,
 	nonrecurrence beyond 24 months = negative.
 	- 86.3% accuracy estimated accuracy on 2-year recurrence using
 	previous version of this data.  Learning method: MSM-T (see
 	below) in the 4-dimensional space of Mean Texture, Worst Area,
 	Worst Concavity, Worst Fractal Dimension.
 
 	2) Predicting Time To Recur (field 3 in recurrent records)
 	- Estimated mean error 13.9 months using Recurrence Surface
 	Approximation. (See references (i) and (ii) above)
 
 4. Relevant information
 
 	Each record represents follow-up data for one breast cancer
 	case.  These are consecutive patients seen by Dr. Wolberg
 	since 1984, and include only those cases exhibiting invasive
 	breast cancer and no evidence of distant metastases at the
 	time of diagnosis. 
 
 	The first 30 features are computed from a digitized image of a
 	fine needle aspirate (FNA) of a breast mass.  They describe
 	characteristics of the cell nuclei present in the image.
 	A few of the images can be found at
 	http://www.cs.wisc.edu/~street/images/
 
 	The separation described above was obtained using
 	Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree
 	Construction Via Linear Programming."" Proceedings of the 4th
 	Midwest Artificial Intelligence and Cognitive Science Society,
 	pp. 97-101, 1992], a classification method which uses linear
 	programming to construct a decision tree.  Relevant features
 	were selected using an exhaustive search in the space of 1-4
 	features and 1-3 separating planes.
 
 	The actual linear program used to obtain the separating plane
 	in the 3-dimensional space is that described in:
 	[K. P. Bennett and O. L. Mangasarian: ""Robust Linear
 	Programming Discrimination of Two Linearly Inseparable Sets"",
 	Optimization Methods and Software 1, 1992, 23-34].
 
 	The Recurrence Surface Approximation (RSA) method is a linear
 	programming model which predicts Time To Recur using both
 	recurrent and nonrecurrent cases.  See references (i) and (ii)
 	above for details of the RSA method. 
 
 	This database is also available through the UW CS ftp server:
 
 	ftp ftp.cs.wisc.edu
 	cd math-prog/cpo-dataset/machine-learn/WPBC/
 
 5. Number of instances: 198
 
 6. Number of attributes: 34 (ID, outcome, 32 real-valued input features)
 
 7. Attribute information
 
 1) ID number
 2) Outcome (R = recur, N = nonrecur)
 3) Time (recurrence time if field 2 = R, disease-free time if 
 	field 2	= N)
 4-33) Ten real-valued features are computed for each cell nucleus:
 
 	a) radius (mean of distances from center to points on the perimeter)
 	b) texture (standard deviation of gray-scale values)
 	c) perimeter
 	d) area
 	e) smoothness (local variation in radius lengths)
 	f) compactness (perimeter^2 / area - 1.0)
 	g) concavity (severity of concave portions of the contour)
 	h) concave points (number of concave portions of the contour)
 	i) symmetry 
 	j) fractal dimension (""coastline approximation"" - 1)
 
 Several of the papers listed above contain detailed descriptions of
 how these features are computed. 
 
 The mean, standard error, and ""worst"" or largest (mean of the three
 largest values) of these features were computed for each image,
 resulting in 30 features.  For instance, field 4 is Mean Radius, field
 14 is Radius SE, field 24 is Worst Radius.
 
 Values for features 4-33 are recoded with four significant digits.
 
 34) Tumor size - diameter of the excised tumor in centimeters
 35) Lymph node status - number of positive axillary lymph nodes
 observed at time of surgery
 
 8. Missing attribute values: 
 	Lymph node status is missing in 4 cases.
 
 9. Class distribution: 151 nonrecur, 47 recur

-----------------------------------------------------------------------------------------------------------
 Luis Torgo's version: (reconstructed)
 - removed the four instances with unknown values of the last attribute
 - exchanged the attribute position of attributes n.3 (Time) and n.35
   (Lymph node).
 - removed the attribute outcome as it is the class attribute if the
   problem is treated as a classification one
-----------------------------------------------------------------------------------------------------------"
192,vineyard,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Dataset from Smoothing Methods in Statistics 
 (ftp stat.cmu.edu/datasets)

 Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag."
193,bolts,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Data from StatLib (ftp stat.cmu.edu/datasets)
 
 SUMMARY:
 
 Data from an experiment on the affects of machine adjustments on
 the time to count bolts.  Data appear as the STATS (Issue 10) Challenge.
 
 DATA:
 
 Submitted by W. Robert Stephenson, Iowa State University
                             email: wrstephe@iastate.edu
 
 A manufacturer of automotive accessories provides hardware, e.g. nuts,
 bolts, washers and screws, to fasten the accessory to the car or truck.
 Hardware is counted and packaged automatically.  Specifically, bolts
 are dumped into a large metal dish.  A plate that forms the bottom of
 the dish rotates counterclockwise.  This rotation forces bolts to the
 outside of the dish and up along a narrow ledge.  Due to the vibration
 of the dish caused by the spinning bottom plate, some bolts fall off 
 the ledge and back into the dish.  The ledge spirals up to a point 
 where the bolts are allowed to drop into a pan on a conveyor belt.  
 As a bolt drops, it passes by an electronic eye that counts it.  When 
 the electronic counter reaches the preset number of bolts, the
 rotation is stopped and the conveyor belt is moved forward.  
 
 There are several adjustments on the machine that affect its operation.  
 These include; a speed setting that controls the speed of rotation
 (SPEED1) of the plate at the bottom of the dish, a total number of 
 bolts (TOTAL) to be counted, a second speed setting (SPEED2) that is 
 used to change the speed of rotation (usually slowing it down) for the
 last few bolts, the number of bolts to be counted at this second speed
 (NUMBER2), and the sensitivity of the electronic eye (SENS).  The 
 sensitivity setting is to insure that the correct number of bolts are 
 counted.  Too few bolts packaged causes customer complaints.  Too many
 bolts packaged increases costs.  For each run conducted in this 
 experiment the correct number of bolts was counted.  From an
 engineering standpoint if the correct number of bolts is counted, the 
 sensitivity should not affect the time to count bolts.  The measured 
 response is the time (TIME), in seconds, it takes to count the desired
 number of bolts.  In order to put times on a equal footing the
 response to be analyzed is the time to count 20 bolts (T20BOLT).
 Below are the data for 40 combinations of settings.  RUN is the order 
 in which the data were collected.
 
 Analyze the data.  What adjustments have the greatest effect on the 
 time to count 20 bolts?  How would you adjust the machine to get
 the shortest time to count 20 bolts?  Are there any unusual features
 to the data?
 
 The data description and data may be freely used for non-commercial
 purposes and can be freely distributed.  Copyright remains with the
 author and STATS Magazine."
194,cleveland,"**Author**: Andras Janosi, M.D.  
Donor: David W. Aha (aha@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) - July 1988  
**Please cite**: The author request that any publications resulting from the use of the data include the name of the author.

**Heart Disease Databases: Cleveland**  
This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to this date.  The ""goal"" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  
    
The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.
One file has been ""processed"", that one containing the Cleveland database. 
     
Attribute documentation:  
>
       1 id: patient identification number
       2 ccf: social security number (I replaced this with a dummy value of 0)
       3 age: age in years
       4 sex: sex (1 = male; 0 = female)
       5 painloc: chest pain location (1 = substernal; 0 = otherwise)
       6 painexer (1 = provoked by exertion; 0 = otherwise)
       7 relrest (1 = relieved after rest; 0 = otherwise)
       8 pncaden (sum of 5, 6, and 7)
       9 cp: chest pain type
         -- Value 1: typical angina
         -- Value 2: atypical angina
         -- Value 3: non-anginal pain
         -- Value 4: asymptomatic
      10 trestbps: resting blood pressure (in mm Hg on admission to the 
         hospital)
      11 htn
      12 chol: serum cholestoral in mg/dl
      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
      14 cigs (cigarettes per day)
      15 years (number of years as a smoker)
      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)
      17 dm (1 = history of diabetes; 0 = no such history)
      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
      19 restecg: resting electrocardiographic results
         -- Value 0: normal
         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST 
                     elevation or depression of > 0.05 mV)
         -- Value 2: showing probable or definite left ventricular hypertrophy
                     by Estes' criteria
      20 ekgmo (month of exercise ECG reading)
      21 ekgday(day of exercise ECG reading)
      22 ekgyr (year of exercise ECG reading)
      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
      28 proto: exercise protocol
           1 = Bruce     
           2 = Kottus
           3 = McHenry
           4 = fast Balke
           5 = Balke
           6 = Noughton 
           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was 
               written!)
           8 = bike 125 kpa min/min  
           9 = bike 100 kpa min/min
          10 = bike 75 kpa min/min
          11 = bike 50 kpa min/min
          12 = arm ergometer
      29 thaldur: duration of exercise test in minutes
      30 thaltime: time when ST measure depression was noted
      31 met: mets achieved
      32 thalach: maximum heart rate achieved
      33 thalrest: resting heart rate
      34 tpeakbps: peak exercise blood pressure (first of 2 parts)
      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
      36 dummy
      37 trestbpd: resting blood pressure
      38 exang: exercise induced angina (1 = yes; 0 = no)
      39 xhypo: (1 = yes; 0 = no)
      40 oldpeak = ST depression induced by exercise relative to rest
      41 slope: the slope of the peak exercise ST segment
         -- Value 1: upsloping
         -- Value 2: flat
         -- Value 3: downsloping
      42 rldv5: height at rest
      43 rldv5e: height at peak exercise
      44 ca: number of major vessels (0-3) colored by flourosopy
      45 restckm: irrelevant
      46 exerckm: irrelevant
      47 restef: rest raidonuclid (sp?) ejection fraction
      48 restwm: rest wall (sp?) motion abnormality
         0 = none
         1 = mild or moderate
         2 = moderate or severe
         3 = akinesis or dyskmem (sp?)
      49 exeref: exercise radinalid (sp?) ejection fraction
      50 exerwm: exercise wall (sp?) motion 
      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
      52 thalsev: not used
      53 thalpul: not used
      54 earlobe: not used
      55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")
      56 cday: day of cardiac cath (sp?)
      57 cyr: year of cardiac cath (sp?)
      58 num: diagnosis of heart disease (angiographic disease status)
         -- Value 0: < 50% diameter narrowing
         -- Value 1: > 50% diameter narrowing
         (in any major vessel: attributes 59 through 68 are vessels)
      59 lmt
      60 ladprox
      61 laddist
      62 diag
      63 cxmain
      64 ramus
      65 om1
      66 om2
      67 rcaprox
      68 rcadist
      69 lvx1: not used
      70 lvx2: not used
      71 lvx3: not used
      72 lvx4: not used
      73 lvf: not used
      74 cathef: not used
      75 junk: not used
      76 name: last name of patient 
         (I replaced this with the dummy string ""name"")"
195,auto_price,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This data set consists of three types of entities:
 (a) the specification of an auto in terms of various characteristics;
 (b) its assigned insurance risk rating,;
 (c) its normalized losses in use as compared to other cars. 
 The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially
 assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by
 moving it up (or down) the scale. Actuarians call this process ""symboling"". A value of +3 indicates that the auto is
 risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year.
 This value is normalized for all autos within a particular size classification (two-door small, station wagons,
 sports/speciality, etc...), and represents the average loss per car per year.
 - Note: Several of the attributes in the database could be used as a ""class"" attribute.
 The original data (from the UCI repository) (http://www.ics.uci.edu/~mlearn/MLSummary.html) has 205 instances
 described by 26 attributes :
 - 15 continuous
 - 1 integer
 - 10 nominal
 The following provides more information on these attributes:
 
   1. symboling:                 -3, -2, -1, 0, 1, 2, 3.
   2. normalized-losses:        continuous from 65 to 256.
   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,
                                isuzu, jaguar, mazda, mercedes-benz, mercury,
                                mitsubishi, nissan, peugot, plymouth, porsche,
                                renault, saab, subaru, toyota, volkswagen, volvo
   4. fuel-type:                diesel, gas.
   5. aspiration:               std, turbo.
   6. num-of-doors:             four, two.
   7. body-style:               hardtop, wagon, sedan, hatchback,convertible.
   8. drive-wheels:             4wd, fwd, rwd.
   9. engine-location:          front, rear.
  10. wheel-base:               continuous from 86.6 120.9.
  11. length:                   continuous from 141.1 to 208.1.
  12. width:                    continuous from 60.3 to 72.3.
  13. height:                   continuous from 47.8 to 59.8.
  14. curb-weight:              continuous from 1488 to 4066.
  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.
  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.
  17. engine-size:              continuous from 61 to 326.
  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.
  19. bore:                     continuous from 2.54 to 3.94.
  20. stroke:                   continuous from 2.07 to 4.17.
  21. compression-ratio:        continuous from 7 to 23.
  22. horsepower:               continuous from 48 to 288.
  23. peak-rpm:                 continuous from 4150 to 6600.
  24. city-mpg:                 continuous from 13 to 49.
  25. highway-mpg:              continuous from 16 to 54.
  26. price:                    continuous from 5118 to 45400.
 
 The original data also has some missing attribute values denoted by ""?"" : 
 
    Attribute #:   Number of instances missing a value:
    2.             41
    6.             2
    19.            4
    20.            4
    22.            2
    23.            2
    26.            4
 
 I've changed the original data in the following way :
 - All instances with unknowns were removed giving 159 instances.
 - The goal variable is ""price""
 - All nominal attributes (10) were removed.
 
 Original source: UCI machine learning repository. (http://www.ics.uci.edu/~mlearn/MLSummary.html). 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 159 cases; 14 continuous variables; 1 nominal vars.."
196,autoMpg,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Identifier attribute deleted.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


 1. Title: Auto-Mpg Data
 
 2. Sources:
    (a) Origin:  This dataset was taken from the StatLib library which is
                 maintained at Carnegie Mellon University. The dataset was 
                 used in the 1983 American Statistical Association Exposition.
    (c) Date: July 7, 1993
 
 3. Past Usage:
     -  See 2b (above)
     -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.
        In Proceedings on the Tenth International Conference of Machine 
        Learning, 236-243, University of Massachusetts, Amherst. Morgan
        Kaufmann.
 
 4. Relevant Information:
 
    This dataset is a slightly modified version of the dataset provided in
    the StatLib library.  In line with the use by Ross Quinlan (1993) in
    predicting the attribute ""mpg"", 8 of the original instances were removed 
    because they had unknown values for the ""mpg"" attribute.  The original 
    dataset is available in the file ""auto-mpg.data-original"".
 
    ""The data concerns city-cycle fuel consumption in miles per gallon,
     to be predicted in terms of 3 multivalued discrete and 5 continuous
     attributes."" (Quinlan, 1993)
 
 5. Number of Instances: 398
 
 6. Number of Attributes: 9 including the class attribute
 
 7. Attribute Information:
 
     1. mpg:           continuous
     2. cylinders:     multi-valued discrete
     3. displacement:  continuous
     4. horsepower:    continuous
     5. weight:        continuous
     6. acceleration:  continuous
     7. model year:    multi-valued discrete
     8. origin:        multi-valued discrete
     9. car name:      string (unique for each instance)
 
 8. Missing Attribute Values:  horsepower has 6 missing values"
197,cpu_act,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

The Computer Activity databases are a collection of computer systems
 activity measures. The data was collected from a Sun Sparcstation
 20/712 with 128 Mbytes of memory running in a multi-user university
 department. Users would typically be doing a large variety of tasks
 ranging from accessing the internet, editing files or running very
 cpu-bound programs.  The data was collected continuously on two
 separate occasions. On both occassions, system activity was gathered
 every 5 seconds. The final dataset is taken from both occasions with
 equal numbers of observations coming from each collection epoch.
 
 System measures used:
 1. lread - Reads (transfers per second ) between system memory and user memory.
 2. lwrite - writes (transfers per second) between system memory and user memory.
 3. scall - Number of system calls of all types per second.
 4. sread - Number of system read calls per second.
 5. swrite - Number of system write calls per second . 
 6. fork - Number of system fork calls per second. 
 7. exec - Number of system exec calls per second. 
 8. rchar - Number of characters transferred per second by system read calls.
 9. wchar - Number of characters transfreed per second by system write calls. 
 10. pgout - Number of page out requests per second.
 11. ppgout - Number of pages, paged out per second. 
 12. pgfree - Number of pages per second placed on the free list. 
 13. pgscan - Number of pages checked if they can be freed per second.
 14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.
 15. pgin - Number of page-in requests per second.
 16. ppgin - Number of pages paged in per second.
 17. pflt - Number of page faults caused by protection errors (copy-on-writes). 
 18. vflt - Number of page faults caused by address translation. 
 19. runqsz - Process run queue size.
 20. freemem - Number of memory pages available to user processes.
 21. freeswap - Number of disk blocks available for page swapping. 
 22. usr - Portion of time (%) that cpus run in user mode.
 23. sys - Portion of time (%) that cpus run in system mode.
 24. wio - Portion of time (%) that cpus are idle waiting for block IO.
 25. idle - Portion of time (%) that cpus are otherwise idle.
 
 The two different regression tasks obtained from these databases are:
 
 CompAct 
 Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.
 
 CompAct(s) 
 Predict usr using a restricted number (excluding the paging information (10-18)
 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Original source: DELVE repository of data. 
 Characteristics: 8192 cases, 22 continuous attributes"
198,delta_elevators,"**Author**: Rui Camacho (rcamacho@garfield.fe.up.pt)  
**Source**: [Regression datasets collection Luis Torgo](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html)  
**Please cite**:   

This data set is also obtained from the task of controlling the ailerons of a F16 aircraft, although the target variable and attributes are different from the ailerons domain. The target variable here is a variation instead of an absolute value, and there was some pre-selection of the attributes."
199,fruitfly,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Identifier attribute deleted.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 NAME:  Sexual activity and the lifespan of male fruitflies
 TYPE:  Designed (almost factorial) experiment
 SIZE:  125 observations, 5 variables
 
 DESCRIPTIVE ABSTRACT:
 A cost of increased reproduction in terms of reduced longevity has been
 shown for female fruitflies, but not for males.  The flies used were an
 outbred stock.  Sexual activity was manipulated by supplying individual
 males with one or eight receptive virgin females per day.  The
 longevity of these males was compared with that of two control types.
 The first control consisted of two sets of individual males kept with
 one or eight newly inseminated females.  Newly inseminated females will
 not usually remate for at least two days, and thus served as a control
 for any effect of competition with the male for food or space.  The
 second control was a set of individual males kept with no females.
 There were 25 males in each of the five groups, which were treated
 identically in number of anaesthetizations (using CO2) and provision of
 fresh food medium.
 
 SOURCE:
 Figure 2 in the article ""Sexual Activity and the Lifespan of Male
 Fruitflies"" by Linda Partridge and Marion Farquhar.  _Nature_, 294,
 580-581, 1981.
 
 VARIABLE DESCRIPTIONS:
 Columns  Variable    Description
 -------  --------    -----------
  1- 2    ID          Serial No. (1-25) within each group of 25
                      (the order in which data points were abstracted)
 
  4       PARTNERS    Number of companions (0, 1 or 8)
 
  6       TYPE        Type of companion
                        0: newly pregnant female
                        1: virgin female
                        9: not applicable (when PARTNERS=0)
 
  8- 9    LONGEVITY   Lifespan, in days
 
 11-14    THORAX      Length of thorax, in mm (x.xx)
 
 16-17    SLEEP       Percentage of each day spent sleeping
 
 
 SPECIAL NOTES:
 `Compliance' of the males in the two experimental groups was documented
 as follows:  On two days per week throughout the life of each
 experimental male, the females that had been supplied as virgins to
 that male were kept and examined for fertile eggs.  The insemination
 rate declined from approximately 7 females/day at age one week to just
 under 2/day at age eight weeks in the males supplied with eight virgin
 females per day, and from just under 1/day at age one week to
 approximately 0.6/day at age eight weeks in the males supplied with one
 virgin female per day.  These `compliance' data were not supplied for
 individual males, but the authors say that ""There were no significant
 differences between the individual males within each experimental
 group.""
 
 STORY BEHIND THE DATA:
 James Hanley found this dataset in _Nature_ and was attracted by the
 way the raw data were presented in classical analysis of covariance
 style in Figure 2.  He read the data points from the graphs and brought
 them to the attention of a colleague with whom he was teaching the
 applied statistics course.  Dr. Liddell thought that with only three
 explanatory variables (THORAX, plus PARTNERS and TYPE to describe the
 five groups), it would not be challenging enough as a data-analysis
 project.  He suggested adding another variable.  James Hanley added
 SLEEP, a variable not mentioned in the published article.  Teachers can
 contact us about the construction of this variable.  (We prefer to
 divulge the details at the end of the data-analysis project.)
 
 Further discussion of the background and pedagogical use of this
 dataset can be found in Hanley (1983) and in Hanley and Shapiro
 (1994).  To obtain the Hanley and Shapiro article, send the one-line
 e-mail message:
 send jse/v2n1/datasets.hanley
 to the address archive@jse.stat.ncsu.edu
 
 PEDAGOGICAL NOTES:
 This has been the most successful and the most memorable dataset we
 have used in an ""applications of statistics"" course, which we have
 taught for ten years.  The most common analysis techniques have been
 analysis of variance, classical analysis of covariance, and multiple
 regression.  Because the variable THORAX is so strong (it explains
 about 1/3 of the variance in LONGEVITY), it is important to consider it
 to increase the precision of between-group contrasts.  When students
 first check and find that the distributions of thorax length, and in
 particular, the mean thorax length, are very similar in the different
 groups, many of them are willing to say (in epidemiological
 terminology) that THORAX is not a confounding variable, and that it can
 be omitted from the analysis.
 
 There is usually lively discussion about the primary contrast.  The
 five groups and their special structure allow opportunities for
 students to understand and verbalize what we mean by the term
 ""statistical interaction.""
 
 There is also much debate as to whether one should take the SLEEP
 variable into account.  Some students say that it is an `intermediate'
 variable.  Some students formally test the mean level of SLEEP across
 groups, find one pair where there is a statistically significant
 difference, and want to treat it as a confounding variable.  A few
 students muse about how it was measured.
 
 There is heteroscedasticity in the LONGEVITY variable.
 
 One very observant student (now a professor) argued that THORAX cannot
 be used as a predictor or explanatory variable for the LONGEVITY
 outcome since fruitflies who die young may not be fully grown, i.e., it
 is also an intermediate variable.  One Ph.D. student who had studied
 entomology assured us that fruitflies do not grow longer after birth;
 therefore, the THORAX length is not time-dependent!
 
 Curiously, the dataset has seldom been analyzed using techniques from
 survival analysis.  The fact that there are no censored observations is
 not really an excuse, and one could easily devise a way to introduce
 censoring of LONGEVITY.
 
 REFERENCES:
 Hanley, J. A. (1983), ""Appropriate Uses of Multivariate Analysis,""
 _Annual Review of Public Health_, 4, 155-180.
 
 Hanley, J. A., and Shapiro, S. H. (1994), ""Sexual Activity and the
 Lifespan of Male Fruitflies:  A Dataset That Gets Attention,"" _Journal
 of Statistics Education_, Volume 2, Number 1.
 
 SUBMITTED BY:
 James A. Hanley and Stanley H. Shapiro
 Department of Epidemiology and Biostatistics
 McGill University
 1020 Pine Avenue West
 Montreal, Quebec, H3A 1A2
 Canada
 tel: +1 (514) 398-6270 (JH) 
      +1 (514) 398-6272 (SS)
 fax: +1 (514) 398-4503
 INJH@musicb.mcgill.ca, StanS@epid.lan.mcgill.ca"
200,pbc,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Case number deleted. X treated as the class attribute.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 NAME:  PBC Data
 SIZE:  418 observations, 20 variables
 
 
 
 DESCRIPTIVE ABSTRACT:
 
 Below is a description of the variables recorded from the Mayo Clinic trial 
 in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and 
 1984.  A total of 424 PBC patients, referred to Mayo Clinic during
 that ten-year interval, met eligibility criteria for the randomized placebo 
 controlled trial of the drug D-penicillamine. The first 312 cases in the data 
 set participated in the randomized trial, and contain largely complete data. 
 The additional 112 cases did not participate in the clinical trial, but 
 consented to have basic measurements recorded and to be followed for survival.
 Six of those cases were lost to follow-up shortly after diagnosis, so there 
 are data here on an additional 106 cases as well as the 312 randomized 
 participants. Missing data items are denoted by ""."".  At least one space 
 separates each variable in the .DAT file.  Censoring was due to liver 
 transplantation for twenty-five subjects with the following case numbers: 
 5, 105, 111, 120, 125, 158, 183, 241, 246, 247, 254, 263, 264, 265, 274, 
 288, 291, 295, 297, 345, 361, 362, 375, 380, 383.
 
 
 
 SOURCE:  Counting Processes and Survival Analysis by T. Fleming & 
          D. Harrington, (1991),  published by John Wiley & Sons.
 
 
 
 VARIABLE DESCRIPTIONS:
 
 The data are in free format.  That is, at least one blank space separates
 each variable.  The variables contained in the .DAT are:
 
 
 N:   Case number.
 X:   The number of days between registration and the earlier of
      death, liver transplantation, or study analysis time in July, 1986.
 D:   1 if X is time to death, 0 if time to censoring
 Z1:  Treatment Code, 1 = D-penicillamine, 2 = placebo.
 Z2:  Age in years. For the first 312 cases, age was calculated by
      dividing the number of days between birth and study registration by 365.
 Z3:  Sex, 0 = male, 1 = female.
 Z4:  Presence of ascites, 0 = no, 1 = yes.
 Z5:  Presence of hepatomegaly, 0 = no, 1 = yes.
 Z6:  Presence of spiders 0 = no, 1 = Yes.
 Z7:  Presence of edema, 0 = no edema and no diuretic therapy for
      edema; 0.5 = edema present for which no diuretic therapy was given, or 
      edema resolved with diuretic therapy; 1 = edema despite diuretic therapy
 Z8:  Serum bilirubin, in mg/dl.
 Z9:  Serum cholesterol, in mg/dl.
 Z10: Albumin, in gm/dl.
 Z11: Urine copper, in mg/day.
 Z12: Alkaline phosphatase, in U/liter.
 Z13: SGOT, in U/ml.
 Z14: Triglycerides, in mg/dl.
 Z15: Platelet count; coded value is number of platelets
      per-cubic-milliliter of blood divided by 1000.
 Z16: Prothrombin time, in seconds.
 Z17: Histologic stage of disease, graded 1, 2, 3, or 4.
 
 
 
 
 STORY BEHIND THE DATA:
 
 Between January, 1974 and May, 1984, the Mayo Clinic conducted a
 double-blinded randomized trial in primary biliary cirrhosis of the liver
 (PBC), comparing the drug D-penicillamine (DPCA) with a placebo. There
 were 424 patients who met the eligibility criteria seen at the Clinic while
 the trial was open for patient registration. Both the treating physician and
 the patient agreed to participate in the randomized trial in 312 of the 424
 cases. The date of randomization and a large number of clinical, biochemical,
 serologic, and histologic parameters were recorded for each of the 312
 clinical trial patients. The data from the trial were analyzed in 1986 for
 presentation in the clinical literature. For that analysis, disease and 
 survival status as of July, 1986, were recorded for as many patients as 
 possible.  By that date, 125 of the 312 patients had died, with only 11 
 not attributable to PBC.  Eight patients had been lost to follow up, and 19 
 had undergone liver transplantation. 
 
 PBC is a rare but fatal chronic liver disease of unknown cause,
 with a prevalence of about 50-cases-per-million population. The primary
 pathologic event appears to be the destruction of interlobular bile ducts,
 which may be mediated by immunologic mechanisms. The data discussed here are
 important in two respects. First, controlled clinical trials are difficult to
 complete in rare diseases, and this case series of patients uniformly
 diagnosed, treated, and followed is the largest existing for PBC. The
 treatment comparison in this trial is more precise than in similar trials
 having fewer participants and avoids the bias that may arise in comparing
 a case series to historical controls. Second, the data present an
 opportunity to study the natural history of the disease. We will see that, 
 despite the immunosuppressive properties of DPCA, there are no detectable
 differences between the distributions of survival times for the DPCA and
 placebo treatment groups. This suggests that these groups can be combined
 in studying the association between survival time from randomization and
 clinical and other measurements. In the early to mid 1980s, the rate of 
 successful liver transplant increased substantially, and transplant has 
 become an effective therapy for PBC. The Mayo Clinic data set is therefore 
 one of the last allowing a study of the natural history of PBC in patients 
 who were treated with only supportive care or its equivalent. The PBC data 
 can be used to: estimate a survival distribution; test for differences 
 between two groups; and estimate covariate effects via a regression
 model."
201,pol,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This is a commercial application described in Weiss & Indurkhya (1995). 
 The data describes a telecommunication problem. No further information
 is available.
 
 Characteristics: (10000+5000) cases, 49 continuous attributes 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Original Source: The data in the original format can be obtained 
 from http://www.cs.su.oz.au/~nitin"
202,autoHorse,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Horsepower treated as the class attribute.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 1. Title: 1985 Auto Imports Database
 
 2. Source Information:
    -- Creator/Donor: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
    -- Date: 19 May 1987
    -- Sources:
      1) 1985 Model Import Car and Truck Specifications, 1985 Ward's
         Automotive Yearbook.
      2) Personal Auto Manuals, Insurance Services Office, 160 Water
         Street, New York, NY 10038 
      3) Insurance Collision Report, Insurance Institute for Highway
         Safety, Watergate 600, Washington, DC 20037

 3. Past Usage:
    -- Kibler,~D., Aha,~D.~W., & Albert,~M. (1989).  Instance-based prediction
       of real-valued attributes.  {it Computational Intelligence}, {it 5},
       51--57.
          -- Predicted price of car using all numeric and Boolean attributes
          -- Method: an instance-based learning (IBL) algorithm derived from a
             localized k-nearest neighbor algorithm.  Compared with a
             linear regression prediction...so all instances
             with missing attribute values were discarded.  This resulted with
             a training set of 159 instances, which was also used as a test
             set (minus the actual instance during testing).
          -- Results: Percent Average Deviation Error of Prediction from Actual
             -- 11.84% for the IBL algorithm
             -- 14.12% for the resulting linear regression equation
 
 4. Relevant Information:
    -- Description
       This data set consists of three types of entities: (a) the
       specification of an auto in terms of various characteristics, (b)
       its assigned insurance risk rating, (c) its normalized losses in use
       as compared to other cars.  The second rating corresponds to the
       degree to which the auto is more risky than its price indicates.
       Cars are initially assigned a risk factor symbol associated with its
       price.   Then, if it is more risky (or less), this symbol is
       adjusted by moving it up (or down) the scale.  Actuarians call this
       process ""symboling"".  A value of +3 indicates that the auto is
       risky, -3 that it is probably pretty safe.
 
       The third factor is the relative average loss payment per insured
       vehicle year.  This value is normalized for all autos within a
       particular size classification (two-door small, station wagons,
       sports/speciality, etc...), and represents the average loss per car
       per year.
 
    -- Note: Several of the attributes in the database could be used as a
             ""class"" attribute.
 
 5. Number of Instances: 205
 
 6. Number of Attributes: 26 total
    -- 15 continuous
    -- 1 integer
    -- 10 nominal
 
 7. Attribute Information:     
      Attribute:                Attribute Range:
      ------------------        -----------------------------------------------
   1. symboling:                -3, -2, -1, 0, 1, 2, 3.
   2. normalized-losses:        continuous from 65 to 256.
   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,
                                isuzu, jaguar, mazda, mercedes-benz, mercury,
                                mitsubishi, nissan, peugot, plymouth, porsche,
                                renault, saab, subaru, toyota, volkswagen, volvo
   4. fuel-type:                diesel, gas.
   5. aspiration:               std, turbo.
   6. num-of-doors:             four, two.
   7. body-style:               hardtop, wagon, sedan, hatchback, convertible.
   8. drive-wheels:             4wd, fwd, rwd.
   9. engine-location:          front, rear.
  10. wheel-base:               continuous from 86.6 120.9.
  11. length:                   continuous from 141.1 to 208.1.
  12. width:                    continuous from 60.3 to 72.3.
  13. height:                   continuous from 47.8 to 59.8.
  14. curb-weight:              continuous from 1488 to 4066.
  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.
  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.
  17. engine-size:              continuous from 61 to 326.
  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.
  19. bore:                     continuous from 2.54 to 3.94.
  20. stroke:                   continuous from 2.07 to 4.17.
  21. compression-ratio:        continuous from 7 to 23.
  22. horsepower:               continuous from 48 to 288.
  23. peak-rpm:                 continuous from 4150 to 6600.
  24. city-mpg:                 continuous from 13 to 49.
  25. highway-mpg:              continuous from 16 to 54.
  26. price:                    continuous from 5118 to 45400.
 
 8. Missing Attribute Values: (denoted by ""?"")
    Attribute #:   Number of instances missing a value:
    2.             41
    6.             2
    19.            4
    20.            4
    22.            2
    23.            2
    26.            4%"
203,lowbwt,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Identification code deleted. 

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 NAME:  LOW BIRTH WEIGHT DATA
 KEYWORDS:  Logistic Regression
 SIZE:  189 observations, 11 variables
 
 NOTE:
         These data come from Appendix 1 of Hosmer and Lemeshow (1989).
 These data are copyrighted and must be acknowledged and used accordingly.
 
 DESCRIPTIVE ABSTRACT:
         The goal of this study was to identify risk factors associated with
 giving birth to a low birth weight baby (weighing less than 2500 grams).
 Data were collected on 189 women, 59 of which had low birth weight babies
 and 130 of which had normal birth weight babies.  Four variables which were
 thought to be of importance were age, weight of the subject at her last
 menstrual period, race, and the number of physician visits during the first
 trimester of pregnancy.
 
 
 SOURCE:
          Data were collected at Baystate Medical Center, Springfield,
 Massachusetts, during 1986.
 
 
 NOTE:
           This data set consists of the complete data.  A paired data set
 created from this low birth weight data may be found in plowbwt.dat and
 a 3 to 1 matched data set created from the low birth weight data may be
 found in mlowbwt.dat.
 
 
 
 Table:  Code Sheet for the Variables in the Low Birth Weight Data Set.
 
 Columns   Variable                                              Abbreviation
 -----------------------------------------------------------------------------
 2-4     Identification Code                                     ID
    
 10      Low Birth Weight (0 = Birth Weight ge 2500g,            LOW
                           l = Birth Weight < 2500g)
   
 17-18   Age of the Mother in Years                              AGE
      
 23-25   Weight in Pounds at the Last Menstrual Period           LWT
      
 32      Race (1 = White, 2 = Black, 3 = Other)                  RACE
      
 40      Smoking Status During Pregnancy (1 = Yes, 0 = No)       SMOKE
      
 48      History of Premature Labor (0 = None, 1 = One, etc.)    PTL
      
 55      History of Hypertension (1 = Yes, 0 = No)               HT
      
 61      Presence of Uterine Irritability (1 = Yes, 0 = No)      UI
      
 67      Number of Physician Visits During the First Trimester   FTV
                 (0 = None, 1 = One, 2 = Two, etc.)
      
 73-76   Birth Weight in Grams                                   BWT
 -----------------------------------------------------------------------------
 
 PEDAGOGICAL NOTES:
         These data have been used as an example of fitting a multiple
 logistic regression model.
 
 STORY BEHIND THE DATA:
         Low birth weight is an outcome that has been of concern to physicians
 for years. This is due to the fact that infant mortality rates and birth
 defect rates are very high for low birth weight babies. A woman's behavior
 during pregnancy (including diet, smoking habits, and receiving prenatal care)
 can greatly alter the chances of carrying the baby to term and, consequently,
 of delivering a baby of normal birth weight.
         The variables identified in the code sheet given in the table have been
 shown to be associated with low birth weight in the obstetrical literature. The
 goal of the current study was to ascertain if these variables were important
 in the population being served by the medical center where the data were
 collected.
 
 
 References:
 
 1. Hosmer and Lemeshow, Applied Logistic Regression, Wiley, (1989)."
204,cholesterol,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Cholesterol treated as the class attribute.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Publication Request: 
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    This file describes the contents of the heart-disease directory.
 
    This directory contains 4 databases concerning heart disease diagnosis.
    All attributes are numeric-valued.  The data was collected from the
    four following locations:
 
      1. Cleveland Clinic Foundation (cleveland.data)
      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)
      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)
      4. University Hospital, Zurich, Switzerland (switzerland.data)
 
    Each database has the same instance format.  While the databases have 76
    raw attributes, only 14 of them are actually used.  Thus I've taken the
    liberty of making 2 copies of each database: one with all the attributes
    and 1 with the 14 attributes actually used in past experiments.
 
    The authors of the databases have requested:
 
       ...that any publications resulting from the use of the data include the 
       names of the principal investigator responsible for the data collection
       at each institution.  They would be:
 
        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
           Robert Detrano, M.D., Ph.D.
 
    Thanks in advance for abiding by this request.
 
    David Aha
    July 22, 1988
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
 
 1. Title: Heart Disease Databases
 
 2. Source Information:
    (a) Creators: 
        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
              Robert Detrano, M.D., Ph.D.
    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   
    (c) Date: July, 1988
 
 3. Past Usage:
     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,
        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it 
        International application of a new probability algorithm for the 
        diagnosis of coronary artery disease.}  {it American Journal of 
        Cardiology}, {it 64},304--310.
        -- International Probability Analysis 
        -- Address: Robert Detrano, M.D.
                    Cardiology 111-C
                    V.A. Medical Center
                    5901 E. 7th Street
                    Long Beach, CA 90028
        -- Results in percent accuracy: (for 0.5 probability threshold)
              Data Name:  CDF    CADENZA
           -- Hungarian   77     74
              Long beach  79     77
              Swiss       81     81
           -- Approximately a 77% correct classification accuracy with a
              logistic-regression-derived discriminant function
     2. David W. Aha & Dennis Kibler
        -- 
           
           
           -- Instance-based prediction of heart-disease presence with the 
              Cleveland database
              -- NTgrowth: 77.0% accuracy
              --       C4: 74.8% accuracy
     3. John Gennari
        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of
           incremental concept formation. {it Artificial Intelligence, 40},
           11--61.
        -- Results: 
           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy
              on the Cleveland database.
 
 4. Relevant Information:
      This database contains 76 attributes, but all published experiments
      refer to using a subset of 14 of them.  In particular, the Cleveland
      database is the only one that has been used by ML researchers to 
      this date.  The ""goal"" field refers to the presence of heart disease
      in the patient.  It is integer valued from 0 (no presence) to 4.
      Experiments with the Cleveland database have concentrated on simply
      attempting to distinguish presence (values 1,2,3,4) from absence (value
      0).  
    
      The names and social security numbers of the patients were recently 
      removed from the database, replaced with dummy values.
 
      One file has been ""processed"", that one containing the Cleveland 
      database.  All four unprocessed files also exist in this directory.
     
 5. Number of Instances: 
         Database:    # of instances:
           Cleveland: 303
           Hungarian: 294
         Switzerland: 123
       Long Beach VA: 200
 
 6. Number of Attributes: 76 (including the predicted attribute)
 
 7. Attribute Information:
    -- Only 14 used
       -- 1. #3  (age)       
       -- 2. #4  (sex)       
       -- 3. #9  (cp)        
       -- 4. #10 (trestbps)  
       -- 5. #12 (chol)      
       -- 6. #16 (fbs)       
       -- 7. #19 (restecg)   
       -- 8. #32 (thalach)   
       -- 9. #38 (exang)     
       -- 10. #40 (oldpeak)   
       -- 11. #41 (slope)     
       -- 12. #44 (ca)        
       -- 13. #51 (thal)      
       -- 14. #58 (num)       (the predicted attribute)
 
    -- Complete attribute documentation:
       1 id: patient identification number
       2 ccf: social security number (I replaced this with a dummy value of 0)
       3 age: age in years
       4 sex: sex (1 = male; 0 = female)
       5 painloc: chest pain location (1 = substernal; 0 = otherwise)
       6 painexer (1 = provoked by exertion; 0 = otherwise)
       7 relrest (1 = relieved after rest; 0 = otherwise)
       8 pncaden (sum of 5, 6, and 7)
       9 cp: chest pain type
         -- Value 1: typical angina
         -- Value 2: atypical angina
         -- Value 3: non-anginal pain
         -- Value 4: asymptomatic
      10 trestbps: resting blood pressure (in mm Hg on admission to the 
         hospital)
      11 htn
      12 chol: serum cholestoral in mg/dl
      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
      14 cigs (cigarettes per day)
      15 years (number of years as a smoker)
      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)
      17 dm (1 = history of diabetes; 0 = no such history)
      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
      19 restecg: resting electrocardiographic results
         -- Value 0: normal
         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST 
                     elevation or depression of > 0.05 mV)
         -- Value 2: showing probable or definite left ventricular hypertrophy
                     by Estes' criteria
      20 ekgmo (month of exercise ECG reading)
      21 ekgday(day of exercise ECG reading)
      22 ekgyr (year of exercise ECG reading)
      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
      28 proto: exercise protocol
           1 = Bruce     
           2 = Kottus
           3 = McHenry
           4 = fast Balke
           5 = Balke
           6 = Noughton 
           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was 
               written!)
           8 = bike 125 kpa min/min  
           9 = bike 100 kpa min/min
          10 = bike 75 kpa min/min
          11 = bike 50 kpa min/min
          12 = arm ergometer
      29 thaldur: duration of exercise test in minutes
      30 thaltime: time when ST measure depression was noted
      31 met: mets achieved
      32 thalach: maximum heart rate achieved
      33 thalrest: resting heart rate
      34 tpeakbps: peak exercise blood pressure (first of 2 parts)
      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
      36 dummy
      37 trestbpd: resting blood pressure
      38 exang: exercise induced angina (1 = yes; 0 = no)
      39 xhypo: (1 = yes; 0 = no)
      40 oldpeak = ST depression induced by exercise relative to rest
      41 slope: the slope of the peak exercise ST segment
         -- Value 1: upsloping
         -- Value 2: flat
         -- Value 3: downsloping
      42 rldv5: height at rest
      43 rldv5e: height at peak exercise
      44 ca: number of major vessels (0-3) colored by flourosopy
      45 restckm: irrelevant
      46 exerckm: irrelevant
      47 restef: rest raidonuclid (sp?) ejection fraction
      48 restwm: rest wall (sp?) motion abnormality
         0 = none
         1 = mild or moderate
         2 = moderate or severe
         3 = akinesis or dyskmem (sp?)
      49 exeref: exercise radinalid (sp?) ejection fraction
      50 exerwm: exercise wall (sp?) motion 
      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
      52 thalsev: not used
      53 thalpul: not used
      54 earlobe: not used
      55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")
      56 cday: day of cardiac cath (sp?)
      57 cyr: year of cardiac cath (sp?)
      58 num: diagnosis of heart disease (angiographic disease status)
         -- Value 0: < 50% diameter narrowing
         -- Value 1: > 50% diameter narrowing
         (in any major vessel: attributes 59 through 68 are vessels)
      59 lmt
      60 ladprox
      61 laddist
      62 diag
      63 cxmain
      64 ramus
      65 om1
      66 om2
      67 rcaprox
      68 rcadist
      69 lvx1: not used
      70 lvx2: not used
      71 lvx3: not used
      72 lvx4: not used
      73 lvf: not used
      74 cathef: not used
      75 junk: not used
      76 name: last name of patient 
         (I replaced this with the dummy string ""name"")
 
 9. Missing Attribute Values: Several.  Distinguished with value -9.0.
 
 10. Class Distribution:
         Database:      0   1   2   3   4 Total
           Cleveland: 164  55  36  35  13   303
           Hungarian: 188  37  26  28  15   294
         Switzerland:   8  48  32  30   5   123
       Long Beach VA:  51  56  41  42  10   200"
205,sleep,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Data from StatLib (ftp stat.cmu.edu/datasets)

 Data from which conclusions  were  drawn  in  the  article  ""Sleep  in 
 Mammals: Ecological and Constitutional Correlates"" by Allison, T.  and 
 Cicchetti, D. (1976), _Science_, November 12, vol. 194,  pp.  732-734. 
 Includes brain and body  weight,  life  span,  gestation  time,  time 
 sleeping, and predation and danger indices for 62 mammals.
 
 
 
 Variables below (from left to right) for Mammals Data Set:
 
 species of animal
 
 body weight in kg
 
 brain weight in g
 
 slow wave (""nondreaming"") sleep (hrs/day)
 
 paradoxical (""dreaming"") sleep (hrs/day)
 
 total sleep (hrs/day)  (sum of slow wave and paradoxical sleep)
 
 maximum life span (years)
 
 gestation time (days)
 
 predation index (1-5)
                 1 = minimum (least likely to be preyed upon)
                 5 = maximum (most likely to be preyed upon)
 
 sleep exposure index (1-5)
                 1 = least exposed (e.g. animal sleeps in a 
                     well-protected den)
                 5 = most exposed
 
 overall danger index (1-5)
                 (based on the above two indices and other information)
                 1 = least danger (from other animals)
                 5 = most danger (from other animals)
 
 Note: Missing values denoted by -999.0
 
 
 For more details, see
 
 Allison, Truett and Cicchetti, Domenic V. (1976), ""Sleep  in  Mammals: 
 Ecological and Constitutional  Correlates"",  _Science_,  November  12, 
 vol. 194, pp. 732-734.
 
 The above data set can be freely used for non-commercial purposes  and 
 can be freely distributed (permission in  writing  obtained  from  Dr. 
 Truett Allison).
 
 Submitted by Roger Johnson
 rwjohnso@silver.sdsmt.edu

 Total sleep treated as the class attribute. Attributes for slow
 wave and paradoxical sleep have been deleted. (The animal's
 name has also been deleted.)"
206,triazines,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

The problem is to learn a regression equation/rule/tree to predict the
 activity from the descriptive structural attributes.  The data and
 methodology is described in detail in: - King, Ross .D., Hurst,
 Jonathan. D., and Sternberg, Michael.J.E. A comparison of artificial
 intelligence methods for modelling QSARs Applied Artificial
 Intelligence, 1994 (in press).  - Hurst, Jonathan. D., King, Ross
 .D. and Sternberg, Michael.J.E. Quantitative Structure-Activity
 Relationships by neural networks and inductive logic programming:
 2. The inhibition of dihydrofolate reductase by triazines. Journal of
 Computer Aided Molecular Design, 1994 (in press).
 
 Original source: ?. 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 186 cases; 61 continuous variables"
207,autoPrice,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 All nominal attributes and instances with missing values are deleted.
 Price treated as the class attribute.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 1. Title: 1985 Auto Imports Database
 
 2. Source Information:
    -- Creator/Donor: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
    -- Date: 19 May 1987
    -- Sources:
      1) 1985 Model Import Car and Truck Specifications, 1985 Ward's
         Automotive Yearbook.
      2) Personal Auto Manuals, Insurance Services Office, 160 Water
         Street, New York, NY 10038 
      3) Insurance Collision Report, Insurance Institute for Highway
         Safety, Watergate 600, Washington, DC 20037

 3. Past Usage:
    -- Kibler,~D., Aha,~D.~W., & Albert,~M. (1989).  Instance-based prediction
       of real-valued attributes.  {it Computational Intelligence}, {it 5},
       51--57.
          -- Predicted price of car using all numeric and Boolean attributes
          -- Method: an instance-based learning (IBL) algorithm derived from a
             localized k-nearest neighbor algorithm.  Compared with a
             linear regression prediction...so all instances
             with missing attribute values were discarded.  This resulted with
             a training set of 159 instances, which was also used as a test
             set (minus the actual instance during testing).
          -- Results: Percent Average Deviation Error of Prediction from Actual
             -- 11.84% for the IBL algorithm
             -- 14.12% for the resulting linear regression equation
 
 4. Relevant Information:
    -- Description
       This data set consists of three types of entities: (a) the
       specification of an auto in terms of various characteristics, (b)
       its assigned insurance risk rating, (c) its normalized losses in use
       as compared to other cars.  The second rating corresponds to the
       degree to which the auto is more risky than its price indicates.
       Cars are initially assigned a risk factor symbol associated with its
       price.   Then, if it is more risky (or less), this symbol is
       adjusted by moving it up (or down) the scale.  Actuarians call this
       process ""symboling"".  A value of +3 indicates that the auto is
       risky, -3 that it is probably pretty safe.
 
       The third factor is the relative average loss payment per insured
       vehicle year.  This value is normalized for all autos within a
       particular size classification (two-door small, station wagons,
       sports/speciality, etc...), and represents the average loss per car
       per year.
 
    -- Note: Several of the attributes in the database could be used as a
             ""class"" attribute.
 
 5. Number of Instances: 205
 
 6. Number of Attributes: 26 total
    -- 15 continuous
    -- 1 integer
    -- 10 nominal
 
 7. Attribute Information:     
      Attribute:                Attribute Range:
      ------------------        -----------------------------------------------
   1. symboling:                -3, -2, -1, 0, 1, 2, 3.
   2. normalized-losses:        continuous from 65 to 256.
   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,
                                isuzu, jaguar, mazda, mercedes-benz, mercury,
                                mitsubishi, nissan, peugot, plymouth, porsche,
                                renault, saab, subaru, toyota, volkswagen, volvo
   4. fuel-type:                diesel, gas.
   5. aspiration:               std, turbo.
   6. num-of-doors:             four, two.
   7. body-style:               hardtop, wagon, sedan, hatchback, convertible.
   8. drive-wheels:             4wd, fwd, rwd.
   9. engine-location:          front, rear.
  10. wheel-base:               continuous from 86.6 120.9.
  11. length:                   continuous from 141.1 to 208.1.
  12. width:                    continuous from 60.3 to 72.3.
  13. height:                   continuous from 47.8 to 59.8.
  14. curb-weight:              continuous from 1488 to 4066.
  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.
  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.
  17. engine-size:              continuous from 61 to 326.
  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.
  19. bore:                     continuous from 2.54 to 3.94.
  20. stroke:                   continuous from 2.07 to 4.17.
  21. compression-ratio:        continuous from 7 to 23.
  22. horsepower:               continuous from 48 to 288.
  23. peak-rpm:                 continuous from 4150 to 6600.
  24. city-mpg:                 continuous from 13 to 49.
  25. highway-mpg:              continuous from 16 to 54.
  26. price:                    continuous from 5118 to 45400.
 
 8. Missing Attribute Values: (denoted by ""?"")
    Attribute #:   Number of instances missing a value:
    2.             41
    6.             2
    19.            4
    20.            4
    22.            2
    23.            2
    26.            4%"
208,detroit,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Data from StatLib (ftp stat.cmu.edu/datasets)

 This is the data set called `DETROIT' in the book `Subset selection in
 regression' by Alan J. Miller published in the Chapman & Hall series of
 monographs on Statistics & Applied Probability, no. 40.   The data are
 unusual in that a subset of three predictors can be found which gives a
 very much better fit to the data than the subsets found from the Efroymson
 stepwise algorithm, or from forward selection or backward elimination.
 
 The original data were given in appendix A of `Regression analysis and its
 application: A data-oriented approach' by Gunst & Mason, Statistics
 textbooks and monographs no. 24, Marcel Dekker.   It has caused problems
 because some copies of the Gunst & Mason book do not contain all of the data,
 and because Miller does not say which variables he used as predictors and
 which is the dependent variable.   (HOM was the dependent variable, and the
 predictors were FTP ... WE)
 
 The data were collected by J.C. Fisher and used in his paper: ""Homicide in
 Detroit: The Role of Firearms"", Criminology, vol.14, 387-400 (1976)
 
 
 The data are on the homicide rate in Detroit for the years 1961-1973.
 FTP    - Full-time police per 100,000 population
 UEMP   - %  unemployed in the population
 MAN    - number of manufacturing workers in thousands
 LIC    - Number of handgun licences per 100,000 population
 GR     - Number of handgun registrations per 100,000 population
 CLEAR  - %  homicides cleared by arrests
 WM     - Number of white males in the population
 NMAN   - Number of non-manufacturing workers in thousands
 GOV    - Number of government workers in thousands
 HE     - Average hourly earnings
 WE     - Average weekly earnings
 
 HOM    - Number of homicides per 100,000 of population
 ACC    - Death rate in accidents per 100,000 population
 ASR    - Number of assaults per 100,000 population
 
 N.B. Each case takes two lines."
209,quake,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Dataset from Smoothing Methods in Statistics 
 (ftp stat.cmu.edu/datasets)

 Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag."
210,cloud,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Data from StatLib (ftp stat.cmu.edu/datasets)

 These data are those collected in a cloud-seeding experiment in Tasmania
 between mid-1964 and January 1971.   Their analysis, using regression
 techniques and permutation tests, is discussed in:
 
       Miller, A.J., Shaw, D.E., Veitch, L.G. & Smith, E.J. (1979).
       `Analyzing the results of a cloud-seeding experiment in Tasmania',
       Communications in Statistics - Theory & Methods, vol.A8(10),
       1017-1047.
 
 The rainfalls are period rainfalls in inches.   TE and TW are the east and
 west target areas respectively, while NC, SC and NWC are the corresponding
 rainfalls in the north, south and north-west control areas respectively.
 S = seeded, U = unseeded.

 Rain in eastern target region is being treated
 as the class attribute. (Attribute for rain
 in the western target region has been deleted.)"
211,longley,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Data from StatLib (ftp stat.cmu.edu/datasets)

 The infamous Longley data, ""An appraisal of least-squares programs from
  the point of view of the user"", JASA, 62(1967) p819-841.

 Variables are: Number of people employed   (usually the y variable)
                GNP implicit price deflator
                GNP
                Unemployed
                Armed forces
                Non-institutionalized population >=14 years of age
                Year

 Employment is being treated as the class
 attribute."
212,diabetes_numeric,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This data set concerns the study of the factors affecting patterns of
 insulin-dependent diabetes mellitus in children.  The objective is to
 investigate the dependence of the level of serum C-peptide on the
 various other factors in order to understand the patterns of residual
 insulin secretion. The response measurement is the logarithm of
 C-peptide concentration (pmol/ml) at the diagnosis, and the predictor
 measurements age and base deficit, a measure of acidity.

 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Original source: Book Generalized Additive Models (p.304) by Hastie &
 Tibshirani, Chapman & Hall.  
 Characteristics: 43 cases; 3 continuous variables"
213,pharynx,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Case number deleted. 

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Name:  Pharynx (A clinical Trial in the Trt. of Carcinoma of the Oropharynx).
 SIZE:  195 observations, 13 variables.
 
 
 
 DESCRIPTIVE ABSTRACT:
 
 The .dat file gives the data for a part of a large clinical trial
 carried out by the Radiation Therapy Oncology Group in the United States. 
 The full study included patients with squamous carcinoma of 15 sites in 
 the mouth and throat, with 16 participating institutions, though only data 
 on three sites in the oropharynx reported by the six largest institutions 
 are considered here. Patients entering the study were randomly assigned to 
 one of two treatment groups, radiation therapy alone or radiation therapy 
 together with a chemotherapeutic agent.  One objective of the study was to 
 compare the two treatment policies with respect to patient survival.
 
 
 
 SOURCE:  The Statistical Analysis of Failure Time Data, by JD Kalbfleisch
          & RL Prentice, (1980),  Published by John Wiley & Sons 
 
 
 
 VARIABLE DESCRIPTIONS:
 
 The data are in free format.  That is, at least one blank space separates 
 each variable in the .dat file.  The variables are as follows:
 
 
 Case:         Case Number
 Inst:         Participating Institution
 sex:          1=male, 2=female
 Treatment:    1=standard, 2=test
 Grade:        1=well differentiated, 2=moderately differentiated, 
               3=poorly differentiated,  9=missing
 Age:          In years at time of diagnosis
 Condition:    1=no disability, 2=restricted work, 3=requires assistance with
               self care, 4=bed confined,  9=missing
 Site:         1=faucial arch, 2=tonsillar fossa, 3=posterior pillar,
               4=pharyngeal tongue, 5=posterior wall
 T staging:    1=primary tumor measuring 2 cm or less in largest diameter,
               2=primary tumor measuring 2 cm to 4 cm in largest diameter with
               minimal infiltration in depth, 3=primary tumor measuring more 
               than 4 cm, 4=massive invasive tumor
 N staging:    0=no clinical evidence of node metastases, 1=single positive
               node 3 cm or less in diameter, not fixed, 2=single positive
               node more than 3 cm in diameter, not fixed, 3=multiple
               positive nodes or fixed positive nodes 
 Entry Date:   Date of study entry: Day of year and year
 Status:       0=censored,  1=dead
 Time:         Survival time in days from day of diagnosis 
 
 
 
 
 
 
 STORY BEHIND THE DATA:
 
 Approximately 30% of the survival times are censored owing primarily to 
 patients surviving to the time of analysis. Some patients were lost
 to follow-up because the patient moved or transferred to an institution not
 participating in the study, though these cases were relatively rare. From 
 a statistical point of view, an important feature of these data is the 
 considerable lack of homogeneity between individuals being studied. 
 Of course, as part of the study design, certain criteria for patient 
 eligibility had to be met which eliminated extremes in the extent of disease, 
 but still many factors are not controlled.
 
 This study included measurements of many covariates which would be expected 
 to relate to survival experience. Six such variables are given in the data 
 (sex, T staging, N staging, age, general condition, and grade).   The site 
 of the primary tumor and possible differences between participating 
 institutions require consideration as well.
      
 The T,N staging classification gives a measure of the extent of the tumor at 
 the primary site and at regional lymph nodes. T=1, refers to a small primary 
 tumor, 2 centimeters or less in largest diameter, whereas T=4 is a massive 
 tumor with extension to adjoining tissue. T=2 and T=3 refer to intermediate
 cases. N=0 refers to there being no clinical evidence of a lymph node 
 metastasis and N=1, N=2, N=3 indicate, in increasing magnitude, the extent of 
 existing lymph node involvement. Patients with classifications T=1,N=0; 
 T=1,N=1;  T=2,N=0; or T=2,N=1, or with distant metastases were excluded 
 from study.
 
 The variable general condition gives a measure of the functional capacity of 
 the patient at the time of diagnosis (1 refers to no disability whereas
 4 denotes bed confinement; 2 and 3 measure intermediate levels). The variable
 grade is a measure of the degree of differentiation of the tumor (the degree
 to which the tumor cell resembles the host cell) from 1 (well differentiated) 
 to 3 (poorly differentiated)
 
 In addition to the primary question whether the combined treatment mode is
 preferable to the conventional radiation therapy, it is of considerable 
 interest to determine the extent to which the several covariates relate to
 subsequent survival.  It is also imperative in answering the primary question 
 to adjust the survivals for possible imbalance that may be present in the 
 study with regard to the other covariates. Such problems are similar to those 
 encountered in the classical theory of linear regression and the analysis of 
 covariance.  Again, the need to accommodate censoring is an important 
 distinguishing point. In many situations it is also important to develop 
 nonparametric and robust procedures since there is frequently little empirical
 or theoretical work to support a particular family of failure time 
 distributions."
214,baskball,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Dataset from Smoothing Methods in Statistics 
 (ftp stat.cmu.edu/datasets)

 Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag.


 Points scored per minute is being treated as
 the class attribute."
215,2dplanes,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This is an artificial data set described in Breiman et al. (1984,p.238) 
 (with variance 1 instead of 2).  
 
 Generate the values of the 10 attributes independently
 using the following probabilities:

 P(X_1 = -1) = P(X_1 = 1) = 1/2
 P(X_m = -1) = P(X_m = 0) = P(X_m = 1) = 1/3, m=2,...,10

 Obtain the value of the target variable Y using the rule:

 if X_1 = 1 set Y = 3 + 3X_2 + 2X_3 + X_4 + sigma(0,1)
 if X_1 = -1 set Y = -3 + 3X_5 + 2X_6 + X_7 + sigma(0,1)

 Characteristics: 40768 cases, 11 continuous attributes
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Original source: Breiman et al. (1984, p.238)."
216,elevators,"This data set is also obtained from the task of controlling a F16
aircraft, although the target variable and attributes are different
from the ailerons domain. In this case the goal variable is related to
an action taken on the elevators of the aircraft."
217,pyrim,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

The task consists of Learning Quantitative Structure Activity
 Relationships (QSARs). The Inhibition of Dihydrofolate Reductase by
 Pyrimidines.The data are described in: King, Ross .D., Muggleton,
 Steven., Lewis, Richard. and Sternberg, Michael.J.E. Drug Design by
 machine learning: the use of inductive logic programming to model the
 structure-activity relationships of trimethoprim analogues binding to
 dihydrofolate reductase.
 
 Original source: ?. 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 74 cases; 28 continuous variables"
218,house_8L,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This database was designed on the basis of data provided by US Census
 Bureau [http://www.census.gov] (under Lookup Access
 [http://www.census.gov/cdrom/lookup]: Summary Tape File 1). The data
 were collected as part of the 1990 US census. These are mostly counts
 cumulated at different survey levels. For the purpose of this data set
 a level State-Place was used. Data from all states was obtained. Most
 of the counts were changed into appropriate proportions.  There are 4
 different data sets obtained from this database: House(8H) House(8L)
 House(16H) House(16L) These are all concerned with predicting the
 median price of the house in the region based on demographic
 composition and a state of housing market in the region. A number in
 the name signifies the number of attributes of the data set. A
 following letter denotes a very rough approximation to the difficulty
 of the task. For Low task difficulty, more correlated attributes were
 chosen as signified by univariate smooth fit of that input on the
 target. Tasks with High difficulty have had their attributes chosen to
 make the modelling more difficult due to higher variance or lower
 correlation of the inputs to the target.
 
 Original source: DELVE repository of data. 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 22784 cases, 9 continuous attributes."
222,echoMonths,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Survival treated as the class attribute

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 1. Title: Echocardiogram Data
 
 2. Source Information:
    -- Donor: Steven Salzberg (salzberg@cs.jhu.edu)
    -- Collector:
       -- Dr. Evlin Kinney
       -- The Reed Institute
       -- P.O. Box 402603
       -- Maimi, FL 33140-0603
    -- Date Received: 28 February 1989
 
 3. Past Usage:
    -- 1. Salzberg, S. (1988).  Exemplar-based learning: Theory and
          implementation (Technical Report TR-10-88).  Harvard University,
          Center for Research in Computing Technology, Aiken Computation
          Laboratory (33 Oxford Street; Cambridge, MA 02138).
       -- Steve applied his EACH program to predict survival (i.e., life
          or death), did not use the wall-motion attribute, and recorded 87 
          correct and 29 incorrect in an incremental application to this
          database.  He also showed that, by tuning EACH to this domain,
          EACH was able to derive (non-incrementally) a set of 28 
          hyper-rectangles that could perfectly classify 119 instances.
    -- 2. Kan, G., Visser, C., Kooler, J., & Dunning, A. (1986).  Short
          and long term predictive value of wall motion score in acute 
          myocardial infarction.  British Heart Journal, 56, 422-427.
       -- They predicted the same variable (whether patients will live
          one year after a heart attack) using a different set of 345
          instances.  Their statistical test recorded a 61% accuracy
          in predicting that a patient will die (post-hoc fit).
    -- 3. Elvin Kinney (in communication with Steven Salzberg) reported
          that a Cox regression application recorded a 60% accuracy
          in predicting that a patient will die.
 
 4. Relevant Information:
   -- All the patients suffered heart attacks at some point in the past.
      Some are still alive and some are not.  The survival and still-alive
      variables, when taken together, indicate whether a patient survived
      for at least one year following the heart attack.  
 
      The problem addressed by past researchers was to predict from the 
      other variables whether or not the patient will survive at least
      one year.  The most difficult part of this problem is correctly
      predicting that the patient will NOT survive.  (Part of the difficulty
      seems to be the size of the data set.)
 
 5. Number of Instances: 132
 
 6. Number of Attributes: 13 (all numeric-valued)
 
 7. Attribute Information:
    1. survival -- the number of months patient survived (has survived,
                   if patient is still alive).  Because all the patients
                   had their heart attacks at different times, it is 
                   possible that some patients have survived less than
                   one year but they are still alive.  Check the second
                   variable to confirm this.  Such patients cannot be 
                   used for the prediction task mentioned above.
    2. still-alive -- a binary variable.  0=dead at end of survival period,
                      1 means still alive 
    3. age-at-heart-attack -- age in years when heart attack occurred
    4. pericardial-effusion -- binary. Pericardial effusion is fluid
                               around the heart.  0=no fluid, 1=fluid
    5. fractional-shortening -- a measure of contracility around the heart
                                lower numbers are increasingly abnormal
    6. epss -- E-point septal separation, another measure of contractility.  
               Larger numbers are increasingly abnormal.
    7. lvdd -- left ventricular end-diastolic dimension.  This is
               a measure of the size of the heart at end-diastole.
               Large hearts tend to be sick hearts.
    8. wall-motion-score -- a measure of how the segments of the left
                            ventricle are moving
    9. wall-motion-index -- equals wall-motion-score divided by number of
                            segments seen.  Usually 12-13 segments are seen
                            in an echocardiogram.  Use this variable INSTEAD
                            of the wall motion score.
    10. mult -- a derivate var which can be ignored
    11. name -- the name of the patient (I have replaced them with ""name"")
    12. group -- meaningless, ignore it
    13. alive-at-1 -- Boolean-valued. Derived from the first two attributes.
                      0 means patient was either dead after 1 year or had
                      been followed for less than 1 year.  1 means patient 
                      was alive at 1 year.
 
 8. Missing Attribute Values: (denoted by ""?"")
    Attribute #:    Number of Missing Values: (total: 132)
    ------------    -------------------------
               1    2  
               2    1  
               3    5  
               4    1  
               5    8  
               6    15 
               7    11 
               8    4  
               9    1  
              10    4 
              11    0 
              12    22
              13    58
 
 9. Distribution of attribute number 2: still-alive
    Value   Number of instances with this value
     ----   -----------------------------------
       0    88 (dead)
       1    43 (alive)
       ?    1
     Total  132
 
 
 10. Distribution of attribute number 13: alive-at-1
    Value   Number of instances with this value
     ----   -----------------------------------
       0    50
       1    24
       ?    58
     Total  132"
223,stock,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This is a dataset obtained from the StatLib repository. Here is the included description:

 The data provided are daily stock prices from January 1988 through October 1991, for ten aerospace companies.

 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Original source: StatLib repository. 
 Characteristics: 950 cases, 10 continuous attributes"
224,breastTumor,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Tumor-size treated as the class attribute.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Citation Request:
    This breast cancer domain was obtained from the University Medical Centre,
    Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and 
    M. Soklic for providing the data.  Please include this citation if you plan
    to use this database.
 
 1. Title: Breast cancer data (Michalski has used this)
 
 2. Sources: 
    -- Matjaz Zwitter & Milan Soklic (physicians)
       Institute of Oncology 
       University Medical Center
       Ljubljana, Yugoslavia
    -- Donors: Ming Tan and Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
    -- Date: 11 July 1988
 
 3. Past Usage: (Several: here are some)
      -- Michalski,R.S., Mozetic,I., Hong,J., & Lavrac,N. (1986). The 
         Multi-Purpose Incremental Learning System AQ15 and its Testing 
         Application to Three Medical Domains.  In Proceedings of the 
         Fifth National Conference on Artificial Intelligence, 1041-1045,
         Philadelphia, PA: Morgan Kaufmann.
         -- accuracy range: 66%-72%
      -- Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In 
         Progress in Machine Learning (from the Proceedings of the 2nd
         European Working Session on Learning), 11-30, Bled, 
         Yugoslavia: Sigma Press.
         -- 8 test results given: 65%-72% accuracy range
      -- Tan, M., & Eshelman, L. (1988). Using weighted networks to 
         represent classification knowledge in noisy domains.  Proceedings 
         of the Fifth International Conference on Machine Learning, 121-134,
         Ann Arbor, MI.
         -- 4 systems tested: accuracy range was 68%-73.5%
     -- Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A
        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko
        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.
        -- Assistant-86: 78% accuracy
 
 4. Relevant Information:
      This is one of three domains provided by the Oncology Institute
      that has repeatedly appeared in the machine learning literature.
      (See also lymphography and primary-tumor.)
 
      This data set includes 201 instances of one class and 85 instances of
      another class.  The instances are described by 9 attributes, some of
      which are linear and some are nominal.
 
 5. Number of Instances: 286
 
 6. Number of Attributes: 9 + the class attribute
 
 7. Attribute Information:
    1. Class: no-recurrence-events, recurrence-events
    2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.
    3. menopause: lt40, ge40, premeno.
    4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44,
                   45-49, 50-54, 55-59.
    5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26,
                  27-29, 30-32, 33-35, 36-39.
    6. node-caps: yes, no.
    7. deg-malig: 1, 2, 3.
    8. breast: left, right.
    9. breast-quad: left-up, left-low, right-up, right-low, central.
   10. irradiat: yes, no.
 
 8. Missing Attribute Values: (denoted by ""?"")
    Attribute #:  Number of instances with missing values:
    6.             8
    9.             1.
 
 9. Class Distribution:
     1. no-recurrence-events: 201 instances
     2. recurrence-events: 85 instances"
225,puma8NH,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

This is a family of datasets synthetically generated from a realistic
 simulation of the dynamics of a Unimation Puma 560 robot arm. There
 are eight datastets in this family . In this repository we only have
 two of them. They are all variations on the same model; a realistic
 simulation of the dynamics of a Puma 560 robot arm. The task in these
 datasets is to predict the angular accelaration of one of the robot
 arm's links. The inputs include angular positions, velocities and
 torques of the robot arm. The family has been specifically generated
 for the delve environment and so the individual datasets span the
 corners of a cube whose dimensions represent:
 
 Number of inputs 8. 
 degree of non-linearity (fairly linear or non-linear) 
 amount of noise in the output (moderate or high). 
 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Original Source: DELVE repository of data. 
 Characteristics: 8192 (4500+3692) cases, 9 continuous variables."
226,gascons,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Dataset from Smoothing Methods in Statistics 
 (ftp stat.cmu.edu/datasets)

 Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag.


 Gasoline comnsumption is being treated as the class
 attribute."
227,cpu_small,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

The Computer Activity databases are a collection of computer systems
 activity measures. The data was collected from a Sun Sparcstation
 20/712 with 128 Mbytes of memory running in a multi-user university
 department. Users would typically be doing a large variety of tasks
 ranging from accessing the internet, editing files or running very
 cpu-bound programs.  The data was collected continuously on two
 separate occasions. On both occassions, system activity was gathered
 every 5 seconds. The final dataset is taken from both occasions with
 equal numbers of observations coming from each collection epoch.
 
 System measures used:
 1. lread - Reads (transfers per second ) between system memory and user memory.
 2. lwrite - writes (transfers per second) between system memory and user memory.
 3. scall - Number of system calls of all types per second.
 4. sread - Number of system read calls per second.
 5. swrite - Number of system write calls per second . 
 6. fork - Number of system fork calls per second. 
 7. exec - Number of system exec calls per second. 
 8. rchar - Number of characters transferred per second by system read calls.
 9. wchar - Number of characters transfreed per second by system write calls. 
 10. pgout - Number of page out requests per second.
 11. ppgout - Number of pages, paged out per second. 
 12. pgfree - Number of pages per second placed on the free list. 
 13. pgscan - Number of pages checked if they can be freed per second.
 14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.
 15. pgin - Number of page-in requests per second.
 16. ppgin - Number of pages paged in per second.
 17. pflt - Number of page faults caused by protection errors (copy-on-writes). 
 18. vflt - Number of page faults caused by address translation. 
 19. runqsz - Process run queue size.
 20. freemem - Number of memory pages available to user processes.
 21. freeswap - Number of disk blocks available for page swapping. 
 22. usr - Portion of time (%) that cpus run in user mode.
 23. sys - Portion of time (%) that cpus run in system mode.
 24. wio - Portion of time (%) that cpus are idle waiting for block IO.
 25. idle - Portion of time (%) that cpus are otherwise idle.
 
 The two different regression tasks obtained from these databases are:
 
 CompAct 
 Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.
 
 CompAct(s) 
 Predict usr using a restricted number (excluding the paging information (10-18)
 
 Original source: DELVE repository of data. 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 8192 cases, 13 continuous attributes"
228,elusage,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Dataset from Smoothing Methods in Statistics 
 (ftp stat.cmu.edu/datasets)

 Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag.


 Electicity usage is being treated as the
 class attribute."
229,pwLinear,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag."
230,machine_cpu,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

The problem concerns Relative CPU Performance Data. More information can be obtained in the UCI Machine
 Learning repository (http://www.ics.uci.edu/~mlearn/MLSummary.html).
 The used attributes are :
 MYCT: machine cycle time in nanoseconds (integer)
 MMIN: minimum main memory in kilobytes (integer)
 MMAX: maximum main memory in kilobytes (integer)
 CACH: cache memory in kilobytes (integer)
 CHMIN: minimum channels in units (integer)
 CHMAX: maximum channels in units (integer)
 PRP: published relative performance (integer) (target variable)
 
 Original source: UCI machine learning repository. 
 Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
 http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
 Characteristics: 209 cases; 6 continuous variables"
231,hungarian,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

Publication Request: 
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    This file describes the contents of the heart-disease directory.
 
    This directory contains 4 databases concerning heart disease diagnosis.
    All attributes are numeric-valued.  The data was collected from the
    four following locations:
 
      1. Cleveland Clinic Foundation (cleveland.data)
      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)
      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)
      4. University Hospital, Zurich, Switzerland (switzerland.data)
 
    Each database has the same instance format.  While the databases have 76
    raw attributes, only 14 of them are actually used.  Thus I've taken the
    liberty of making 2 copies of each database: one with all the attributes
    and 1 with the 14 attributes actually used in past experiments.
 
    The authors of the databases have requested:
 
       ...that any publications resulting from the use of the data include the 
       names of the principal investigator responsible for the data collection
       at each institution.  They would be:
 
        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
           Robert Detrano, M.D., Ph.D.
 
    Thanks in advance for abiding by this request.
 
    David Aha
    July 22, 1988
    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
 
 1. Title: Heart Disease Databases
 
 2. Source Information:
    (a) Creators: 
        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
              Robert Detrano, M.D., Ph.D.
    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   
    (c) Date: July, 1988
 
 3. Past Usage:
     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,
        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it 
        International application of a new probability algorithm for the 
        diagnosis of coronary artery disease.}  {it American Journal of 
        Cardiology}, {it 64},304--310.
        -- International Probability Analysis 
        -- Address: Robert Detrano, M.D.
                    Cardiology 111-C
                    V.A. Medical Center
                    5901 E. 7th Street
                    Long Beach, CA 90028
        -- Results in percent accuracy: (for 0.5 probability threshold)
              Data Name:  CDF    CADENZA
           -- Hungarian   77     74
              Long beach  79     77
              Swiss       81     81
           -- Approximately a 77% correct classification accuracy with a
              logistic-regression-derived discriminant function
     2. David W. Aha & Dennis Kibler
        -- 
           
           
           -- Instance-based prediction of heart-disease presence with the 
              Cleveland database
              -- NTgrowth: 77.0% accuracy
              --       C4: 74.8% accuracy
     3. John Gennari
        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of
           incremental concept formation. {it Artificial Intelligence, 40},
           11--61.
        -- Results: 
           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy
              on the Cleveland database.
 
 4. Relevant Information:
      This database contains 76 attributes, but all published experiments
      refer to using a subset of 14 of them.  In particular, the Cleveland
      database is the only one that has been used by ML researchers to 
      this date.  The ""goal"" field refers to the presence of heart disease
      in the patient.  It is integer valued from 0 (no presence) to 4.
      Experiments with the Cleveland database have concentrated on simply
      attempting to distinguish presence (values 1,2,3,4) from absence (value
      0).  
    
      The names and social security numbers of the patients were recently 
      removed from the database, replaced with dummy values.
 
      One file has been ""processed"", that one containing the Cleveland 
      database.  All four unprocessed files also exist in this directory.
     
 5. Number of Instances: 
         Database:    # of instances:
           Cleveland: 303
           Hungarian: 294
         Switzerland: 123
       Long Beach VA: 200
 
 6. Number of Attributes: 76 (including the predicted attribute)
 
 7. Attribute Information:
    -- Only 14 used
       -- 1. #3  (age)       
       -- 2. #4  (sex)       
       -- 3. #9  (cp)        
       -- 4. #10 (trestbps)  
       -- 5. #12 (chol)      
       -- 6. #16 (fbs)       
       -- 7. #19 (restecg)   
       -- 8. #32 (thalach)   
       -- 9. #38 (exang)     
       -- 10. #40 (oldpeak)   
       -- 11. #41 (slope)     
       -- 12. #44 (ca)        
       -- 13. #51 (thal)      
       -- 14. #58 (num)       (the predicted attribute)
 
    -- Complete attribute documentation:
       1 id: patient identification number
       2 ccf: social security number (I replaced this with a dummy value of 0)
       3 age: age in years
       4 sex: sex (1 = male; 0 = female)
       5 painloc: chest pain location (1 = substernal; 0 = otherwise)
       6 painexer (1 = provoked by exertion; 0 = otherwise)
       7 relrest (1 = relieved after rest; 0 = otherwise)
       8 pncaden (sum of 5, 6, and 7)
       9 cp: chest pain type
         -- Value 1: typical angina
         -- Value 2: atypical angina
         -- Value 3: non-anginal pain
         -- Value 4: asymptomatic
      10 trestbps: resting blood pressure (in mm Hg on admission to the 
         hospital)
      11 htn
      12 chol: serum cholestoral in mg/dl
      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
      14 cigs (cigarettes per day)
      15 years (number of years as a smoker)
      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)
      17 dm (1 = history of diabetes; 0 = no such history)
      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
      19 restecg: resting electrocardiographic results
         -- Value 0: normal
         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST 
                     elevation or depression of > 0.05 mV)
         -- Value 2: showing probable or definite left ventricular hypertrophy
                     by Estes' criteria
      20 ekgmo (month of exercise ECG reading)
      21 ekgday(day of exercise ECG reading)
      22 ekgyr (year of exercise ECG reading)
      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
      28 proto: exercise protocol
           1 = Bruce     
           2 = Kottus
           3 = McHenry
           4 = fast Balke
           5 = Balke
           6 = Noughton 
           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was 
               written!)
           8 = bike 125 kpa min/min  
           9 = bike 100 kpa min/min
          10 = bike 75 kpa min/min
          11 = bike 50 kpa min/min
          12 = arm ergometer
      29 thaldur: duration of exercise test in minutes
      30 thaltime: time when ST measure depression was noted
      31 met: mets achieved
      32 thalach: maximum heart rate achieved
      33 thalrest: resting heart rate
      34 tpeakbps: peak exercise blood pressure (first of 2 parts)
      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
      36 dummy
      37 trestbpd: resting blood pressure
      38 exang: exercise induced angina (1 = yes; 0 = no)
      39 xhypo: (1 = yes; 0 = no)
      40 oldpeak = ST depression induced by exercise relative to rest
      41 slope: the slope of the peak exercise ST segment
         -- Value 1: upsloping
         -- Value 2: flat
         -- Value 3: downsloping
      42 rldv5: height at rest
      43 rldv5e: height at peak exercise
      44 ca: number of major vessels (0-3) colored by flourosopy
      45 restckm: irrelevant
      46 exerckm: irrelevant
      47 restef: rest raidonuclid (sp?) ejection fraction
      48 restwm: rest wall (sp?) motion abnormality
         0 = none
         1 = mild or moderate
         2 = moderate or severe
         3 = akinesis or dyskmem (sp?)
      49 exeref: exercise radinalid (sp?) ejection fraction
      50 exerwm: exercise wall (sp?) motion 
      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
      52 thalsev: not used
      53 thalpul: not used
      54 earlobe: not used
      55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")
      56 cday: day of cardiac cath (sp?)
      57 cyr: year of cardiac cath (sp?)
      58 num: diagnosis of heart disease (angiographic disease status)
         -- Value 0: < 50% diameter narrowing
         -- Value 1: > 50% diameter narrowing
         (in any major vessel: attributes 59 through 68 are vessels)
      59 lmt
      60 ladprox
      61 laddist
      62 diag
      63 cxmain
      64 ramus
      65 om1
      66 om2
      67 rcaprox
      68 rcadist
      69 lvx1: not used
      70 lvx2: not used
      71 lvx3: not used
      72 lvx4: not used
      73 lvf: not used
      74 cathef: not used
      75 junk: not used
      76 name: last name of patient 
         (I replaced this with the dummy string ""name"")
 
 9. Missing Attribute Values: Several.  Distinguished with value -9.0.
 
 10. Class Distribution:
         Database:      0   1   2   3   4 Total
           Cleveland: 164  55  36  35  13   303
           Hungarian: 188  37  26  28  15   294
         Switzerland:   8  48  32  30   5   123
       Long Beach VA:  51  56  41  42  10   200"
232,fishcatch,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 Weight treated as the class attribute. Identifier deleted.

 As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
 using instance-based learning with encoding length selection. In Progress
 in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 NAME:  fishcatch
 TYPE:  Sample 
 SIZE:  159 observations, 8 variables
 
 DESCRIPTIVE ABSTRACT:
 
 159 fishes of 7 species are caught and measured. Altogether there are
 8 variables.  All the fishes are caught from the same lake
 (Laengelmavesi) near Tampere in Finland.
 
 SOURCES:
 Brofeldt, Pekka: Bidrag till kaennedom on fiskbestondet i vaera
         sjoear. Laengelmaevesi. T.H.Jaervi: Finlands Fiskeriet  Band 4,
         Meddelanden utgivna av fiskerifoereningen i Finland.
         Helsingfors 1917
 
 VARIABLE DESCRIPTIONS:
 
 1  Obs       Observation number ranges from 1 to 159
 2  Species   (Numeric)
         Code Finnish  Swedish    English        Latin      
          1   Lahna    Braxen     Bream          Abramis brama
          2   Siika    Iiden      Whitewish      Leusiscus idus
          3   Saerki   Moerten    Roach          Leuciscus rutilus
          4   Parkki   Bjoerknan  ?              Abramis bjrkna
          5   Norssi   Norssen    Smelt          Osmerus eperlanus
          6   Hauki    Jaedda     Pike           Esox lucius
          7   Ahven    Abborre    Perch          Perca fluviatilis
 
 3  Weight      Weight of the fish (in grams)
 4  Length1     Length from the nose to the beginning of the tail (in cm)
 5  Length2     Length from the nose to the notch of the tail (in cm)
 6  Length3     Length from the nose to the end of the tail (in cm)
 7  Height%     Maximal height as % of Length3
 8  Width%      Maximal width as % of Length3
 9  Sex         1 = male 0 = female
 
 
 
           ___/////___                  _
          /               ___          |
        /             _ /  /          H
      <   )            __)             |
        /__________/   __          _
 
      |------- L1 -------|
      |------- L2 ----------|
      |------- L3 ------------|
 
 
 Values are aligned and delimited by blanks.
 Missing values are denoted with NA.
 There is one data line for each case.
 
 SPECIAL NOTES:
 I have usually calculated
            Height =  Height%*Length3/100
            Widht  =  Widht%*Length3/100
 
 
 PEDAGOGICAL NOTES:
 I have mainly used only  Species=7 (Perch) and here is some of the
 models and test, we have used
 
       Weight=a+b*(Length3*Height*Width)+epsilon
          Ho: a=0;
          Heteroscedastic case. Question: What is proper weighting, 
          if you use Length3 as a weighting variable.
 
       Log(Weight)=a+b1*Length3+epsilon
 
       Weight^(1/3)=a+b1*Length3+epsilon
       (Given by Box-Cox-transformation)
          Ho: a=0;
 
       Log(Weight)=a+b1*Length3+b2*Height+b3*Width+epsilon
          Ho: b1+b2+b3=3;  
          i.e. dimension of the fish = 3
 
       Weight^(1/3)=a+b1*Length3+b2*Height+b3*Width+epsilon
       (Given by Box-Cox-transformation)
          Ho: a=0;
 
       Weight=a*Length3^b1*Height^b2*Width^b3+epsilon
          Nonlinear, heteroscedastic case.
          What is proper weighting?
 
       Is obs 143
 
       143  7  840.0 32.5  35.0  37.3  30.8  20.9  0
 
       an outlier? It had in its stomach 6 roach.
 
 
 
 REFERENCES:
 Brofeldt, Pekka: Bidrag till kaennedom on fiskbestondet i vaara
         sjoear. Laengelmaevesi. T.H.Jaervi: Finlands Fiskeriet  Band 4,
         Meddelanden utgivna av fiskerifoereningen i Finland.
         Helsingfors 1917
 
 
 SUBMITTED BY:
 Juha Puranen
 Departement of statistics
 PL33 (Aleksanterinkatu 7)
 000014 University of Helsinki
 Finland
 e-mail: jpuranen@noppa.helsinki.fi"
244,BNG(anneal),
245,BNG(anneal.ORIG),
246,BNG(labor),
247,BNG(letter),
248,BNG(autos),
249,BNG(lymph),
250,BNG(mfeat-fourier),
251,BNG(breast-w),
252,BNG(mfeat-karhunen),
253,BNG(bridges_version1),
254,BNG(mfeat-zernike),
255,BNG(cmc),
256,BNG(colic.ORIG),
257,BNG(colic),
258,BNG(credit-a),
259,BNG(page-blocks),
260,BNG(credit-g),
261,BNG(pendigits),
262,BNG(cylinder-bands),
263,BNG(dermatology),
264,BNG(sonar),
265,BNG(glass),
266,BNG(heart-c),
267,BNG(heart-statlog),
268,BNG(vehicle),
269,BNG(hepatitis),
271,BNG(waveform-5000),
272,BNG(zoo),
273,IMDB.drama,"**Author**:   Read, Jesse and Bifet, Albert and Pfahringer, Bernhard and Holmes, Geoff
**Source**: 
**Please cite**:   Read, Jesse & Bifet, Albert & Pfahringer, Bernhard & Holmes, Geoff. (2012). Batch-Incremental versus Instance-Incremental Learning in Dynamic and Evolving Data. 313-323. 10.1007/978-3-642-34156-4_29."
274,20_newsgroups.drift,
275,meta_all.arff,
276,meta_batchincremental.arff,
277,meta_ensembles.arff,
278,meta_instanceincremental.arff,
279,meta_stream_intervals.arff,
285,flags,"**Author**: Richard S. Forsyth  
**Source**: Unknown - 5/15/1990  
**Please cite**:   

ARFF version of UCI dataset 'flags'.

Creators: Collected primarily from the ""Collins Gem Guide to Flags"": Collins Publishers (1986). Donor: Richard S. Forsyth. Date 5/15/1990

This data file contains details of various nations and their flags.
With this data you can try things like predicting the religion of a country from its size and the colours in its flag. 10 attributes are numeric-valued.  The remainder are either Boolean-  or nominal-valued.

Number of Instances: 194. Number of attributes: 30 (overall). Missing values: none

Attribute Information:
1. name Name of the country concerned
2. landmass 1=N.America, 2=S.America, 3=Europe, 4=Africa, 4=Asia, 6=Oceania
3. zone Geographic quadrant, based on Greenwich and the Equator 1=NE, 2=SE, 3=SW, 4=NW
4. area in thousands of square km
5. population in round millions
6. language 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others
7. religion 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others
8. bars     Number of vertical bars in the flag
9. stripes  Number of horizontal stripes in the flag
10. colours  Number of different colours in the flag
11. red      0 if red absent, 1 if red present in the flag
12. green    same for green
13. blue     same for blue
14. gold     same for gold (also yellow)
15. white    same for white
16. black    same for black
17. orange   same for orange (also brown)
18. mainhue  predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)
19. circles  Number of circles in the flag
20. crosses  Number of (upright) crosses
21. saltires Number of diagonal crosses
22. quarters Number of quartered sections
23. sunstars Number of sun or star symbols
24. crescent 1 if a crescent moon symbol present, else 0
25. triangle 1 if any triangles present, 0 otherwise
26. icon     1 if an inanimate image present (e.g., a boat), otherwise 0
27. animate  1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise
28. text     1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise
29. topleft  colour in the top-left corner (moving right to decide tie-breaks)
30. botright Colour in the bottom-left corner (moving left to decide 
tie-breaks)"
287,wine_quality,"**Author**: Tobias Kuehn  
**Source**: Unknown - 2009  
**Please cite**:   

1. Title: Wine Quality 

2. Sources
Created by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009
    
3. Past Usage:
P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
Modeling wine preferences by data mining from physicochemical properties.
In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.

In the above reference, two datasets were created, using red and white wine samples.
The inputs include objective tests (e.g. PH values) and the output is based on sensory data (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model these datasets under a regression approach. The support vector machine model achieved the best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T), etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity analysis procedure).
 
4. Relevant Information:
The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables  are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).
These datasets can be viewed as classification or regression tasks.
The classes are ordered and not balanced (e.g. there are munch more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods. 

5. Number of Instances: red wine - first 1599 instances; white wine - instances 1600 to 6497. 
 
6. Number of Attributes: 11 + output attribute
Note: several of the attributes may be correlated, thus it makes sense to apply some sort of feature selection.

7. Attribute information:
For more information, read [Cortez et al., 2009].
Input variables (based on physicochemical tests):
1 - fixed acidity
2 - volatile acidity
3 - citric acid
4 - residual sugar
5 - chlorides
6 - free sulfur dioxide
7 - total sulfur dioxide
8 - density
9 - pH
10 - sulphates
11 - alcohol
Output variable (based on sensory data): 
12 - quality (score between 0 and 10)

8. Missing Attribute Values: None"
293,covertype,"**Author**: Jock A. Blackard, Dr. Denis J. Dean, Dr. Charles W. Anderson   
**Source**: [LibSVM repository](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) - 2013-11-14  
**Please cite**: For the binarization: R. Collobert, S. Bengio, and Y. Bengio. A parallel mixture of SVMs for very large scale problems. Neural Computation, 14(05):1105-1114, 2002.

This is the famous covertype dataset in its binary version, retrieved 2013-11-13 from the libSVM site (called covtype.binary there). Additional to the preprocessing done there (see LibSVM site for details), this dataset was created as  follows:
-load covertpype dataset, unscaled.
-normalize each file columnwise according to the following rules:
-If a column only contains one value (constant feature), it will set to zero and thus removed by sparsity.
-If a column contains two values (binary feature), the value occuring more often will be set to zero, the other to one.
-If a column contains more than two values (multinary/real feature), the column is divided by its std deviation.
-duplicate lines were finally removed.

Preprocessing: Transform from multiclass into binary class."
294,satellite_image,"**Author**:   
**Source**: Unknown - 1993  
**Please cite**:   

Source:
Ashwin Srinivasan
Department of Statistics and Data Modeling
University of Strathclyde
Glasgow
Scotland
UK
ross '@' uk.ac.turing

The original Landsat data for this database was generated from data purchased from NASA by the Australian Centre for Remote Sensing, and used for research at: 
The Centre for Remote Sensing
University of New South Wales
Kensington, PO Box 1
NSW 2033
Australia.

The sample database was generated taking a small section (82 rows and 100 columns) from the original data. The binary values were converted to their present ASCII form by Ashwin Srinivasan. The classification for each pixel was performed on the basis of an actual site visit by Ms. Karen Hall, when working for Professor John A. Richards, at the Centre for Remote Sensing at the University of New South Wales, Australia. Conversion to 3x3 neighbourhoods and splitting into test and training sets was done by Alistair Sutherland.

Data Set Information:
The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by  integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach. One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels. The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes:

Number Class
1 red soil
2 cotton crop
3 grey soil
4 damp grey soil
5 soil with vegetation stubble
6 mixture class (all types present)
7 very damp grey soil
NB. There are no examples with class 6 in this dataset.
 
The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset. In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary.

Attribute Information:
The attributes are numerical, in the range 0 to 255.

UCI: http://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)"
296,Ailerons,"**Author**: Luis Torgo"",""Rui Camacho  
**Source**: Unknown - 2014-08-18  
**Please cite**:   

This data set addresses a control problem, namely flying a F16 aircraft. The attributes describe the status of the aeroplane, while the goal is to predict the control action on the ailerons of the aircraft."
298,coil2000,"**Author**: Peter van der Putten  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+(COIL+2000))  
**Please cite**: P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000. [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)

**Insurance Company Benchmark (COIL 2000)**
Information about customers consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the Dutch data mining company Sentient Machine Research and is based on a real world business problem. The training set contains over 5000 descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains 4000 customers of whom only the organisers know if they have a caravan insurance policy.

The data dictionary describes the variables used and their values: TIC Benchmark Homepage: http://www.liacs.nl/~putten/library/cc2000/ 

### Attribute Information  
Each record consists of 86 attributes, containing sociodemographic data (attribute 1-43) and product ownership (attributes 44-86).The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Attribute ""CARAVAN"", the number of mobile home policies, is the target variable.

All the variables starting with M are zipcode variables. They give information on the distribution of that variable, e.g. Rented house, in the zipcode area of the customer. 

```
1 MOSTYPE Customer Subtype see L0
2 MAANTHUI Number of houses 1  10
3 MGEMOMV Avg size household 1  6
4 MGEMLEEF Avg age see L1
5 MOSHOOFD Customer main type see L2
6 MGODRK Roman catholic see L3
7 MGODPR Protestant ...
8 MGODOV Other religion
9 MGODGE No religion
10 MRELGE Married
11 MRELSA Living together
12 MRELOV Other relation
13 MFALLEEN Singles
14 MFGEKIND Household without children
15 MFWEKIND Household with children
16 MOPLHOOG High level education
17 MOPLMIDD Medium level education
18 MOPLLAAG Lower level education
19 MBERHOOG High status
20 MBERZELF Entrepreneur
21 MBERBOER Farmer
22 MBERMIDD Middle management
23 MBERARBG Skilled labourers
24 MBERARBO Unskilled labourers
25 MSKA Social class A
26 MSKB1 Social class B1
27 MSKB2 Social class B2
28 MSKC Social class C
29 MSKD Social class D
30 MHHUUR Rented house
31 MHKOOP Home owners
32 MAUT1 1 car
33 MAUT2 2 cars
34 MAUT0 No car
35 MZFONDS National Health Service
36 MZPART Private health insurance
37 MINKM30 Income < 30>123.000
42 MINKGEM Average income
43 MKOOPKLA Purchasing power class
44 PWAPART Contribution private third party insurance see L4
45 PWABEDR Contribution third party insurance (firms) ...
46 PWALAND Contribution third party insurane (agriculture)
47 PPERSAUT Contribution car policies
48 PBESAUT Contribution delivery van policies
49 PMOTSCO Contribution motorcycle/scooter policies
50 PVRAAUT Contribution lorry policies
51 PAANHANG Contribution trailer policies
52 PTRACTOR Contribution tractor policies
53 PWERKT Contribution agricultural machines policies 
54 PBROM Contribution moped policies
55 PLEVEN Contribution life insurances
56 PPERSONG Contribution private accident insurance policies
57 PGEZONG Contribution family accidents insurance policies
58 PWAOREG Contribution disability insurance policies
59 PBRAND Contribution fire policies
60 PZEILPL Contribution surfboard policies
61 PPLEZIER Contribution boat policies
62 PFIETS Contribution bicycle policies
63 PINBOED Contribution property insurance policies
64 PBYSTAND Contribution social security insurance policies
65 AWAPART Number of private third party insurance 1 - 12
66 AWABEDR Number of third party insurance (firms) ...
67 AWALAND Number of third party insurane (agriculture)
68 APERSAUT Number of car policies
69 ABESAUT Number of delivery van policies
70 AMOTSCO Number of motorcycle/scooter policies
71 AVRAAUT Number of lorry policies
72 AAANHANG Number of trailer policies
73 ATRACTOR Number of tractor policies
74 AWERKT Number of agricultural machines policies
75 ABROM Number of moped policies
76 ALEVEN Number of life insurances
77 APERSONG Number of private accident insurance policies
78 AGEZONG Number of family accidents insurance policies
79 AWAOREG Number of disability insurance policies
80 ABRAND Number of fire policies
81 AZEILPL Number of surfboard policies
82 APLEZIER Number of boat policies
83 AFIETS Number of bicycle policies
84 AINBOED Number of property insurance policies
85 ABYSTAND Number of social security insurance policies
86 CARAVAN Number of mobile home policies 0 - 1

L0: Value Label
1 High Income, expensive child
2 Very Important Provincials
3 High status seniors
4 Affluent senior apartments
5 Mixed seniors
6 Career and childcare
7 Dinki's (double income no kids)
8 Middle class families
9 Modern, complete families
10 Stable family
11 Family starters
12 Affluent young families
13 Young all american family
14 Junior cosmopolitan
15 Senior cosmopolitans
16 Students in apartments
17 Fresh masters in the city
18 Single youth
19 Suburban youth
20 Etnically diverse
21 Young urban have-nots
22 Mixed apartment dwellers
23 Young and rising
24 Young, low educated 
25 Young seniors in the city
26 Own home elderly
27 Seniors in apartments
28 Residential elderly
29 Porchless seniors: no front yard
30 Religious elderly singles
31 Low income catholics
32 Mixed seniors
33 Lower class large families 
34 Large family, employed child
35 Village families
36 Couples with teens 'Married with children'
37 Mixed small town dwellers
38 Traditional families
39 Large religous families
40 Large family farms
41 Mixed rurals

L1:
1 20-30 years
2 30-40 years
3 40-50 years
4 50-60 years
5 60-70 years
6 70-80 years

L2:
1 Successful hedonists
2 Driven Growers
3 Average Family
4 Career Loners
5 Living well
6 Cruising Seniors
7 Retired and Religeous
8 Family with grown ups
9 Conservative families
10 Farmers

L3:
0 0%
1 1 - 10%
2 11 - 23%
3 24 - 36%
4 37 - 49%
5 50 - 62%
6 63 - 75%
7 76 - 88%
8 89 - 99%
9 100%

L4:
0 f 0
1 f 1  49
2 f 50  99
3 f 100  99
4 f 200  499
5 f 500  999
6 f 1000  4999
7 f 5000  9999
8 f 10.000 - 19.999
9 f 20.000 - ?
```"
299,libras_move,"**Author**: Daniel Baptista Dias, Sarajane Marques Peres, Helton Hideraldo Biscaro  
University of Sao Paulo, School of Art, Sciences and Humanities, Sao Paulo, SP, Brazil  
**Source**: Unknown - November 2008  
**Please cite**:   

### LIBRAS Movement Database
LIBRAS, acronym of the Portuguese name ""LIngua BRAsileira de Sinais"", is the official brazilian sign language. The dataset (movement_libras) contains 15 classes of 24 instances each, where each class references to a hand movement type in LIBRAS. The hand movement is represented as a bidimensional curve performed by the hand in a period of time. The curves were obtained from videos of hand movements, with the Libras performance from 4 different people, during 2 sessions. Each video corresponds to only one hand movement and has about $7$ seconds. Each video corresponds to a function F in a functions space which is the continual version of the input dataset. In the video pre-processing, a time normalization is carried out selecting 45 frames from each video, in according to an uniform distribution. In each frame, the centroid pixels of the segmented objects (the hand) are found, which compose the discrete version of the curve F with 45 points. All curves are normalized in the unitary space.
In order to prepare these movements to be analysed by algorithms, we have carried out a mapping operation, that is, each curve F is mapped in a representation with 90 features, with representing the coordinates of movement. 
Each instance represents 45 points on a bi-dimensional space, which can be plotted in an ordered way (from 1 through 45 as the X coordinate) in order to draw the path of the movement."
300,isolet,"**Author**: Ron Cole and Mark Fanty (cole@cse.ogi.edu, fanty@cse.ogi.edu)  
**Donor**: Tom Dietterich (tgd@cs.orst.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ISOLET)   
**Please cite**: UCI  

### Description

ISOLET (Isolated Letter Speech Recognition) dataset was generated as follows: 150 subjects spoke the name of each letter of the alphabet twice. Hence, there are 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each, 4 groups can serve as training set, the last group as the test set. A total of 3 examples are missing, the authors dropped them due to difficulties in recording. 

This is a good domain for a noisy, perceptual task. It is also a very good domain for testing the scaling abilities of algorithms. For example, C4.5 on this domain is slower than backpropagation!

### Source

* Creators: 
Ron Cole and Mark Fanty 
Department of Computer Science and Engineering, 
Oregon Graduate Institute, Beaverton, OR 97006. 
cole '@' cse.ogi.edu, fanty '@' cse.ogi.edu 

* Donor: 
Tom Dietterich 
Department of Computer Science 
Oregon State University, Corvallis, OR 97331 
tgd '@' cs.orst.edu

### Attributes Information
  
All attributes are continuous, real-valued attributes scaled into the range -1.0 to 1.0. The features are described in the paper by Cole and Fanty cited below. 
The features include spectral coefficients; contour features, sonorant features, pre-sonorant features, and post-sonorant features. The exact order of appearance of the features is not known.

### Relevant papers

Fanty, M., Cole, R. (1991).  Spoken letter recognition.  
In Lippman, R. P., Moody, J., and Touretzky, D. S. (Eds). Advances in Neural Information Processing Systems 3.  San Mateo, CA: Morgan Kaufmann.

Dietterich, T. G., Bakiri, G. (1991)  Error-correcting output codes: A general method for improving multiclass inductive learning programs.  
Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), Anaheim, CA: AAAI Press.

Dietterich, T. G., Bakiri, G. (1994) Solving Multiclass Learning Problems via Error-Correcting Output Codes."
301,ozone_level,"**Author**:   
**Source**: Unknown -   
**Please cite**:   

1. Title: Ozone Level Detection
2. Source:
Kun Zhang
zhang.kun05 '@' gmail.com
Department of Computer Science, 
Xavier University of Lousiana

Wei Fan
wei.fan '@' gmail.com
IBM T.J.Watson Research

XiaoJing Yuan
xyuan '@' uh.edu
Engineering Technology Department, 
College of Technology, University of Houston 

3. Past Usage:
Forecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008.
Discusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods.

A shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in:
Forecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764 

4. Relevant Information:
The following are specifications for several most important attributes 
that are highly valued by Texas Commission on Environmental Quality (TCEQ). 
More details can be found in the two relevant papers.
 
-- O 3 - Local ozone peak prediction
-- Upwind - Upwind ozone background level
-- EmFactor - Precursor emissions related factor
-- Tmax - Maximum temperature in degrees F
-- Tb - Base temperature where net ozone production begins (50 F)
-- SRd - Solar radiation total for the day
-- WSa - Wind speed near sunrise (using 09-12 UTC forecast mode)
-- WSp - Wind speed mid-day (using 15-21 UTC forecast mode) 

5. Number of Instances: 2536

6. Number of Attributes: 73

7. Attribute Information:
1,0 | two classes 1: ozone day, 0: normal day"
307,vowel,"**Author**: Peter Turney (peter@ai.iit.nrc.ca)   
**Source**: [UCI](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/vowel/) - date unknown  
**Please cite**: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)

**Vowel Recognition (Deterding data)**
Speaker independent recognition of the eleven steady state vowels of British English using a specified training set of lpc derived log area ratios.
Collected by David Deterding (data and non-connectionist analysis), Mahesan Niranjan (first connectionist analysis), Tony Robinson (description, program, data, and results)

A very comprehensive description including comments by the authors can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/vowel/vowel.names)

The problem is specified by the accompanying data file, ""vowel.data"".  This
consists of a three dimensional array: voweldata [speaker, vowel, input].
The speakers are indexed by integers 0-89.  (Actually, there are fifteen
individual speakers, each saying each vowel six times.)  The vowels are
indexed by integers 0-10.  For each utterance, there are ten floating-point
input values, with array indices 0-9.

The problem is to train the network as well as possible using only on data
from ""speakers"" 0-47, and then to test the network on speakers 48-89,
reporting the number of correct classifications in the test set.

For a more detailed explanation of the problem, see the excerpt from Tony
Robinson's Ph.D. thesis in the COMMENTS section.  In Robinson's opinion,
connectionist problems fall into two classes, the possible and the
impossible.  He is interested in the latter, by which he means problems
that have no exact solution.  Thus the problem here is not to see how fast
a network can be trained (although this is important), but to maximise a
less than perfect performance.

#### METHODOLOGY

Report the number of test vowels classified correctly, (i.e. the number of
occurences when distance of the correct output to the actual output was the
smallest of the set of distances from the actual output to all possible
target outputs).

Though this is not the focus of Robinson's study, it would also be useful
to report how long the training took (measured in pattern presentations or
with a rough count of floating-point operations required) and what level of
success was achieved on the training and testing data after various amounts
of training.  Of course, the network topology and algorithm used should be
precisely described as well.

#### VARIATIONS

This benchmark is proposed to encourage the exploration of different node
types.  Please theorise/experiment/hack.  The author (Robinson) will try to
correspond by email if requested.  In particular there has been some
discussion recently on the use of a cross-entropy distance measure, and it
would be interesting to see results for that.

#### Notes

1. Each of these numbers is based on a single trial with random starting
weights.  More trials would of course be preferable, but the computational
facilities available to Robinson were limited.

2. Graphs are given in Robinson's thesis showing test-set performance vs.
epoch count for some of the training runs.  In most cases, performance
peaks at around 250 correct, after which performance decays to different
degrees.  The numbers given above are final performance figures after about
3000 trials, not the peak performance obtained during the run.

#### REFERENCES

[Deterding89] D. H. Deterding, 1989, University of Cambridge, ""Speaker
 Normalisation for Automatic Speech Recognition"", submitted for PhD.

[NiranjanFallside88] M. Niranjan and F. Fallside, 1988, Cambridge University
 Engineering Department, ""Neural Networks and Radial Basis Functions in
 Classifying Static Speech Patterns"", CUED/F-INFENG/TR.22.

[RenalsRohwer89-ijcnn] Steve Renals and Richard Rohwer, ""Phoneme
 Classification Experiments Using Radial Basis Functions"", Submitted to
 the International Joint Conference on Neural Networks, Washington,
 1989.

[RabinerSchafer78] L. R. Rabiner and R. W. Schafer, Englewood Cliffs, New
 Jersey, 1978, Prentice Hall, ""Digital Processing of Speech Signals"".

[PragerFallside88] R. W. Prager and F. Fallside, 1988, Cambridge University
 Engineering Department, ""The Modified Kanerva Model for Automatic
 Speech Recognition"", CUED/F-INFENG/TR.6.

[BroomheadLowe88] D. Broomhead and D. Lowe, 1988, Royal Signals and Radar
 Establishment, Malvern, ""Multi-variable Interpolation and Adaptive
 Networks"", RSRE memo, #4148.

[RobinsonNiranjanFallside88-tr] A. J. Robinson and M. Niranjan and F. 
   Fallside, 1988, Cambridge University Engineering Department,
 ""Generalising the Nodes of the Error Propagation Network"",
 CUED/F-INFENG/TR.25.

[Robinson89] A. J. Robinson, 1989, Cambridge University Engineering
 Department, ""Dynamic Error Propagation Networks"".

[McCullochAinsworth88] N. McCulloch and W. A. Ainsworth, Proceedings of
 Speech'88, Edinburgh, 1988, ""Speaker Independent Vowel Recognition
 using a Multi-Layer Perceptron"".

[RobinsonFallside88-neuro] A. J. Robinson and F. Fallside, 1988, Proceedings
 of nEuro'88, Paris, June, ""A Dynamic Connectionist Model for Phoneme
 Recognition.


#### Notes
* This is version 2. Version 1 is hidden because it includes a feature dividing the data in train and test set. In OpenML this information is explicitly available in the corresponding task."
308,puma32H,"**Author**:   
  
**Source**: Unknown -   
**Please cite**:   

This is one of a family of datasets synthetically generated from a realistic simulation of the dynamics of a Unimation Puma 560 robot arm. There are eight datastets in this family . In this repository we only have two of them. They are all variations on the same model; a realistic simulation of the dynamics of a Puma 560 robot arm. The task in these datasets is to predict the angular accelaration of one of the robot arm's links. The inputs include angular positions, velocities and torques of the robot arm. The family has been specifically generated for the delve environment and so the individual datasets span the corners of a cube whose dimensions represent:

Number of inputs 32 
degree of non-linearity (fairly linear or non-linear) 
amount of noise in the output (moderate or high). 

Source: collection of regression datasets by Luis Torgo (torgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Original Source: DELVE repository of data. 
Characteristics: 8192 (4500+3692) cases, 33 continuous variables."
310,mammography,"**Author**:   
  
**Source**: Unknown -   
**Please cite**:   

Mammography dataset

Past Usage:
1. Woods, K., Doss, C., Bowyer, K., Solka, J., Priebe, C.,"
311,oil_spill,"**Author**:   
  
**Source**: Unknown -   
**Please cite**:   

Oil dataset

Past Usage:
1. Kubat, M., Holte, R.,"
312,scene,"**Author**: Matthew R. Boutell, Jiebo Luo, Xipeng Shen, and Christopher M. Brown.  
**Source**: [Mulan](http://mulan.sourceforge.net/datasets-mlc.html)     
**Please cite**: 

### Description

Scene recognition dataset - It contains characteristics about images and their classes. 
The original dataset is a multi-label classification problem with 6 different labels: {Beach, Sunset, FallFoliage, Field, Mountain, Urban}.
The current dataset is a binary classification problem considering just the 'Urban' label.

### Sources

Matthew R. Boutell, Jiebo Luo, Xipeng Shen, and Christopher M. Brown.
Learning multi-label scene classification.
Pattern Recognition, 37(9):1757-1771, 2004. 

### Dataset Information

Multi-label classification problem, based on real-world images.   
Instances: 2407    
Features: 294 numerical features with values between [0,1]   
Classes/Labels: 2 {Urban, Nor Urban}   
No missing values"
313,spectrometer,"**Author**:   
  
**Source**: Unknown - 1988  
**Please cite**:   

1. Title: Part of the IRAS Low Resolution Spectrometer Database
 
2. Sources:
(a) Originator: Infra-Red Astronomy Satellite Project Database
(b) Donor: John Stutz <STUTZ@pluto.arc.nasa.gov> 
(c) Date: March 1988 (approximately)

3. Past Usage: unknown
-- A NASA-Ames research group concerned with unsupervised learning tasks may have used this database during their empirical studies of their algorithm/system (AUTOCLASS II).  See the 1988 Machine Learning Conference Proceedings, 54-64, for a description of their algorithm.

4. Relevant Information: (from John Stutz)
 The Infra-Red Astronomy Satellite (IRAS) was the first attempt to map the full sky at infra-red wavelengths.  This could not be done from ground observatories because large portions of the infra-red spectrum is absorbed by the atmosphere.  The primary observing program was the full high resolution sky mapping performed by scanning at 4 frequencies. The Low Resolution Observation (IRAS-LRS) program observed high intensity sources over two continuous spectral bands.  This database derives from a subset of the higher quality LRS observations taken between 12h and 24h right ascension. 
This database contains 531 high quality spectra derived from the IRAS-LRS database.  The original data contained 100 spectral measurements in each of two overlapping bands.  Of these, 44 blue band and 49 red band channels contain usable flux measurements.  Only these are included here.  The original spectral intensities values are compressed to 4-digits, and each spectrum includes 5 rescaling parameters.  We have used the LRS specified algorithm to rescale these to units of spectral intensity (Janskys).  Total intensity differences have been eliminated by normalizing each spectrum to a mean value of 5000.
This database was originally obtained for use in development and testing of our AutoClass system for Bayesian classification.  We have not retained any results from this development, having concentrated our efforts of a 5425 element version of the same data.  Our classifications were based upon simultaneous modeling of all 93 spectral intensities. With the larger database we were able to find classes that correspond well with known spectral types associated with particular stellar types. We also found classes that match with the spectra expected of certain stellar processes under investigation by Ames astronomers.  These classes have considerably enlarged the set of stars being investigated by those researchers.  

Original Data
The original fortran data file is given in spectra-2.data.  The file spectra-2.head contains information about the .data file contents and how to rescale the compressed spectral intensities. 

5. Number of Instances: 531
 
6. Number of Attributes: 103 (including the 10-attribute ""header"")
 
7. Attribute Information: 
1. LRS-name: (Suspected format: 5 digits, ""+"" or ""-"", 4 digits)
2. LRS-class: integer - The LRS-class values range from 0 - 99 with
the 10's digit giving the basic class and the 1's digit giving the subclass. These classes are based on features (peaks, valleys, and trends) of the spectral curves.  
3. ID-type: integer
4. Right-Ascension: float - Astronomical longitude. 1h = 15deg
5. Declination: float - Astronomical lattitude. -90 <= Dec <= 90
6. Scale Factor: float - Proportional to source strength
7. Blue base 1: integer - linear rescaling coefficient
8. Blue base 2: integer - linear rescaling coefficient
9. Red base 1: integer - linear rescaling coefficient
10. Red base 2: integer - linear rescaling coefficient
11-54: fluxes from the following 44 blue-band channel wavelengths: 
(all given as floating point numerals)
55-103: fluxes from the following 49 red-band channel wavelengths:  (all given as floating point numerals)

UCI: http://archive.ics.uci.edu/ml/datasets/Low+Resolution+Spectrometer"
315,us_crime,"**Author**:   
  
**Source**: Unknown - 2009  
**Please cite**:   

Title: Communities and Crime
 
Abstract: Communities within the United States. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.

Data Set Characteristics:  Multivariate
Attribute Characteristics: Real
Associated Tasks: Regression
Number of Instances: 1994
Number of Attributes: 128
Missing Values? Yes
Area: Social
Date Donated: 2009-07-13
 
Source:
Creator: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle 
University; Philadelphia, PA, 19141, USA
-- culled from 1990 US Census, 1995 US FBI Uniform Crime Report, 1990 US Law Enforcement Management and Administrative Statistics Survey, available from ICPSR at U of Michigan.
-- Donor: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA
-- Date: July 2009

Data Set Information:
Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=122), plus the attribute to be predicted (Per Capita Violent Crimes). The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units. The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in incorrect values for per capita violent crime. These cities are not included in the dataset. Many of these omitted communities were from the midwestern USA. Data is described below based on original values. All numeric data was normalized into the decimal range 0.00-1.00 using an Unsupervised, equal-interval binning method. 
Attributes retain their distribution and skew (hence for example the population 
attribute has a mean value of 0.06 because most communities are small). E.g. An attribute described as 'mean people per household' is actually the normalized (0-1) version of that value. The normalization preserves rough ratios of values WITHIN an attribute (e.g. double the value for double the population within the available precision - except for extreme values (all values more than 3 SD above the mean are normalized to 1.00; all values more than 3 SD below the mean are nromalized to 0.00)).

However, the normalization does not preserve relationships between values BETWEEN attributes (e.g. it would not be meaningful to compare the value for whitePerCap with the value for blackPerCap for a community)
A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data."
316,yeast_ml8,"**Author**:   
  
**Source**: Unknown -   
**Please cite**:   

Yeast dataset

Past Usage:
André Elisseeff and Jason Weston.
A kernel method for multi-labelled classification.
In Thomas G. Dietterich, Susan Becker, and Zoubin Ghahramani, editors, Advances in Neural Information Processing Systems 14, 2002."
327,bridges,"**Author**: Yoram Reich"",""Steven J. Fenves  
  
**Source**: [original](http://openml.org/d/17) -   
**Please cite**:   

Pittsburgh bridges  

This version is derived from version 1 by removing all instances with missing values in the last (target) attribute. The bridges dataset is originally not a classification dataset, put is used so extensively in the literature, using the last attribute as the target attribute. However, this attribute has missing values, which may lead to confusing benchmarking result. Therefore, these instances have been removed. 

Sources: 
-- Yoram Reich and Steven J. Fenves Department of Civil Engineering and Engineering Design Research Center Carnegie Mellon University Pittsburgh, PA 15213  Compiled from various sources.  
-- Date: 1 August 1990  

Attribute Information:   The type field state whether a property is continuous/integer (c)  or nominal (n). For properties with c,n type, the range of continuous numbers is given  first and the possible values of the nominal follow the semi-colon.   

name type possible values comments 
------------------------------------------------------------------------ 
1. IDENTIF - - identifier of the examples 
2. RIVER n A, M, O 
3. LOCATION n 1 to 52 
4. ERECTED c,n 1818-1986 -  CRAFTS, EMERGING, MATURE, MODERN 
5. PURPOSE n WALK, AQUEDUCT, RR, HIGHWAY 
6. LENGTH c,n 804-4558 - SHORT, MEDIUM, LONG 
7. LANES c,n 1, 2, 4, 6 - 1, 2, 4, 6 
8. CLEAR-G n N, G 
9. T-OR-D n THROUGH, DECK 
10. MATERIAL n WOOD, IRON, STEEL 
11. SPAN n SHORT, MEDIUM, LONG 
12. REL-L n S, S-F, F 
13. TYPE n WOOD, SUSPEN, SIMPLE-T, ARCH, CANTILEV, CONT-T"
328,bridges,"**Author**: Yoram Reich"",""Steven J. Fenves  
  
**Source**: [original](http://openml.org/d/19) -   
**Please cite**:   

Pittsburgh bridges  

This version is derived from version 2 (the discretized version) by removing all instances with missing values in the last (target) attribute. The bridges dataset is originally not a classification dataset, put is used so extensively in the literature, using the last attribute as the target attribute. However, this attribute has missing values, which may lead to confusing benchmarking result. Therefore, these instances have been removed. 

Sources: 
-- Yoram Reich and Steven J. Fenves Department of Civil Engineering and Engineering Design Research Center Carnegie Mellon University Pittsburgh, PA 15213  Compiled from various sources.  
-- Date: 1 August 1990  

Attribute Information:   The type field state whether a property is continuous/integer (c)  or nominal (n). For properties with c,n type, the range of continuous numbers is given  first and the possible values of the nominal follow the semi-colon.   

name type possible values comments 
------------------------------------------------------------------------ 
1. IDENTIF - - identifier of the examples 
2. RIVER n A, M, O 
3. LOCATION n 1 to 52 
4. ERECTED c,n 1818-1986 -  CRAFTS, EMERGING, MATURE, MODERN 
5. PURPOSE n WALK, AQUEDUCT, RR, HIGHWAY 
6. LENGTH c,n 804-4558 - SHORT, MEDIUM, LONG 
7. LANES c,n 1, 2, 4, 6 - 1, 2, 4, 6 
8. CLEAR-G n N, G 
9. T-OR-D n THROUGH, DECK 
10. MATERIAL n WOOD, IRON, STEEL 
11. SPAN n SHORT, MEDIUM, LONG 
12. REL-L n S, S-F, F 
13. TYPE n WOOD, SUSPEN, SIMPLE-T, ARCH, CANTILEV, CONT-T"
329,hayes-roth,"**Author**: Barbara and Frederick Hayes-Roth  
  
**Source**: [original](https://archive.ics.uci.edu/ml/datasets/Hayes-Roth) -   
**Please cite**:   

Hayes-Roth Database

This is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.

Source Information: 
(a) Creators: Barbara and Frederick Hayes-Roth 
(b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779  
(c) Date: March, 1989  

Attribute Information: 
-- 1. name: distinct for each instance and represented numerically 
-- 2. hobby: nominal values ranging between 1 and 3 
-- 3. age: nominal values ranging between 1 and 4 
-- 4. educational level: nominal values ranging between 1 and 4 
-- 5. marital status: nominal values ranging between 1 and 4 
-- 6. class: nominal value between 1 and 3  

Detailed description of the experiment: 
1. 3 categories (1, 2, and neither -- which I call 3) 
-- some of the instances could be classified in either class 1 or 2, and they have been evenly distributed between the two classes 
2. 5 Attributes 
-- A. name (a randomly-generated number between 1 and 132) 
-- B. hobby (a randomly-generated number between 1 and 3) 
-- C. age (a number between 1 and 4) 
-- D. education level (a number between 1 and 4) 
-- E. marital status (a number between 1 and 4) 
3. Classification:  
-- only attributes C-E are diagnostic; values for A and B are ignored 
-- Class Neither: if a 4 occurs for any attribute C-E 
-- Class 1: Otherwise, if (# of 1's)>(# of 2's) for attributes C-E 
-- Class 2: Otherwise, if (# of 2's)>(# of 1's) for attributes C-E 
-- Either 1 or 2: Otherwise, if (# of 2's)=(# of 1's) for attributes C-E 
4. Prototypes: 
-- Class 1: 111 
-- Class 2: 222 
-- Class Either: 333 
-- Class Neither: 444"
333,monks-problems-1,"**Author**: Sebastian Thrun (Carnegie Mellon University)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MONK's+Problems) - October 1992  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**The Monk's Problems: Problem 1**  
Once upon a time, in July 1991, the monks of Corsendonk Priory were faced with a school held in their priory, namely the 2nd European Summer School on Machine Learning. After listening more than one week to a wide variety of learning algorithms, they felt rather confused: Which algorithm would be optimal? And which one to avoid? As a consequence of this dilemma, they created a simple task on which all learning algorithms ought to be compared: the three MONK's problems.

The target concept associated with the 1st Monk's problem is the binary outcome of the logical formula:  
MONK-1: (a1 == a2) or (a5 == 1)

In this dataset, the original train and test sets were merged to allow other sampling procedures. However, the original train-test splits can be found as one of the OpenML tasks. 

### Attribute information: 
* attr1: 1, 2, 3 
* attr2: 1, 2, 3 
* attr3: 1, 2 
* attr4: 1, 2, 3 
* attr5: 1, 2, 3, 4 
* attr6: 1, 2 

### Relevant papers  
The MONK's Problems - A Performance Comparison of Different Learning Algorithms, by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. Technical Report CS-CMU-91-197, Carnegie Mellon University, Dec. 1991."
334,monks-problems-2,"**Author**: Sebastian Thrun (Carnegie Mellon University)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MONK's+Problems) - October 1992  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**The Monk's Problems: Problem 2**  
Once upon a time, in July 1991, the monks of Corsendonk Priory were faced with a school held in their priory, namely the 2nd European Summer School on Machine Learning. After listening more than one week to a wide variety of learning algorithms, they felt rather confused: Which algorithm would be optimal? And which one to avoid? As a consequence of this dilemma, they created a simple task on which all learning algorithms ought to be compared: the three MONK's problems.

The target concept associated with the 2nd Monk's problem is the binary outcome of the logical formula:  
MONK-2: EXACTLY TWO of {a1 = 1, a2 = 1, a3 = 1, a4 = 1, a5 = 1, a6 = 1}

In this dataset, the original train and test sets were merged to allow other sampling procedures. However, the original train-test splits can be found as one of the OpenML tasks. 

### Attribute information: 
* attr1: 1, 2, 3 
* attr2: 1, 2, 3 
* attr3: 1, 2 
* attr4: 1, 2, 3 
* attr5: 1, 2, 3, 4 
* attr6: 1, 2 

### Relevant papers  
The MONK's Problems - A Performance Comparison of Different Learning Algorithms, by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. Technical Report CS-CMU-91-197, Carnegie Mellon University, Dec. 1991."
335,monks-problems-3,"**Author**: Sebastian Thrun (Carnegie Mellon University)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MONK's+Problems) - October 1992  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   

**The Monk's Problems: Problem 3**  
Once upon a time, in July 1991, the monks of Corsendonk Priory were faced with a school held in their priory, namely the 2nd European Summer School on Machine Learning. After listening more than one week to a wide variety of learning algorithms, they felt rather confused: Which algorithm would be optimal? And which one to avoid? As a consequence of this dilemma, they created a simple task on which all learning algorithms ought to be compared: the three MONK's problems.

The target concept associated with the 3rd Monk's problem is the binary outcome of the logical formula:  
MONK-3: (a5 = 3 and a4 = 1) or (a5 /= 4 and a2 /= 3)  
In addition, 5% class noise was added to the training set

In this dataset, the original train and test sets were merged to allow other sampling procedures. However, the original train-test splits can be found as one of the OpenML tasks. 

### Attribute information: 
* attr1: 1, 2, 3 
* attr2: 1, 2, 3 
* attr3: 1, 2 
* attr4: 1, 2, 3 
* attr5: 1, 2, 3, 4 
* attr6: 1, 2 

### Relevant papers  
The MONK's Problems - A Performance Comparison of Different Learning Algorithms, by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. Technical Report CS-CMU-91-197, Carnegie Mellon University, Dec. 1991."
336,SPECT,"**Author**: Krzysztof J. Cios"",""Lukasz A.  
**Source**: [original](https://archive.ics.uci.edu/ml/datasets/SPECT+Heart) -   
**Please cite**:   

SPECT heart data

This is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.  

Sources: 
-- Original owners: Krzysztof J. Cios, Lukasz A. Kurgan University of Colorado at Denver, Denver, CO 80217, U.S.A. Krys.Cios@cudenver.edu Lucy S. Goodenday Medical College of Ohio, OH, U.S.A.  
-- Donors: Lukasz A.Kurgan, Krzysztof J. Cios 
-- Date: 10/01/01  

Relevant Information: The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images.  Each of the patients is classified into two categories: normal and abnormal.  The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images.  As a result, 44 continuous feature pattern was created for each patient. The pattern was further processed to obtain 22 binary feature patterns. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 84.0% accurate (as compared with cardiologists' diagnoses).   

Attribute Information: 
1. OVERALL_DIAGNOSIS: 0,1 (class attribute, binary) 
2. F1: 0,1 (the partial diagnosis 1, binary) 
3. F2: 0,1 (the partial diagnosis 2, binary) 
4. F3: 0,1 (the partial diagnosis 3, binary) 
5. F4: 0,1 (the partial diagnosis 4, binary) 
6. F5: 0,1 (the partial diagnosis 5, binary) 
7. F6: 0,1 (the partial diagnosis 6, binary) 
8. F7: 0,1 (the partial diagnosis 7, binary) 
9. F8: 0,1 (the partial diagnosis 8, binary) 
10. F9: 0,1 (the partial diagnosis 9, binary) 
11. F10: 0,1 (the partial diagnosis 10, binary) 
12. F11: 0,1 (the partial diagnosis 11, binary) 
13. F12: 0,1 (the partial diagnosis 12, binary) 
14. F13: 0,1 (the partial diagnosis 13, binary) 
15. F14: 0,1 (the partial diagnosis 14, binary) 
16. F15: 0,1 (the partial diagnosis 15, binary) 
17. F16: 0,1 (the partial diagnosis 16, binary) 
18. F17: 0,1 (the partial diagnosis 17, binary) 
19. F18: 0,1 (the partial diagnosis 18, binary) 
20. F19: 0,1 (the partial diagnosis 19, binary) 
21. F20: 0,1 (the partial diagnosis 20, binary) 
22. F21: 0,1 (the partial diagnosis 21, binary) 
23. F22: 0,1 (the partial diagnosis 22, binary)"
337,SPECTF,"**Author**: Krzysztof J. Cios"",""Lukasz A.  
**Source**: [original](https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart) -   
**Please cite**:   

SPECTF heart data

This is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.  

NOTE: See the SPECT heart data for binary data for the same classification task.

Sources: 
-- Original owners: Krzysztof J. Cios, Lukasz A. Kurgan University of Colorado at Denver, Denver, CO 80217, U.S.A. Krys.Cios@cudenver.edu Lucy S. Goodenday Medical College of Ohio, OH, U.S.A. 
-- Donors: Lukasz A.Kurgan, Krzysztof J. Cios 
-- Date: 10/01/01  

Relevant Information: The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 77.0% accurate (as compared with cardiologists' diagnoses)."
338,grub-damage,"**Author**: R. J. Townsend  
**Source**: [original](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) -   
**Please cite**:   

Grass Grubs and Damage Ranking

Data source:   R. J. Townsend
AgResearch, Lincoln, New Zealand

Grass grubs are one of the major insect pests of pasture in Canterbury and  can cause severe pasture damage and economic loss. Pastoral damage may occur periodically over wide ranging areas. Grass grub populations are often influenced by biotic factors (diseases) and farming practices (such as irrigation and heavy rolling). The objective of the report was to report on grass grub population and damage levels to provide objective estimates of the annual losses caused by grass grubs.

The original machine learning objective was to find a relationship between grass grub numbers, irrigation and damage ranking for the period between 1986 to 1992.

Attribute Information:
1. year_zone - Years 0, 1, 2, 6, 7, 8, 9 divided into three zones: f, m, c - enumerated
2. year - year of trial - enumerated
3. strip - strip of paddock sampled - integer
4. pdk - paddock sampled - integer
5. damage_rankRJT - RJ Townsends damage ranking - enumerated
6. damage_rankALL - other researchers damage ranking - enumerated
7. dry_or_irr - indicates if paddock was dry or irrigated (D: dryland, O: irrigated overhead, B: irrigated border dyke) - enumerated
8. zone - position of paddock (F: foothills, M: midplain, C: coastal) - enumerated
9. GG_new - based on grass grubs per metre squared - enumerated"
339,pasture,"**Author**: Dave Barker  
**Source**: [original](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) -   
**Please cite**:   

Pasture Production

Data source:   Dave Barker
AgResearch Grasslands, Palmerston North, New Zealand

The objective was to predict pasture production from a variety of biophysical factors. Vegetation and soil variables from areas of grazed North Island hill country with different management (fertilizer application/stocking rate) histories (1973-1994) were measured and subdivided into 36 paddocks. Nineteen vegetation (including herbage production); soil chemical, physical and biological; and soil water variables were selected as potentially useful biophysical indicators.

Attribute Information:
1.  fertiliser - fertiliser used - enumerated
2.  slope - slope of the paddock - integer
3.  aspect-dev-NW - the deviation from the north-west - integer
4.  OlsenP - integer
5.  MinN - integer
6.  TS - integer
7.  Ca-Mg - calcium magnesium ration - real
8.  LOM - soil lom (g/100g) - real
9.  NFIX-mean - a mean calculation - real
10. Eworms-main-3 - main 3 spp earth worms per g/m2 - real
11. Eworms-No-species - number of spp - integer
12. KUnSat - mm/hr - real
13. OM - real
14. Air-Perm - real
15. Porosity - real
16. HFRG-pct-mean - mean percent - real
17. legume-yield - kgDM/ha - real
18. OSPP-pct-mean - mean percent - real
19. Jan-Mar-mean-TDR - real
20. Annual-Mean-Runoff - in mm - real
21. root-surface-area - m2/m3 - real
22. Leaf-P - ppm - real
23. pasture-prod-class - pasture production categorisation - enumerated"
340,squash-stored,"**Author**: Winna Harvey  
**Source**: [original](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) -   
**Please cite**:   

Squash Harvest Stored

Data source: Winna Harvey
Crop and Food Research, Christchurch, New Zealand

The purpose of the research was to determine the changes taking place in squash fruit during the maturation and ripening so as to pinpoint the best time to give the best quality at the marketplace (Japan). The squash is transported to Japan by refrigerated cargo vessels and takes three to four weeks to reach the market. Evaluations were carried out at a stage representing the quality inspection stage prior to export and also at the stage it would reach on arriving at the market place. 

The original objectives were to determine which pre-harvest variables contribute to good tasting squash after different periods of storage time. This is determined by whether a measure of acceptability found by categorising each squash as either unacceptable, acceptable or excellent.

The fruit in this dataset were stored before being measured, and they have an extra attribute that squash-unstored lacks - the weight of the fruit after storage.

Attribute Information:
1.  site - where fruit is located - enumerated
2.  daf - number of days after flowering - enumerated
3.  fruit - individual number of the fruit (not unique) - enumerated
4.  weight - weight of whole fruit in grams - real
5.  storewt - weight of fruit after storage - real
6.  pene - penetrometer indicates maturity of fruit at harvest - integer
7.  solids_% - a test for dry matter - integer
8.  brix - a refractometer measurement used to indicate sweetness or ripeness of the fruit - integer 
9.  a - the a coordinate of the HunterLab L-a-b notation of colour measurement - integer
10. egdd - the heat accumulation above a base of 8c from emergence of the plant to harvest of the fruit - real
11. fgdd - the heat accumulation above a base of 8c from flowering to harvesting - real
12. groundspot_a - the number indicating colour of skin where the fruit rested on the ground - integer
13. glucose - measured in mg/100g of fresh weight - integer
14. fructose - measured in mg/100g of fresh weight - integer
15. sucrose - measured in mg/100g of fresh weight - integer
16. total - measured in mg/100g of fresh weight - integer
17. glucose+fructose - measured in mg/100g of fresh weight - integer
18. starch - measured in mg/100g of fresh weight - integer
19. sweetness - the mean of eight taste panel scores; out of 1500 - integer
20. flavour - the mean of eight taste panel scores; out of 1500 - integer
21. dry/moist - the mean of eight taste panel scores; out of 1500 - integer
22. fibre - the mean of eight taste panel scores; out of 1500 - integer
23. heat_input_emerg - the amount of heat emergence after harvest - real
24. heat_input_flower - the amount of heat input before flowering - real
25. Acceptability - the acceptability of the fruit - enumerated"
342,squash-unstored,"**Author**: Winna Harvey  
**Source**: [original](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) -   
**Please cite**:   

Squash Harvest Unstored

Data source: Winna Harvey
Crop and Food Research, Christchurch, New Zealand

The purpose of the research was to determine the changes taking place in squash fruit during the maturation and ripening so as to pinpoint the best time to give the best quality at the market place (Japan). The squash is transported to Japan by refrigerated cargo vessels and takes three to four weeks to reach the market. Evaluations were carried out at a stage representing the quality inspection stage prior to export and also at the stage it would reach on arriving at the market place. 

The original objectives were to determine which pre-harvest variables contribute to good tasting squash after different periods of storage time. This is determined by whether a measure of acceptability found by categorising each squash as either unacceptable, acceptable or excellent.

The fruit in this dataset were not stored before being measured, so they lack an attribute present in the stored data - the weight of the fruit after
storage.

Attribute Information:
1.  site - where fruit is located - enumerated
2.  daf - number of days after flowering - enumerated
3.  fruit - individual number of the fruit (not unique) - enumerated
4.  weight - weight of whole fruit in grams - real
5.  pene - penetrometer indicates maturity of fruit at harvest - integer
6.  solids_% - a test for dry matter - integer
7.  brix - a refractometer measurement used to indicate sweetness or ripeness of the fruit - integer
8.  a - the a-coordinate of the HunterLab L-a-b notation of colour measurement - integer
9.  egdd - the heat accumulation above a base of 8c from emergence of the plant to harvest of the fruit - real
10. fgdd - the heat accumulation above a base of 8c from flowering to harvesting - real
11. groundspot_a - the number indicating colour of skin where the fruit rested on the ground - integer
12. glucose - measured in mg/100g of fresh weight - integer
13. fructose - measured in mg/100g of fresh weight - integer
14. sucrose - measured in mg/100g of fresh weight - integer
15. total - measured in mg/100g of fresh weight - integer
16. glucose+fructose - measured in mg/100g of fresh weight - integer
17. starch - measured in mg/100g of fresh weight - integer
18. sweetness - the mean of eight taste panel scores; out of 1500 - integer
19. flavour - the mean of eight taste panel scores; out of 1500 - integer
20. dry/moist - the mean of eight taste panel scores; out of 1500 - integer
21. fibre - the mean of eight taste panel scores; out of 1500 - integer
22. heat_input_emerg - the amount of heat emergence after harvest - real
23. heat_input_flower - the amount of heat input before flowering - real
24. Acceptability - the acceptability of the fruit - enumerated"
343,white-clover,"**Author**: Ian Tarbotton  
**Source**: [original](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) -   
**Please cite**:   

White Clover Persistence Trials

Data source:   Ian Tarbotton
AgResearch, Whatawhata Research Centre, Hamilton, New Zealand

The objective was to determine the mechanisms which influence the persistence of white clover populations in summer dry hill land. In particular reference to the consequence of a severe summer dry period in 1993/1994 and how it impacted on the performance of three white clover cultivars in an on-going experiment located at Whatawhata Research Centre.

The machine learning objective was to predict the amount of white clover in 1994 from the amount of white clover and other species in the years 1991 to 1994 as well as information on the 'strata' where the white clover was being grown.

Attribute Information:
1.  strata - enumerated
2.  plot - enumerated
3.  paddock - enumerated
4.  WhiteClover-91 - white clover measurement in 1991 - real
5.  BareGround-91 - bare ground measurement in 1991 - real
6.  Cocksfoot-91 - cocksfoot measurement in 1991 - real
7.  OtherGrasses-91 - other grasses measurement in 1991 - real
8.  OtherLegumes-91 - other legumes measurement in 1991 - real
9.  RyeGrass-91 - ryegrass measurement in 1991 - real
10. Weeds-91 - weeds measurement in 1991 - real
11. WhiteClover-92 - white clover measurement in 1992 - real
12. BareGround-92 - bare ground measurement in 1992 - real
13. Cocksfoot-92 - cocksfoot measurement in 1992 - real
14. OtherGrasses-92 - other grasses measurement in 1992 - real
15. OtherLegumes-92 - other legumes measurement in 1992 - real
16. RyeGrass-92 - ryegrass measurement in 1992 - real
17. Weeds-92 - weeds measurement in 1992 - real
18. WhiteClover-93 - white clover measurement in 1993 - real
19. BareGround-93 - bare ground measurement in 1993 - real
20. Cocksfoot-93 - cocksfoot measurement in 1993 - real
21. OtherGrasses-93 - other grasses measurement in 1993 - real
22. OtherLegumes-93 - other legumes measurement in 1993 - real
23. RyeGrass-93 - ryegrass measurement in 1993 - real
24. Weeds-93 - weeds measurement in 1993 - real
25. BareGround-94 - bare ground measurement in 1994 - real
26. Cocksfoot-94 - cocksfoot measurement in 1994 - real
27. OtherGrasses-94 - other grasses measurement in 1994 - real
28. OtherLegumes-94 - other legumes measurement in 1994 - real
29. RyeGrass-94 - ryegrass measurement in 1994 - real
30. Weeds-94 - weeds measurement in 1994 - real
31. strata-combined - enumerated
32.  WhiteClover-94 - white clover measurement in 1994 - enumerated"
344,mv,"**Author**: Luis Torgo  
**Source**: [original](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html) -   
**Please cite**:   

This is an artificial data set with dependencies between the attribute values. The cases are generated using the following method:

X1 : uniformly distributed over [-5,5]
X2 : uniformly distributed over [-15,-10]
X3 : IF (X1 > 0) THEN X3 = green
 ELSE X3 = red with probability 0.4 and X4=brown with prob. 0.6
X4 : IF (X3=green) THEN X4=X1+2X2
 ELSE X4=X1/2 with prob. 0.3, and X4=X2/2 with prob. 0.7
X5 : uniformly distributed over [-1,1]
X6 : X6=X4*[epsilon], where [epsilon] is uniformly distribute over [0,5]
X7 : X7=yes with prob. 0.3 and X7=no with prob. 0.7
X8 : IF (X5 < 0.5) THEN X8 = normal ELSE X8 = large
X9 : uniformly distributed over [100,500]
X10 : uniformly distributed integer over the interval [1000,1200]
 
Obtain the value of the target variable Y using the rules:
IF (X2 > 2 ) THEN Y = 35 - 0.5 X4
 ELSE IF (-2 <= X4 <= 2) THEN Y = 10 - 2 X1
 ELSE IF (X7 = yes) THEN Y = 3 -X1/X4
 ELSE IF (X8 = normal) THEN Y = X6 + X1
 ELSE Y = X1/2

Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html"
346,aids,"**Author**: Jeffrey S. Simonoff  
**Source**: [original](http://www.stern.nyu.edu/~jsimonof/AnalCatData) -   
**Please cite**: Jeffrey S. Simonoff. Analyzing Categorical Data, Springer-Verlag, New York, 2003  

Data originating from the book ""Analyzing Categorical Data"" by Jeffrey S. Simonoff."
350,webdata_wXa,"**Author**: John Platt  
**Source**: [libSVM](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) - Date unknown  
**Please cite**:   John C. Platt. 
Fast training of support vector machines using sequential minimal optimization. 
In Bernhard Schölkopf, Christopher J. C. Burges, and Alexander J. Smola, editors, Advances in Kernel Methods - Support Vector Learning, Cambridge, MA, 1998. MIT Press.a

This is the famous webdata dataset w[1-8]a in its binary version, retrieved 2014-11-14 from the libSVM site. Additional to the preprocessing done there (see LibSVM site for details), this dataset was created as follows: 

* load all web data  datasets, train and test, e.g. w1a, w1a.t, w2a, w2a.t, w3a, ... 
* join test and train for each subset, e.g. w1a and w1a.t, w2a and w2a.t 
* normalize each file columnwise according to the following rules: 
* If a column only contains one value (constant feature), it will set to zero and thus removed by sparsity. 
* If a column contains two values (binary feature), the value occuring more often will be set to zero, the other to one. 
* If a column contains more than two values (multinary/real feature), the column is divided by its std deviation.
* afterwards all these 8 files are merged into one, and randomly sorted. 
* duplicate lines were finally removed.

An R script which does all of these steps can be found here:
https://github.com/openml/data_scripts/blob/master/webdata_wXa/dataDownloader.R"
351,codrna,"**Author**: Andrew V Uzilov"",""Joshua M Keegan"",""David H Mathews.  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) -   
**Please cite**: [AVU06a]
Andrew V Uzilov, Joshua M Keegan, and David H Mathews. 
Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change. 
BMC Bioinformatics, 7(173), 2006.  

This is the cod-rna dataset, retrieved 2014-11-14 from the libSVM site. Additional to the preprocessing done there (see LibSVM site for details), this dataset was created as follows: 
-join test, train and rest datasets   
-normalize each file columnwise according to the following rules:    
-If a column only contains one value (constant feature), it will set to zero and thus removed by sparsity.    
-If a column contains two values (binary feature), the value occuring more often will be set to zero, the other to one.    
-If a column contains more than two values (multinary/real feature), the column is divided by its std deviation.    

NOTE: please keep in mind that cod-rna has many duplicated data points, within each file &#40;train,test,rest&#41; and also accross these files. these duplicated points have not been removed!"
354,poker,"**Author**: UCI  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) -   
**Please cite**:   

This is the poker dataset, retrieved 2013-11-14 from the libSVM site. Additional to the preprocessing done there (see LibSVM site for details), this dataset was created as follows:    

-join test and train datasets (non-scaled versions)   
-relabel classes 0=positive class and 1,2,...9=negative class   
-normalize each file columnwise according to the following rules:    
-If a column only contains one value (constant feature), it will set to zero and thus removed by sparsity.    
-If a column contains two values (binary feature), the value occuring more often will be set to zero, the other to one.   
-If a column contains more than two values (multinary/real feature), the column is divided by its std deviation.   

NOTE: please keep in mind that poker has a mild redundancy, e.g. some duplicated data points, roughly 0.2%, within each file &#40;train,test&#41;. these duplicated points have not been removed!"
357,vehicle_sensIT,"**Author**: M. Duarte, Y. H. Hu  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) - 2013-11-14 -   
**Please cite**:   M. Duarte and Y. H. Hu. 
Vehicle classification in distributed sensor networks. 
Journal of Parallel and Distributed Computing, 64(7):826-838, July 2004.


This is the SensIT Vehicle (combined)  dataset, retrieved 2013-11-14 from the libSVM site. Additional to the preprocessing done there (see LibSVM site for details), this dataset was created as follows: 
-join test and train datasets (2 files, already pre-combined)
-relabel classes 1,2=positive class and 3=negative class
-normalize each file columnwise according to the following rules: 
-If a column only contains one value (constant feature), it will set to zero and thus removed by sparsity. 
-If a column contains two values (binary feature), the value occuring more often will be set to zero, the other to one. -If a column contains more than two values (multinary/real feature), the column is divided by its std deviation."
372,internet_usage,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Internet Usage Data
 
 Data Type
 
    multivariate
 
 Abstract
 
    This data contains general demographic information on internet users
    in 1997.
 
 Sources
 
     Original Owner
 
 [1]Graphics, Visualization, & Usability Center
 College of Computing
 Geogia Institute of Technology
 Atlanta, GA
 
     Donor
 
 [2]Dr Di Cook
 Department of Statistics
 Iowa State University
 
    Date Donated: June 30, 1999
 
 Data Characteristics
 
    This data comes from a survey conducted by the Graphics and
    Visualization Unit at Georgia Tech October 10 to November 16, 1997.
    The full details of the survey are available [3]here.
 
    The particular subset of the survey provided here is the ""general
    demographics"" of internet users. The data have been recoded as
    entirely numeric, with an index to the codes described in the ""Coding""
    file.
 
    The full survey is available from the web site above, along with
    summaries, tables and graphs of their analyses. In addition there is
    information on other parts of the survey, including technology
    demographics and web commerce.
 
 Data Format
 
    The data is stored in an ASCII files with one observation per line.
    Spaces separate fields.
 
 Past Usage
 
    This data was used in the American Statistical Association Statistical
    Graphics and Computing Sections 1999 Data Exposition.
      _________________________________________________________________
 
 
     [4]The UCI KDD Archive
     [5]Information and Computer Science
     [6]University of California, Irvine
     Irvine, CA 92697-3425
 
    Last modified: June 30, 1999
 
 References
 
    1. http://www.gvu.gatech.edu/gvu/user_surveys/survey-1997-10/
    2. http://www.public.iastate.edu/~dicook/
    3. http://www.cc.gatech.edu/gvu/user_surveys/survey-1997-10/
    4. http://kdd.ics.uci.edu/
    5. http://www.ics.uci.edu/
    6. http://www.uci.edu/


 Information about the dataset
 CLASSTYPE: nominal
 CLASSINDEX: none specific"
373,UNIX_user_data,"**Author**: Terran Lane (terran@ecn.purdue.edu)   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/UNIX+User+Data) - Date unknown  
**Please cite**:   

This file contains 9 sets of sanitized user data drawn from the command histories of 8 UNIX computer users at Purdue over the course of up to 2 years (USER0 and USER1 were generated by the same person, working on different platforms and different projects).  The data is drawn from tcsh(1) history files and has been parsed and sanitized to remove filenames, user names, directory structures, web addresses, host names, and other possibly identifying items.  Command names, flags, and shell metacharacters have been preserved.  Additionally, **SOF** and **EOF** tokens have been inserted at the start and end of
shell sessions, respectively.  Sessions are concatenated by date order and tokens appear in the order issued within the shell session, but no timestamps are included in this data.  For example, the two sessions:

cd ~/private/docs  
ls -laF | more  
cat foo.txt bar.txt zorch.txt > somewhere  
exit  

cd ~/games/  
xquake &  
fg  
vi scores.txt  
mailx john_doe@somewhere.com  
exit  

would be represented by the token stream  

**SOF**  
cd  
\<1\>                  (one ""file name"" argument)  
ls  
-laF  
|  
more  
cat  
\<3\>                     (three ""file"" arguments)
\>  
\<1\>  
exit  
**EOF**  
**SOF**  
cd  
\<1\>  
xquake  
&  
fg  
vi  
\<1\>  
mailx  
\<1\>  
exit  
**EOF**

This data is made available under conditions of anonymity for the contributing users and may be used for research purposes only. Summaries and research results employing this data may be published, but literal tokens or token sequences from the data may not be published except with express consent of the originators of the data. No portion of this data may be released with or included in a commercial product, nor may any portion of this data be sold or redistributed for profit or as part of of a profit-making endeavor."
374,SyskillWebert-BioMedical,"**Author**: Michael Pazzani (pazzani@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Syskill+and+Webert+Web+Page+Ratings)- 1999  
**Please cite**:   

**Syskill and Webert Web Page Ratings**  
This database contains the HTML source of web pages plus the ratings of a single user on these web pages. The web pages are on four separate subjects (Bands- recording artists; Goats; Sheep; and BioMedical)

The HTML source of a web page is given. Users looked at each web page and indicated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentive to rate pages.

The problem is to predict user ratings for web pages (within a subject category). The accuracy of predicting ratings is reported in early publications. Later publications used the precision at top N or the F-measure.

**Past Usage**  
Pazzani M., Billsus, D. (1997). Learning and Revising User Profiles: The identification of interesting web sites. Machine Learning 27, 313-331

Pazzani, M., Muramatsu J., Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. Proceedings of the National Conference on Artificial Intelligence, Portland, OR."
375,JapaneseVowels,"**Author**: Mineichi Kudo, Jun Toyama, Masaru Shimbo    
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels)    
**Please cite**:   

**Japanese vowels**  
This dataset records 640 time series of 12 LPC cepstrum coefficients taken from nine male speakers.

The data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients).

Similar data are available for different utterances /ei/, /iu/, /uo/, /oa/ in addition to /ae/. Please contact the donor if you are interested in using this data.

The number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing.

Analysis parameters:  
* Sampling rate : 10kHz
* Frame length : 25.6 ms
* Shift length : 6.4ms
* Degree of LPC coefficients : 12

Each line represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis
frame. Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames.

Each speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on.

**Past Usage**

M. Kudo, J. Toyama and M. Shimbo. (1999). ""Multidimensional Curve Classification Using Passing-Through Regions"". Pattern Recognition Letters, Vol. 20, No. 11--13, pages 1103--1111.

If you publish any work using the dataset, please inform the donor. Use for commercial purposes requires donor permission.

References  

1. http://ips9.main.eng.hokudai.ac.jp/index_e.html
2. mailto:mine@main.eng.hokudai.ac.jp
3. mailto:jun@main.eng.hokudai.ac.jp
4. mailto:shimbo@main.eng.hokudai.ac.jp
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/"
376,SyskillWebert-Sheep,"**Author**: Michael Pazzani (pazzani@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Syskill+and+Webert+Web+Page+Ratings)- 1999  
**Please cite**:   

**Syskill and Webert Web Page Ratings**  
This database contains the HTML source of web pages plus the ratings of a single user on these web pages. The web pages are on four separate subjects (Bands- recording artists; Goats; Sheep; and BioMedical)

The HTML source of a web page is given. Users looked at each web page and indicated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentive to rate pages.

The problem is to predict user ratings for web pages (within a subject category). The accuracy of predicting ratings is reported in early publications. Later publications used the precision at top N or the F-measure.

**Past Usage**  
Pazzani M., Billsus, D. (1997). Learning and Revising User Profiles: The identification of interesting web sites. Machine Learning 27, 313-331

Pazzani, M., Muramatsu J., Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. Proceedings of the National Conference on Artificial Intelligence, Portland, OR."
377,synthetic_control,"**Author**: Dr Robert Alcock (rob@skyblue.csd.auth.gr)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Synthetic+Control+Chart+Time+Series) - 1999  
**Please cite**:   

### Description
Synthetic Control Chart Time Series.
This is actually time series classification.

### Sources
```
* Original Owner and Donor
Dr Robert Alcock 
rob@skyblue.csd.auth.gr
```
### Dataset Information
  
This data consists of synthetically generated control charts. This dataset contains 600 examples of control charts synthetically generated by the process in Alcock and Manolopoulos (1999). There are six different classes of control charts:

```
1. Normal
2. Cyclic
3. Increasing trend
4. Decreasing trend
5. Upward shift
6. Downward shift
````

### Relevante papers

Alcock R.J. and Manolopoulos Y. Time-Series Similarity Queries Employing a Feature-Based Approach. 7th Hellenic Conference on
Informatics. August 27-29. Ioannina,Greece 1999.

D.T. Pham and A.B. Chan ""Control Chart Pattern Recognition using a New Type of Self Organizing Neural Network"" Proc. Instn, Mech, Engrs. Vol 212, No 1, pp 115-127 1998.

### References  

1. http://skyblue.csd.auth.gr/~rob/
2. mailto:rob@skyblue.csd.auth.gr
3. http://kdd.ics.uci.edu/
4. http://www.ics.uci.edu/
5. http://www.uci.edu/"
378,ipums_la_99-small,"**Author**: IPUMS (ipums@hist.umn.edu)  
**Donor**: Stephen Bay (sbay@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/IPUMS+Census+Database) - 1999   
**Please cite**:   

**IPUMS Database**  
This data set contains unweighted PUMS census data from the Los Angeles and Long Beach areas for the years 1970, 1980, and 1990. The coding schemes have been standardized (by the IPUMS project) to be consistent across years. The original source for this data set is the IPUMS project (RugglesSobek, 1997). The IPUMS project is a large collection of federal census data which has standardized coding schemes to make comparisons across time easy.

The data is an unweighted 1 in 100 sample of responses from the Los Angeles -- Long Beach area for the years 1970, 1980, and 1990. The household and individual records were flattened into a single table and we used all variables that were available for all three years. When there was more than one version of a variable, such as for race, we used the most general. For occupation and industry we used the 1950 basis.

Note that PUMS data is based on cluster samples, i.e. samples are made of households or dwellings from which there may be multiple individuals. Individuals from the same household are no longer independent. Ruggles (1995) considers this issue further and discusses its effect (along with the effects of stratification) on standard errors.

The variable schltype appears to have different coding values across the years 1970, 1980, and 1990.

There are two versions of this data set. The small data set contains a 1 in 1000 sample of the Los Angeles and
Long Beach area. It was formed by sampling from the large data set. The large data set contains a 1 in 100 sample of the Los Angeles and Long Beach area.

**Past Usage**  
S. D. Bay and M. J. Pazzani. (1999) ""Detecting Group Differences: Mining Contrast Sets"". submitted.

**Copyright Information**  
All persons are granted a limited license to use and distribute this documentation and the accompanying data, subject to the following conditions:
* No fee may be charged for use or distribution.
* Publications and research reports based on the database must cite it appropriately. The citation should include the following: Steven Ruggles and Matthew Sobek et. al. Integrated Public Use Microdata Series: Version 2.0 Minneapolis: Historical Census Projects, University of Minnesota, 1997

If possible, citations should also include the URL for the IPUMS site: http://www.ipums.umn.edu/.

In addition, we request that users send us a copy of any publications, research reports, or educational material making use of the data or documentation. Send all electronic material to ipums@hist.umn.edu

References  

1. http://www.ipums.umn.edu/
2. mailto:ipums@hist.umn.edu
3. http://www.ics.uci.edu/~sbay
4. mailto:sbay@ics.uci.edu
5. http://www.ipums.umn.edu/
6. mailto:ipums@hist.umn.edu
7. http://www.ipums.umn.edu/
8. http://www.census.gov/
9. http://kdd.ics.uci.edu/
10. http://www.ics.uci.edu/
11. http://www.uci.edu/"
379,SyskillWebert-Goats,"**Author**: Michael Pazzani (pazzani@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Syskill+and+Webert+Web+Page+Ratings)- 1999  
**Please cite**:   

**Syskill and Webert Web Page Ratings**  
This database contains the HTML source of web pages plus the ratings of a single user on these web pages. The web pages are on four separate subjects (Bands- recording artists; Goats; Sheep; and BioMedical)

The HTML source of a web page is given. Users looked at each web page and indicated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentive to rate pages.

The problem is to predict user ratings for web pages (within a subject category). The accuracy of predicting ratings is reported in early publications. Later publications used the precision at top N or the F-measure.

**Past Usage**  
Pazzani M., Billsus, D. (1997). Learning and Revising User Profiles: The identification of interesting web sites. Machine Learning 27, 313-331

Pazzani, M., Muramatsu J., Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. Proceedings of the National Conference on Artificial Intelligence, Portland, OR."
380,SyskillWebert-Bands,"**Author**: Michael Pazzani (pazzani@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Syskill+and+Webert+Web+Page+Ratings)- 1999  
**Please cite**:   

**Syskill and Webert Web Page Ratings**  
This database contains the HTML source of web pages plus the ratings of a single user on these web pages. The web pages are on four separate subjects (Bands- recording artists; Goats; Sheep; and BioMedical)

The HTML source of a web page is given. Users looked at each web page and indicated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentive to rate pages.

The problem is to predict user ratings for web pages (within a subject category). The accuracy of predicting ratings is reported in early publications. Later publications used the precision at top N or the F-measure.

**Past Usage**  
Pazzani M., Billsus, D. (1997). Learning and Revising User Profiles: The identification of interesting web sites. Machine Learning 27, 313-331

Pazzani, M., Muramatsu J., Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. Proceedings of the National Conference on Artificial Intelligence, Portland, OR."
381,ipums_la_98-small,"**Author**: IPUMS (ipums@hist.umn.edu)  
**Donor**: Stephen Bay (sbay@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/IPUMS+Census+Database) - 1999   
**Please cite**:   

**IPUMS Database**  
This data set contains unweighted PUMS census data from the Los Angeles and Long Beach areas for the years 1970, 1980, and 1990. The coding schemes have been standardized (by the IPUMS project) to be consistent across years. The original source for this data set is the IPUMS project (RugglesSobek, 1997). The IPUMS project is a large collection of federal census data which has standardized coding schemes to make comparisons across time easy.

The data is an unweighted 1 in 100 sample of responses from the Los Angeles -- Long Beach area for the years 1970, 1980, and 1990. The household and individual records were flattened into a single table and we used all variables that were available for all three years. When there was more than one version of a variable, such as for race, we used the most general. For occupation and industry we used the 1950 basis.

Note that PUMS data is based on cluster samples, i.e. samples are made of households or dwellings from which there may be multiple individuals. Individuals from the same household are no longer independent. Ruggles (1995) considers this issue further and discusses its effect (along with the effects of stratification) on standard errors.

The variable schltype appears to have different coding values across the years 1970, 1980, and 1990.

There are two versions of this data set. The small data set contains a 1 in 1000 sample of the Los Angeles and
Long Beach area. It was formed by sampling from the large data set. The large data set contains a 1 in 100 sample of the Los Angeles and Long Beach area.

**Past Usage**  
S. D. Bay and M. J. Pazzani. (1999) ""Detecting Group Differences: Mining Contrast Sets"". submitted.

**Copyright Information**  
All persons are granted a limited license to use and distribute this documentation and the accompanying data, subject to the following conditions:
* No fee may be charged for use or distribution.
* Publications and research reports based on the database must cite it appropriately. The citation should include the following: Steven Ruggles and Matthew Sobek et. al. Integrated Public Use Microdata Series: Version 2.0 Minneapolis: Historical Census Projects, University of Minnesota, 1997

If possible, citations should also include the URL for the IPUMS site: http://www.ipums.umn.edu/.

In addition, we request that users send us a copy of any publications, research reports, or educational material making use of the data or documentation. Send all electronic material to ipums@hist.umn.edu

References  

1. http://www.ipums.umn.edu/
2. mailto:ipums@hist.umn.edu
3. http://www.ics.uci.edu/~sbay
4. mailto:sbay@ics.uci.edu
5. http://www.ipums.umn.edu/
6. mailto:ipums@hist.umn.edu
7. http://www.ipums.umn.edu/
8. http://www.census.gov/
9. http://kdd.ics.uci.edu/
10. http://www.ics.uci.edu/
11. http://www.uci.edu/"
382,ipums_la_97-small,"**Author**: IPUMS (ipums@hist.umn.edu)  
**Donor**: Stephen Bay (sbay@ics.uci.edu)  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/IPUMS+Census+Database) - 1999   
**Please cite**:   

**IPUMS Database**  
This data set contains unweighted PUMS census data from the Los Angeles and Long Beach areas for the years 1970, 1980, and 1990. The coding schemes have been standardized (by the IPUMS project) to be consistent across years. The original source for this data set is the IPUMS project (RugglesSobek, 1997). The IPUMS project is a large collection of federal census data which has standardized coding schemes to make comparisons across time easy.

The data is an unweighted 1 in 100 sample of responses from the Los Angeles -- Long Beach area for the years 1970, 1980, and 1990. The household and individual records were flattened into a single table and we used all variables that were available for all three years. When there was more than one version of a variable, such as for race, we used the most general. For occupation and industry we used the 1950 basis.

Note that PUMS data is based on cluster samples, i.e. samples are made of households or dwellings from which there may be multiple individuals. Individuals from the same household are no longer independent. Ruggles (1995) considers this issue further and discusses its effect (along with the effects of stratification) on standard errors.

The variable schltype appears to have different coding values across the years 1970, 1980, and 1990.

There are two versions of this data set. The small data set contains a 1 in 1000 sample of the Los Angeles and
Long Beach area. It was formed by sampling from the large data set. The large data set contains a 1 in 100 sample of the Los Angeles and Long Beach area.

**Past Usage**  
S. D. Bay and M. J. Pazzani. (1999) ""Detecting Group Differences: Mining Contrast Sets"". submitted.

**Copyright Information**  
All persons are granted a limited license to use and distribute this documentation and the accompanying data, subject to the following conditions:
* No fee may be charged for use or distribution.
* Publications and research reports based on the database must cite it appropriately. The citation should include the following: Steven Ruggles and Matthew Sobek et. al. Integrated Public Use Microdata Series: Version 2.0 Minneapolis: Historical Census Projects, University of Minnesota, 1997

If possible, citations should also include the URL for the IPUMS site: http://www.ipums.umn.edu/.

In addition, we request that users send us a copy of any publications, research reports, or educational material making use of the data or documentation. Send all electronic material to ipums@hist.umn.edu

References  

1. http://www.ipums.umn.edu/
2. mailto:ipums@hist.umn.edu
3. http://www.ics.uci.edu/~sbay
4. mailto:sbay@ics.uci.edu
5. http://www.ipums.umn.edu/
6. mailto:ipums@hist.umn.edu
7. http://www.ipums.umn.edu/
8. http://www.census.gov/
9. http://kdd.ics.uci.edu/
10. http://www.ics.uci.edu/
11. http://www.uci.edu/"
383,tr45.wc,
384,tr21.wc,
385,tr31.wc,
386,oh15.wc,
387,tr11.wc,
388,tr23.wc,
389,fbis.wc,
390,new3s.wc,
391,re0.wc,
392,oh0.wc,
393,la2s.wc,
394,oh5.wc,"**Author**:   [George Forman](https://scholar.google.com/citations?user=r0a222QAAAAJ)
**Source**: http://tunedit.org/repo/Data/Text-wc/oh5.wc.arff
**Please cite**:"
395,re1.wc,
396,la1s.wc,
397,tr12.wc,
398,wap.wc,
399,ohscal.wc,
400,tr41.wc,
401,oh10.wc,
402,yokohoma2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
403,heyl,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
404,yokohoma1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
405,mtp,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
406,qsbr_y2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
407,krystek,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
408,depreux,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
409,pdgfr,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
410,carbolenes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
411,garrat2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
412,Phen,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
413,siddiqi,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
414,lewis,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
415,thompson,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
416,yprop_4_1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
417,tsutumi,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
418,strupcz,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
419,PHENETYL1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
420,cristalli,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
421,selwood,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
422,topo_2_1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
423,svensson,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
424,pah,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
425,penning,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
426,qsfsr1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
427,qsfrdhla,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
428,qsprcmpx,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
429,qsfsr2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
430,mtp2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
431,qsbralks,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
432,stevenson,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
433,qsartox,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
434,benzo32,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
435,uehling,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
436,rosowky,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
437,garrat,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
438,doherty,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
439,chang,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
440,qsabr2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
441,qsabr1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
442,qsbr_rw1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).
The molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. 

The last attribute in each file is the target.

Original studies:

carbolenes
""B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140""

mtp2
""Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185""

chang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2	
""David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of """"Molecular Diversity"""" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.""

mtp
""Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590""

benzo32
""Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662""

PHENETYL1	
""H. Kubinyi (Ed.): """"QSAR: Hansch Analysis and Related Approaches"""", VCH, Weinhein (Ger), 1993, pp.57-68""

pah	
""Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.""

pdgfr	
""R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189""

Phen	
""Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577""

topo_2_1, yprop_4_1	
""Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470""

qsabr1, qsabr2	
""Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997""

qsartox	
""Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998""

qsbr_rw1	
""Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998""

qsbr_y2	
""Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers""

qsbralks	
""Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998""

qsfrdhla	
""Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997""

qsfsr1	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsfsr2	
""Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998""

qsprcmpx	
""Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000""

selwood	
""Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142"""
443,analcatdata_broadway,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
444,analcatdata_boxing2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
446,prnn_crabs,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets for `Pattern Recognition and Neural Networks' by B.D. Ripley
=====================================================================

Cambridge University Press (1996)  ISBN  0-521-46086-7

The background to the datasets is described in section 1.4; this file
relates the computer-readable files to that description.



Cushing's syndrome
------------------

Data from Aitchison & Dunsmore (1975, Tables 11.1-3).

Data file Cushings.dat has four columns,

Label of the patient
Tetrhydrocortisone  (mg/24hr)
Pregnanetriol  (mg/24hr)
Type

The type of the last six patients (u1 to u6) should be
regarded as unknown.  (The code `o' indicates `other').



synthetic two-class problem
---------------------------

Data from Ripley (1994a).

This has two real-valued co-ordinates (xs and ys) and a class (xc)
which is 0 or 1.

Data file  synth.tr   has 250 rows of the training set
synth.te   has 1000 rows of the test set  (not used here)



viruses
-------

This is a dataset on 61 viruses with rod-shaped particles affecting
various crops (tobacco, tomato, cucumber and others) described by
{Fauquet et al. (1988) and analysed by Eslava-G\'omez (1989).  There
are 18 measurements on each virus,  the number of amino acid residues
per molecule of coat protein.

Data file  viruses.dat  has 61 rows of 18 counts
virus3.dat   has 38 rows corresponding to the distinct
Tobamoviruses.

The whole dataset is in order Hordeviruses (3), Tobraviruses (6),
Tobamoviruses (39) and `furoviruses' (13).



Leptograpsus crabs
------------------

Data from Campbell & Mahon (1974) on the morphology of rock crabs of
genus Leptograpsus.

There are 50 specimens of each sex of each of two colour forms.

Data file  crabs.dat has rows

sp	`species', coded B (blue form) or O (orange form)
sex	coded M or F
index	within each group of 50
FL	frontal lip of carapace (mm)
RW	rear width of carapace (mm)
CL	length along the midline of carapace (mm)
CW	maximum width of carapace (mm)
BD	body depth (mm)



Forensic glass
--------------

This example comes from forensic testing of glass collected by
B. German on 214 fragments of glass.  It is also contained in the
UCI machine-learning database collection (Murphy & Aha, 1995).

Data file fglass.dat has 214 rows with data for a single glass
fragment.

RI	refractive index
Na	% weight of sodium oxide(s)
Mg	% weight of magnesium oxide(s)
Al	% weight of aluminium oxide(s)
Si	% weight of silicon oxide(s)
K	% weight of potassium oxide(s)
Ca	% weight of calcium oxide(s)
Ba	% weight of barium oxide(s)
Fe	% weight of iron oxide(s)
type	coded 1 to 7

The type codes are:

1 (WinF) window float glass
2 (WinNF) window non-float glass
3 (Veh) vehicle glass
5 (Con)  containers
6 (Tabl) tableware
7 (Head) vehicle headlamp glass

The ten groups used for the cross-validation experiments (I believe)
are listed as row numbers in the file fglass.grp,



Diabetes in Pima Indians
------------------------

A population of women who were at least 21 years old, of Pima Indian heritage
and living near Phoenix, Arizona,  was tested for diabetes
according to World Health Organization criteria.  The data
were collected by the US National Institute of Diabetes and Digestive and
Kidney Diseases (Smith et al, 1988). This example is also contained in the
UCI machine-learning database collection (Murphy & Aha, 1995).

The data files have rows containing

npreg 	number of pregnancies
glu 	plasma glucose concentration in an oral glucose tolerance test
bp 	diastolic blood pressure (mm Hg)
skin 	triceps skin fold thickness (mm)
ins	serum insulin (micro U/ml)
bmi 	body mass index (weight in kg/(height in m)^2)
ped 	diabetes pedigree function
age 	in years
type	No / Yes

Data file pima.tr   has 200 rows of complete training data.
pima.te   has 332 rows of complete test data.
pima.tr2  has the 200 rows of pima.tr plus 100 incomplete rows.



Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 1"
448,analcatdata_boxing1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
449,analcatdata_homerun,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
450,analcatdata_lawsuit,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
451,irish,"**Author**: Vincent Greaney, Thomas Kelleghan (St. Patrick's College, Dublin)   
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/irish.ed) - 1984  
**Please cite**: [StatLib](http://lib.stat.cmu.edu/datasets/)

**Irish Educational Transitions Data**  
Data on educational transitions for a sample of 500 Irish schoolchildren aged 11 in 1967. The data were collected by Greaney and Kelleghan (1984), and reanalyzed by Raftery and Hout (1985, 1993). 

### Attribute information  

* Sex: 1=male; 2=female.
* DVRT (Drumcondra Verbal Reasoning Test Score).
* Educational level attained
* Leaving Certificate. 1 if Leaving Certificate not taken; 2 if taken.
* Prestige score for father's occupation (calculated by Raftery and Hout, 1985).
* Type of school: 1=secondary; 2=vocational; 9=primary terminal leaver.

### Relevant papers  

Greaney, V. and Kelleghan, T. (1984). Equality of Opportunity in Irish
Schools. Dublin: Educational Company.

Kass, R.E. and Raftery, A.E. (1993). Bayes factors and model uncertainty.
Technical Report no. 254, Department of Statistics, University of Washington.
Revised version to appear in Journal of the American Statistical
Association.

Raftery, A.E. (1988). Approximate Bayes factors for generalized linear models.
Technical Report no. 121, Department of Statistics, University of Washington.

Raftery, A.E. and Hout, M. (1985). Does Irish education approach the
meritocratic ideal? A logistic analysis.
Economic and Social Review, 16, 115-140.

Raftery, A.E. and Hout, M. (1993). Maximally maintained inequality:
Expansion, reform and opportunity in Irish schools.
Sociology of Education, 66, 41-62.


### Ownership Statement  
This data belongs to Vincent Greaney and Thomas Kelleghan, Educational Research Centre, St. Patrick's College, Drumcondra, Dublin 9, Ireland, who retain the copyright.

In the form given here, it may be used solely as an example for research on the development of statistical methods. For any other use of the data, permission must be obtained from the owners."
452,analcatdata_broadwaymult,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
453,analcatdata_bondrate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
454,analcatdata_halloffame,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
455,cars,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Committee on Statistical Graphics of the American Statistical
Association (ASA) invites you to participate in its Second (1983)
Exposition of Statistical Graphics Technology. The purposes of the
Exposition are (l) to provide a forum in which users and providers of
statistical graphics technology can exchange information and ideas and
(2) to expose those members of the ASA community who are less familiar
with statistical graphics to its capabilities and potential benefits
to them. The Exposition wil1 be held in conjunction with the Annual
Meetings in Toronto, August 15-18, 1983 and is tentatively scheduled
for the afternoon of Wednesday, August 17.

Seven providers of statistical graphics technology participated in the
l982 Exposition. By all accounts, the Exposition was well received by
the ASA community and was a worthwhile experience for the
participants. We hope to have those seven involved again this year,
along with as many new participants as we can muster. The 1982
Exposition was summarized in a paper to appear in the Proceeding of
the Statistical Computing Section. A copy of that paper is enclosed
for your information.

The basic format of the 1983 Exposition will be similar to that of
1982. However, based upon comments received and experience gained,
there are some changes. The basic structure, intended to be simpler
and more flexible than last year, is as follows:

A fixed data set is to be analyzed. This data set is a version of the
CRCARS data set of

Donoho, David and Ramos, Ernesto (1982), ``PRIMDATA:
Data Sets for Use With PRIM-H'' (DRAFT).

Because of the Committee's limited (zero) budget for the Exposition,
we are forced to provide the data in hardcopy form only (enclosed).
(Sorry!)

There are 406 observations on the following 8 variables: MPG (miles
per gallon), # cylinders, engine displacement (cu. inches), horsepower,
vehicle weight (lbs.), time to accelerate from O to 60 mph (sec.),
model year (modulo 100), and origin of car (1. American, 2. European,
3. Japanese). These data appear on seven pages. Also provided are the
car labels (types) in the same order as the 8 variables on seven
separate pages. Missing data values are marked by series of question
marks.

You are asked to analyze these data using your statistical graphics
software. Your objective should be to achieve graphical displays which
will be meaningful to the viewers and highlight relevant aspects of
the data. If you can best achieve this using simple graphical formats,
fine. If you choose to illustrate some of the more sophisticated
capabilities of your software and can do so without losing relevancy
to the data, that is fine, too. This year, there will be no Committee
commentary on the individual presentations, so you are not competing
with other presenters. The role of each presenter is to do his/her
best job of presenting their statistical graphics technology to the
viewers.

Each participant will be provided with a 6'(long) by 4'(tall)
posterboard on which to display the results of their analyses. This is
the same format as last year. You are encouraged to remain by your
presentation during the Exposition to answer viewers' questions. Three
copies of your presentation must be submitted to me by July 1. Movie
or slide show presentations cannot be accommodated (sorry). The
Committee will prepare its own poster presentation which will orient
the viewers to the data and the purposes of the Exposition.

The ASA has asked us to remind all participants that the Exposition is
intended for educational and scientific purposes and is not a
marketing activity. Even though last year's participants did an
excellent job of maintaining that distinction, a cautionary note at
this point is appropriate.

Those of us who were involved with the 1982 Exposition found it
worthwhile and fun to do. We would very much like to have you
participate this year. For planning purposes, please RSVP (to me, in
writing please) by April 15 as to whether you plan to accept the
Committee's invitation.

If you have any questions about the Exposition, please call me on
(301/763-5350). If you have specific questions about the data, or the
analysis, please call Karen Kafadar on (301/921-3651). If you cannot
participate but know of another person or group in your organization
who can, please pass this invitation along to them.

Sincerely,



LAWRENCE H. COX
Statistical Research Division
Bureau of the Census
Room 3524-3
Washington, DC 20233




Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last"
456,analcatdata_birthday,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
457,prnn_cushings,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets for `Pattern Recognition and Neural Networks' by B.D. Ripley
=====================================================================

Cambridge University Press (1996)  ISBN  0-521-46086-7

The background to the datasets is described in section 1.4; this file
relates the computer-readable files to that description.



Cushing's syndrome
------------------

Data from Aitchison & Dunsmore (1975, Tables 11.1-3).

Data file Cushings.dat has four columns,

Label of the patient
Tetrhydrocortisone  (mg/24hr)
Pregnanetriol  (mg/24hr)
Type

The type of the last six patients (u1 to u6) should be
regarded as unknown.  (The code `o' indicates `other').



synthetic two-class problem
---------------------------

Data from Ripley (1994a).

This has two real-valued co-ordinates (xs and ys) and a class (xc)
which is 0 or 1.

Data file  synth.tr   has 250 rows of the training set
synth.te   has 1000 rows of the test set  (not used here)



viruses
-------

This is a dataset on 61 viruses with rod-shaped particles affecting
various crops (tobacco, tomato, cucumber and others) described by
{Fauquet et al. (1988) and analysed by Eslava-G\'omez (1989).  There
are 18 measurements on each virus,  the number of amino acid residues
per molecule of coat protein.

Data file  viruses.dat  has 61 rows of 18 counts
virus3.dat   has 38 rows corresponding to the distinct
Tobamoviruses.

The whole dataset is in order Hordeviruses (3), Tobraviruses (6),
Tobamoviruses (39) and `furoviruses' (13).



Leptograpsus crabs
------------------

Data from Campbell & Mahon (1974) on the morphology of rock crabs of
genus Leptograpsus.

There are 50 specimens of each sex of each of two colour forms.

Data file  crabs.dat has rows

sp	`species', coded B (blue form) or O (orange form)
sex	coded M or F
index	within each group of 50
FL	frontal lip of carapace (mm)
RW	rear width of carapace (mm)
CL	length along the midline of carapace (mm)
CW	maximum width of carapace (mm)
BD	body depth (mm)



Forensic glass
--------------

This example comes from forensic testing of glass collected by
B. German on 214 fragments of glass.  It is also contained in the
UCI machine-learning database collection (Murphy & Aha, 1995).

Data file fglass.dat has 214 rows with data for a single glass
fragment.

RI	refractive index
Na	% weight of sodium oxide(s)
Mg	% weight of magnesium oxide(s)
Al	% weight of aluminium oxide(s)
Si	% weight of silicon oxide(s)
K	% weight of potassium oxide(s)
Ca	% weight of calcium oxide(s)
Ba	% weight of barium oxide(s)
Fe	% weight of iron oxide(s)
type	coded 1 to 7

The type codes are:

1 (WinF) window float glass
2 (WinNF) window non-float glass
3 (Veh) vehicle glass
5 (Con)  containers
6 (Tabl) tableware
7 (Head) vehicle headlamp glass

The ten groups used for the cross-validation experiments (I believe)
are listed as row numbers in the file fglass.grp,



Diabetes in Pima Indians
------------------------

A population of women who were at least 21 years old, of Pima Indian heritage
and living near Phoenix, Arizona,  was tested for diabetes
according to World Health Organization criteria.  The data
were collected by the US National Institute of Diabetes and Digestive and
Kidney Diseases (Smith et al, 1988). This example is also contained in the
UCI machine-learning database collection (Murphy & Aha, 1995).

The data files have rows containing

npreg 	number of pregnancies
glu 	plasma glucose concentration in an oral glucose tolerance test
bp 	diastolic blood pressure (mm Hg)
skin 	triceps skin fold thickness (mm)
ins	serum insulin (micro U/ml)
bmi 	body mass index (weight in kg/(height in m)^2)
ped 	diabetes pedigree function
age 	in years
type	No / Yes

Data file pima.tr   has 200 rows of complete training data.
pima.te   has 332 rows of complete test data.
pima.tr2  has the 200 rows of pima.tr plus 100 incomplete rows.



Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last"
458,analcatdata_authorship,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
459,analcatdata_asbestos,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 1


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
460,analcatdata_reviewer,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
461,analcatdata_creditscore,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
462,analcatdata_challenger,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 4


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
463,backache,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data file:
This data from ""Problem-Solving"" on ""backache in pregnancy""
is in somewhat different
format from that listed in the book. Each integer is preceded by a space.
This makes it easier to read. Each line is split in two separated by an
ampersand. Each line also has a full stop (or period) at the end of each
line which should be removed. If you have any queries, please contact me.
Chris Chatfield.
cc@maths.bath.ac.uk


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last"
464,prnn_synth,"**Author**: B.D. Ripley  
**Source**: Unknown - Date unknown  
**Please cite**:   

Dataset from `Pattern Recognition and Neural Networks' by B.D. Ripley. Cambridge University Press (1996)  ISBN  0-521-46086-7. The background to the datasets is described in section 1.4; this file relates the computer-readable files to that description.

**synthetic two-class problem**
Data from Ripley (1994a).

This has two real-valued co-ordinates (xs and ys) and a class (xc)
which is 0 or 1."
465,analcatdata_cyyoung8092,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
466,schizo,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Schizophrenic Eye-Tracking Data in Rubin and Wu (1997)
Biometrics. Yingnian Wu (wu@hustat.harvard.edu) [14/Oct/97]


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last"
467,analcatdata_japansolvent,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 2


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
468,confidence,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

CODING:

ITEM 1 = BUSINESS CONDIDIONS 6 MONTHS FROM NOW  (CONFERENCE BOARD)
ITEM 2 = JOBS 6 MONTHS FROM NOW (CONFERENCE BOARD)
ITEM 3 = FAMILY INCOME 6 MONTHS FROM NOW  (CONFERENCE BOARD)
ITEM 4 = BUSINESS CONDITIONS A YEAR FROM NOW  (MICHIGAN)
ITEM 5 = JOBS DURING THE COMING 12 MONTHS  (MICHIGAN)
ITEM 6 = FAMILY INCOME DURING THE NEXT 12 MONTHS  (MICHIGAN)

RESPONSE P = PESSIMISTIC
RESPONSE N = NEUTRAL
RESPONSE O = OPTIMISTIC


1992 DATA:




I AM GORDON BECHTEL AT E-MAIL BECHTEL AT NERVM.NERDC.UFL.EDU
I AM WILLING TO HELP THOSE WHO HAVE PROBLEMS WITH THESE DATA.


(3) THE CONFERENCE BOARD HAS GIVEN ITS PERMISSION TO PLACE ITS THREE
""6 MONTH"" ITEMS IN STATLIB.
THE SURVEY RESEARCH CENTER AT THE UNIVERSITY OF MICHIGAN HAS GIVEN
ITS PERMISSION TO PLACE ITS THREE ""12 MONTH"" ITEMS IN STATLIB.


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 1"
469,analcatdata_dmft,"**Author**: Unknown   
**Source**: [Jeffrey S. Simonoff](http://people.stern.nyu.edu/jsimonof/AnalCatData/Data/) - 2003    
**Please cite**: Jeffrey S. Simonoff, Analyzing Categorical Data, Springer-Verlag, 2003

One of the datasets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff. It contains data on the DMFT Index (Decayed, Missing, and Filled Teeth) before and after different prevention strategies. The prevention strategy is commonly used as the (categorical) target.

### Attribute information  
* DMFT.Begin and DMFT.End: DMFT index before and after the prevention strategy
* Gender of the individual
* Ethnicity of the individual"
470,profb,"**Author**: Hal Stern, Robin Lock  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/profb)   
**Please cite**:   

PRO FOOTBALL SCORES  (raw data appears after the description below)

How well do the oddsmakers of Las Vegas predict the outcome of
professional football games?  Is there really a home field advantage - if
so how large is it?  Are teams that play the Monday Night game at a
disadvantage when they play again the following Sunday?  Do teams benefit
from having a ""bye"" week off in the current schedule?  These questions and
a host of others can be investigated using this data set.

Hal Stern from the Statistics Department at Harvard University has
made available his compilation of scores for all National Football League
games from the 1989, 1990, and 1991 seasons.  Dr. Stern used these data as
part of his presentation ""Who's Number One?"" in the special ""Best of
Boston"" session at the 1992 Joint Statistics Meetings.

Several variables in the data are keyed to the oddsmakers ""point
spread"" for each game.  The point spread is a value assigned before each
game to serve as a handicap for whichever is perceived to be the better
team.  Thus, to win against the point spread, the ""favorite"" team must beat
the ""underdog"" team by more points than the spread.  The underdog ""wins""
against the spread if it wins the game outright or manages to lose by fewer
points than the spread.  In theory, the point spread should represent the
""expert"" prediction as to the game's outcome.  In practice, it more usually
denotes a point at which an equal amount of money will be wagered both for
and against the favored team.

Raw data below contains 672 cases (all 224 regular season games in
each season and informatino on the following 9 varialbes:     .

Home/Away       = Favored team is at home (1) or away (0)
Favorite Points = Points scored by the favored team
Underdog Points = Points scored by the underdog team
Pointspread     = Oddsmaker's points to handicap the favored team
Favorite Name   = Code for favored team's name
Underdog name   = Code for underdog's name
Year            = 89, 90, or 91
Week            = 1, 2, ... 17
Special         = Mon.night (M), Sat. (S), Thur. (H), Sun. night (N)
ot - denotes an overtime game"
471,analcatdata_draft,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
472,lupus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

87 persons with lupus nephritis. Followed up 15+ years. 35 deaths. Var =
duration of disease. Over 40 baseline variables avaiable from authors.
Description :
For description of this data set arising from 87 persons
with lupus nephritis followed for 15+ years after an initial
renal biopsy (the starting point of follow-up) see the introduction to
Abrahamowicz, MacKenzie and Esdaile (December 1996 issue).
This data set only contains time to death/censoring, indicator,
duration and log(1+duration), where duration is the duration
of untreated  disease prior to biopsy. This variable was the
focus in the aforementioned JASA article because it clearly
violates the proportionality of hazards assumption. More than
40 other variables acquired at baseline are available from
authors.
Permission :
This data can be freely used for non-commercial purposes and
distributed freely.
Michal Abrahamowicz, Todd MacKenzie and John Esdaile


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 2"
473,cjs,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

---------------------------------------------------------------------------
Short description
---------------------------------------------------------------------------
Data on tree growth used in the Case Study published in the September, 1995
issue of the Canadian Journal of Statistics

---------------------------------------------------------------------------
Permission
---------------------------------------------------------------------------
This data set was been provided by Dr. Fernando Camacho,
Ontario Hydro Technologies, 800 Kipling Ave, Toronto Canada M3Z 5S4.
It forms the basis of the Case Study in Data Analysis published in
the Canadian Journal of Statistics, September 1995.
It can be freely used for non-commercial purposes, as long as proper
acknowledgement to the source and to the Canadian Journal of Statistics
is made.

---------------------------------------------------------------------------
Description
---------------------------------------------------------------------------

The effects of the Growth Regulators Paclobutrazol (PP 333)
and Flurprimidol (EL-500) on the Number and Length of Internodes
in Terminal Sprouts Formed on Trimmed Silver Maple Trees.

Introduction:

The trimming of trees under distribution lines on city streets and
in rural areas is a major problem and expense for electrical
utilities.  Such operations are routinely performed at intervals of
one to eight years depending upon the individual species growth rate
and the amount of clearance required.  Ontario Hydro trims about
500,000 trees per year at a cost of about $25 per tree.

Much effort has been spent in developing chemicals for the horticultural
industry to retard the growth of woody and herbaceous plants.  Recently,
a group of new growth regulators was introduced which was shown to be
effective in controlling the growth of trees without producing
noticeable injury symptoms.  In this group are PP 333 ( common name
paclobutrazol) (2RS, 3RS - 1 -(4-chlorophenyl) - 4,4 - dimethyl - 2 -
(1,2,4-triazol-l-yl) pentan - 3- ol and EL-500 (common name flurprimidol
and composition alpha - (1-methylethyl) - alpha - [4-(trifluromethoxyl)
phenyl] - 5- pyrimidine - methanol).  Both EL-500 and PP-333 have been
reported to control excessive sprout growth in a number of species
when applied as a foliar spray, as a soil drench, or by trunk injection.
Sprout length is a function of both the number of internodes and
the length of the individual internodes in the sprout.  While there
have been many reports that both PP 333 and EL-500 cause a reduction
in the length of internodes formed in sprouts on woody plants treated
with the growth regulators, there has been but one report that EL-500
application to apple trees resulted in a reduction of the number
of internodes formed per sprout.

The purpose of the present study was to investigate the length of the
terminal sprouts, the length of the individual internodes in those
sprouts, and the number of internodes in trimmed silver maple trees
following trunk injection with the growth regulators PP 333 and EL-500.

Experimental Details.

Multistemmed 12-year-old silver maple trees growing at Wesleyville,
Ontario were trunk injected with methanolic solutions of EL-500
and PP-333 in May of 1985 using a third generation Asplundh
tree injector.

Two different application rates (20 g/L and 4 g/L) were used for each
chemical.  The volume of solution (and hence the amount of active
ingredient) injected into each tree was determined from the diameter
of the tree, using the formula: vol(mL) = (dbh)*(dbh)*.492 where dbh
is the diameter at breast height.  Two sets of control trees were
included in the experiment.  In one set, tree received no injection
(control) and in a second set, the trees were injected with
methanol, the carrier in the growth regulator solutions.  Ten trees,
chosen at random, were used in each of the control and experimental
sets.  Prior to injection, all the trees were trimmed by a forestry
crew, with their heights being reduced by about one third.

In January 1987, twenty months after the trees were injected, between
six and eight limbs were removed at random from the bottom two-thirds
of the canopy of each of the ten trees in each experimental and control
set.  The limbs were returned to the laboratory and the length of all
the terminal sprouts, the lengths of the individual internodes, and
the number of internodes recorded.  Between one and 25 terminal
sprouts were found on each limb collected.  Sprouts which had a
length of 1 cm or less were recorded as being 1 cm in length.
In such spouts, the internode lengths were not measured, but were
calculated from the total length of the sprout and the number
of internodes counted.  Internode lengths were then expressed to one
decimal place.  In two instances, one of the ten trees in a set
could not be sampled because limb removal would have jeopardized the
health of the tree over the long-term.

Data set:

Each of the records represents a terminal sprout and contains the
following information:
N  - the sprout number
TR - treatment 1 - control
2 - methanol control
3 - PP 333 20g/L
4 - PP 333  4g/L
5 - EL 500 20g/L
6 - EL 500  4g/L
TREE - tree id
BR   - branch id
TL   - total sprout length (cm)
IN   - number of internodes on the sprout
INTER- a list of the lengths of the internodes in the sprout,
starting from the base of the sprout (1-29 entries)

Sprouts 1868 to 1879 do not have branch identification data.

Here is a portion of the data file.

1   1 G28  A  75.0 15  1.0  2.3  7.4  8.6  6.7  7.2  6.6  6.2  5.5  5.0  5.4  5.0  4.4  2.6  0.8
2   1 G28  B  18.0  7  0.7  1.3  4.0  5.2  2.8  2.2  1.5
3   1 G28  C  46.0 11  0.5  1.0  4.3  8.8  6.8  7.6  6.2  4.7  3.5  2.2  0.5
4   1 G28  C  16.0  8  0.5  1.2  3.5  4.2  2.2  2.8  1.5  0.1
5   1 G28  D  56.0 16  0.5  1.0  3.5  8.2  5.3  6.2  4.8  4.7  3.1  3.8  3.3  4.3  3.5  2.4  1.2  0.3
.
.
.
10   1 G28  G   1.0  3  0.3  0.5  0.3
11   1 G28  G   1.0  3  0.2  0.6  0.5
12   1 G28  G   4.0  5  0.5  0.7  1.3  1.0  0.1
13   1 G28  G  16.0  8  0.7  1.2  3.2  4.7  2.8  1.8  1.0  0.2
14   1 G28  G   3.0  4  0.5  1.0  1.2  0.1
15   1 G28  G  21.0 10  0.5  0.8  2.4  4.0  3.0  3.2  2.6  2.1  1.4  0.7
.
.
.
18   1 M33  A   9.0  5  1.2  2.2  3.1  2.2  0.7
19   1 M33  A  20.5  7  0.6  3.0  5.8  5.4  3.6  1.7  0.4
20   1 M33  A  47.0 13  0.5  2.4  2.8  3.5  3.1  3.6  3.8  5.1  8.6  6.5  5.6  1.1  0.3
21   1 M33  A   4.0  4  0.4  2.0  1.7  0.2
22   1 M33  A   5.0  5  0.2  1.2  1.6  1.5  0.7
.
.
.

---------------------------------------------------------------------------


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 2"
474,analcatdata_marketing,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
475,analcatdata_germangss,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 1


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
476,analcatdata_bankruptcy,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
477,fl2000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

County data from the 2000 Presidential Election in Florida.

Compiled by Brett Presnell
Department of Statistics, University of Florida

These data are derived from three sources, described below.  As far
as I am aware, you are free to use these data in any way that you
see fit, though some acknowledgement is always nice.

The candidate vote counts are the final certified counts reported
by the Florida Division of Elections.  These were obtained from
the NORC web site in the file Cert_results.csv.  Note that these
do NOT inculde the federal absentee votes (so that Gore's total
vote is actually higher here than Bush's).

The undervote and overvote counts were extracted from the NORC
ballot level data in the file aligned.txt.  Since aligned.txt is
too large to work with in R (or almost any other program) I used
cut (a standard UNIX program) to extract just the columns I needed:

cut -f 2,9,10 -d""|"" aligned.txt  > tmp

Then I read the results into R and processed them there.

The technology and columns data were extracted from the Media
Group data from the NORC web site.  ""Technology"" is simply the
type of voting machine used, and ""columns"" is 1 if the ballot
listed the presidential candidates in a single column on a single
page, and 2 if the presidential candidates were spread over two
columns or two pages of the ballot.

These agree with some earlier data that I had obtained from the NY
Times web site, except that in the media group data the PalmBeach
county ballot (the famous butterfly ballot) was listed as having
one column.  I would definitely call this a two-column ballot, so
that is the designation recorded here.  At one time I thought that
MiamiDade County also used a two-column ballot, but I was wrong
(the ballot listed the candidates and parties in English and
Spanish in opposing columns).  Images of most of the ballots can
be found on the New York Times web site:
www.nytimes.com/images/2001/11/12/politics/recount/index_BALLOT.html



Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: 2"
479,analcatdata_cyyoung9302,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
480,prnn_viruses,"**Author**: B.D. Ripley  
**Source**: StatLib - Date unknown  
**Please cite**:   

Dataset from `Pattern Recognition and Neural Networks' by B.D. Ripley. Cambridge University Press (1996)  ISBN  0-521-46086-7

The background to the datasets is described in section 1.4; this file relates the computer-readable files to that description.

viruses

This is a dataset on 61 viruses with rod-shaped particles affecting various crops (tobacco, tomato, cucumber and others) described by {Fauquet et al. (1988) and analysed by Eslava-G\'omez (1989).  There are 18 measurements on each virus,  the number of amino acid residues per molecule of coat protein.

The whole dataset is in order Hordeviruses (3), Tobraviruses (6), Tobamoviruses (39) and `furoviruses' (13).

These were added as the last (target) attribute"
481,biomed,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

February 23, 1982

The 1982 annual meetings of the American Statistical Association (ASA)
will be held August 16-19, 1982 in Cincinnati.  At that meeting, the ASA
Committee on Statistical Graphics plans to sponsor an ""Exposition of
Statistical Graphics Technology.""  The purpose of this activity is to
more fully inform the ASA membership about the capabilities and uses of
computer graphcis in statistical work.   This letter is to invite you to
participate in the Exposition.

Attached is a set of biomedical data containing 209 observations (134
for ""normals"" and 75 for ""carriers"").  Each vendor of provider of
statistical graphics software participating in the Exposition is to
analyze these data using their software and to prepare tabular, graphical
and text output illustrating the use of graphics in these analyses and
summarizing their conclusions.  The tabular and graphical materials must be
direct computer output from the statistical graphics software; the
textual descriptions and summaries need not be.  The total display space
available to each participant at the meeting will be a standard poster-
board (approximately 4' x 2 1/2').  All entries will be displayed in one
location at the meetings, together with brief written commentary by
the committee summarizing the results of this activity.

Reference

Exposition of Statistical Graphics Technology,
L. H. Cox, M. M. Johnson, K. Kafadar,
ASA Proc Stat. Comp Section, 1982, pp 55-56.
Enclosures


THE DATA

The following data arose in a study to develop screening methods to
identify carriers of a rare genetic disorder. Four measurements m1,
m2, m3, m4 were made on blood samples. One of these, m1, has been used
before.

The disease is Duchenne muscular dystrophy. Measurements are:  
M1- serum creatine kinase.  
M2- hemopexin.  
M3- pyruvate kinase.  
M4- lactate dehydrogenase.  

Because the disease is rare, there are only a few carriers of
the disease from whom data are available. The data come in two files,
one for normals and one for carriers of the disease. A description of
the files is provided. The data have been stripped of the names and
other identifiers. Otherwise the data are as received by the analyst.


PURPOSE OF THE ANALYSIS

The purpose of the analysis is to develop a screening procedure to
detect carriers and to describe its effectiveness.  Experts in the
field have noted that young people tend to have higher measurements.
The laboratory which prepared the measurements is worried that there
may be a systematic drift over time in their measurement process.
These effects should be considered in the analysis.  Can graphical
displays show the differences between the distributions of carriers
and normals?


FILE DESCRIPTION


Column	Content

1	Observation number (sequence number per patient)
Note that there are several samples per patient
for some patients.
2-8	Blank
9-12	Hospital identification number for blood sample
13-18	Blank
19-20	Age of patient
21-26	Blank
27-32	Date that blood sample was taken (mmddyy)
Note that all day entries are 00.
33-39	Blank
40-43	ml (measurement 1) sss.s
44-50	Blank
51-54	m2 (measurement 2) xxx.x Eight missing data points.
55-61	Blank
62-65	m3 (measurement 3) xxx.x
66-72	Blank
73-75	m4 (measurement 4) xxx Seven missing data points.



Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last"
482,arsenic-male-bladder,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
483,iq_brain_size,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Relationship between IQ and Brain Size

Summary:
Monozygotic twins share numerous physical, psychological, and pathological traits.  Recent advances in in vivo brain image acquisition and analysis have made it possible to determine quantitatively whether: 1) twins share neuroanatomical traits; and 2) neuroanatomical measures correlate with brain size.
Using magnetic resonance imaging and computer-based image analysis techniques, measurements of the volume of the forebrain, the surface area of the cerebral cortex and the mid-sagittal area of the corpus callosum were obtained in 10 pairs of monozygotic twins.  Head circumference, body weight, and Full-Scale IQ were also measured.  Analyses of variance were carried out using genotype, birth order, and sex, as between-subject factors.  Pearson correlation coefficients were computed to assess the interrelationships between brain measures, head circumference, and IQ.
Effects of genotype (but not of birth order) were found for total forebrain volume, total cortical surface area, and callosal area.  Consistent with previous twin studies, highly significant effects of genotype but not birth order were also found for head circumference, body weight, and Full-Scale IQ.  The significant effect of genotype on all measures was not attributable to sex differences across unrelated twin pairs.  Significant correlations were observed between forebrain volume, cortical surface area, and callosal area as well as between each brain measure and head circumference.  No correlation between IQ and any other measure was found.
Monozygotic twins share similarities in forebrain volume, cortical surface area, and callosal area.  Brain measures are highly correlated with one another and with head circumference, but none is correlated with IQ.

Authorization: Contact Authors

Reference:
Tramo MJ, Loftus WC, Green RL, Stukel TA, Weaver JB, Gazzaniga MS.  Brain Size, Head Size, and IQ in Monozygotic Twins.  Neurology  1998; 50:1246-1252.

Description:  This datafile contains 20 observations (10 pairs of twins) on 9 variables.  This data set can be used to demonstrate simple linear regression and correlation.


Variable Names in order from left to right:
CCMIDSA: Corpus Collasum Surface Area (cm2)
FIQ: Full-Scale IQ
HC: Head Circumference (cm)
ORDER: Birth Order
PAIR: Pair ID (Genotype)
SEX: Sex (1=Male 2=Female)
TOTSA: Total Surface Area (cm2)
TOTVOL: Total Brain Volume (cm3)
WEIGHT: Body Weight (kg)



Therese Stukel
Dartmouth Hitchcock Medical Center
One Medical Center Dr.
Lebanon, NH 03756
e-mail: stukel@dartmouth.edu


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 2"
485,analcatdata_vehicle,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
486,papir_1,"**Author**: Magne Aldrin (magne.aldrin@nr.no)  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - April 14. 1999  
**Please cite**:   

One of two multivariate regression data sets from paper industry, from an experiment at the paper plant Norske Skog, Skogn, Norway. They have been described and analysed in:  
Aldrin, M. (1996), ""Moderate projection pursuit regression for multivariate response data"", Computational Statistics and Data Analysis,
21, p. 501-531.

It consists of 30 observations (rows) and 22 variables (columns), but all response variables are missing for the 28th observation. Columns 1 to 13 are response variables that describes various qualities of the paper. Columns 14 to 22 are 9 predictor variables. The first three predictor variables (x1 in column 14, x2 in column 15 and x3 in column 16) were varied systematically through the experiment, taking the values 1, 0 and -1. The next three predictor variables (columns 17 to 19) are constructed as x1**2, x2**2 and x3**2. The last three predictor variables (columns 20 to 22) are constructed as x1*x2, x1*x3 and x2*x3."
487,papir_2,"**Author**: Magne Aldrin (magne.aldrin@nr.no)  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - April 14. 1999  
**Please cite**:   

One of two multivariate regression data sets from paper industry, from an experiment at the paper plant Saugbruksforeningen, Norway. They have been described and analysed in:  
Aldrin, M. (1996), ""Moderate projection pursuit regression for multivariate response data"", Computational Statistics and Data Analysis,
21, p. 501-531.

It consists of 30 observations (rows) and 41 variables (columns). Columns 1 to 32 are response variables that describes various qualities 
of the paper. Columns 33 to 41 are 9 predictor variables. The first three predictor variables  (x1 in column 33, x2 in column 34 and x3 in column 35) were varied systematically through the experiment. The next three predictor variables (columns 36 to 38) are constructed as x1**2, x2**2 and x3**2. The last three predictor variables (columns 39 to 41) are constructed as x1*x2, x1*x3 and x2*x3."
488,colleges_aaup,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The AAUP dataset for the ASA Statistical Graphics Section's 1995
Data Analysis Exposition contains information on faculty salaries
for 1161 American colleges and universities.  The data may be
obtained in either of two formats.

AAUP.DATA contains the raw data in comma delimited fields with a
single data line for each school. The order of variables is the
same as given below for the fixed column version, although the
spacing varies for each school.

AAUP2.DATA has the data arranged in fixed columns, with two data
lines for each school and a maximum line length of 80 characters.

This dataset is taken from the March-April 1994 issue of Academe.
Thanks to Maryse Eymonerie, Consultant to AAUP, for assistance in
supplying the data.  Faculty salary data are for the 1993-94
school year. You may wish to consult a copy of the special issue
of Academe for more detailed descriptions of the variables.

Data Revised: Wed Jan 18 1995

VARIABLE DESCRIPTIONS (AAUP2.DAT)
Fixed column format with two data lines per school

Line #1
1 -  5   FICE (Federal ID number)
7 - 37   College name
38 - 39   State (postal code)
40 - 43   Type  (I, IIA, or IIB)
44 - 48   Average salary - full professors
49 - 52   Average salary - associate professors
53 - 56   Average salary - assistant professors
57 - 60   Average salary - all ranks
61 - 65   Average compensation - full professors
66 - 69   Average compensation - associate professors
70 - 73   Average compensation - assistant professors
74 - 78   Average compensation - all ranks

Line #2
1 -  4   Number of full professors
5 -  8   Number of associate professors
9 - 12   Number of assistant professors
13 - 16   Number of instructors
17 - 21   Number of faculty - all ranks

Missing values are denoted with *
All salary and compensation figures are yearly in $100's

**************************************************************
To obtain the dataset from Statlib, send one of the single line
messages below to the address statlib@lib.stat.cmu.edu

send aaup.data from colleges
or
send aaup2.data from colleges


For more information on the ASA Statistical Graphics Section's
1995 Data Analysis Exposition send the message

send readme from colleges

%%%%%%%%%%%%%%
INFORMATION %
%%%%%%%%%%%%%%

WHAT'S WHAT AMONG AMERICAN COLLEGES AND UNIVERSITIES?

This is the subject of the 1995 Data Analysis Exposition
sponsored by the Statistical Graphics Section of the American
Statistical Association.  The purpose of the Exposition is to
encourage statisticians to demonstrate techniques, especially
graphical, for analyzing data and displaying the results of an
analysis.  Individuals and groups will work with the same set of
data and present their analyses at a special session as part of
the annual Joint Statistical Meetings in Orlando, Florida on
August 13th-17th, 1995.  The datasets for 1995 are drawn from two
sources, U.S. News & World Report's Guide to Americas Best
Colleges and the AAUP (American Association of University
Professors) 1994 Salary Survey which appeared in the March-April
1994 issue of Academe.

The U.S. News data contains information on tuition, room & board
costs, SAT or ACT scores, application/acceptance rates,
graduation rate, student/faculty ratio, spending per student, and
a number of other variables for 1300+ schools. The AAUP data
includes average salary, overall compensation, and number of
faculty broken down by full, associate, and assistant professor
ranks.

The raw data and documentation are contained in the files
described below.  To obtain any of these files send a message to
statlib@lib.stat.cmu.edu of the following form  (substituting the
file you want for XXXXX)

send XXXXX from colleges

Available files

usnews.doc      Documentation for the U.S. News data
usnews.data     U.S. News data in comma delimited format
usnews3.data    U.S. News data in fixed column format

aaup.doc        Documentation for the AAUP salary data
aaup.data       AAUP salary data in comma delimited format
aaup2.data      AAUP salary data in fixed column format

Two versions of each dataset are provided to accommodate users
with different software constraints.  The comma delimited
versions (USNEWS.DATA and AAUP.DATA) contain information for each
college on a separate line with values delimited by commas.  The
fixed column versions (USNEWS3.DATA and AAUP2.DATA) use 2 or 3
data lines per school and a maximum line length of 80 characters.

To participate in the 1995 Data Analysis Exposition you must send
an abstract form to the American Statistical Association by
February 1st, 1995.  Information is available from the ASA
Meetings Department by e-mail (meetings@asa.mhs.compuserve.com),
phone (703-684-1221), fax (703-684-2037), or surface mail (ASA,
1429 Duke St., Alexandria, VA 22314).  Your initial abstract may
be fairly general since you may do the bulk of your analysis
after the February 1 deadline.

You may choose your own path to proceed in analyzing the data or
use some of the suggested questions below to get started.

... How well can we model tuition using the other variables?
... How might we cluster colleges into similar comparison groups?
... How can we best display faculty salary structure?
... Can we find a reasonable way to rank the schools?

You may work on your own or put together a team.  Show off the
capabilities of your favorite software package or use the data
for a class project and display your students results.  You may
choose to consider just a subset of schools or examine regional
patterns.  The main point is to find innovative ways to display
the interesting features of the data.

Further questions about the 1995 Exposition can be directed to
Robin Lock, Mathematics Department, St. Lawrence University,
Canton, NY 13617  e-mail   rlock@vm.stlawu.edu

If you would like to be informed about any subsequent adjustments
or error fixes to the 1995 Exposition data, please send an e-mail
message to register your interest to rlock@vm.stlawu.edu.

Special thanks for providing data for the 1995 Exposition to:
Robert Morse, Director of Research for America's Best Colleges at
U.S. News & World Report
Maryse Eymonerie, Consultant to AAUP.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
490,hip,"**Author**: cc@maths.bath.ac.uk  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - Date unknown  
**Please cite**:   

This is the hip measurement data from Table B.13 in Chatfield's Problem Solving (1995, 2nd edn, Chapman and Hall). It is given in 8 columns. First 4 columns are for Control Group. Last 4 columns are for Treatment group (Note there is no pairing. Patient 1 in Control Group is NOT patient 1 in Treatment Group)."
491,analcatdata_negotiation,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
492,newton_hema,"**Author**: Michael Newton (newton@stat.wisc.edu)  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 11-6-93  
**Please cite**:   

Data on fluctuating proportions of marked cells in marrow from heterozygous Safari cats from a study of early hematopoiesis.

The data included below are 11 time series of proportions of marked progenitor cells from the bone marrow of the hybrid Safari
cat.  These data come from experiments done by J. L. Abkowitz and colleagues at the University of Washington, Seattle.  

There are four columns and a total of 140 records. The first column is an id for the cat in the study. The second colum records the
time, in weeks from the start of monitoring, that the measurement from marrow is recorded. The third column gives the percent of domestic-type progenitor cells observed in a sample of cells at that time. The fourth column gives the sample size at that time, i.e. the number of progenitor cells analyzed.

For background on the data, see:  
Abkowitz et al., 1988, Blood 71:1687--1692  
Abkowitz et al., 1990, PNAS, 87:9062--9066  
Abkowitz et al, 1993, Blood, 82:2096--2103  
Guttorp et al., 1990, IMA J. Math. App. Med. Bio., 7:125--143  

These particular data are used in an analysis by Newton et al, 1993 ``Stochastic Modeling of Early Hematopoiesis.''"
493,wind_correlations,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

These data are estimated correlations between daily 3 p.m. wind
measurements during September and October 1997 for a network
of 45 stations in the Sydney region.
The first column below gives a list of station latitudes,
the second gives a list of station longitudes, and
the remaining 45 columns give the 45 x 45 spatial correlation
matrix of the station measurements.
Further details about the data are contained
in the following technical report:
Nott and Dunsmuir (1998) ``Analysis of Spatial Covariance
Structure from Monitoring Data,'' Technical Report,
Department of Statistics, University of New South Wales.
Email djn@maths.unsw.edu.au with any questions or to
obtain a copy of the latest version of the above report.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
494,analcatdata_hiroshima,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 2


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
495,baseball-pitcher,"**Author**: Lorraine Denby    
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/)  
**Please cite**:   

**Analysis of Baseball Salary Data: Pitchers**  
This analysis describes and summarizes the relationships between 1987 salaries of major league baseball players and the player's performance. The salary data were taken from Sports Illustrated, April 20, 1987. The salary of any player not included in that article is listed as an NA. The 1986 and career statistics were taken from The 1987 Baseball Encyclopedia Update published by Collier  Books,  Macmillan  Publishing  Company, New York. The team attendance figures were obtained from the Elias Sports Bureau, personal conversation.  

The data consist of data on the regular and leading substitute pitchers in 1986 of North American Major League Baseball players. 

### Attribute information  
There is one line per pitcher. The variables are:  
pitcher's name,  
player's team at the end of in 1986,  
player's league at the end of 1986,  
number of wins in 1986,  
number of losses in 1986,  
earned run average in 1986,  
number of games in 1986,  
number of innings pitched in 1986,  
number of saves in 1986,  
number of years in the major leagues,  
number of wins during his career,  
number of losses during his career,  
earned run average during his career,  
number of games during his career,  
number of innings pitched during his career,  
number of saves during his career,  
1987 annual salary on opening day in thousands of  dollars,  
player's league at the beginning of 1987,  
player's team at the beginning of 1987."
497,veteran,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Veteran's Administration Lung Cancer Trial
Taken from Kalbfleisch and Prentice, pages 223-224

Variables
Treatment  1=standard,  2=test
Celltype   1=squamous,  2=smallcell,  3=adeno,  4=large
Survival in days
Status     1=dead, 0=censored
Karnofsky score
Months from Diagnosis
Age in years
Prior therapy  0=no, 10=yes



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
498,analcatdata_runshoes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
500,analcatdata_vineyard,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
501,analcatdata_impeach,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
502,analcatdata_whale,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
503,wind,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

wind   daily average wind speeds for 1961-1978 at 12 synoptic meteorological
stations in the Republic of Ireland (Haslett and raftery 1989).

These data were analyzed in detail in the following article:
Haslett, J. and Raftery, A. E. (1989). Space-time Modelling with
Long-memory Dependence: Assessing Ireland's Wind Power Resource
(with Discussion). Applied Statistics 38, 1-50.

Each line corresponds to one day of data in the following format:
year, month, day, average wind speed at each of the stations in the order given
in Fig.4 of Haslett and Raftery :
RPT, VAL, ROS, KIL, SHA, BIR, DUB, CLA, MUL, CLO, BEL, MAL

Fortan format : ( i2, 2i3, 12f6.2)

The data are in knots, not in m/s.

Permission granted for unlimited distribution.

Please report all anomalies to fraley@stat.washington.edu

Be aware that the dataset is 532494 bytes long (thats over half a
Megabyte).  Please be sure you want the data before you request it.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
504,analcatdata_supreme,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
505,tecator,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is the Tecator data set: The task is to predict the fat content of a
meat sample on the basis of its near infrared absorbance spectrum.
1. Statement of permission from Tecator (the original data source)

These data are recorded on a Tecator Infratec Food and Feed Analyzer
working in the wavelength range 850 - 1050 nm by the Near Infrared
Transmission (NIT) principle. Each sample contains finely chopped pure
meat with different moisture, fat and protein contents.

If results from these data are used in a publication we want you to
mention the instrument and company name (Tecator) in the publication.
In addition, please send a preprint of your article to

Karin Thente, Tecator AB,
Box 70, S-263 21 Hoganas, Sweden

The data are available in the public domain with no responsability from
the original data source. The data can be redistributed as long as this
permission note is attached.
For more information about the instrument - call Perstorp Analytical's
representative in your area.


2. Description of the data file

For each meat sample the data consists of a 100 channel spectrum of
absorbances and the contents of moisture (water), fat and protein.
The absorbance is -log10 of the transmittance
measured by the spectrometer. The three contents, measured in percent,
are determined by analytic chemistry.

There are 240 samples which are divided into 5 data sets for the purpose
of model validation and extrapolation studies. The data sets, further
described in reference 1, are:

Data set  Use               Samples
C         Traning               129
M         Monitoring             43
T         Testing                43
E1        Extrapolation, Fat      8
E2        Extrapolation, Protein 17

The data for all 240 samples appear at the end of this file - 25 lines
per sample. The data sets appear in the order of the table above.
The spectra are preprocessed using a principal component analysis on the
data set C, and the first 22 principal components (scaled to unit
variance) are included for each sample.
Thus if you want to use the data for a standard (interpolation) test
of your algorithm, use sample 1-172 for training and sample 173-215
for testing (and ignore the last 25 samples), and use the first 13 or so
principal components to predict the fat content.

Each line contains the 100 absorbances followed by the 22 principal
components and finally the contents of moisture, fat and protein.

Preceeding the data lines, the following lines appear:

real_in=122
real_out=3
training_examples=172
test_examples=43
extrapolation_examples=25


3. More details on how to use the data

The data are made available as a benchmark for regression models. In order
to compare models, it is practical to use the data set as follows:

C and M combined are used to tune (estimate, train) the model. (Some
approaches set aside some training data to control overfitting. These data
should be a subset of C+M. In (1) the subset M was used for this purpose.)

T is used to test the model once it has been tuned.
If each model has an element of randomness (as is the case
for neural networks) the most reliable measure of performance of a single
model is obtained by selecting a handful of models on the basis of C+M and
quoting the average of the performances on T.
In the presence of randomness it is bad practice to train a lot of models
on C+M and then select the best of these on the basis of T.

C, M and T are drawn from the same pool of data, so T is used to test the
ability of the models to interpolate. The data sets E1 and E2 contain
more fat and protein respectively and are intended to be used to test the
ability of the models to extrapolate.


4. Performance of neural network models

The performance is measured as Standard Error of Prediction (SEP) which
is the root mean square of the difference between the true and the predicted
content.

For the prediction of fat on the data set T the following results were obtained

Reference SEP   method (see the papers for details)
(1)       0.65  10-6-1 network, early stopping
(2)       0.52  10-3-1 network, Bayesian
(3)       0.36  13-X-1 network, Bayesian, Automatic Relevance Determination

A linear model with 10 inputs yields SEP=2.78.

5. References

(1) C.Borggaard and H.H.Thodberg,
""Optimal Minimal Neural Interpretation of Spectra"",
Analytical Chemistry 64 (1992), p 545-551.
(2) H.H.Thodberg, ""Ace of Bayes: Application of Neural Networks with Pruning""
Manuscript 1132, Danish Meat Research Institute (1993),
available by anonymous ftp in the file:
pub/neuroprose/thodberg.ace-of-bayes.ps.Z on the Internet node
archive.cis.ohio-state.edu (128.146.8.52).

(3) Revised and extended version of (2), in preparation, to be
submitted to IEEE Trans. Neural Networks (1995)
available by anonymous ftp in the file:
pub/neuroprose/thodberg.bayesARD.ps.Z on the Internet node
archive.cis.ohio-state.edu (128.146.8.52).

Hans Henrik Thodberg                Email: thodberg@nn.dmri.dk
Danish Meat Research Institute      Phone: (+45) 42 36 12 00
Maglegaardsvej 2, Postboks 57       Fax:   (+45) 42 36 48 36
DK-4000 Roskilde, Denmark

real_in=122
real_out=3
training_examples=172
test_examples=43
extrapolation_examples=25


Note: all 240 samples are included in the same order as mentioned above


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
506,analcatdata_gsssexsurvey,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
507,space_ga,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Geographical Analysis Spatial Data

This georeferenced data set was used in:

Pace, R. Kelley, and Ronald Barry, Quick Computation of Regressions with a Spatially
Autoregressive Dependent Variable, Geographical Analysis, Volume 29, Number 3, July
1997, p. 232-247.

It contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.
Specifically, it contains the total number of votes cast in the 1980 presidential election per
county (VOTES), the population in each county of 18 years of age or older (POP), the
population in each county with a 12th grade or higher education (EDUCATION), the
number of owner-occupied housing units (HOUSES), the aggregate income (INCOME), the X
spatial coordinate of the county (XCOORD), and the Y spatial coordinate of the county
(YCOORD).

The dependent variable is the log of the proportion of votes cast for both candidates in the
1980 presidential election. Hence, we can express our dependent variable as ln(VOTES/
POP) = ln(VOTES)-ln(POP).

The overall data set has the following structure

[ln(VOTES/POP) POP EDUCATION HOUSES INCOME XCOORD YCOORD]

Additional details can be found, along with other data, manuscripts, free spatial software, and
so forth, at www.spatial-statistics.com or www.finance.lsu.edu/re (follow the spatial statistics
link). In particular, the above mentioned manuscript which used the data is available for
download. If you have any questions, send an email to kelley@spatial-statistics.com.






Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 1"
508,nflpass,"**Author**: Roger W. Johnson      
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/)  
**Please cite**:  

**National Football League Passes**  
Dataset listing all-time NFL passers through 1994 by the NFL passing efficiency rating.
Associated passing statistics from which this rating is computed are included.

The dataset lists statistics for 26 players. The first 25 are the top 25 all-time career best rating leaders recognized by the NFL. The 26th player, Otto Graham, has statistics which include his performance in the All-America Football Conference (1946-1949) which is not recognized by the NFL. The statistics given are current through the 1994 regular season. Only passers with a minimum of 1,500 career passing attempts are included.

The NFL describes how to compute its rating in its 1977 document ""National Football League Passer Rating System"" (410 Park Avenue, New York, NY 10022-4444, (212) 758-1500) through the use of tables. No formula is explicitly stated for rating. But, examining the tables in the ""National
Football League Passer Rating System"" one can infer that NFL passer rating is

[5(Completion Percentage-30)/6] + [10(Touchdown Percentage)/3] +
[25(19-2(Interception Percentage))/12] + [25(Yards/Attempts-3)/6]

where it is understood that the values within each set of square brackets are
truncated to be no smaller than zero and no larger than 475/12. This implies a
minimal rating of 0 and a maximal rating of 475/3 or about 158.3. If

30%  &lt;     Completion Percentage   &lt; 77.5%
0%   &lt;     Touchdown Percentage    &lt; 11.875%
0%   &lt;     Interception Percentage &lt;  9.5%
3   &lt;         Yards per Attempt   &lt; 12.5,

which is true of most passers having a reasonable number of passing attempts,
then the rating formula simplifies to

[25 + 10(Completion Percentage) + 40(Touchdown Percentage)
- 50(Interception Percentage) + 50(Yards/Attempt)]/12

(see Johnson (1993, 1994). Note that the weights on interception percentage and
yards per attempt are greatest in magnitude, closely followed by touchdown
percentage. The weight on completion percentage is a distant fourth in
magnitude.


### Classroom Use of this Data   
Using the NFL data from Meserole (1995), for which the above inequalities
hold, one can uncover (at least approximately) the simplified rating formula
using multiple regression. Students can be told that NFL rating is ""based on
performance standards established for completion percentage, average gain,
touchdown percentage and interception percentage"" (Meserole (1995)), but the
actual formula for rating is not widely publicized. Once the rating formula is
uncovered, one can see the relative weights that the NFL assigns to these four
performance standards (see Barra and Neyer (1995) for an alternative). Also, by
citing unusual passers who don't satisfy the above inequalities an instructor
can remind students of the dangers of extrapolation when building regression
models. Here are a few such unusual passers:

Name   Attempts Completions Yards Touchdowns Interceptions Rating

Rypien    3          3       15       0            0        87.5
Marshall  1          1       81       1            0       158.3
Muster    1          0        0       0            1         0.0

The data for Arthur Marshall, a wide-receiver for Denver, and for Brad Muster,
a full-back for Chicago are from the 1992 season. The data for quarterback Mark
Rypien is for his performance at one point during the 1995 season (see _USA
Today_, Thursday September 28, 1995, 9C).

One might also try tracking down the passing (not receiving!) records of Jerry
Rice for the 1995 season as he apparently threw for a touchdown in the regular
season finale.

### Variables (from left to right)  
Passing Attempts  
Passing Completions  
Passing Yards  
Touchdowns by Passing  
Interceptions  
NFL Rating (usually to the nearest tenth, sometimes to the nearest hundredth to eliminate ties that would result when only given to the nearest tenth)  
Name of NFL Player  


### References
Barra, A. and Neyer, R. (1995), ""When rating quarterbacks, yards per throw
matters"", _The Wall Street Journal_, Friday, November 24, B5.

Johnson, R. (1994), ""Rating quarterbacks: An amplification"", _The College
Mathematics Journal_, vol. 25, no. 4, p. 340.

Johnson, R. (1993), ""How does the NFL rate the passing ability of
quarterbacks?"", _The College Mathematics Journal_, vol. 24, no. 5, pp. 451-453.

Meserole, M., editor, (1995), ""The 1996 Information Please Sports Almanac"",
p. 265."
509,places,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This dataset is taken from the Places Rated Almanac, by Richard
Boyer and David Savageau, copyrighted and published by Rand McNally.
This book order (SBN) number is 0-528-88008-X, and it retails for
$14.95 .  The data are reproduced by kind permission of the
publisher, and with the request that the copyright notice of Rand
McNally, and the names of the authors appear in any paper or
presentation using these data.

The nine rating criteria used by Places Rated Almanac are:
Climate & Terrain
Housing
Health Care & Environment
Crime
Transportation
Education
The Arts
Recreation
Economics

For all but two of the above criteria, the higher the score, the
better.  For Housing and Crime, the lower the score the better.

The scores are computed using the following component statistics for
each criterion (see the Places Rated Almanac for details):

Climate & Terrain: very hot and very cold months, seasonal
temperature variation, heating- and cooling-degree days, freezing
days, zero-degree days, ninety-degree days.

Housing: utility bills, property taxes, mortgage payments.

Health Care & Environment: per capita physicians, teaching hospitals,
medical schools, cardiac rehabilitation centers, comprehensive cancer
treatment centers, hospices, insurance/hospitalization costs index,
flouridation of drinking water, air pollution.

Crime: violent crime rate, property crime rate.

Transportation: daily commute, public transportation, Interstate
highways, air service, passenger rail service.

Education: pupil/teacher ratio in the public K-12 system, effort
index in K-12, accademic options in higher education.

The Arts: museums, fine arts and public radio stations, public
television stations, universities offering a degree or degrees in the
arts, symphony orchestras, theatres, opera companies, dance
companies, public libraries.

Recreation: good restaurants, public golf courses, certified lanes
for tenpin bowling, movie theatres, zoos, aquariums, family theme
parks, sanctioned automobile race tracks, pari-mutuel betting
attractions, major- and minor- league professional sports teams, NCAA
Division I football and basketball teams, miles of ocean or Great
Lakes coastline, inland water, national forests, national parks, or
national wildlife refuges, Consolidated Metropolitan Statistical Area
access.

Economics: average household income adjusted for taxes and living
costs, income growth, job growth.


The data are recorded in two ASCII files, PLACES.DAT, and
PLACES.KEY .  The first file contains 329 observations, 9 columns
plus an index column.  The index stands for the location.  PLACES.KEY
gives the index in the first column and the associated name of the
place in the second column.  All data analysis can be done with
numeric variables and the index, as read in from PLACES.DAT .
Alternatively, the numerical key can be replaced by the alphabetic
name, as given by PLACES.KEY .


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 9"
510,sleep,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This dataset contains 3 more features compared to version 1 of the same dataset.

Data from which conclusions  were  drawn  in  the  article  ""Sleep  in
Mammals: Ecological and Constitutional Correlates"" by Allison, T.  and
Cicchetti, D. (1976), _Science_, November 12, vol. 194,  pp.  732-734.
Includes brain and body  weight,  life  span,  gestation  time,  time
sleeping, and predation and danger indices for 62 mammals.



Variables below (from left to right) for Mammals Data Set:

species of animal

body weight in kg

brain weight in g

slow wave (""nondreaming"") sleep (hrs/day)

paradoxical (""dreaming"") sleep (hrs/day)

total sleep (hrs/day)  (sum of slow wave and paradoxical sleep)

maximum life span (years)

gestation time (days)

predation index (1-5)
1 = minimum (least likely to be preyed upon)
5 = maximum (most likely to be preyed upon)

sleep exposure index (1-5)
1 = least exposed (e.g. animal sleeps in a
well-protected den)
5 = most exposed

overall danger index (1-5)
(based on the above two indices and other information)
1 = least danger (from other animals)
5 = most danger (from other animals)



For more details, see

Allison, Truett and Cicchetti, Domenic V. (1976), ""Sleep  in  Mammals:
Ecological and Constitutional  Correlates"",  _Science_,  November  12,
vol. 194, pp. 732-734.



The above data set can be freely used for non-commercial purposes  and
can be freely distributed (permission in  writing  obtained  from  Dr.
Truett Allison).

Submitted by Roger Johnson
rwjohnso@silver.sdsmt.edu



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
511,plasma_retinol,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Determinants of Plasma Retinol and Beta-Carotene Levels

Summary:
Observational studies have suggested that low dietary intake or low plasma concentrations of retinol, beta-carotene, or other carotenoids might be associated with increased risk of developing certain types of cancer.  However, relatively few studies have investigated the determinants of plasma concentrations of these micronutrients. We designed a cross-sectional study to investigate the relationship between personal characteristics and dietary factors, and plasma concentrations of retinol, beta-carotene and other carotenoids. Study subjects (N = 315) were patients who had an elective surgical procedure during a three-year period to biopsy or remove a lesion of the lung, colon, breast, skin, ovary or uterus that was found to be non-cancerous. We display the data for only two of the analytes.
Plasma concentrations of the micronutrients varied widely from subject to subject.  While plasma retinol levels varied by age and sex, the only dietary predictor was alcohol consumption (R^2 = .38). Plasma beta-carotene levels were log-transformed prior to the analyses due to severe asymmetry of the residuals on the original scale. For log beta-carotene, dietary intake, regular use of vitamins, and intake of fiber were associated with higher plasma concentrations, while Quetelet Index (defined as weight/height^2 in the units kg/m^2) and cholesterol intake were associated with lower plasma levels, adjusting for the other factors (R^2 = .50). There was one extremely high leverage point in alcohol consumption that was deleted prior to the analyses. Plasma concentrations of retinol and beta-carotene were not correlated.
We conclude that there is wide variability in plasma concentrations of these micronutrients in humans, and that much of this variability is associated with dietary habits and personal characteristics.  A better understanding of the physiological relationship between some personal characteristics and plasma concentrations of these micronutrients will require further study.

Authorization: Contact Authors

Reference: These data have not been published yet but a related reference is
Nierenberg DW, Stukel TA, Baron JA, Dain BJ, Greenberg ER.  Determinants of plasma levels of beta-carotene and retinol.  American Journal of Epidemiology 1989;130:511-521.

Description:  This datafile contains 315 observations on 14 variables.  This data set can be used to demonstrate multiple regression, transformations, categorical variables, outliers, pooled tests of significance and model building strategies.

Variable Names in order from left to right:
AGE: Age (years)
SEX: Sex (1=Male, 2=Female).
SMOKSTAT: Smoking status (1=Never, 2=Former, 3=Current Smoker)
QUETELET: Quetelet (weight/(height^2))
VITUSE: Vitamin Use (1=Yes, fairly often, 2=Yes, not often, 3=No)
CALORIES: Number of calories consumed per day.
FAT: Grams of fat consumed per day.
FIBER: Grams of fiber consumed per day.
ALCOHOL: Number of alcoholic drinks consumed per week.
CHOLESTEROL: Cholesterol consumed (mg per day).
BETADIET: Dietary beta-carotene consumed (mcg per day).
RETDIET: Dietary retinol consumed (mcg per day)
BETAPLASMA: Plasma beta-carotene (ng/ml)
RETPLASMA: Plasma Retinol (ng/ml)




Therese Stukel
Dartmouth Hitchcock Medical Center
One Medical Center Dr.
Lebanon, NH 03756
e-mail: stukel@dartmouth.edu


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
512,balloon,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The data consist of 2001 observations taken from a balloon about 30 kilometres
above the surface of the earth. In the section of the flight shown here the
balloon increases in height. As radiation increases with height there is a
non-decreasing trend in the data. The outliers are caused by the fact that the
balloon slowly rotates, causing the ropes from which the measuring instrument
is suspended to cut off the direct radiation from the sun. The first column
contains the raw data, the second column the residuals after the removal of a
non-decreasing trend.
Reference:
Davies, L. and Gather, U. (1993), ""The Identification of Multiple
Outliers"" (discussion paper), to appear in JASA.
Mailing address:  Laurie Davies
Universitaet-Gesamthochschule Essen
Fachbereich 6 Mathematik
Universitaetsstrasse 3
D-4300 Essen 1
Germany


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
513,arsenic-female-lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
515,baseball-team,"**Author**: Lorraine Denby    
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/)  
**Please cite**:   

**Analysis of Baseball Salary Data: Team statistics**  
This analysis describes and summarizes the relationships between 1987 salaries of major league baseball players and the player's performance. The salary data were taken from Sports Illustrated, April 20, 1987. The salary of any player not included in that article is listed as an NA. The 1986 and career statistics were taken from The 1987 Baseball Encyclopedia Update published by Collier  Books,  Macmillan  Publishing  Company, New York. The team attendance figures were obtained from the Elias Sports Bureau, personal conversation."
516,pbcseq,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Primary Biliary Cirrhosis

This data set is a follow-up to the original PBC data set, as discussed
in appendix D of Fleming and Harrington, Counting Processes and Survival
Analysis, Wiley, 1991.  An analysis based on the enclised data is found in
Murtaugh PA. Dickson ER. Van Dam GM. Malinchoc M. Grambsch PM.
Langworthy AL. Gips CH.  ""Primary biliary cirrhosis: prediction of short-term
survival based on repeated patient visits."" Hepatology. 20(1.1):126-34, 1994.

Quoting from F&H.  ""The following pages contain the data from the Mayo Clinic
trial in primary biliary cirrhosis (PBC) of the liver conducted between 1974
and 1984.  A description of the clinical background for the trial and the
covariates recorded here is in Chapter 0, especially Section 0.2.  A more
extended discussion can be found in Dickson, et al., Hepatology 10:1-7 (1989)
and in Markus, et al., N Eng J of Med 320:1709-13 (1989).
""A total of 424 PBC patients, referred to Mayo Clinic during that ten-year
interval, met eligibility criteria for the randomized placebo controlled
trial of the drug D-penicillamine.  The first 312 cases in the data set
participated in the randomized trial and contain largely complete data.  The
additional 112 cases did not participate in the clinical trial, but consented
to have basic measurements recorded and to be followed for survival.  Six of
those cases were lost to follow-up shortly after diagnosis, so the data here
are on an additional 106 cases as well as the 312 randomized participants.
Missing data items are denoted by `.'. ""

The F&H data set contains only baseline measurements of the laboratory
paramters.  This data set contains multiple laboratory results, but
only on the first 312 patients.  Some baseline data values in this file
differ from the original PBC file, for instance, the data errors in
prothrombin time and age which were discovered after the orignal analysis,
during research work on dfbeta residuals.  (These two data points are
discussed in F&H, figure 4.6.7).  Another major difference is that
there was significantly more follow-up for many of the patients at the
time this data set was assembled.

One ""feature"" of the data deserves special comment.  The last
observation before death or liver transplant often has many more
missing covariates than other data rows.  The original clinical
protocol for these patients specified visits at 6 months, 1 year, and
annually thereafter.  At these protocol visits lab values were
obtained for a large pre-specified battery of tests.  ""Extra"" visits,
often undertaken because of worsening medical condition, did not
necessarily have all this lab work.  The missing values are thus
potentially informative, and violate the usual ""missing at random""
(MCAR or MAC) assumptions that are assumed in analyses.  Because of
the earlier published results on the Mayo PBC risk score, however, the
5 variables involved in that computation were usually obtained, i.e.,
age, bilirubin, albumin, prothrombin time, and edema score.

Variables:
case number
number of days between registration and the earlier of death,
transplantion, or study analysis time
status: 0=alive, 1=transplanted, 2=dead
drug: 1= D-penicillamine, 0=placebo
age in days, at registration
sex: 0=male, 1=female
day: number of days between enrollment and this visit date, remaining
values on the line of data refer to this visit.
presence of asictes:       0=no 1=yes
presence of hepatomegaly   0=no 1=yes
presence of spiders        0=no 1=yes
presence of edema          0=no edema and no diuretic therapy for edema;
.5 = edema present without diuretics, or edema resolved by diuretics;
1 = edema despite diuretic therapy
serum bilirubin in mg/dl
serum cholesterol in mg/dl
albumin in gm/dl
alkaline phosphatase in U/liter
SGOT in U/ml  (serum glutamic-oxaloacetic transaminase, the enzyme name
has subsequently changed to ""ALT"" in the medical literature)
platelets per cubic ml / 1000
prothrombin time in seconds
histologic stage of disease


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 3"
518,analcatdata_gviolence,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
519,vinnie,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Following are data on the shooting of Vinnie Johnson of the Detroit
Pistons during the 1985-1986 through 1988-1989 seasons. Source was the
New York Times.
The data are analyzed in the Carnegie Mellon Ph.D. Thesis of
Kate Hsiao and some results are cited in Example 2 of Kass, R.E. and
Raftery, A.E. (1995), Bayes Factors, J. Amer. Statist. Assoc.,
The first column is the year, with 85 indicating 1985-1986, etc..
The second column is Field Goals, the third column is Field Goal
Attempts.
A more complete version of the data, including free throws, is
appended together with additional information.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
520,analcatdata_wildcat,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
521,analcatdata_ncaa,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 3 or 4


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
522,pm10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The data are a subsample of 500 observations from a data set
that originate in a study where air pollution at a road is
related to traffic volume and meteorological variables,
collected by the Norwegian Public Roads Administration. The
response variable (column 1) consist of hourly values of the
logarithm of the concentration of PM10 (particles), measured at
Alnabru in Oslo, Norway, between October 2001 and August 2003.
The predictor variables (columns 2 to 8) are the logarithm of
the number of cars per hour, temperature $2$ meter above ground
(degree C), wind speed (meters/second), the temperature
difference between $25$ and $2$ meters above ground (degree C),
wind direction (degrees between 0 and 360), hour of day and day
number from October 1. 2001. Submitted by Magne Aldrin
(magne.aldrin@nr.no). [28/Jul/04] (19kbytes)

Note: description of data is from this website
http://lib.stat.cmu.edu/datasets/


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
523,analcatdata_neavote,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 3


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
524,pbc,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

------------------------------------------------------------------------
Primary Biliary Cirrhosis

The data set found in appendix D of Fleming and Harrington, Counting
Processes and Survival Analysis, Wiley, 1991.  The only differences are:
age is in days
status is coded as 0=censored, 1=censored due to liver tx, 2=death
the sex and stage variables are not missing for obs 313-418

Quoting from F&H.  ""The following pages contain the data from the Mayo Clinic
trial in primary biliary cirrhosis (PBC) of the liver conducted between 1974
and 1984.  A description of the clinical background for the trial and the
covariates recorded here is in Chapter 0, especially Section 0.2.  A more
extended discussion can be found in Dickson, et al., Hepatology 10:1-7 (1989)
and in Markus, et al., N Eng J of Med 320:1709-13 (1989).
""A total of 424 PBC patients, referred to Mayo Clinic during that ten-year
interval, met eligibility criteria for the randomized placebo controlled
trial of the drug D-penicillamine.  The first 312 cases in the data set
participated in the randomized trial and contain largely complete data.  The
additional 112 cases did not participate in the clinical trial, but consented
to have basic measurements recorded and to be followed for survival.  Six of
those cases were lost to follow-up shortly after diagnosis, so the data here
are on an additional 106 cases as well as the 312 randomized participants.
Missing data items are denoted by `.'. ""

Variables:
case number
number of days between registration and the earlier of death,
transplantion, or study analysis time in July, 1986
status
drug: 1= D-penicillamine, 2=placebo
age in days
sex: 0=male, 1=female
presence of asictes:       0=no 1=yes
presence of hepatomegaly   0=no 1=yes
presence of spiders        0=no 1=yes
presence of edema          0=no edema and no diuretic therapy for edema;
.5 = edema present without diuretics, or edema resolved by diuretics;
1 = edema despite diuretic therapy
serum bilirubin in mg/dl
serum cholesterol in mg/dl
albumin in gm/dl
urine copper in ug/day
alkaline phosphatase in U/liter
SGOT in U/ml
triglicerides in mg/dl
platelets per cubic ml / 1000
prothrombin time in seconds
histologic stage of disease


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 3"
525,baseball-hitter,"**Author**: Lorraine Denby    
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/)  
**Please cite**:   

**Analysis of Baseball Salary Data: Hitters**
This analysis describes and summarizes the relationships between 1987 salaries of major league baseball players and the player's performance. The salary data were taken from Sports Illustrated, April 20, 1987. The salary of any player not included in that article is listed as an NA. The 1986 and career statistics were taken from The 1987 Baseball Encyclopedia Update published by Collier  Books,  Macmillan  Publishing  Company, New York. The team attendance figures were obtained from the Elias Sports Bureau, personal conversation.  

The data consist of data on the regular and leading substitute hitters in 1986 of North American Major League Baseball players. 

### Attribute information  
There is one line per hitter. The variables are:
hitter's name,  
number of times at bat in 1986,  
number of hits in 1986,  
number of home runs in 1986,  
number of runs in 1986,  
number of runs batted in in 1986,  
number of walks in 1986,  
number of years in the major leagues,  
number of times at bat during his career,  
number of hits during his career,  
number of home runs during his career,  
number of runs during his career,  
number of runs batted in during his career,  
number of walks during his career,  
player's league at the end of 1986,  
player's division at the end of 1986,  
player's team at the end of 1986,  
player's position(s) in 1986,  
number of put outs in 1986,  
number of assists in 1986,  
number of errors in 1986,  
1987 annual salary on opening day in thousands of dollars,  
player's league at the beginning of 1987,  
player's team at the beginning of 1987."
526,analcatdata_seropositive,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 3


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
527,analcatdata_election2000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
528,humandevel,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Human Development Index [DATA]
United Nations Development Program compiled an Index of Human
Development.  Column 1: Country(character) 2: Index 3: GNP


GNP PER
CAPITA RANK   RANK -
RANK                  HDI   1987          GNP RANK

1 Niger             0.116     20           -19
2 Mali              0.143     15           -13
3 Burkina Faso      0.150     13           -10
4 Sierra Leone      0.150     27           -23
5 Chad              0.157      4             1

6 Guinea            0.162     31           -25
7 Somalia           0.200     23           -16
8 Mauritania        0.208     40           -32
9 Afghanistan       0.212     17            -8
10 Benin             0.212     28           -18

11 Burundi           0.235     18            -7
12 Bhutan            0.236      3             9
13 Mozambique        0.239     10             3
14 Malawi            0.250      7             7
15 Sudan             0.255     32           -17

16 Central Afr. Rep. 0.258     29           -13
17 Nepal             0.273      8             9
18 Senegal           0.274     43           -25
19 Ethiopia          0.282      1            18
20 Zaire             0.294      5            15

21 Rwanda            0.304     26            -5
22 Angola            0.304     58           -36
23 Bangladesh        0.318      6            17
24 Nigeria           0.322     36           -12
25 Yemen Arab Rep.   0.328     47           -22

26 Liberia           0.333     42           -16
27 Togo              0.337     24             3
28 Uganda            0.354     21             7
29 Haiti             0.356     34            -5
30 Ghana             0.360     37            -7

31 Yemen PDR         0.369     39            -8
32 Cote d'Ivoire     0.393     52           -20
33 Congo             0.395     59           -26
34 Namibia           0.404     60           -26
35 Tanzania          0.413     12            23

36 Pakistan          0.423     33             3
37 India             0.439     25            12
38 Madagascar        0.440     14            24
39 Papua New Guinea  0.471     50           -11
40 Kampuchea         0.471      2            38

41 Cameroon          0.474     64           -23
42 Kenya             0.481     30            12
43 Zambia            0.481     19            24
44 Morocco           0.489     48            -4
45 Egypt             0.501     49            -4

46 Laos              0.506      9            37
47 Gabon             0.525     93           -46
48 Oman              0.535    104           -56
49 Bolivia           0.548     44             5
50 Burma (Myanmar)   0.561     11            39

51 Honduras          0.563     53            -2
52 Zimbabwe          0.576     45             7
53 Lesotho           0.580     35            18
54 Indonesia         0.591     41            13
55 Guatemala         0.592     63            -8

56 Viet Nam          0.608     16            40
57 Algeria           0.609     91           -34
58 Botwswana         0.646     69           -11
59 El Salvador       0.651     56             3
60 Tunisia           0.657     70           -10

61 Iran              0.660     97           -36
62 Syria             0.691     79           -17
63 Dominican Rep.    0.699     51            12
64 Saudi Arabia      0.702    107           -43
65 Philipines        0.714     46            19

66 China             0.716     22            44
67 Libya             0.719    103           -36
68 South Africa      0.731     82           -14
69 Lebanon           0.735     78            -9
70 Mongolia          0.737     57            13

71 Nicaragua         0.743     54            17
72 Turkey            0.751     71             1
73 Jordan            0.752     76            -3
74 Peru              0.753     74             0
75 Ecuador           0.758     68             7

76 Iraq              0.759     96           -20
77 United Arab Emir. 0.782    127           -50
78 Thailand          0.783     55            23
79 Paraguay          0.784     65            14
80 Brazil            0.784     85            -5

81 Mauritius         0.788     75             6
82 Korea, Dem. Rep.  0.789     67            15
83 Sri Lanka         0.789     38            45
84 Albania           0.790     61            23
85 Malaysia          0.800     80             5

86 Colombia          0.801     72            14
87 Jamaica           0.824     62            25
88 Kuwait            0.824    122           -34
89 Venezuela         0.861     95            -6
90 Romania           0.863     84             6

91 Mexico            0.876     81            10
92 Cuba              0.877     66            26
93 Panama            0.883     88             5
94 Trinidad/Tobago   0.885    100            -6
95 Portugal          0.899     94             1

96 Singapore         0.899    110           -14
97 Korea, Rep.       0.903     92             5
98 Poland            0.910     83            15
99 Argentina         0.910     89            10
100 Yugoslavia        0.913     90            10

101 Hungary           0.915     87            14
102 Uruguay           0.916     86            16
103 Costa Rica        0.916     77            26
104 Bulgaria          0.918     99             5
105 USSR              0.920    101             4

106 Czechoslovakia    0.931    102             4
107 Chile             0.931     73            34
108 Hong Kong         0.936    111            -3
109 Greece            0.946     98            11
110 German Dem. Rep.  0.953    115            -5

111 Israel            0.957    108             3
112 USA               0.961    129           -17
113 Austria           0.961    118            -5
114 Ireland           0.961    106             8
115 Spain             0.965    105            10

116 Belgium           0.966    116             0
117 Italy             0.966    112             5
118 New Zealand       0.966    109             9
119 Germany, Fed. R.  0.967    120            -1
120 Finland           0.967    121            -1

121 United Kingdom    0.970    113             8
122 Denmark           0.971    123            -1
123 France            0.974    119             4
124 Australia         0.978    114            10
125 Norway            0.983    128            -3

126 Canada            0.983    124             2
127 Netherlands       0.984    117            10
128 Switzerland       0.986    130            -2
129 Sweden            0.987    125             4
130 Japan             0.996    126             4


[From 5 September ""Mennonite Weekly Review""]

Posted on Activist's Mailing List (ACTIV-L@UMCVMB) which should
legally place the data in the public domain, right?

Copied from there and contributed by Tim Arnold (arnold@stat.ncsu.edu)

================================================================

Human Development Index [INFO]
United Nations Development Program compiled an Index of Human
Development. Information file companion to the DATA file.
============================================================================

To measure the quality of life in a nation, the United Nations Development
Program started figuring a Human Development Index.  A nation's HDI is
composed of life expectancy, adult literacy and Gross National Product per
capita.

By combining these three elements and by pitting each nation's indicators
against ""the best,"" we come up with a worldwide HDI.  Comparing the HDI
rating with the traditional GNP per capita rating reveals some poor
countries' remarkable progress in human development.

These countries got more bang for their development buck by giving their
aid to the most needy people.  The comparison also shows that some
countries, including the U.S., did not translate their wealth into social
benefits.

In the HDI rankings, the Arab and Moslem countries come out poorly, mainly
because of low literacy among women.  The formerly communist countries
come out rather well because literacy is a priority and their GNP is
generally low.

Latin America comes out with many plusses because their GNPs are low while
they still enjoy the higher literacy and improved health-care investments
of earlier years.

Africa is a mixed lot.  Some oil exporters, such as Angola, Gabon,
Cameroon and the Congo, did not translate their wealth into social
benefits.  Others--Tanzania, Madagascar, Zambia, which have poorly managed
economies--were still able to improve their people's health and schooling.

Among the wealthier countries, the physical and educational benefits
generally kept pace with improved economies.  An exception is the U.S.,
where the economy flourished in the '80s but social services stagnated and
declined.

The chart below lists the world's countries according to their Human
Development Index--a measure of quality of life based on life expectancy,
adult literacy and Gross National Product per capita.  The nations are
ranked from lowest quality of life to highest.  The ""HDI rank minus GNP
rank column measures how well the nations translate the wealth they have
into benefits for their citizens.  A positive number in this column
indicates the country makes good use of its resources to help its people.
A negative number indicates it does not.
=======================================================================
Posted on Activist's Mailing List (ACTIV-L@UMCVMB) which should
legally place the data in the public domain, right?

Copied from there and contributed by Tim Arnold (arnold@stat.ncsu.edu)



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
529,pollen,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This dataset is synthetic.  It was generated by David Coleman
at RCA Laboratories in Princeton, N.J.  For convenience, we will
refer to it as the POLLEN DATA.  The first three variables are the
lengths of geometric features observed sampled pollen grains - in the
x, y, and z dimensions: a ""ridge"" along x, a ""nub"" in the y
direction, and a ""crack"" in along the z dimension.  The fourth
variable is pollen grain weight, and the fifth is density.

There are 3848 observations, in random order (for people whose
software packages cannot handle this much data, it is recommended
that the data be sampled).  The dataset is broken up into eight
pieces, POLLEN1.DAT - POLLEN8.DAT, each with 481 observations.
We will call the variables:

1. RIDGE
2. NUB
3. CRACK
4. WEIGHT
5. DENSITY

6. OBSERVATION NUMBER (for convenience)

The data analyst is advised that there is more than one ""feature"" to
these data.  Each feature can be observed through various graphical
techniques, but analytic methods, as well, can help ""crack"" the
dataset.

Additional Info:

I no longer have the description handed out during the JSM, but can
tell you how I generated the data, in minitab.

1. Part A was generated: 5000 (I think) 5-variable, uncorrelated, i.i.d.
Gaussian observations.

2. To get part B, I duplicated part A, then reversed the sign on the
observations for 3 of the 5 variables.

3. Part B was appended to Part A.

4. The order of the observations was randomized.

5. While waiting for my tardy car-pool companion, I took a piece of
graph paper, and figured out a dot-matrix representation of the word,
""EUREKA.""  I then added these observations to the ""center"" of the
datatset.

6. The data were scaled, by variable (something like 1,3,5,7,11).

7. The data were rotated, then translated.

8. A few points in space within the datacloud were chosen as ellipsoid
centers, then for each center, all observations within a (scaled and
rotated) radius were identified, and eliminated - to form ellipsoidal
voids.

9. The variables were given entirely ficticious names.

FYI, only the folks at Bell Labs, Murray Hill, found everything,
including the voids.

Hope this is helpful!

References:

Becker, R.A., Denby, L., McGill, R., and Wilks,
A. (1986). Datacryptanalysis: A Case Study.
Proceedings of the Section on Statistical Graphics, 92-97.

Slomka, M. (1986). The Analysis of a Synthetic Data Set.
Proceedings of the Section on Statistical Graphics, 113-116.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
530,analcatdata_olympic2000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
531,boston,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic
prices and the demand for clean air', J. Environ. Economics & Management,
vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics
...', Wiley, 1980.   N.B. Various transformations are used in the table on
pages 244-261 of the latter.
Variables in order:
CRIM     per capita crime rate by town
ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
INDUS    proportion of non-retail business acres per town
CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
NOX      nitric oxides concentration (parts per 10 million)
RM       average number of rooms per dwelling
AGE      proportion of owner-occupied units built prior to 1940
DIS      weighted distances to five Boston employment centres
RAD      index of accessibility to radial highways
TAX      full-value property-tax rate per $10,000
PTRATIO  pupil-teacher ratio by town
B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
LSTAT    % lower status of the population
MEDV     Median value of owner-occupied homes in $1000's


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
532,analcatdata_uktrainacc,"**Author**: Jeffrey S. Simonoff  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 2003  
**Please cite**: Jeffrey S. Simonoff. Analyzing Categorical Data. Springer-Verlag, New York, 2003  

One of the data sets used in the book ""Analyzing Categorical Data"" by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. Further details concerning the book, including information on statistical software, are available at the [web site](http://people.stern.nyu.edu/jsimonof/AnalCatData/)."
533,arsenic-female-bladder,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
534,cps_85_wages,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Determinants of Wages from the 1985 Current Population Survey

Summary:
The Current Population Survey (CPS) is used to supplement census information between census years. These data consist of a random sample of 534 persons from the CPS, with information on wages and other characteristics of the workers, including sex, number of years of education, years of work experience, occupational status, region of residence and union membership. We wish to determine (i) whether wages are related to these characteristics and (ii) whether there is a gender gap in wages.
Based on residual plots, wages were log-transformed to stabilize the variance. Age and work experience were almost perfectly correlated (r=.98). Multiple regression of log wages against sex, age, years of education, work experience, union membership, southern residence, and occupational status showed that these covariates were related to wages (pooled F test, p < .0001). The effect of age was not significant after controlling for experience. Standardized residual plots showed no patterns, except for one large outlier with lower wages than expected. This was a male, with 22 years of experience and 12 years of education, in a management position, who lived in the north and was not a union member. Removing this person from the analysis did not substantially change the results, so that the final model included the entire sample.
Adjusting for all other variables in the model, females earned 81% (75%, 88%) the wages of males (p < .0001). Wages increased 41% (28%, 56%) for every 5 additional years of education (p < .0001). They increased by 11% (7%, 14%) for every additional 10 years of experience (p < .0001). Union members were paid 23% (12%, 36%) more than non-union members (p < .0001). Northerns were paid 11% (2%, 20%) more than southerns (p =.016). Management and professional positions were paid most, and service and clerical positions were paid least (pooled F-test, p < .0001). Overall variance explained was R2 = .35.
In summary, many factors describe the variations in wages: occupational status, years of experience, years of education, sex, union membership and region of residence. However, despite adjustment for all factors that were available, there still appeared to be a gender gap in wages. There is no readily available explanation for this gender gap.

Authorization: Public Domain

Reference: Berndt, ER. The Practice of Econometrics. 1991. NY: Addison-Wesley.

Description:  The datafile contains 534 observations on 11 variables sampled from the Current Population Survey of 1985.  This data set demonstrates multiple regression, confounding, transformations, multicollinearity, categorical variables, ANOVA, pooled tests of significance, interactions and model building strategies.

Variable names in order from left to right:
EDUCATION: Number of years of education.
SOUTH: Indicator variable for Southern Region (1=Person lives in 		South, 0=Person lives elsewhere).
SEX: Indicator variable for sex (1=Female, 0=Male).
EXPERIENCE: Number of years of work experience.
UNION: Indicator variable for union membership (1=Union member, 		0=Not union member).
WAGE: Wage (dollars per hour).
AGE: Age (years).
RACE: Race (1=Other, 2=Hispanic, 3=White).
OCCUPATION: Occupational category (1=Management, 		2=Sales, 3=Clerical, 4=Service, 5=Professional, 6=Other).
SECTOR: Sector (0=Other, 1=Manufacturing, 2=Construction).
MARR: Marital Status (0=Unmarried,  1=Married)


Therese Stukel
Dartmouth Hitchcock Medical Center
One Medical Center Dr.
Lebanon, NH 03756
e-mail: stukel@dartmouth.edu


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
535,analcatdata_chlamydia,"**Author**: Jeffrey S. Simonoff  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 2003  
**Please cite**: Jeffrey S. Simonoff. Analyzing Categorical Data. Springer-Verlag, New York, 2003  

One of the data sets used in the book ""Analyzing Categorical Data"" by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. Further details concerning the book, including information on statistical software, are available at the [web site](http://people.stern.nyu.edu/jsimonof/AnalCatData/)."
536,arsenic-male-lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
537,houses,"**Author**:  Kelley Pace

**Source**: http://lib.stat.cmu.edu/datasets/

**Please cite**:   

If you use an algorithm, dataset, or other information from StatLib, please acknowledge both StatLib and the original contributor of the material. 

Pace and Barry (1997), ""Sparse Spatial Autoregressions"", Statistics and Probability Letters.

@article{pace1997sparse,
  title={Sparse spatial autoregressions},
  author={Pace, R Kelley and Barry, Ronald},
  journal={Statistics \& Probability Letters},
  volume={33},
  number={3},
  pages={291--297},
  year={1997},
  publisher={Elsevier}
}

**Data description**

S&P Letters Data
We collected information on the variables using all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. Naturally, the geographical area included varies inversely with the population density. We computed distances among the centroids of each block group as measured in latitude and longitude. We excluded all the block groups reporting zero entries for the independent and dependent variables. The final data contained 20,640 observations on 9 variables. The dependent variable is ln(median house value)."
538,colleges_usnews,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The USNEWS dataset for the ASA Statistical Graphics Section's
1995 Data Analysis Exposition contains information on over 1300
American colleges and universities.  The data may be obtained in
either of two formats.

USNEWS.DATA contains the raw data in comma delimited fields with
a single data line for each school. The order of variables is the
same as given below for the fixed column version, although the
spacing varies for each school.

USNEWS3.DATA has the data arranged in fixed columns, with three
data lines for each school and a maximum line length of 80
characters.

This dataset is taken from the 1995 U.S. News & World Report's
Guide to America's Best Colleges.  This dataset is protected by
copyright, is reproduced with permission of the copyright
holder(s), and may not be downloaded or otherwise copied, except
solely for the purpose of analysis in connection with the
American Statistical Association's 1995 Data Analysis Exposition.
The data are reporduced with the permission of the publisher.

Most of the data are for the 1993-94 school year. You may wish to
consult a copy of the U.S. News source for more detailed
descriptions of the variables.


KEY FOR USNEWS3.DATA
Fixed column format with three data lines per school

Line #1
1 -  5   FICE (Federal ID number)
7 - 51   College name
53 - 54   State (postal code)

Line #2
1 -  2   Public/private indicator (public=1, private=2)
3 -  6   Average Math SAT score
7 - 10   Average Verbal SAT score
11 - 15   Average Combined SAT score
16 - 18   Average ACT score
19 - 22   First quartile - Math SAT
23 - 26   Third quartile - Math SAT
27 - 30   First quartile - Verbal SAT
31 - 34   Third quartile - Verbal SAT
35 - 37   First quartile - ACT
38 - 40   Third quartile - ACT
41 - 46   Number of applications received
47 - 52   Number of applicants accepted
53 - 57   Number of new students enrolled
58 - 61   Pct. new students from top 10% of H.S. class
62 - 65   Pct. new students from top 25% of H.S. class

Line #3
1 -  6   Number of fulltime undergraduates
7 - 12   Number of parttime undergraduates
13 - 18   In-state tuition
19 - 24   Out-of-state tuition
25 - 29   Room and board costs
30 - 34   Room costs
35 - 39   Board costs
40 - 44   Additional fees
45 - 49   Estimated book costs
50 - 54   Estimated personal spending
55 - 58   Pct. of faculty with Ph.D.'s
59 - 62   Pct. of faculty with terminal degree
63 - 67   Student/faculty ratio
68 - 70   Pct.alumni who donate
71 - 76   Instructional expenditure per student
77 - 80   Graduation rate

Missing values are denoted with *

**************************************************************
To obtain the dataset from Statlib, send one of the single line
messages below to the address statlib@lib.stat.cmu.edu

send usnews.data from colleges
or
send usnews3.data from colleges


For more information on the ASA Statistical Graphics Section's
1995 Data Analysis Exposition send the message

send readme from colleges

%%%%%%%%%%%%%%
INFORMATION %
%%%%%%%%%%%%%%

WHAT'S WHAT AMONG AMERICAN COLLEGES AND UNIVERSITIES?

This is the subject of the 1995 Data Analysis Exposition
sponsored by the Statistical Graphics Section of the American
Statistical Association.  The purpose of the Exposition is to
encourage statisticians to demonstrate techniques, especially
graphical, for analyzing data and displaying the results of an
analysis.  Individuals and groups will work with the same set of
data and present their analyses at a special session as part of
the annual Joint Statistical Meetings in Orlando, Florida on
August 13th-17th, 1995.  The datasets for 1995 are drawn from two
sources, U.S. News & World Report's Guide to Americas Best
Colleges and the AAUP (American Association of University
Professors) 1994 Salary Survey which appeared in the March-April
1994 issue of Academe.

The U.S. News data contains information on tuition, room & board
costs, SAT or ACT scores, application/acceptance rates,
graduation rate, student/faculty ratio, spending per student, and
a number of other variables for 1300+ schools. The AAUP data
includes average salary, overall compensation, and number of
faculty broken down by full, associate, and assistant professor
ranks.

The raw data and documentation are contained in the files
described below.  To obtain any of these files send a message to
statlib@lib.stat.cmu.edu of the following form  (substituting the
file you want for XXXXX)

send XXXXX from colleges

Available files

usnews.doc      Documentation for the U.S. News data
usnews.data     U.S. News data in comma delimited format
usnews3.data    U.S. News data in fixed column format

aaup.doc        Documentation for the AAUP salary data
aaup.data       AAUP salary data in comma delimited format
aaup2.data      AAUP salary data in fixed column format

Two versions of each dataset are provided to accommodate users
with different software constraints.  The comma delimited
versions (USNEWS.DATA and AAUP.DATA) contain information for each
college on a separate line with values delimited by commas.  The
fixed column versions (USNEWS3.DATA and AAUP2.DATA) use 2 or 3
data lines per school and a maximum line length of 80 characters.

To participate in the 1995 Data Analysis Exposition you must send
an abstract form to the American Statistical Association by
February 1st, 1995.  Information is available from the ASA
Meetings Department by e-mail (meetings@asa.mhs.compuserve.com),
phone (703-684-1221), fax (703-684-2037), or surface mail (ASA,
1429 Duke St., Alexandria, VA 22314).  Your initial abstract may
be fairly general since you may do the bulk of your analysis
after the February 1 deadline.

You may choose your own path to proceed in analyzing the data or
use some of the suggested questions below to get started.

... How well can we model tuition using the other variables?
... How might we cluster colleges into similar comparison groups?
... How can we best display faculty salary structure?
... Can we find a reasonable way to rank the schools?

You may work on your own or put together a team.  Show off the
capabilities of your favorite software package or use the data
for a class project and display your students results.  You may
choose to consider just a subset of schools or examine regional
patterns.  The main point is to find innovative ways to display
the interesting features of the data.

Further questions about the 1995 Exposition can be directed to
Robin Lock, Mathematics Department, St. Lawrence University,
Canton, NY 13617  e-mail   rlock@vm.stlawu.edu

If you would like to be informed about any subsequent adjustments
or error fixes to the 1995 Exposition data, please send an e-mail
message to register your interest to rlock@vm.stlawu.edu.

Special thanks for providing data for the 1995 Exposition to:
Robert Morse, Director of Research for America's Best Colleges at
U.S. News & World Report
Maryse Eymonerie, Consultant to AAUP.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
539,analcatdata_galapagos,"**Author**: Jeffrey S. Simonoff  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 2003  
**Please cite**: Jeffrey S. Simonoff. Analyzing Categorical Data. Springer-Verlag, New York, 2003  

One of the data sets used in the book ""Analyzing Categorical Data"" by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. Further details concerning the book, including information on statistical software, are available at the [web site](http://people.stern.nyu.edu/jsimonof/AnalCatData/)."
540,mu284,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains the data in ""The MU284 Population"" from Appendix B of
the book ""Model Assisted Survey Sampling"" by Sarndal, Swensson and Wretman,
published by Springer-Verlag, New York, 1992. The data set contains 284
observations on 11 variables, plus a line with variabel names. Please
consult the mentioned appendix for more information about this data set.
The data were scanned from the book and interpreted with OCR-technique.
Please note that errors may occur in such a process. The result was
macro-edited against ""The Clustered MU284 Population"" in Appendix C of the
book. Please use the data at your own risk - I take no responsibility for
any problems eventual remaining errors will cause you.
four typos in the first printing of the book have been corrected:
Label 107, ME84 should be 1100, not 1110
Label 141, RMT85 should be 396, not 369
Label 220, ME84 should be 461, not 491
Label 229, ME84 should be 1239, not 1238.
The data was submitted to StatLib with the permission of Springer-Verlag
(ref: John Kimmel).
Esbjorn Ohlsson
Stockholm University
esbj@matematik.su.se


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
541,socmob,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

17x17x2x2 tables of counts in GLIM-ready format used for the analyses
in Biblarz, Timothy J., and Adrian E. Raftery. 1993. ""The Effects of
Family Disruption on Social Mobility."" American Sociological Review
(In press). For further details of the data, see this reference.
Column 1 is father's occupation, coded as follows:
17. Professional, Self-Employed
16. Professional-Salaried
15. Manager
14. Salesman-Nonretail
13. Proprietor
12. Clerk
11. Salesman-Retail
10. Craftsman-Manufacturing
9. Craftsmen-Other
8. Craftsman-Construction
7. Service Worker
6. Operative-Nonmanufacturing
5. Operative-Manufacturing
4. Laborer-Manufacturing
3. Laborer-Nonmanufacturing
2. Farmer/Farm Manager
1. Farm Laborer
Column 2 is son's occupation, coded in the same way as father's.
Column 3 is family structure, coded 1=intact family background and
2=nonintact family background.
Column 4 is race, coded 1=white and 2=black.
Column 5 is counts for son's first occupation.
Column 6 is counts for son's current occupation.
The counts have been weighted to take account of the survey
design, which is why they are not integers.
************************************************************
***********************************************************
This file was constructed from publicly available data collected
by David Featherman and Robert Hauser in 1973: the ""Occupational
Change in a Generation II"" (OCG II) Survey. Permission is hereby given to
use the above data for non-commercial scholarly and teaching purposes.
If these data are used in a published article or book,
the authors, the original data (in the form given in
Biblarz and Raftery (1993), cited above), and StatLib should
all be acknowledged.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
542,pollution,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is the pollution data so loved by writers of papers on ridge regression.
Source: McDonald, G.C. and Schwing, R.C. (1973) 'Instabilities of regression
estimates relating air pollution to mortality', Technometrics, vol.15, 463-
Variables in order:
PREC   Average annual precipitation in inches
JANT   Average January temperature in degrees F
JULT   Same for July
OVR65  % of 1960 SMSA population aged 65 or older
POPN   Average household size
EDUC   Median school years completed by those over 22
HOUS   % of housing units which are sound & with all facilities
DENS   Population per sq. mile in urbanized areas, 1960
NONW   % non-white population in urbanized areas, 1960
WWDRK  % employed in white collar occupations
POOR   % of families with income < $3000
HC     Relative hydrocarbon pollution potential
NOX    Same for nitric oxides
SO@    Same for sulphur dioxide
HUMID  Annual average % relative humidity at 1pm
MORT   Total age-adjusted mortality rate per 100,000


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
543,boston_corrected,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
544,transplant,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

DATA FILE:
Data on patient deaths within 30 days of surgery in 131 U.S.
hospitals.  See Christiansen and Morris, Bayesian Biostatistics, D.
Berry and D. Stangl, editors, 1996, Marcel Dekker, Inc.


Data on 131 heart transplant hospitals in the US.  The 3646 transplants
took place during a 27 month period from October 1987 through December
1989.  The columns are:  obs = hospital #, e = expected #
of deaths within 30 days of the transplant surgeries, z = number of
deaths within 30 days of surgery, n = # of patients receiving heart
transplant within this time period.  (Christiansen and Morris, Bayesian
Biostatistics, D.  Berry and D. Stangl, editors, 1996.) The patient
level data used to create this data set was provided by the United
Network for Organ Sharing, 1100 Boulders Parkway, Suite 500, P.O. Box
13770, Richmond, VA, 23225.

The following data may be used for non-commercial purposes and can be
distributed freely.  If you use the data, please acknowledge StatLib,
the United Network for Organ Sharing, and Christiansen and Morris,
1996.




Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
545,lmpavw,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

-------------------------------------------------------------------------------

TIME SERIES USED IN
LONG-MEMORY PROCESSES, THE ALLAN VARIANCE AND WAVELETS
BY D. B. PERCIVAL AND P. GUTTORP, A CHAPTER IN
WAVELETS IN GEOPHYSICS
EDITED BY E. FOUFOULA-GEORGIOU AND P. KUMAR, ACADEMIC PRESS, 1994.
-------------------------------------------------------------------------------

VERTICAL OCEAN SHEAR ""TIME"" SERIES (SHOWN IN FIGURE 1 OF CHAPTER)
SOURCE: APPLIED PHYSICS LABORATORY, UNIVERSITY OF WASHINGTON (MIKE GREGG)
SAMPLING INTERVAL (DELTA T):           0.1 METERS
SAMPLE SIZE: 6875
DEPTH (""TIME"") OF FIRST DATA POINT:  350.0 METERS
DEPTH          OF  LAST DATA POINT: 1037.4 METERS


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: 1"
546,sensory,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data for the sensory evaluation experiment in Brien, C.J. and Payne,
R.W. (1996) Tiers, structure formulae and the analysis of complicated
experiments.  submitted for publication.
The experiment involved two phases.  In the field phase a viticultural
experiment was conducted to investigate the differences between 4
types of trellising and 2 methods of pruning.  The design was a
split-plot design in which the trellis types were assigned to the main
plots using two adjacent Youden squares of 3 rows and 4 columns.  Each
main plot was split into two subplots (or halfplots) and the methods
of pruning assigned at random independently to the two halfplots in
each main plot.  The produce of each halfplot was made into a wine so
that there were 24 wines altogether.
The second phase was an evaluation phase in which the produce from the
halplots was evaluated by 6 judges all of whom took part in 24
sittings.  In the first 12 sittings the judges evaluated the wines
made from the halfplots of one square; the final 12 sittings were to
evaluate the wines from the other square.  At each sitting, each judge
assessed two glasses of wine from each of the halplots of one of the
main plots.  The main plots allocated to the judges at each sitting
were determined as follows.  For the allocation of rows, each occasion
was subdivided into 3 intervals of 4 consecutive sittings.  During
each interval, each judge examined plots from one particular row,
these being determined using two 3x3 Latin squares for each occasion,
one for judges 1-3 and the other for judges 4-6.  At each sitting
judges 1-3 examined wines from one particular column and judges 4-6
examined wines from another column.  The columns were randomized to
the 2 sets of judges x 3 intervals x 4 sittings using duplicates of a
balanced incomplete block design for v=4 and k=2 that were latinized.
This balanced incomplete block design consists of three sets of 2
blocks, each set containing the 4 ""treatments"".  For each interval, a
different set of 2 blocks was taken and each block assigned to two
sittings, but with the columns within the block placed in reverse
order in one sitting compared to the other sitting.  Thus, in each
interval, a judge would evaluate a wine from each of the 4 columns.
The scores assigned in evaluating the wines, and the factors indexing
them, are given below.  The factors are as follows:
Occasion
Judges
Interval
Sittings
Position
Squares
Rows
Columns
Halfplot
Trellis
Method
followed by the response variable
Score
The scores are ordered so that the factors Occasion, Judges, Interval,
Sittings and Position are in standard order; the remaining factors are
in randomized order.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
547,no2,"**Author**: Magne Aldrin (magne.aldrin@nr.no)  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 2004  
**Please cite**:   

The data are a subsample of 500 observations from a data set that originate in a study where air pollution at a road is
related to traffic volume and meteorological variables, collected by the Norwegian Public Roads Administration. The response variable (column 1) consist of hourly values of the logarithm of the concentration of NO2 (particles), measured at Alnabru in Oslo, Norway, between October 2001 and August 2003. 

The predictor variables (columns 2 to 8) are the logarithm of the number of cars per hour, temperature $$2$$ meter above ground (degree C), wind speed (meters/second), the temperature difference between $$25$$ and $$2$$ meters above ground (degree C), wind direction (degrees between 0 and 360), hour of day and day number from October 1. 2001."
549,strikes,"**Author**: Bruce Western (western@datacomm.iue.it)   
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 1999  
**Please cite**:   

The data consist of annual observations on the level of strike volume (days lost due to industrial disputes per 1000 wage salary earners), and their covariates in 18 OECD countries from 1951-1985. The average level and variance of strike volume varies across countries. The data distribution also features a long right tail and several large outliers. 

The 7 data fields include the following variables:  
>
(1) country code;  
(2) year;  
(3) strike volume;  
(4) unemployment;  
(5) inflation;  
(6) parliamentary representation of social democratic and labor parties  
(7) a time-invariant measure of union centralization.

These data were analyzed in the forthcoming paper by Bruce Western, ""Vague Theory and Model Uncertainty in Macrosociology,"" which is to appear in Sociological Methodology. Permission is given by the author to freely use and redistribute these data."
550,quake,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

smoothmeth  A collection of the data sets used in the book ""Smoothing
Methods in Statistics,"" by Jeffrey S. Simonoff,
Springer-Verlag, New York, 1996. Submitted by Jeff
Simonoff (jsimonoff@stern.nyu.edu).


This submission consists of 37 files, plus this README file.
Each file represents a data set analyzed in the book.
The names of the files correspond to the names given in
the book. The data files are written in plain ASCII (character)
text. Missing values are represented by ""M"" in all data files.

Several of the files include an alphabetic (labeling) variable. It is
likely that these files would have to be input into a package using fixed,
rather than free, format. The relevant files, along with appropriate
Fortran format statements, are as follows:

adptvisa.dat: (f10.4,4x,f7.4,3x,a20)

airaccid.dat: (i3,3x,a34)

basesal.dat : (f8.1,4x,a17)

baskball.dat: (f7.4,4x,f6.4,3x,i3,4x,f5.2,3x,i2,3x,a17)

cars93.dat  : (f5.1,2x,i2,2x,i2,3x,f3.1,2x,i3,3x,f4.1,2x,i4,2x,a21)

elusage.dat : (i4,3x,f7.3,2x,a7)

hckshoot.dat: (f7.3,4x,i1,4x,a20)

jantemp.dat : (i6,3x,a30)

marathon.dat: (f10.2,4x,a27)

newscirc.dat: (f8.2,3x,f7.2,2x,a25)

racial.dat  : (f7.4,4x,a32)

safewatr.dat: (i5,3x,i3,3x,a26)

schlvote.dat: (i3,4x,f5.2,2x,i8,4x,f4.1,5x,f5.2,2x,i7,2x,a25)

Description of data sources, and further information about the data sets,
can be found in the ""Descriptions of the data sets"" section of the book.
Pointing a World Wide Web browser to the URL

http://www.stern.nyu.edu/SOR/SmoothMeth

will provide access to a site devoted to the book.

NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the reference above).


File: ../data/smoothmeth/quake.dat


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
551,analcatdata_michiganacc,"**Author**: Jeffrey S. Simonoff  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 2003  
**Please cite**: Jeffrey S. Simonoff. Analyzing Categorical Data. Springer-Verlag, New York, 2003  

One of the data sets used in the book ""Analyzing Categorical Data"" by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. Further details concerning the book, including information on statistical software, are available at the [web site](http://people.stern.nyu.edu/jsimonof/AnalCatData/)."
552,detroit,"**Author**: J.C. Fisher  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 1992  
**Please cite**:   

Data on the homicide rate in Detroit for the years 1961-1973. This is the data set called DETROIT in the book 'Subset selection in regression' by Alan J. Miller published in the Chapman & Hall series of monographs on Statistics & Applied Probability, no. 40. The data are unusual in that a subset of three predictors can be found which gives a very much better fit to the data than the subsets found from the Efroymson stepwise algorithm, or from forward selection or backward elimination.

The original data were given in appendix A of `Regression analysis and its application: A data-oriented approach' by Gunst & Mason, Statistics textbooks and monographs no. 24, Marcel Dekker. It has caused problems because some copies of the Gunst & Mason book do not contain all of the data, and because Miller does not say which variables he used as predictors and which is the dependent variable. (HOM was the dependent variable, and the predictors were FTP ... WE)

The data were collected by J.C. Fisher and used in his paper: ""Homicide in Detroit: The Role of Firearms"", Criminology, vol.14, 387-400 (1976)

Attributes:  
>
FTP    - Full-time police per 100,000 population  
UEMP   - % unemployed in the population  
MAN    - number of manufacturing workers in thousands  
LIC    - Number of handgun licences per 100,000 population  
GR     - Number of handgun registrations per 100,000 population  
CLEAR  - % homicides cleared by arrests  
WM     - Number of white males in the population  
NMAN   - Number of non-manufacturing workers in thousands  
GOV    - Number of government workers in thousands  
HE     - Average hourly earnings  
WE     - Average weekly earnings  
HOM    - Number of homicides per 100,000 of population  
ACC    - Death rate in accidents per 100,000 population  
ASR    - Number of assaults per 100,000 population"
553,kidney,"**Author**: McGilchrist and Aisbett  
**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 1999  
**Please cite**:   

Data on the recurrence times to infection, at the point of insertion of the catheter, for kidney patients using portable dialysis equipment. Catheters may be removed for reasons other than infection, in which case the observation is censored.  Each patient has exactly 2 observations.

The data set has been used by several authors to illustrate random effects (""frailty"") models for survival data. However, any non-zero estimate of the random effect is almost entirely due to one outlier, subject 21.

Variables: patient, time, status, age, sex (1=male, 2=female), disease type (0=Glomerulo Nephritis, 1=Acute Nephritis,
2=Polycystic Kidney Disease, 3=Other), author's estimate of the frailty

References:  
McGilchrist and Aisbett, Biometrics 47, 461-66, 1991"
554,mnist_784,"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  
**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  
**Please cite**:  

The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  

It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  

With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  

The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available."
555,analcatdata_apnea3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
556,analcatdata_apnea2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
557,analcatdata_apnea1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

analcatdata    A collection of data sets used in the book ""Analyzing Categorical Data,""
by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission
consists of a zip file containing two versions of each of 84 data sets,
plus this README file. Each data set is given in comma-delimited ASCII
(.csv) form, and Microsoft Excel (.xls) form.

NOTICE: These data sets may be used freely for scientific, educational and/or
noncommercial purposes, provided suitable acknowledgment is given (by citing
the above-named reference).

Further details concerning the book, including information on statistical software
(including sample S-PLUS/R and SAS code), are available at the web site

http://www.stern.nyu.edu/~jsimonof/AnalCatData


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last


Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced
with Underscores"
558,bank32nh,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

A family of datasets synthetically generated from a simulation of how bank-customers choose their banks. Tasks are
based on predicting the fraction of bank customers who leave the bank because of full queues. The bank family of
datasets are generated from a simplistic simulator, which simulates the queues in a series of banks. The simulator was
constructed with the explicit purpose of generating a family of datasets for DELVE. Customers come from several
residential areas, choose their preferred bank depending on distances and have tasks of varying complexity, and various
levels of patience. Each bank has several queues, that open and close according to demand. The tellers have various
effectivities, and customers may change queue, if their patience expires. In the rej prototasks, the object is to predict the
rate of rejections, ie the fraction of customers that are turned away from the bank because all the open tellers have full
queues.
Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Orginal source: DELVE repository of data.
Characteristics: Data set contains 8192 (4500+3692) cases. and 33 continuous
attributes"
559,schlvote,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Dataset from Smoothing Methods in Statistics
(ftp stat.cmu.edu/datasets)

Simonoff, J.S. (1996). Smoothing Methods in Statistics. New York: Springer-Verlag."
560,bodyfat,"**Author**: Roger W. Johnson  
**Source**: [UCI (not available anymore)](https://archive.ics.uci.edu/ml/index.php), [TunedIT](http://tunedit.org/repo/UCI/numeric/bodyfat.arff)  
**Please cite**: None. 

Short Summary:
Lists estimates of the percentage of body fat determined by underwater
weighing and various body circumference measurements for 252 men.

Classroom use of this data set:
This data set can be used to illustrate multiple regression techniques.
Accurate measurement of body fat is inconvenient/costly and it is
desirable to have easy methods of estimating body fat that are not
inconvenient/costly.

More Details:
A variety of popular health books suggest that the readers assess their
health, at least in part, by estimating their percentage of body fat. In
Bailey (1994), for instance, the reader can estimate body fat from tables
using their age and various skin-fold measurements obtained by using a
caliper. Other texts give predictive equations for body fat using body
circumference measurements (e.g. abdominal circumference) and/or skin-fold
measurements. See, for instance, Behnke and Wilmore (1974), pp. 66-67;
Wilmore (1976), p. 247; or Katch and McArdle (1977), pp. 120-132).

Percentage of body fat for an individual can be estimated once body density
has been determined. Folks (e.g. Siri (1956)) assume that the body consists
of two components - lean body tissue and fat tissue. Letting

D = Body Density (gm/cm^3)
A = proportion of lean body tissue
B = proportion of fat tissue (A+B=1)
a = density of lean body tissue (gm/cm^3)
b = density of fat tissue (gm/cm^3)

we have

D = 1/[(A/a) + (B/b)]

solving for B we find

B = (1/D)*[ab/(a-b)] - [b/(a-b)].

Using the estimates a=1.10 gm/cm^3 and b=0.90 gm/cm^3 (see Katch and McArdle
(1977), p. 111 or Wilmore (1976), p. 123) we come up with ""Siri's equation"":

Percentage of Body Fat (i.e. 100*B) = 495/D - 450.

Volume, and hence body density, can be accurately measured a variety of ways.
The technique of underwater weighing ""computes body volume as the difference
between body weight measured in air and weight measured during water
submersion. In other words, body volume is equal to the loss of weight in
water with the appropriate temperature correction for the water's density""
(Katch and McArdle (1977), p. 113). Using this technique,

Body Density = WA/[(WA-WW)/c.f. - LV]

where

WA = Weight in air (kg)
WW = Weight in water (kg)
c.f. = Water correction factor (=1 at 39.2 deg F as one-gram of water
occupies exactly one cm^3 at this temperature, =.997 at 76-78 deg F)
LV = Residual Lung Volume (liters)

(Katch and McArdle (1977), p. 115). Other methods of determining body volume
are given in Behnke and Wilmore (1974), p. 22 ff.


The variables listed below, from left to right, are:

Density determined from underwater weighing
Percent body fat from Siri's (1956) equation
Age (years)
Weight (lbs)
Height (inches)
Neck circumference (cm)
Chest circumference (cm)
Abdomen 2 circumference (cm)
Hip circumference (cm)
Thigh circumference (cm)
Knee circumference (cm)
Ankle circumference (cm)
Biceps (extended) circumference (cm)
Forearm circumference (cm)
Wrist circumference (cm)

(Measurement standards are apparently those listed in Benhke and Wilmore
(1974), pp. 45-48 where, for instance, the abdomen 2 circumference is
measured ""laterally, at the level of the iliac crests, and anteriorly, at
the umbilicus"".)

These data are used to produce the predictive equations for lean
body weight given in the abstract ""Generalized body composition prediction
equation for men using simple measurement techniques"", K.W. Penrose, A.G.
Nelson, A.G. Fisher, FACSM, Human Performance Research Center, Brigham Young
University, Provo, Utah  84602 as listed in _Medicine and Science in Sports
and Exercise_, vol. 17, no. 2, April 1985, p. 189. (The predictive equations
were obtained from the first 143 of the 252 cases that are listed below).
The data were generously supplied by Dr. A. Garth Fisher who gave permission to
freely distribute the data and use for non-commercial purposes.

References:

Bailey, Covert (1994). _Smart Exercise: Burning Fat, Getting Fit_,
Houghton-Mifflin Co., Boston, pp. 179-186.

Behnke, A.R. and Wilmore, J.H. (1974). _Evaluation and Regulation of Body
Build and Composition_, Prentice-Hall, Englewood Cliffs, N.J.

Siri, W.E. (1956), ""Gross composition of the body"", in _Advances in
Biological and Medical Physics_, vol. IV, edited by J.H. Lawrence and C.A.
Tobias, Academic Press, Inc., New York.

Katch, Frank and McArdle, William (1977). _Nutrition, Weight Control, and
Exercise_, Houghton Mifflin Co., Boston.

Wilmore, Jack (1976). _Athletic Training and Physical Fitness: Physiological
Principles of the Conditioning Process_, Allyn and Bacon, Inc., Boston."
561,cpu,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Attributes 2 and 8 deleted.

As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
using instance-based learning with encoding length selection. In Progress
in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

1. Title: Relative CPU Performance Data

2. Source Information
-- Creators: Phillip Ein-Dor and Jacob Feldmesser
-- Ein-Dor: Faculty of Management; Tel Aviv University; Ramat-Aviv;
Tel Aviv, 69978; Israel
-- Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779
-- Date: October, 1987

3. Past Usage:
1. Ein-Dor and Feldmesser (CACM 4/87, pp 308-317)
-- Results:
-- linear regression prediction of relative cpu performance
-- Recorded 34% average deviation from actual values
2. Kibler,D. & Aha,D. (1988).  Instance-Based Prediction of
Real-Valued Attributes.  In Proceedings of the CSCSI (Canadian
AI) Conference.
-- Results:
-- instance-based prediction of relative cpu performance
-- similar results; no transformations required
- Predicted attribute: cpu relative performance (numeric)

4. Relevant Information:
-- The estimated relative performance values were estimated by the authors
using a linear regression method.  See their article (pp 308-313) for
more details on how the relative performance values were set.

5. Number of Instances: 209

6. Number of Attributes: 10 (6 predictive attributes, 2 non-predictive,
1 goal field, and the linear regression's guess)

7. Attribute Information:
1. vendor name: 30
(adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec,
dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson,
microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry,
sratus, wang)
2. Model Name: many unique symbols
3. MYCT: machine cycle time in nanoseconds (integer)
4. MMIN: minimum main memory in kilobytes (integer)
5. MMAX: maximum main memory in kilobytes (integer)
6. CACH: cache memory in kilobytes (integer)
7. CHMIN: minimum channels in units (integer)
8. CHMAX: maximum channels in units (integer)
9. PRP: published relative performance (integer)
10. ERP: estimated relative performance from the original article (integer)

8. Missing Attribute Values: None

9. Class Distribution: the class value (PRP) is continuously valued.
PRP Value Range:   Number of Instances in Range:
0-20               31
21-100             121
101-200            27
201-300            13
301-400            7
401-500            4
501-600            2
above 600          4

Summary Statistics:
Min  Max   Mean    SD      PRP Correlation
MCYT:   17   1500  203.8   260.3   -0.3071
MMIN:   64   32000 2868.0  3878.7   0.7949
MMAX:   64   64000 11796.1 11726.6  0.8630
CACH:   0    256   25.2    40.6     0.6626
CHMIN:  0    52    4.7     6.8      0.6089
CHMAX:  0    176   18.2    26.0     0.6052
PRP:    6    1150  105.6   160.8    1.0000
ERP:   15    1238  99.3    154.8    0.9665"
562,cpu_small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Computer Activity databases are a collection of computer systems
activity measures. The data was collected from a Sun Sparcstation
20/712 with 128 Mbytes of memory running in a multi-user university
department. Users would typically be doing a large variety of tasks
ranging from accessing the internet, editing files or running very
cpu-bound programs.  The data was collected continuously on two
separate occasions. On both occassions, system activity was gathered
every 5 seconds. The final dataset is taken from both occasions with
equal numbers of observations coming from each collection epoch.

System measures used:
1. lread - Reads (transfers per second ) between system memory and user memory.
2. lwrite - writes (transfers per second) between system memory and user memory.
3. scall - Number of system calls of all types per second.
4. sread - Number of system read calls per second.
5. swrite - Number of system write calls per second .
6. fork - Number of system fork calls per second.
7. exec - Number of system exec calls per second.
8. rchar - Number of characters transferred per second by system read calls.
9. wchar - Number of characters transfreed per second by system write calls.
10. pgout - Number of page out requests per second.
11. ppgout - Number of pages, paged out per second.
12. pgfree - Number of pages per second placed on the free list.
13. pgscan - Number of pages checked if they can be freed per second.
14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.
15. pgin - Number of page-in requests per second.
16. ppgin - Number of pages paged in per second.
17. pflt - Number of page faults caused by protection errors (copy-on-writes).
18. vflt - Number of page faults caused by address translation.
19. runqsz - Process run queue size.
20. freemem - Number of memory pages available to user processes.
21. freeswap - Number of disk blocks available for page swapping.
22. usr - Portion of time (%) that cpus run in user mode.
23. sys - Portion of time (%) that cpus run in system mode.
24. wio - Portion of time (%) that cpus are idle waiting for block IO.
25. idle - Portion of time (%) that cpus are otherwise idle.

The two different regression tasks obtained from these databases are:

CompAct
Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.

CompAct(s)
Predict usr using a restricted number (excluding the paging information (10-18)

Original source: DELVE repository of data.
Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Characteristics: 8192 cases, 13 continuous attributes"
563,kdd_el_nino-small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

El Nino Data

Data Type

spatio-temporal

Abstract

The data set contains oceanographic and surface meteorological
readings taken from a series of buoys positioned throughout the
equatorial Pacific. The data is expected to aid in the understanding
and prediction of El Nino/Southern Oscillation (ENSO) cycles.

Sources

Original Owner

[1]Pacific Marine Environmental Laboratory
National Oceanic and Atmospheric Administration
US Department of Commerce

Donor

[2]Dr Di Cook
Department of Statistics
Iowa State University
[3]dicook@iastate.edu

Date Donated: June 30, 1999

Data Characteristics

This data was collected with the Tropical Atmosphere Ocean (TAO) array
which was developed by the international Tropical Ocean Global
Atmosphere (TOGA) program. The TAO array consists of nearly 70 moored
buoys spanning the equatorial Pacific, measuring oceanographic and
surface meteorological variables critical for improved detection,
understanding and prediction of seasonal-to-interannual climate
variations originating in the tropics, most notably those related to
the El Nino/Southern Oscillation (ENSO) cycles.

The moorings were developed by National Oceanic and Atmospheric
Administration's (NOAA) Pacific Marine Environmental Laboratory
(PMEL). Each mooring measures air temperature, relative humidity,
surface winds, sea surface temperatures and subsurface temperatures
down to a depth of 500 meters and a few a of the buoys measure
currents, rainfall and solar radiation. The data from the array, and
current updates, can be viewed on the web at the this address .

The data consists of the following variables: date, latitude,
longitude, zonal winds (west<0, east>0), meridional winds (south<0,
north>0), relative humidity, air temperature, sea surface temperature
and subsurface temperatures down to a depth of 500 meters. Data taken
from the buoys from as early as 1980 for some locations. Other data
that was taken in various locations are rainfall, solar radiation,
current levels, and subsurface temperatures.

Variable Characteristics

The latitude and longitude in the data showed that the bouys moved
around to different locations. The latitude values stayed within a
degree from the approximate location. Yet the longitude values were
sometimes as far as five degrees off of the approximate location.

Looking at the wind data, both the zonal and meridional winds
fluctuated between -10 m/s and 10 m/s. The plot of the two wind
variables showed no linear relationship. Also, the plots of each wind
variable against the other three meteorolgical data showed no linear
relationships.

The relative humidity values in the tropical Pacific were typically
between 70% and 90%.

Both the air temperature and the sea surface temperature fluctuated
between 20 and 30 degrees Celcius. The plot of the two temperatures
variables shows a positive linear relationship existing. The two
temperatures when each plotted against time also have similar plot
designs. Plots of the other meteorological variables against the
temperature variables showed no linear relationship.

There are missing values in the data. As mentioned earlier, not all
buoys are able to measure currents, rainfall, and solar radiation, so
these values are missing dependent on the individual buoy. The amount
of data available is also dependent on the buoy, as certain buoys were
commissioned earlier than others.

All readings were taken at the same time of day.

Other Relevant Information

Background

The El Nino/Southern Oscillation (ENSO) cycle of 1982-1983, the
strongest of the century, created many problems throughout the world.
Parts of the world such as Peru and the Unites States experienced
destructive flooding from increased rainfalls while the western
Pacific areas experienced drought and devastating brush fires. The
ENSO cycle was neither predicted nor detected until it was near its
peak. This highlighted the need for an ocean observing system (i.e.
the TAO array) to support studies of large scale ocean-atmosphere
interactions on seasonal-to-interannual time scales.

The TAO array provides real-time data to climate researchers, weather
prediction centers and scientists around the world. Forcasts for
tropical Pacific Ocean temperatures for one to two years in advance
can be made using the ENSO cycle data. These forcasts are possible
because of the moored buoys, along with drifting buoys, volunteer ship
temperature probes, and sea level measurements.

Research Questions

Research questions of interest include:
* How can the data be used to predict weather conditions throughout
the world?
* How do the variables relate to each other?
* Which variables have a greater effect on the climate variations?
* Does the amount of movement of the buoy effect the reliability of
the data?

When performing an analysis of the data, one should pay attention the
possible affect of autocorrelation. Using a multiple regression
approach to model the data would require a look at autoregression
since the weather statistics of the previous days will affect today's
weather.

Data Format

The data is stored in an ASCII files with one observation per line.
Spaces separate fields and periods (.) denote missing values.

Past Usage

This data was used in the American Statistical Association Statistical
Graphics and Computing Sections 1999 Data Exposition.

References and Further Information

More information and data from the TAO array can be found at the
Pacific Marine Environmental Laboratory [4]TAO data webpage.

Information on storm data is available [5]here. This site contains
data from January 1994 to April 1998 in a chronological listing by
state provided by the National Weather Service. The data includes
hurricanes, tornadoes, thunderstorms, hail, floods, drought
conditions, lightning, high winds, snow, and temperature extremes.

Hurricane tracking data for the Atlantic is available [6]here. The
site contains a map showing the paths of the Atlantic hurricanes and
also includes the storms winds (in knots), pressure (in millibars),
and the category of the storm based on Saffir-Simpson scale.

Another site of interest related to the ENSO cyles is available
[7]here. This site contains information on twelve areas of the world
that have demonstrated ENSO-precipitation relationships. Included in
the site are maps of the areas and time series plots of actual daily
precipitation and accumulated normal precipitation for the areas.
_________________________________________________________________


[8]The UCI KDD Archive
[9]Information and Computer Science
[10]University of California, Irvine
Irvine, CA 92697-3425

Last modified: June 30, 1999

References

1. http://www.pmel.noaa.gov/
2. http://www.public.iastate.edu/~dicook/
3. mailto:dicook@iastate.edu
4. http://www.pmel.noaa.gov/toga-tao/
5. http://www.ncdc.noaa.gov/pdfs/sd/sd.html
6. http://wxp.eas.purdue.edu/hur_atlantic/
7. http://www.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/current_impacts/precip_accum.html
8. http://kdd.ics.uci.edu/
9. http://www.ics.uci.edu/
10. http://www.uci.edu/


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
564,fried,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is an artificial data set used in Friedman (1991) and also
described in Breiman (1996,p.139). The cases are generated using the
following method: Generate the values of 10 attributes, X1, ..., X10
independently each of which uniformly distributed over [0,1]. Obtain
the value of the target variable Y using the equation:

Y = 10 * sin(pi * X1 * X2) + 20 * (X3 - 0.5)^2 + 10 * X4 + 5 * X5 + sigma(0,1)

Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Original source: Breiman (1996, p.139).
Characteristics: 40768 cases, 11 continuous attributes

References

BREIMAN, L. (1996): Bagging Predictors. Machine Learning, 24(3), 123--140. Kluwer Academic Publishers.
FRIEDMAN, J. (1991): Multivariate Adaptative Regression Splines. Annals of Statistics, 19:1, 1--141."
565,water-treatment,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: Faults in a urban waste water treatment plant

2. Source Information:
-- Creators: Manel Poch (igte2@cc.uab.es)
Unitat d'Enginyeria Quimica
Universitat Autonoma de Barcelona. Bellaterra. Barcelona; Spain
-- Donor: Javier Bejar and Ulises Cortes (bejar@lsi.upc.es)
Dept. Llenguatges i Sistemes Informatics;
Universitat Politecnica de Catalunya. Barcelona; Spain
-- Date: June, 1993

3. Past Usage:
1. J. De Gracia.
``Avaluacio de tecniques de classificacio per a la gestio de
Bioprocessos: Aplicacio a un reactor de fangs activats''
Master Thesis. Dept. de Quimica. Unitat d'Enginyeria Quimica.
Universitat Autonoma de Barcelona. Bellaterra (Barcelona). 1993.
-- Results:
Comparison between the classification of plant situations using
cluster analysis and conceptual clustering. The induced classes
are exposed and contrasted.


2. J. Bejar, U. Cort\'es and M. Poch.
``LINNEO+: A Classification Methodology for Ill-structured Domains''.
Research report RT-93-10-R. Dept. Llenguatges i Sistemes Informatics.
Barcelona. 1993.
-- Results:
The conceptual clustering algorithm used in the first reference
is exposed. Some results are given about the use of a priori
expert knowledge to bias the classification process in the plant
domain.

3.  Ll. Belanche, U. Cortes and M. S\`anchez.
``A knowledge-based system for the diagnosis of waste-water treatment
plant''. Proceedings of the 5th international conference of industrial
and engineering applications of AI and Expert Systems IEA/AIE-92. Ed
Springer-Verlag. Paderborn, Germany, June 92.
-- Results:
Explanation of the waste water treatment plant diagnosis problems
Not directly related to the dataset.



4. Relevant Information:

This dataset comes from the daily measures of sensors in a urban waste
water treatment plant. The objective is to classify the operational
state of the plant in order to predict faults through the state
variables of the plant at each of the stages of the treatment process.
This domain has been stated as an ill-structured domain.


5. Number of instances: 527

6. Number of Attributes: 38

There are some missing values, all are unknown information.

7. Attribute Information:

All atrributes are numeric and continuous

N.  Attrib.
1  Q-E        (input flow to plant)
2  ZN-E       (input Zinc to plant)
3  PH-E       (input pH to plant)
4  DBO-E      (input Biological demand of oxygen to plant)
5  DQO-E      (input chemical demand of oxygen to plant)
6  SS-E       (input suspended solids to plant)
7  SSV-E      (input volatile supended solids to plant)
8  SED-E      (input sediments to plant)
9  COND-E     (input conductivity to plant)
10  PH-P       (input pH to primary settler)
11  DBO-P      (input Biological demand of oxygen to primary settler)
12  SS-P       (input suspended solids to primary settler)
13  SSV-P      (input volatile supended solids to primary settler)
14  SED-P      (input sediments to primary settler)
15  COND-P     (input conductivity to primary settler)
16  PH-D       (input pH to secondary settler)
17  DBO-D      (input Biological demand of oxygen to secondary settler)
18  DQO-D      (input chemical demand of oxygen to secondary settler)
19  SS-D       (input suspended solids to secondary settler)
20  SSV-D      (input volatile supended solids to secondary settler)
21  SED-D      (input sediments to secondary settler)
22  COND-D     (input conductivity to secondary settler)
23  PH-S       (output pH)
24  DBO-S      (output Biological demand of oxygen)
25  DQO-S      (output chemical demand of oxygen)
26  SS-S       (output suspended solids)
27  SSV-S      (output volatile supended solids)
28  SED-S      (output sediments)
29  COND-S     (output conductivity)
30  RD-DBO-P   (performance input Biological demand of oxygen in primary settler)
31  RD-SS-P    (performance input suspended solids to primary settler)
32  RD-SED-P   (performance input sediments to primary settler)
33  RD-DBO-S   (performance input Biological demand of oxygen to secondary settler)
34  RD-DQO-S   (performance input chemical demand of oxygen to secondary settler)
35  RD-DBO-G   (global performance input Biological demand of oxygen)
36  RD-DQO-G   (global performance input chemical demand of oxygen)
37  RD-SS-G    (global performance input suspended solids)
38  RD-SED-G   (global performance input sediments)


-- Statistics:

N.  Attrib.     min      max       mean      st-dev
1  Q-E        10000    60081     37226.56  6571.46
2  ZN-E           0.1     33.5       2.36     2.74
3  PH-E           6.9      8.7       7.81     0.24
4  DBO-E         31      438       188.71    60.69
5  DQO-E         81      941       406.89   119.67
6  SS-E          98     2008       227.44   135.81
7  SSV-E         13.2     85.0      61.39    12.28
8  SED-E          0.4     36         4.59     2.67
9  COND-E       651     3230      1478.62   394.89
10  PH-P           7.3      8.5       7.83     0.22
11  DBO-P         32      517       206.20    71.92
12  SS-P         104     1692       253.95   147.45
13  SSV-P          7.1     93.5      60.37    12.26
14  SED-P          1.0     46.0       5.03     3.27
15  COND-P       646     3170      1496.03   402.58
16  PH-D           7.1      8.4       7.81     0.19
17  DBO-D         26      285       122.34    36.02
18  DQO-D         80      511       274.04    73.48
19  SS-D          49      244        94.22    23.94
20  SSV-D         20.2    100        72.96    10.34
21  SED-D          0.0      3.5       0.41     0.37
22  COND-D        85     3690      1490.56   399.99
23  PH-S           7.0      9.7       7.70     0.18
24  DBO-S          3      320        19.98    17.20
25  DQO-S          9      350        87.29    38.35
26  SS-S           6      238        22.23    16.25
27  SSV-S         29.2    100        80.15     9.00
28  SED-S          0.0      3.5       0.03     0.19
29  COND-S       683     3950      1494.81   387.53
30  RD-DBO-P       0.6     79.1      39.08    13.89
31  RD-SS-P        5.3     96.1      58.51    12.75
32  RD-SED-P       7.7    100        90.55     8.71
33  RD-DBO-S       8.2     94.7      83.44     8.4
34  RD-DQO-S       1.4     96.8      67.67    11.61
35  RD-DBO-G      19.6     97        89.01     6.78
36  RD-DQO-G      19.2     98.1      77.85     8.67
37  RD-SS-G       10.3     99.4      88.96     8.15
38  RD-SED-G      36.4    100        99.08     4.32


8. Missing Attribute Values:

N. Attrib.   N. of Missings
1  Q-E:	18
2  ZN-E:	 3
3  PH-E:	 0
4  DBO-E:	23
5  DQO-E:	 6
6  SS-E:	 1
7  SSV-E:	11
8  SED-E:	25
9  COND-E:	 0
10  PH-P:	 0
11  DBO-P:	40
12  SS-P:	 0
13  SSV-P:	11
14  SED-P:	24
15  COND-P:	 0
16  PH-D:	 0
17  DBO-D:	28
18  DQO-D:	 9
19  SS-D:	 2
20  SSV-D:	13
21  SED-D:	25
22  COND-D:	 0
23  PH-S:	 1
24  DBO-S:	23
25  DQO-S:	18
26  SS-S:	 5
27  SSV-S:      17
28  SED-S:      28
29  COND-S:	 1
30  RD-DBO-P:   62
31  RD-SS-P:     4
32  RD-SED-P:   27
33  RD-DBO-S:   40
34  RD-DQO-S:   26
35  RD-DBO-G:   36
36  RD-DQO-G:   25
37  RD-SS-G:     8
38  RD-SSED-G:  31


9. Class Distribution

These are the classes induced by out conceptual clustering algorithm:

-- Class 1: Normal situation

- Objects (275 days):

D-1/3/90 to  D-12/3/90, D-16/3/90 to D-30/3/90, D-1/2/90 to D-19/2/90, D-21/2/90 to D-28/2/90,
D-1/1/90 to D-26/1/90, D-29/1/90 to D-31/1/90, D-1/6/90 to D-4/6/90, D-6/6/90 to D-8/6/90,
D-24/6/90, D-25/6/90, D-28/6/90, D-29/6/90, D-1/5/90 to D-6/5/90, D-8/5/90 to D-20/5/90,
D-24/5/90, D-25/5/90, D-29/5/90, D-1/4/90, D-4/4/90 to D-8/4/90, D-10/4/90 to D-20/4/90,
D-27/4/90, D-2/7/90, D-4/7/90 to D-8/7/90, D-12/7/90 to D-15/7/90, D-19/7/90, D-23/7/90,
D-26/7/90, D-4/9/90, D-5/9/90, D-23/9/90, D-28/9/90, D-30/9/90, D-17/8/90, D-21/8/90 to D-25/8/90,
D-29/8/90, D-30/8/90, D-3/12/90, D-9/12/90, D-16/12/90 to D-20/12/90, D-23/12/90, D-24/12/90,
D-27/12/90 to D-30/12/90,  D-6/11/90 to D-8/11/90, D-14/11/90, D-16/11/90, D-18/11/90,
D-20/11/90, D-21/11/90, D-27/11/90, D-10/10/90, D-18/10/90, D-29/10/90, D-30/10/90,
D-3/3/91 to D-6/3/91, D-10/3/91 to D-12/3/91, D-18/3/91, D-20/3/91, D-27/3/91, D-29/3/91,
D-3/2/91, D-5/2/91, D-8/2/91, D-14/2/91, D-17/2/91, D-18/2/91, D-21/2/91 to D-24/2/91,
D-1/1/91, D-2/1/91, D-6/1/91, D-8/1/91, D-10/1/91 to D-20/1/91, D-25/1/91, D-2/5/91, D-3/5/91,
D-7/5/91, D-14/5/91, D-15/5/91, D-17/5/91, D-19/5/91, D-21/5/91 to D-23/5/91, D-1/4/91 to D-3/4/91,
D-5/4/91 to D-12/4/91, D-15/4/91 to D-21/4/91, D-23/4/91, D-1/7/91, D-3/7/91, D-4/7/91, D-7/7/91,
D-10/7/91 to D-12/7/91, D-15/7/91, D-16/7/91, D-22/7/91 to D-25/7/91, D-28/7/91, D-30/7/91, D-31/7/91,
D-2/6/91 to D-4/6/91, D-6/6/91, D-7/6/91, D-13/6/91, D-16/6/91 to D-21/6/91, D-25/6/91 to D-30/6/91,
D-4/10/91, D-6/10/91, D-17/10/91 to D-30/10/91, D-1/8/91, D-2/8/91, D-27/8/91, D-29/8/91.


-- Class 2: Secondary settler problems-1

- Objects (1 day): D-13/3/90

-- Class 3: Secondary settler problems-2

- Objects (1 day): D-14/3/90

-- Class 4: Secondary settler problems-3

- Objects (1 day): D-15/3/90, D-17/7/91 to D-19/7/91

-- Class 5: Normal situation with performance over the mean

- Objects (116 days):

D-28/1/90, D-10/6/90 to D-22/6/90, D-26/6/90, D-27/6/90, D-7/5/90, D-21/5/90 to D-23/5/90,
D-27/5/90, D-28/5/90, D-30/5/90, D-2/4/90, D-3/4/90, D-9/4/90, D-22/4/90 to D-26/4/90, D-1/7/90,
D-3/7/90, D-9/7/90 to D-11/7/90, D-16/7/90 to D-18/7/90, D-20/7/90, D-22/7/90, D-24/7/90, D-25/7/90,
D-27/7/90 to D-31/7/90, D-2/9/90, D-3/9/90, D-6/9/90 to D-13/9/90, D-16/9/90 to D-21/9/90,
D-24/9/90 to D-27/9/90, D-1/8/90 to D-7/8/90, D-16/8/90, D-28/8/90, D-31/8/90, D-7/12/90,
D-2/11/90, D-5/11/90, D-9/11/90, D-12/11/90, D-13/11/90, D-1/10/90 to D-5/10/90, D-24/10/90,
D-25/10/90, D-1/3/91, D-8/3/91, D-17/3/91, D-26/3/91, D-31/3/91, D-9/1/91, D-10/5/91, D-16/5/91,
D-20/5/91, D-29/5/91, D-30/5/91, D-14/4/91, D-22/4/91, D-24/4/91, D-25/4/91, D-5/7/91, D-8/7/91,
D-9/7/91, D-21/7/91, D-26/7/91, D-5/6/91, D-10/6/91, D-12/6/91, D-14/6/91, D-2/10/91, D-8/10/91,
D-9/10/91, D-11/10/91,D-13/10/91, D-16/10/91.

-- Class 6: Solids overload-1

- Objects (3 days):   D-5/6/90 D-28/5/91 D-31/5/91

-- Class 7: Secondary settler problems-4

- Objects (1 day): D-29/4/90

-- Class 8: Storm-1

- Objects (1 day): D-14/9/90

-- Class 9: Normal situation with low influent

- Objects (69 days):

D-8/8/90 to D-10/8/90, D-13/8/90, D-15/8/90, D-19/8/90, D-20/8/90, D-27/8/90, D-1/11/90,
D-4/11/90, D-11/11/90, D-19/11/90, D-7/10/90 to D-9/10/90, D-12/10/90 to D-17/10/90,
D-21/10/90, D-23/10/90, D-26/10/90, D-28/10/90, D-7/3/91, D-24/3/91, D-25/3/91,
D-1/5/91, D-5/5/91, D-8/5/91, D-9/5/91, D-12/5/91, D-13/5/91, D-26/5/91, D-27/5/91,
D-26/4/91, D-28/4/91, D-29/4/91, D-2/7/91, D-14/7/91, D-29/7/91, D-9/6/91, D-24/6/91,
D-1/10/91, D-3/10/91, D-5/10/91, D-12/10/91, D-15/10/91, D-4/8/91  D-9/8/91 to D-26/8/91,
D-28/8/91, D-30/8/91.

-- Class 10: Storm-2

- Objects (1 day): D-12/8/90

-- Class 11: Normal situation

- Objects (53 days):

D-2/12/90, D-4/12/90, D-6/12/90, D-10/12/90 to D-14/12/90 D-21/12/90, D-26/12/90,
D-15/11/90, D-22/11/90 to D-26/11/90, D-28/11/90 to D-30/11/90, D-19/10/90,
D-13/3/91 to D-15/3/91, D-19/3/91, D-21/3/91, D-22/3/91, D-1/2/91, D-4/2/91,
D-6/2/91, D-7/2/91, D-10/2/91 to  D-13/2/91, D-15/2/91, D-19/2/91,
D-25/2/91 to D-28/2/91, D-3/1/91, D-4/1/91, D-7/1/91, D-21/1/91 to D-24/1/91,
D-27/1/91 to D-31/1/91, D-6/5/91, D-4/4/91.

-- Class 12: Storm-3

- Objects (1 day): D-22/10/90

-- Class 13: Solids overload-2

- Objects (1 day): D-24/5/91



-- Comments to the data file:

The first element of each line is the day of the data,
the rest are the attribute values




Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
566,meta,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: meta-data

2. Sources:
(a) Creator:
LIACC - University of Porto
R.Campo Alegre 823
4150 PORTO
(b) Donor: P.B.Brazdil or J.Gama            Tel.:  +351 600 1672
LIACC, University of Porto               Fax.:  +351 600 3654
Rua Campo Alegre 823                     Email:  statlog-adm@ncc.up.pt
4150 Porto, Portugal
(c) Date: March, 1996

(d) Acknowlegements:
LIACC wishes to thank Commission of European Communities
for their support. Also, we wish to thank the following partners
for providing the individual test results:

- Dept. of Statistics, University of Strathclyde, Glasgow, UK
- Dept. of Statistics, University of Leeds, UK
- Aston University, Birmingham, UK
- Forschungszentrum Ulm, Daimler-Benz AG, Germany
- Brainware GmbH, Berlin, Germany
- Frauenhofer Gesellschaft IITB-EPO, Berlin, Germany
- Institut fuer Kybernetik, Bochum, Germany
- ISoft, Gif sur Yvette, France
- Dept. of CS and AI, University of Granada, Spain


3. Past Usage:


Meta-Data was used in order to give advice about which classification
method is appropriate for a particular dataset.
This work is described in:

-""Machine Learning, Neural and Statistical Learning""
Eds. D.Michie,D.J.Spiegelhalter and C.Taylor
Ellis Horwood-1994

- ""Characterizing the Applicability of
Classification Algorithms Using Meta-Level Learning"",
P. Brazdil, J.Gama and B.Henery:
in Proc. of Machine Learning - ECML-94,
ed. F.Bergadano and L.de Raedt,LNAI Vol.784 Springer-Verlag.

-""Characterization of Classification Algorithms""
J.Gama, P.Brazdil
in Proc. of EPIA 95, LNAI Vol.990
Springer-Verlag, 1995


4. Relevant Information:n
This DataSet is about the results of Statlog project.
The project performed a comparative study between Statistical, Neural
and Symbolic learning algorithms.

Project StatLog (Esprit Project 5170) was concerned with comparative
studies of different machine learning, neural and statistical
classification algorithms. About 20 different algorithms were
evaluated on more than 20 different datasets. The tests carried out
under project produced many interesting results.

Algorithms                      DataSets
-------------------------       --------------------------
C4.5            NewId           Credit_Austr    Belgian
AC2             CART            Chromosome      Credit_Man
IndCART         Cal5            CUT             DNA
CN2             ITRule          Diabetes        Digits44
Discrim         QuaDisc         Credit_German   Faults
LogDisc         ALLOC80         Head            Heart
kNN             SMART           KLDigits        Letters
BayesTree       CASTLE          New_Belgian     Sat_Image
DIPLO92         RBF             Segment         Shuttle
LVQ             Backprop        Technical       TseTse
Kohonen                         Vehicle


The results of these tests are comprehensively described in a book
(D.Michie et.al, 1994).

5. Number of Instances: 528

6. Number of Attributes: 22 (including an Id#) plus the class attribute
-- all but two attributes are continuously valued

7. Attribute Information:
1.   DS_Name         categorical     Name of DataSet
2.   T               continuous      Number of examples in test set
3.   N               continuous      Number of examples
4.   p               continuous      Number of attributes
5.   k               continuous      Number of classes
6.   Bin             continuous      Number of binary Attributes
7.   Cost            continuous      Cost (1=yes,0=no)
8.   SDratio         continuous      Standard deviation ratio
9.   correl          continuous      Mean correlation between attributes
10.   cancor1         continuous      First canonical correlation
11.   cancor2         continuous      Second canonical correlation
12.   fract1          continuous      First eigenvalue
13.   fract2          continuous      Second eigenvalue
14.   skewness        continuous      Mean of |E(X-Mean)|^3/STD^3
15.   kurtosis        continuous      Mean of |E(X-Mean)|^4/STD^4
16.   Hc              continuous      Mean entropy of attributes
17.   Hx              continuous      Entropy of classes
18.   MCx             continuous      Mean mutual entropy of class and attributes
19.   EnAtr           continuous      Equivalent number of attributes
20.   NSRatio         continuous      Noise-signal ratio
21.   Alg_Name        categorical     Name of Algorithm
22.   Norm_error      continuous      Normalized Error (continuous class)


8. Missing Attribute Values:

Note that fract2 and cancor2 only apply to datasets with more than
2 classes. When they appear as '?' this means a don't care value.

Summary Statistics:

Attribute       Min     Max     Mean    Std
T               270     20000   4569.05 5704.01
N               270     58000   10734.2 14568.8
p               6       180     29.5455 36.8533
k               2       91      9.72727 19.3568
Bin             0       43      3.18182 9.29227
Cost            0       1       0.13636 0.35125
SdRatio         1.0273  4.0014  1.4791  0.65827
Correl          0.0456  0.751   0.23684 0.1861
Cancor1         0.5044  0.9884  0.79484 0.15639
Cancor2         0.1057  0.9623  0.74106 0.269
Fract1          0.1505  1       0.70067 0.3454
Fract2          0.2807  1       0.70004 0.29405
Skewness        0.1802  6.7156  1.78422 1.79022
Kurtosis        0.9866  160.311 22.6672 41.8496
Hc              0.2893  4.8787  1.87158 1.44665
Hx              0.3672  6.5452  3.34502 1.80383
Mcx             0.0187  1.3149  0.31681 0.33548
EnAtr           1.56006 160.644 20.6641 35.6614
NsRatio         1.02314 159.644 28.873  37.925"
567,kdd_coil_1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 1/7"
568,kdd_coil_2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 2/7"
569,auto93,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Attributes 2,4, and 6 deleted. Midrange price treated as the class
attribute.

As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction
using instance-based learning with encoding length selection. In Progress
in Connectionist-Based Information Systems. Singapore: Springer-Verlag.

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

NAME:  1993 New Car Data
TYPE:  Sample
SIZE:  93 observations, 26 variables

DESCRIPTIVE ABSTRACT:
Specifications are given for 93 new car models for the 1993 year.
Several measures are given to evaluate price, mpg ratings, engine size,
body size, and features.

SOURCES:
_Consumer Reports:  The 1993 Cars - Annual Auto Issue_ (April 1993),
Yonkers, NY: Consumers Union.
_PACE New Car & Truck 1993 Buying Guide_ (1993), Milwaukee, WI: Pace
Publications Inc.

VARIABLE DESCRIPTIONS:
Line 1
Columns
1 - 14  Manufacturer
15 - 29  Model
30 - 36  Type
Small, Sporty, Compact, Midsize, Large - as defined in the
_Consumer Reports_ article
38 - 41  Minimum Price (in $1,000) - Price for basic version of this model
43 - 46  Midrange Price (in $1,000) - Average of Min and Max prices
48 - 51  Maximum Price (in $1,000) - Price for a premium version
53 - 54  City MPG (miles per gallon by EPA rating)
56 - 57  Highway MPG
59 - 59  Air Bags standard
0 = none, 1 = driver only, 2 = driver & passenger
61 - 61  Drive train type
0 = rear wheel drive
1 = front wheel drive
2 = all wheel drive
63 - 63  Number of cylinders
65 - 67  Engine size (liters)
69 - 71  Horsepower (maximum)
73 - 76  RPM (revs per minute at maximum horsepower)

Line 2
Columns
1 -  4  Engine revolutions per mile (in highest gear)
6 -  6  Manual transmission available
0 = No, 1 = Yes
8 - 11  Fuel tank capacity (gallons)
13 - 13  Passenger capacity (persons)
15 - 17  Length    (inches)
19 - 21  Wheelbase (inches)
23 - 24  Width     (inches)
26 - 27  U-turn space (feet)
29 - 32  Rear seat room (inches)
34 - 35  Luggage capacity (cu. ft.)
37 - 40  Weight (pounds)
42 - 42  Domestic?
0 = non-U.S. manufacturer, 1 = U.S. manufacturer

Values are aligned and delimited by blanks.
Missing values are denoted with *.
There are two data lines for each case.

SPECIAL NOTES:
The only missing values are for CYLINDERS in the rotary engine Mazda
RX-7, REAR SEAT room for the two-seaters (Corvette and RX-7), and
LUGGAGE capacity for the vans and two-seaters.

WEIGHT is taken from the _Consumer Reports_ data and includes a full
fuel tank, automatic transmission (if available), and air conditioning.

STORY BEHIND THE DATA:
Cars were selected at random from among 1993 passenger car models that
were listed in both the _Consumer Reports_ issue and the _PACE Buying
Guide_.  Pickup trucks and Sport/Utility vehicles were eliminated due
to incomplete information in the _Consumer Reports_ source.  Duplicate
models (e.g., Dodge Shadow and Plymouth Sundance) were listed at most
once.

A similar dataset for 1989 model cars appeared as one of the sample
datasets shipped with the _Student Edition of Execustat_ (PWS-KENT
1990).

Further description can be found in the ""Datasets and Stories"" article
""1993 New Car Data"" in the _Journal of Statistics Education_ (Lock 1993).
Send the message

send jse/v1n1/datasets.lock

to the address archive@jse.stat.ncsu.edu

PEDAGOGICAL NOTES:
This is a multi-purpose dataset that can be used at many points in an
introductory course.  It includes many good numeric variables and
several options for dividing the cars up into groups.  Students tend to
be familiar with most of the variables (and specific car models).  They
can anticipate and pose explanations for many of the relationships to
be found in the data, although some surprises may be encountered.  One
can easily find examples of pairs of variables that demonstrate strong
or weak, positive or negative associations.  PRICE and MPG variables
tend to be popular choices as ""dependent"" variables.  Basic graphs will
often reveal unusual data values (like the price for a Mercedes-Benz).

REFERENCES:
Lock, R. H. (1993), ""1993 New Car Data,"" _Journal of Statistics
Education_, 1, No. 1.
_Student Edition of Execustat_ (1990), Boston, MA: PWS-KENT
Publishing Co.

SUBMITTED BY:
Robin H. Lock
Mathematics Department
St. Lawrence University
Canton, NY  13617
(315) 379-5960
rlock@stlawu.bitnet"
570,kdd_coil_3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 3/7"
572,bank8FM,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

A family of datasets synthetically generated from a simulation of how bank-customers choose their banks. Tasks are
based on predicting the fraction of bank customers who leave the bank because of full queues. The bank family of
datasets are generated from a simplistic simulator, which simulates the queues in a series of banks. The simulator was
constructed with the explicit purpose of generating a family of datasets for DELVE. Customers come from several
residential areas, choose their preferred bank depending on distances and have tasks of varying complexity, and various
levels of patience. Each bank has several queues, that open and close according to demand. The tellers have various
effectivities, and customers may change queue, if their patience expires. In the rej prototasks, the object is to predict the
rate of rejections, ie the fraction of customers that are turned away from the bank because all the open tellers have full
queues.
Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Orginal source: DELVE repository of data.
Characteristics: Data set contains 8192 (4500+3692) cases. and 9 continuous
attributes"
573,cpu_act,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Computer Activity databases are a collection of computer systems
activity measures. The data was collected from a Sun Sparcstation
20/712 with 128 Mbytes of memory running in a multi-user university
department. Users would typically be doing a large variety of tasks
ranging from accessing the internet, editing files or running very
cpu-bound programs.  The data was collected continuously on two
separate occasions. On both occassions, system activity was gathered
every 5 seconds. The final dataset is taken from both occasions with
equal numbers of observations coming from each collection epoch.

System measures used:
1. lread - Reads (transfers per second ) between system memory and user memory.
2. lwrite - writes (transfers per second) between system memory and user memory.
3. scall - Number of system calls of all types per second.
4. sread - Number of system read calls per second.
5. swrite - Number of system write calls per second .
6. fork - Number of system fork calls per second.
7. exec - Number of system exec calls per second.
8. rchar - Number of characters transferred per second by system read calls.
9. wchar - Number of characters transfreed per second by system write calls.
10. pgout - Number of page out requests per second.
11. ppgout - Number of pages, paged out per second.
12. pgfree - Number of pages per second placed on the free list.
13. pgscan - Number of pages checked if they can be freed per second.
14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.
15. pgin - Number of page-in requests per second.
16. ppgin - Number of pages paged in per second.
17. pflt - Number of page faults caused by protection errors (copy-on-writes).
18. vflt - Number of page faults caused by address translation.
19. runqsz - Process run queue size.
20. freemem - Number of memory pages available to user processes.
21. freeswap - Number of disk blocks available for page swapping.
22. usr - Portion of time (%) that cpus run in user mode.
23. sys - Portion of time (%) that cpus run in system mode.
24. wio - Portion of time (%) that cpus are idle waiting for block IO.
25. idle - Portion of time (%) that cpus are otherwise idle.

The two different regression tasks obtained from these databases are:

CompAct
Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.

CompAct(s)
Predict usr using a restricted number (excluding the paging information (10-18)

Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Original source: DELVE repository of data.
Characteristics: 8192 cases, 22 continuous attributes"
574,house_16H,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This database was designed on the basis of data provided by US Census
Bureau [http://www.census.gov] (under Lookup Access
[http://www.census.gov/cdrom/lookup]: Summary Tape File 1). The data
were collected as part of the 1990 US census. These are mostly counts
cumulated at different survey levels. For the purpose of this data set
a level State-Place was used. Data from all states was obtained. Most
of the counts were changed into appropriate proportions.  There are 4
different data sets obtained from this database: House(8H) House(8L)
House(16H) House(16L) These are all concerned with predicting the
median price of the house in the region based on demographic
composition and a state of housing market in the region. A number in
the name signifies the number of attributes of the data set. A
following letter denotes a very rough approximation to the difficulty
of the task. For Low task difficulty, more correlated attributes were
chosen as signified by univariate smooth fit of that input on the
target. Tasks with High difficulty have had their attributes chosen to
make the modelling more difficult due to higher variance or lower
correlation of the inputs to the target.

Original source: DELVE repository of data.
Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at
http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html
Characteristics: 22784 cases, 17 continuous attributes."
575,kdd_coil_4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 4/7"
576,kdd_coil_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 5/7"
577,kdd_coil_6,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 6/7"
578,kdd_coil_7,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%
Data-Description %
%%%%%%%%%%%%%%%%%%%

COIL 1999 Competition Data

Data Type

multivariate

Abstract

This data set is from the 1999 Computational Intelligence and Learning
(COIL) competition. The data contains measurements of river chemical
concentrations and algae densities.

Sources

Original Owner

[1]ERUDIT
European Network for Fuzzy Logic and Uncertainty Modelling
in Information Technology

Donor

Jens Strackeljan
Technical University Clausthal
Institute of Applied Mechanics
Graupenstr. 3, 38678 Clausthal-Zellerfeld, Germany
[2]tmjs@itm.tu-clausthal.de

Date Donated: September 9, 1999

Data Characteristics

This data comes from a water quality study where samples were taken
from sites on different European rivers of a period of approximately
one year. These samples were analyzed for various chemical substances
including: nitrogen in the form of nitrates, nitrites and ammonia,
phosphate, pH, oxygen, chloride. In parallel, algae samples were
collected to determine the algae population distributions.

Other Relevant Information

The competition involved the prediction of algal frequency
distributions on the basis of the measured concentrations of the
chemical substances and the global information concerning the season
when the sample was taken, the river size and its flow velocity. The
competition [3]instructions contain additional information on the
prediction task.

Data Format

There are a total of 340 examples each containing 17 values. The first
11 values of each data set are the season, the river size, the fluid
velocity and 8 chemical concentrations which should be relevant for
the algae population distribution. The last 8 values of each example
are the distribution of different kinds of algae. These 8 kinds are
only a very small part of the whole community, but for the competition
we limited the number to 7. The value 0.0 means that the frequency is
very low. The data set also contains some empty fields which are
labeled with the string XXXXX.

The training data are saved in the file: analysis.data (ASCII format).

Table 1: Structure of the file analysis.data

A


K

a


g

CC[1,1]


CC[1,11]

AG[1,1]


AG[1,7]

CC[200,1]


CC[200,11]

AG[200,1]


AG[200,7]

Explanation:
CC[i,j]: Chemical concentration or river characteristic
AG[i,j]: Algal frequency

The chemical parameters are labeled as A, ..., K. The columns of the
algaes are labeled as a, ..,g.

Past Usage

[4]The Third (1999) International COIL Competition Home Page
_________________________________________________________________


[5]The UCI KDD Archive
[6]Information and Computer Science
[7]University of California, Irvine
Irvine, CA 92697-3425

Last modified: October 13, 1999

References

1. http://www.erudit.de/
2. mailto:tmjs@itm.tu-clausthal.de
3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt
4. http://www.erudit.de/erudit/activities/ic-99/index.htm
5. http://kdd.ics.uci.edu/
6. http://www.ics.uci.edu/
7. http://www.uci.edu/

%%%%%%%%%%%%%%%%%%%
Task-Description %
%%%%%%%%%%%%%%%%%%%


Third International Competition

Protecting rivers and streams by monitoring chemical concentrations and
algae communities.


Intelligent Techniques for Monitoring Water Quality using chemical
indicators and algae population

Recent years have been characterised by increasing concern at the
impact man is having on the environment.
The impact on the environment of toxic waste, from a wide variety
of manufacturing processes, is well known. More recently, however,
it has become clear that the more subtle effects of nutrient level
and chemical balance changes arising from farming land run-off and
sewage water treatment also have a serious, but indirect, effect on
the states of rivers, lakes and even the sea.  In temperate climates
across the world summers are characterized by numerous reports excessive
summer algae growth resulting in poor water clarity, mass deaths of
river fish from reduced oxygen levels and the closure of recreational
water facilities on account of the toxic effects of this annual algal bloom.
Reducing the impact of these man-made changes in river nutrient levels
has stimulated much biological research with the aim of identifying
the crucial chemical control variables for the biological
processes.

The data used in this problem comes from one such study.
During the research study water quality samples were
taken from sites on different European rivers of a period of
approximately one year.  These samples were analyzed for various
chemical substances including: nitrogen in the form of nitrates,
nitrites and ammonia, phosphate, pH, oxygen, chloride.
In parallel, algae samples were collected to determine the algae population
distributions. It is well known that the dynamics of the
algae community is determined by external chemical
environment with one or more factors being predominant.
While the chemical analysis is cheap and easily
automated, the biological part involves microscopic examination,
requires trained manpower and is therefore both
expensive and slow.

Diatoms like Cymbella are major contributors to primary production
throughout the world. The diatom reacts with
large sensitivity to even small changes in acidity .

Over a three and half billion year history algae have evolved and
adapted as primary plant colonizers of almost
every known habitant in terrestrial and aquatic environments.
They respond very rapidly to man-made environment changes.



The relationship between the chemical and biological features is
complex and can be expected to need the application of advanced
techniques. Typical of such real-life problems, the particular
data set for the problem contains a mixture of (fuzzy) qualiative
variables and numerical measurement values, with much of the data
being incomplete.

The competition task is the prediction of algal frequency distributions
on the basis of  the measured concentrations of the chemical
substances and the global information concerning the season when the sample
was taken, the river size and its flow velocity. The two last variables
are given as linguistic variables.

340 data sets were taken and each contain 17 values. The
first 11 values of each data set are the season, the river
size, the fluid velocity and 8 chemical concentrations which
should be relevant for the algae population distribution.
The last 8 values of each data set are the distribution of
different kinds of algae. These 8 kinds are only a very small
part of the whole community, but for the competition we limited
the number to 7. The value 0.0 means that the frequency is very low.
The data set also contains some empty fields which are labeled
with the string XXXXX.

Each participant in the competition receives 200 complete data sets
(training data) and 140 data sets (evaluation data) containing only
the 11 values of the river descriptions and the chemical concentrations.

This training data is to be used in obtainin
a 'model' providing a prediction of the algal distributions associated
with the evaluation data.



The training data are saved in the file:

analysis.txt (ASCII format).

Structure of the file analysis.txt

A                          K              a                   g
CC1,1   ...                CC1,11         AG1,1    ...        AG1,7
....                        ...            ...                 ...


CC200,1 ...                CC200,11       AG240,1  ...        AG240,7


Explanation:
CCi,j:  Chemical concentration    j=1,..11
AGi,k: Algal frequency            k=1...7


The chemical parameters are labeled as A, ..., K.
The columns of the algaes are labeled as a, ..,g.


Evaluation data are saved in file eval.txt (ASCII format).


Table 2: Structure of the file eval.*
A                               K
CC1,1     ...                   CC1,11

.....                            ...

CC140,1   ...                   CC140,11

_____________________________________________________________

Objective

The objective of the competition is to provide a prediction
model on basis of the training data. Having obtained this
prediction model, each participant must provide the solution
in the form of the results of applying this model to the
evaluation data. The results obtained in this way should
correspond to the results of the evaluation data
(which are known to the organizer). The criteria used to evaluate
the results is given below.
All 7 Algae frequency distributions must be determined.
For this purpose any number of partial models may be developed.

_____________________________________________________________

Judgment of the results

To judge the results, the sum of squared errors will be calculated.
The following Table describes the results of a particular participant.

Matrix of results
a                     g

Res1,1   ...          Res1,7

....                   ...

Res140,1              Res140,7


All solutions that lead to a smallest total error will
be regarded as winner of the contest.



Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last

ALGAE #: 7/7"
579,fri_c0_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
580,fri_c4_250_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
581,fri_c3_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
582,fri_c1_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
583,fri_c1_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
584,fri_c4_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
585,fri_c3_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
586,fri_c3_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
587,fri_c3_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
588,fri_c4_1000_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
589,fri_c2_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
590,fri_c0_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
591,fri_c1_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
592,fri_c4_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
593,fri_c1_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
594,fri_c2_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
595,fri_c0_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
596,fri_c2_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
597,fri_c2_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
598,fri_c0_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
599,fri_c2_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
600,fri_c0_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
601,fri_c1_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
602,fri_c3_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
603,fri_c0_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
604,fri_c4_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
605,fri_c2_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
606,fri_c2_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
607,fri_c4_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
608,fri_c3_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
609,fri_c0_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
610,fri_c4_500_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
611,fri_c3_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
612,fri_c1_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
613,fri_c3_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
614,fri_c1_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
615,fri_c4_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
616,fri_c4_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
617,fri_c3_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
618,fri_c3_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
619,fri_c4_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
620,fri_c1_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
621,fri_c0_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
622,fri_c2_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
623,fri_c4_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
624,fri_c0_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
625,fri_c4_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
626,fri_c2_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
627,fri_c2_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
628,fri_c3_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
629,fri_c1_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
630,fri_c2_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
631,fri_c1_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
632,fri_c3_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
633,fri_c0_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
634,fri_c2_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
635,fri_c0_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
636,fri_c1_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
637,fri_c1_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
638,fri_c2_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
639,fri_c3_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
640,fri_c4_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
641,fri_c1_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
642,fri_c4_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
643,fri_c2_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
644,fri_c4_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
645,fri_c3_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
646,fri_c3_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
647,fri_c1_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
648,fri_c1_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
649,fri_c0_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
650,fri_c0_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
651,fri_c0_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
652,fri_c4_100_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
653,fri_c0_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
654,fri_c0_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
655,fri_c2_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
656,fri_c1_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
657,fri_c2_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
658,fri_c3_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

The Friedman datasets are 80 artificially generated datasets originating from: J.H. Friedman (1999). Stochastic Gradient Boosting

The dataset names are coded as ""fri_colinearintydegree_samplenumber_featurenumber"".

Friedman is the one of the most used functions for data generation (Friedman, 1999). Friedman functions include both linear and non-linear relations between input and output, and a normalized noise (e) is added to the output. The Friedman function is as follows: 

y=10*sin(pi*x1*x2)+20*(x3-0.5)^2=10*X4+5*X5+e

In the original Friedman function, there are 5 features for input. To measure the effects of non-related features, additional features are added to the datasets. These added features are independent from the output. However, to measure the algorithm's robustness to the colinearity, the datasets are generated with 5 different colinearity degrees. The colinearity degrees is the number of features depending on other features. 

The generated Friedman dataset's parameters and values are given below: 
The number of features: 5 10 25 50 100 (only the first 5 features are related to the output. The rest are completely random)
The number of samples: 100 250 500 1000
Colinearity degrees: 0 1 2 3 4
For the datasets with colinearity degree 4, the numbers of features are generated as 10, 25, 50 and 100.
The other datasets have 5, 10, 25 and 50 features.

As a result, 80 artificial datasets are generated by (4 different feature number * 4 different sample number * 5 different colinearity degree)

The last attribute in each file is the target."
659,sleuth_ex1714,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/ex1714.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
660,rabe_265,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.265

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
661,sleuth_case1102,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/case1102.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
663,rabe_266,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.266

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
664,chscase_census6,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: census6.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
665,sleuth_case2002,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/case2002.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
666,rmftsa_ladata,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Sets for 'Regression Models for Time Series Analysis' by
B. Kedem and K. Fokianos, Wiley 2002. Submitted by Kostas
Fokianos (fokianos@ucy.ac.cy) [8/Nov/02] (176k)

Note: - attribute names were generated manually
- information about data taken from here:
http://lib.stat.cmu.edu/datasets/

File: ../data/rmftsa/ladata

LA Pollution-Mortality Study:
1970-1979, 508 observations,  6-day spacing. Weekly FILTERED data.
The data were lowpass filtered, filtering out frequencies above 0.1
cycles per day.
Mortality:          (1) Mrt: Total Mortality
(2) Rsp: Respiratory Mortality
(3) Crd: Cardiovascular Mortality
Weather:            (4) Tmp: Temperature
(5) Hum: Relative Humidity
Pollution:          (6) Crb: Carbon Monoxide
(7) Slf: Sulfur Dioxideglm.LAshumway
(8) Nit: Nitrogen Dioxide
(9) Hdr: Hydrocarbons
(10) Ozn: Ozone
(11) Par: Particulates


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
668,witmer_census_1980,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

A shar archive of data from the book Data Analysis: An
Introduction(1992) Prentice Hall bu Jeff Witmer. Submitted by
Jeff Witmer (fwitmer@ocvaxa.cc.oberlin.edu) [28/Jun/94] (29
kbytes)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/witmer/DATA_FILES/Census_1980


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
669,chscase_adopt,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: adopt.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
670,chscase_census5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook

NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: census5.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
671,chscase_census4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: census4.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
672,chscase_census3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: census3.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
673,chscase_census2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: census2.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
674,chscase_demand,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: demand.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
675,visualizing_slope,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/slope.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
676,disclosure_x_tampered,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Used in ""A BAYESIAN APPROACH TO DATA DISCLOSURE: OPTIMAL
INTRUDER BEHAVIOR FOR CONTINUOUS DATA""
by Stephen E. Fienberg, Udi E. Makov, and Ashish P. Sanil

Background:
==========
In this paper we develop an approach to data disclosure in survey settings by
adopting a probabilistic definition of disclosure due to Dalenius. Our approach
is based on the principle that a data collection agency must consider
disclosure from the perspective of an intruder in order to efficiently evaluate
data disclosure limitation procedures. The probabilistic definition and our
attempt to study optimal intruder behavior lead naturally to a Bayesian
formulation.  We apply the methods in a small-scale simulation study using data
adapted from an actual survey conducted by the Institute for Social Research at
York University. (See Sections 1-3 of the paper for details oF the model
formulation and related issues.)

The Data:
========
Our case study uses data from the survey data Elite Canadian
Decision-Makers collected by the Institute for Social Research at York
University.  This survey was conducted in 1981 using telephone
interviews and there were 1348 respondents, but many of these did not
supply complete data.  We have extracted data on 12 variables, each of which
was measured on a 5-point scale:

Civil-liberties:
- ---------------
C1 - Free speech is just not worth it.
C2 - We have gone too far in pushing equal rights in this country.
C3 - It is better to live in an  orderly  society  than  to  allow people so
much freedom.
C5 - Free speech ought to be allowed for all political groups.

Attitudes towards Jews:
- ----------------------
A15 - Most Jews don't care what happens to people who are not Jews.
A18 - Jews are more willing than others to use shady practices  to
get ahead.

Canada-US relationship:
- ----------------------
CUS1 - Ensure independent Canada.
CUS5 - Canada should have free trade with the USA.
CUS6 - Canada's way of life is influenced strongly by USA.
CUS7 - Canada benefits from US investments.


In addition, we have data on two approximately continuous variables:

Personal information:
- --------------------
Income - Total family income before taxes (with top-coding at \$80,000).
Age - Based on year of birth.


We transformed the original survey data  as follows in order to create
a database of approximately continuous variables:

[A]  We add categorical  variables  (all  but  income) to increase the number
of levels. (When necessary we reversed the order of levels of a response  to a
question.)  The new variables are defined as follows:

Civil     = C1 + C2 + C3 + (8 - C5)
Attitude  = A15 + A18
Can/US    = (5 - CUS1) + CUS5 + (5 - CUS6) + CUS7

After we removed cases with missing observations and  two  cases involving
young children, we had a  data-base consisting of 662 observations.

[B]  In order to enhance continuity, we took the following measures:

Age:  We added normal  distributed  variates,  with  0   mean  and
variance 4 to all observations.
Income: We added uniform variates on the range of $0 - $10,000 to all incomes
below $80,000.  Since all cases of incomes exceeding $80,000 were
lumped together  in  the  survey,  we simulated their values by means
of a t(8) distribution. Drawing values from the upper 38% tail of t(8),
we evaluated the values of income as $60,000 + 25,000*t(8).
Other variables: We added  normal distributed variates, with 0 mean and
variance  0.5 to the variables.

We assume that the agency releases information about all
variables, except for Attitudes (towards Jews), which  is unavailable to
the intruder and is at the center of the intruder's investigation.

We denote the released data by

Z = (( z(i,j) ))   with i=1,..,662; j=1,2,3,4.

We assume that the intruder's data, X, are accurate and are related to Z via
the following transformation:
x(0,j) = z(i,j)*theta(i,j) + xi(j),

where theta(i,j) is a bias removing parameter normally distributed with mean 1
and variance  v(j), and xi(j) is normally distributed disturbance with 0  mean
and variance sigma2(j).

The following table provides the values of
v(j), sigma2(j) used in the study:

v(j)     sigma2(j)
Civil                      0.1732       25
Can/US                     0.1732       25
Age                        0.1732       9
Income (in $10000's)       0.1732       4


We first generated several realizations of the above transformation on small
subsets of the data to ascertain the impact of the process of the error
on the data. In Table 4-1 in the paper we present 10 records the the intruder's
accurate data, X, and the biased and corrupted released data, Z, which we
obtained from one realization of the transformation.

Section 4.2 of the paper contains details of the implementation of our Bayesian
model.

Data Used in the Computations:
=============================
We conducted a complete simulation of the procedures for the complete set of
662 cases.  We considered four different scenarios for the simulation. (The
names of datasets used in each of the scenarios appear in brackets below. The
datasets are appended to this text.)

* The released data contains no bias or noise (i.e. v(j)=0 and sigma2(j)=0 for
all j). [Z.DATA]
* The released data contains only noise (i.e., v(j)=0 for all j and
and $sigma2(j)$ as given in the above Table). [X_NOISE.DATA]
* The released data contains only bias (i.e., sigma2(j)=0 for all j and v(j)
as given in the above Table). [X_BIAS.DATA]
* The released data contains both bias and noise (i.e., v(j) and sigma2(j) as
given in the above Table). [X_TAMPERED.DATA]

We took each individual in turn as the object of the intruder's efforts and
carried out the calculations.

Structure of the Datasets:
- -------------------------
Each attached dataset consists of four space-separated columns containing the
data on Age, Civil, Can/US and Income ($) respectively.



Dataset: X_TAMPERED


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
678,visualizing_environmental,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/environmental.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
679,rmftsa_sleepdata,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Sets for 'Regression Models for Time Series Analysis' by
B. Kedem and K. Fokianos, Wiley 2002. Submitted by Kostas
Fokianos (fokianos@ucy.ac.cy) [8/Nov/02] (176k)

Note: - attribute names were generated manually
- information about data taken from here:
http://lib.stat.cmu.edu/datasets/

File: ../data/rmftsa/sleepdata.txt

Sleep state measurements of a newborn infant (column 2) together
with his heart rate (column 1) and temperature (column 3).


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
680,chscase_funds,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: funds.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
681,hutsof99_logis,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Graeme D. Hutcheson and Nick Sofroniou 1999

The Multivariate Social Scientist:
Introductory Statistics Using Generalized Linear Models.

SAGE Publications.

Copyright: Graeme D. Hutcheson & Nick Sofroniou, 1999

This software can be freely used for non-commercial purposes and can be
freely distributed.


Readme file
===========

The data sets in this directory are taken from the above book.
The data are presented in two formats, *.dat (ascii) and
*.por (SPSS portable). The GLIM code and macros are provided in
files *.glm and *.mac. Please read the errata file which indicates some
minor differences between these data sets and those reported in the
book.




DATA FILE      SOURCE IN BOOK    DESCRIPTION

Chapter 1
tab1_01.*   Table 1.1         Video Games and Hostility

Chapter 2
tab2_01.*   Table 2.1         Normal Errors
tab2_02.*   Table 2.2         Skewed Errors
tab2_03.*   Table 2.3         Curvilinearity

Chapter 3
tab3_01.*   Table 3.1         Two Simple Models
tab3_05.*   Table 3.5         Cost and Sound Quality
tab3_07.*   Table 3.7         Exam marks and College Offers
tab3_11.*   Table 3.11        Quality of Children's Testimonies
Age: 5-6 = 0; 8-9 = 1
Gender: female = 0; male = 1
Location: 1 = home; 2 = school;
3 = police interview
4 = special interview
tab3_11d.*  Table 3.11        Data in Table 3.11 with indicator dummy codes
added

Chapter 4
tab4_01.*   Table 4.1         Infection Severity and Treatment Outcome
Treatment Outcome: 0 = survived
1 = died
tab4_14.*   Table 4.14        Infection severity, Treatment outcome and
Hospital Attended
Hospital: 1 = hospital A
2 = hospital B
3 = hospital C
tab4.14d.*  Table 4.14        Infection severity, Treatment outcome and
Hospital Attended including dummy codes

logis.*                       Child witness data: copy of
tab3_11, but includes prosecution
logis_d.*                     Child witness data: copy of
tab3_11d, but includes prosecution

logis.por and logis_d.por provide the data to
obtain the parameters calculated in the book
(pages 147 to 152). It should be noted that
these differ slightly to the parameters
obtained using the data sets logis.dat and
logis_d.dat, as the *.dat files only record
the variable 'coherence' to 2 decimal places.

Chapter 5

tab5_01.*    Table 5.1        Job Satisfaction for doctors and dentists
tab5_04.*    Table 5.4        Race, Housing and Illness
tab5_07.*    Table 5.7        Dopamine and psychosis: integer scoring
tab5_08.*    Table 5.8        Dopamine and psychosis: mid-ranks scoring
tab5_10.*    Table 5.10       Treatment and Depression: integer scoring
tab5_11.*    Table 5.11       Treatment and depression: mid-ranks scoring
tab5_13.*    Table 5.13       Alcohol consumption and Libido: integer scores
tab5_16.*    Table 5.16       Alcohol consumption and libido: low vs medium
or high
tab5_17.*    Table 5.17       Alcohol consumption and libido: medium vs high


Chapter 6

tab6_11.*    Table 6.11       Child witness example data set

File: ../data/hutsof99/logis.dat

Note: changes from Errata.txt where not included!


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
682,sleuth_ex2016,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/ex2016.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
683,sleuth_ex2015,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/ex2015.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
684,rabe_166,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.166

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
685,visualizing_livestock,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/livestock.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
686,rmftsa_ctoarrivals,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Sets for 'Regression Models for Time Series Analysis' by
B. Kedem and K. Fokianos, Wiley 2002. Submitted by Kostas
Fokianos (fokianos@ucy.ac.cy) [8/Nov/02] (176k)

Note: - attribute names were generated manually
- information about data taken from here:
http://lib.stat.cmu.edu/datasets/

File: ../data/rmftsa/ctoarrivals.txt

Montly number of tourist arrivals in Cyprus starting from
January 1979 and ending in December 2000.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
687,sleuth_ex1605,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/ex1605.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
688,visualizing_soil,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/soil.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
689,chscase_vine2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: vine2.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
690,visualizing_galaxy,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/galaxy.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
691,chscase_vine1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: vine1.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
692,rabe_131,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.131

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
693,diggle_table_a1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

DATA-SETS FROM DIGGLE, P.J. (1990). TIME SERIES : A BIOSTATISTICAL
INTRODUCTION. Oxford University Press.

Table: Table A1 Lutenizing hormone


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
694,diggle_table_a2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

DATA-SETS FROM DIGGLE, P.J. (1990). TIME SERIES : A BIOSTATISTICAL
INTRODUCTION. Oxford University Press.

Table: Table A2 Wool prices


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
695,chatfield_4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file is a text file giving details about the time series analysed
in 'The Analysis of Time Series' by Chris Chatfield.
The 5th edn was published in 1996 and the 6th edn in 2003.
The series are listed separately at the author's home web site at
www.bath.ac.uk/~mascc/  and via the CRC Press web site at
www.crcpress.com
An individual series can readily be abstracted from this file.


Figure 11.1 - the sunspots data is available in many places but is
repeated here for convenience.
Monthly sunspots numbers from 1749 to 1983.


Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
696,hutsof99_child_witness,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Graeme D. Hutcheson and Nick Sofroniou 1999

The Multivariate Social Scientist:
Introductory Statistics Using Generalized Linear Models.

SAGE Publications.

Copyright: Graeme D. Hutcheson & Nick Sofroniou, 1999

This software can be freely used for non-commercial purposes and can be
freely distributed.


Readme file
===========

The data sets in this directory are taken from the above book.
The data are presented in two formats, *.dat (ascii) and
*.por (SPSS portable). The GLIM code and macros are provided in
files *.glm and *.mac. Please read the errata file which indicates some
minor differences between these data sets and those reported in the
book.




DATA FILE      SOURCE IN BOOK    DESCRIPTION

Chapter 1
tab1_01.*   Table 1.1         Video Games and Hostility

Chapter 2
tab2_01.*   Table 2.1         Normal Errors
tab2_02.*   Table 2.2         Skewed Errors
tab2_03.*   Table 2.3         Curvilinearity

Chapter 3
tab3_01.*   Table 3.1         Two Simple Models
tab3_05.*   Table 3.5         Cost and Sound Quality
tab3_07.*   Table 3.7         Exam marks and College Offers
tab3_11.*   Table 3.11        Quality of Children's Testimonies
Age: 5-6 = 0; 8-9 = 1
Gender: female = 0; male = 1
Location: 1 = home; 2 = school;
3 = police interview
4 = special interview
tab3_11d.*  Table 3.11        Data in Table 3.11 with indicator dummy codes
added

Chapter 4
tab4_01.*   Table 4.1         Infection Severity and Treatment Outcome
Treatment Outcome: 0 = survived
1 = died
tab4_14.*   Table 4.14        Infection severity, Treatment outcome and
Hospital Attended
Hospital: 1 = hospital A
2 = hospital B
3 = hospital C
tab4.14d.*  Table 4.14        Infection severity, Treatment outcome and
Hospital Attended including dummy codes

logis.*                       Child witness data: copy of
tab3_11, but includes prosecution
logis_d.*                     Child witness data: copy of
tab3_11d, but includes prosecution

logis.por and logis_d.por provide the data to
obtain the parameters calculated in the book
(pages 147 to 152). It should be noted that
these differ slightly to the parameters
obtained using the data sets logis.dat and
logis_d.dat, as the *.dat files only record
the variable 'coherence' to 2 decimal places.

Chapter 5

tab5_01.*    Table 5.1        Job Satisfaction for doctors and dentists
tab5_04.*    Table 5.4        Race, Housing and Illness
tab5_07.*    Table 5.7        Dopamine and psychosis: integer scoring
tab5_08.*    Table 5.8        Dopamine and psychosis: mid-ranks scoring
tab5_10.*    Table 5.10       Treatment and Depression: integer scoring
tab5_11.*    Table 5.11       Treatment and depression: mid-ranks scoring
tab5_13.*    Table 5.13       Alcohol consumption and Libido: integer scores
tab5_16.*    Table 5.16       Alcohol consumption and libido: low vs medium
or high
tab5_17.*    Table 5.17       Alcohol consumption and libido: medium vs high


Chapter 6

tab6_11.*    Table 6.11       Child witness example data set

File: ../data/hutsof99/tab6_11.dat

Note: changes from Errata.txt where not included!


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
697,rabe_97,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.97

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
698,rabe_176,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.176

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
699,disclosure_z,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Used in ""A BAYESIAN APPROACH TO DATA DISCLOSURE: OPTIMAL
INTRUDER BEHAVIOR FOR CONTINUOUS DATA""
by Stephen E. Fienberg, Udi E. Makov, and Ashish P. Sanil

Background:
==========
In this paper we develop an approach to data disclosure in survey settings by
adopting a probabilistic definition of disclosure due to Dalenius. Our approach
is based on the principle that a data collection agency must consider
disclosure from the perspective of an intruder in order to efficiently evaluate
data disclosure limitation procedures. The probabilistic definition and our
attempt to study optimal intruder behavior lead naturally to a Bayesian
formulation.  We apply the methods in a small-scale simulation study using data
adapted from an actual survey conducted by the Institute for Social Research at
York University. (See Sections 1-3 of the paper for details oF the model
formulation and related issues.)

The Data:
========
Our case study uses data from the survey data Elite Canadian
Decision-Makers collected by the Institute for Social Research at York
University.  This survey was conducted in 1981 using telephone
interviews and there were 1348 respondents, but many of these did not
supply complete data.  We have extracted data on 12 variables, each of which
was measured on a 5-point scale:

Civil-liberties:
- ---------------
C1 - Free speech is just not worth it.
C2 - We have gone too far in pushing equal rights in this country.
C3 - It is better to live in an  orderly  society  than  to  allow people so
much freedom.
C5 - Free speech ought to be allowed for all political groups.

Attitudes towards Jews:
- ----------------------
A15 - Most Jews don't care what happens to people who are not Jews.
A18 - Jews are more willing than others to use shady practices  to
get ahead.

Canada-US relationship:
- ----------------------
CUS1 - Ensure independent Canada.
CUS5 - Canada should have free trade with the USA.
CUS6 - Canada's way of life is influenced strongly by USA.
CUS7 - Canada benefits from US investments.


In addition, we have data on two approximately continuous variables:

Personal information:
- --------------------
Income - Total family income before taxes (with top-coding at \$80,000).
Age - Based on year of birth.


We transformed the original survey data  as follows in order to create
a database of approximately continuous variables:

[A]  We add categorical  variables  (all  but  income) to increase the number
of levels. (When necessary we reversed the order of levels of a response  to a
question.)  The new variables are defined as follows:

Civil     = C1 + C2 + C3 + (8 - C5)
Attitude  = A15 + A18
Can/US    = (5 - CUS1) + CUS5 + (5 - CUS6) + CUS7

After we removed cases with missing observations and  two  cases involving
young children, we had a  data-base consisting of 662 observations.

[B]  In order to enhance continuity, we took the following measures:

Age:  We added normal  distributed  variates,  with  0   mean  and
variance 4 to all observations.
Income: We added uniform variates on the range of $0 - $10,000 to all incomes
below $80,000.  Since all cases of incomes exceeding $80,000 were
lumped together  in  the  survey,  we simulated their values by means
of a t(8) distribution. Drawing values from the upper 38% tail of t(8),
we evaluated the values of income as $60,000 + 25,000*t(8).
Other variables: We added  normal distributed variates, with 0 mean and
variance  0.5 to the variables.

We assume that the agency releases information about all
variables, except for Attitudes (towards Jews), which  is unavailable to
the intruder and is at the center of the intruder's investigation.

We denote the released data by

Z = (( z(i,j) ))   with i=1,..,662; j=1,2,3,4.

We assume that the intruder's data, X, are accurate and are related to Z via
the following transformation:
x(0,j) = z(i,j)*theta(i,j) + xi(j),

where theta(i,j) is a bias removing parameter normally distributed with mean 1
and variance  v(j), and xi(j) is normally distributed disturbance with 0  mean
and variance sigma2(j).

The following table provides the values of
v(j), sigma2(j) used in the study:

v(j)     sigma2(j)
Civil                      0.1732       25
Can/US                     0.1732       25
Age                        0.1732       9
Income (in $10000's)       0.1732       4


We first generated several realizations of the above transformation on small
subsets of the data to ascertain the impact of the process of the error
on the data. In Table 4-1 in the paper we present 10 records the the intruder's
accurate data, X, and the biased and corrupted released data, Z, which we
obtained from one realization of the transformation.

Section 4.2 of the paper contains details of the implementation of our Bayesian
model.

Data Used in the Computations:
=============================
We conducted a complete simulation of the procedures for the complete set of
662 cases.  We considered four different scenarios for the simulation. (The
names of datasets used in each of the scenarios appear in brackets below. The
datasets are appended to this text.)

* The released data contains no bias or noise (i.e. v(j)=0 and sigma2(j)=0 for
all j). [Z.DATA]
* The released data contains only noise (i.e., v(j)=0 for all j and
and $sigma2(j)$ as given in the above Table). [X_NOISE.DATA]
* The released data contains only bias (i.e., sigma2(j)=0 for all j and v(j)
as given in the above Table). [X_BIAS.DATA]
* The released data contains both bias and noise (i.e., v(j) and sigma2(j) as
given in the above Table). [X_TAMPERED.DATA]

We took each individual in turn as the object of the intruder's efforts and
carried out the calculations.

Structure of the Datasets:
- -------------------------
Each attached dataset consists of four space-separated columns containing the
data on Age, Civil, Can/US and Income ($) respectively.



Dataset: Z


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
700,chscase_whale,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: whale.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
702,sleuth_ex1221,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/ex1221.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
703,chscase_foot,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: foot.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
704,disclosure_x_noise,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Used in ""A BAYESIAN APPROACH TO DATA DISCLOSURE: OPTIMAL
INTRUDER BEHAVIOR FOR CONTINUOUS DATA""
by Stephen E. Fienberg, Udi E. Makov, and Ashish P. Sanil

Background:
==========
In this paper we develop an approach to data disclosure in survey settings by
adopting a probabilistic definition of disclosure due to Dalenius. Our approach
is based on the principle that a data collection agency must consider
disclosure from the perspective of an intruder in order to efficiently evaluate
data disclosure limitation procedures. The probabilistic definition and our
attempt to study optimal intruder behavior lead naturally to a Bayesian
formulation.  We apply the methods in a small-scale simulation study using data
adapted from an actual survey conducted by the Institute for Social Research at
York University. (See Sections 1-3 of the paper for details oF the model
formulation and related issues.)

The Data:
========
Our case study uses data from the survey data Elite Canadian
Decision-Makers collected by the Institute for Social Research at York
University.  This survey was conducted in 1981 using telephone
interviews and there were 1348 respondents, but many of these did not
supply complete data.  We have extracted data on 12 variables, each of which
was measured on a 5-point scale:

Civil-liberties:
- ---------------
C1 - Free speech is just not worth it.
C2 - We have gone too far in pushing equal rights in this country.
C3 - It is better to live in an  orderly  society  than  to  allow people so
much freedom.
C5 - Free speech ought to be allowed for all political groups.

Attitudes towards Jews:
- ----------------------
A15 - Most Jews don't care what happens to people who are not Jews.
A18 - Jews are more willing than others to use shady practices  to
get ahead.

Canada-US relationship:
- ----------------------
CUS1 - Ensure independent Canada.
CUS5 - Canada should have free trade with the USA.
CUS6 - Canada's way of life is influenced strongly by USA.
CUS7 - Canada benefits from US investments.


In addition, we have data on two approximately continuous variables:

Personal information:
- --------------------
Income - Total family income before taxes (with top-coding at \$80,000).
Age - Based on year of birth.


We transformed the original survey data  as follows in order to create
a database of approximately continuous variables:

[A]  We add categorical  variables  (all  but  income) to increase the number
of levels. (When necessary we reversed the order of levels of a response  to a
question.)  The new variables are defined as follows:

Civil     = C1 + C2 + C3 + (8 - C5)
Attitude  = A15 + A18
Can/US    = (5 - CUS1) + CUS5 + (5 - CUS6) + CUS7

After we removed cases with missing observations and  two  cases involving
young children, we had a  data-base consisting of 662 observations.

[B]  In order to enhance continuity, we took the following measures:

Age:  We added normal  distributed  variates,  with  0   mean  and
variance 4 to all observations.
Income: We added uniform variates on the range of $0 - $10,000 to all incomes
below $80,000.  Since all cases of incomes exceeding $80,000 were
lumped together  in  the  survey,  we simulated their values by means
of a t(8) distribution. Drawing values from the upper 38% tail of t(8),
we evaluated the values of income as $60,000 + 25,000*t(8).
Other variables: We added  normal distributed variates, with 0 mean and
variance  0.5 to the variables.

We assume that the agency releases information about all
variables, except for Attitudes (towards Jews), which  is unavailable to
the intruder and is at the center of the intruder's investigation.

We denote the released data by

Z = (( z(i,j) ))   with i=1,..,662; j=1,2,3,4.

We assume that the intruder's data, X, are accurate and are related to Z via
the following transformation:
x(0,j) = z(i,j)*theta(i,j) + xi(j),

where theta(i,j) is a bias removing parameter normally distributed with mean 1
and variance  v(j), and xi(j) is normally distributed disturbance with 0  mean
and variance sigma2(j).

The following table provides the values of
v(j), sigma2(j) used in the study:

v(j)     sigma2(j)
Civil                      0.1732       25
Can/US                     0.1732       25
Age                        0.1732       9
Income (in $10000's)       0.1732       4


We first generated several realizations of the above transformation on small
subsets of the data to ascertain the impact of the process of the error
on the data. In Table 4-1 in the paper we present 10 records the the intruder's
accurate data, X, and the biased and corrupted released data, Z, which we
obtained from one realization of the transformation.

Section 4.2 of the paper contains details of the implementation of our Bayesian
model.

Data Used in the Computations:
=============================
We conducted a complete simulation of the procedures for the complete set of
662 cases.  We considered four different scenarios for the simulation. (The
names of datasets used in each of the scenarios appear in brackets below. The
datasets are appended to this text.)

* The released data contains no bias or noise (i.e. v(j)=0 and sigma2(j)=0 for
all j). [Z.DATA]
* The released data contains only noise (i.e., v(j)=0 for all j and
and $sigma2(j)$ as given in the above Table). [X_NOISE.DATA]
* The released data contains only bias (i.e., sigma2(j)=0 for all j and v(j)
as given in the above Table). [X_BIAS.DATA]
* The released data contains both bias and noise (i.e., v(j) and sigma2(j) as
given in the above Table). [X_TAMPERED.DATA]

We took each individual in turn as the object of the intruder's efforts and
carried out the calculations.

Structure of the Datasets:
- -------------------------
Each attached dataset consists of four space-separated columns containing the
data on Age, Civil, Can/US and Income ($) respectively.



Dataset: X_NOISE


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
705,chscase_health,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: health.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
706,sleuth_case1202,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/case1202.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
707,sleuth_case1201,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Contains 110 data sets from the book 'The Statistical Sleuth'
by Fred Ramsey and Dan Schafer; Duxbury Press, 1997.
(schafer@stat.orst.edu) [14/Oct/97] (172k)

Note: description taken from this web site:
http://lib.stat.cmu.edu/datasets/

File: ../data/sleuth/case1201.asc


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
708,visualizing_hamster,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/hamster.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
709,disclosure_x_bias,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data Used in ""A BAYESIAN APPROACH TO DATA DISCLOSURE: OPTIMAL
INTRUDER BEHAVIOR FOR CONTINUOUS DATA""
by Stephen E. Fienberg, Udi E. Makov, and Ashish P. Sanil

Background:
==========
In this paper we develop an approach to data disclosure in survey settings by
adopting a probabilistic definition of disclosure due to Dalenius. Our approach
is based on the principle that a data collection agency must consider
disclosure from the perspective of an intruder in order to efficiently evaluate
data disclosure limitation procedures. The probabilistic definition and our
attempt to study optimal intruder behavior lead naturally to a Bayesian
formulation.  We apply the methods in a small-scale simulation study using data
adapted from an actual survey conducted by the Institute for Social Research at
York University. (See Sections 1-3 of the paper for details oF the model
formulation and related issues.)

The Data:
========
Our case study uses data from the survey data Elite Canadian
Decision-Makers collected by the Institute for Social Research at York
University.  This survey was conducted in 1981 using telephone
interviews and there were 1348 respondents, but many of these did not
supply complete data.  We have extracted data on 12 variables, each of which
was measured on a 5-point scale:

Civil-liberties:
- ---------------
C1 - Free speech is just not worth it.
C2 - We have gone too far in pushing equal rights in this country.
C3 - It is better to live in an  orderly  society  than  to  allow people so
much freedom.
C5 - Free speech ought to be allowed for all political groups.

Attitudes towards Jews:
- ----------------------
A15 - Most Jews don't care what happens to people who are not Jews.
A18 - Jews are more willing than others to use shady practices  to
get ahead.

Canada-US relationship:
- ----------------------
CUS1 - Ensure independent Canada.
CUS5 - Canada should have free trade with the USA.
CUS6 - Canada's way of life is influenced strongly by USA.
CUS7 - Canada benefits from US investments.


In addition, we have data on two approximately continuous variables:

Personal information:
- --------------------
Income - Total family income before taxes (with top-coding at \$80,000).
Age - Based on year of birth.


We transformed the original survey data  as follows in order to create
a database of approximately continuous variables:

[A]  We add categorical  variables  (all  but  income) to increase the number
of levels. (When necessary we reversed the order of levels of a response  to a
question.)  The new variables are defined as follows:

Civil     = C1 + C2 + C3 + (8 - C5)
Attitude  = A15 + A18
Can/US    = (5 - CUS1) + CUS5 + (5 - CUS6) + CUS7

After we removed cases with missing observations and  two  cases involving
young children, we had a  data-base consisting of 662 observations.

[B]  In order to enhance continuity, we took the following measures:

Age:  We added normal  distributed  variates,  with  0   mean  and
variance 4 to all observations.
Income: We added uniform variates on the range of $0 - $10,000 to all incomes
below $80,000.  Since all cases of incomes exceeding $80,000 were
lumped together  in  the  survey,  we simulated their values by means
of a t(8) distribution. Drawing values from the upper 38% tail of t(8),
we evaluated the values of income as $60,000 + 25,000*t(8).
Other variables: We added  normal distributed variates, with 0 mean and
variance  0.5 to the variables.

We assume that the agency releases information about all
variables, except for Attitudes (towards Jews), which  is unavailable to
the intruder and is at the center of the intruder's investigation.

We denote the released data by

Z = (( z(i,j) ))   with i=1,..,662; j=1,2,3,4.

We assume that the intruder's data, X, are accurate and are related to Z via
the following transformation:
x(0,j) = z(i,j)*theta(i,j) + xi(j),

where theta(i,j) is a bias removing parameter normally distributed with mean 1
and variance  v(j), and xi(j) is normally distributed disturbance with 0  mean
and variance sigma2(j).

The following table provides the values of
v(j), sigma2(j) used in the study:

v(j)     sigma2(j)
Civil                      0.1732       25
Can/US                     0.1732       25
Age                        0.1732       9
Income (in $10000's)       0.1732       4


We first generated several realizations of the above transformation on small
subsets of the data to ascertain the impact of the process of the error
on the data. In Table 4-1 in the paper we present 10 records the the intruder's
accurate data, X, and the biased and corrupted released data, Z, which we
obtained from one realization of the transformation.

Section 4.2 of the paper contains details of the implementation of our Bayesian
model.

Data Used in the Computations:
=============================
We conducted a complete simulation of the procedures for the complete set of
662 cases.  We considered four different scenarios for the simulation. (The
names of datasets used in each of the scenarios appear in brackets below. The
datasets are appended to this text.)

* The released data contains no bias or noise (i.e. v(j)=0 and sigma2(j)=0 for
all j). [Z.DATA]
* The released data contains only noise (i.e., v(j)=0 for all j and
and $sigma2(j)$ as given in the above Table). [X_NOISE.DATA]
* The released data contains only bias (i.e., sigma2(j)=0 for all j and v(j)
as given in the above Table). [X_BIAS.DATA]
* The released data contains both bias and noise (i.e., v(j) and sigma2(j) as
given in the above Table). [X_TAMPERED.DATA]

We took each individual in turn as the object of the intruder's efforts and
carried out the calculations.

Structure of the Datasets:
- -------------------------
Each attached dataset consists of four space-separated columns containing the
data on Age, Civil, Can/US and Income ($) respectively.



Dataset: X_BIAS


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
710,rabe_148,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This file contains data from Regression Analysis By Example, 2nd Edition,
by Samprit Chatterjee and Bertram Price, John Wiley, 1991.
Data sets have names of the form 'rabe.xxx' where xxx is the page number
in the book where the data occurs.

For additional information, Samprit Chatterjee can be reached using
""schatter@stern.nyu.edu"".

File: ../data/rabe/rabe.148

Note: there were no information about the columns in the data set,
hence automatically generated names


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
711,visualizing_ethanol,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This S dump contains 22 data sets from the
book Visualizing Data published by
Hobart Press (books@hobart.com).
The dump was created by data.dump()
and can be read back into S by data.restore().
The name of each S data set is the name of
the data set used in the book. To find the
description of the data set in the book look
under the entry - data, name - in the index.
For example, one data set is barley.
To find the description of barley, look
in the index under the entry - data, barley.

File: ../data/visualizing/ethanol.csv


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
712,chscase_geyser1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

File README
-----------

chscase  A collection of the data sets used in the book
""A Casebook for a First Course in Statistics and Data Analysis,""
by Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,
John Wiley and Sons, New York, 1995. Submitted by
Samprit Chatterjee (schatterjee@stern.nyu.edu),
Mark Handcock (mhandcock@stern.nyu.edu) and
Jeff Simonoff (jsimonoff@stern.nyu.edu)

This submission consists of 38 files, plus this README file.
Each file represents a data set analyzed in the book. The names
of the files correspond to the names used in the book. The data
files are written in plain ASCII (character) text. Missing
values are represented by ""M"" in all data files.

More information about the data sets and the book can be
obtained via gopher at the address
swis.stern.nyu.edu

The information is filed under
---> Academic Departments & Research Centers
---> Statistics and Operations Research
---> Publications
---> A Casebook for a First Course in Statistics and Data Analysis
---> Welcome!

It can also be accessed from the World Wide Web (WWW) using a
WWW browser (e.g., netscape) starting from the URL address
http://www.stern.nyu.edu/SOR/Casebook



NOTICE: These datasets may be used freely for scientific,
educational and/or non-commercial purposes, provided suitable
acknowledgment is given (by citing the Chatterjee, Handcock and
Simonoff reference above).

File: geyser1.dat

Note: attribute names were generated automatically since there was no
information in the data itself.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: none specific"
713,vineyard,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
714,fruitfly,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
715,fri_c3_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
716,fri_c3_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
717,rmftsa_ladata,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
718,fri_c4_1000_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
719,veteran,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
720,abalone,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
721,pwLinear,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
722,pol,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
723,fri_c4_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
724,analcatdata_vineyard,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
725,bank8FM,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
726,fri_c2_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
727,2dplanes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
728,analcatdata_supreme,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
729,visualizing_slope,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
730,fri_c1_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
731,baskball,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
732,fri_c0_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
733,machine_cpu,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
734,ailerons,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
735,cpu_small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
736,visualizing_environmental,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
737,space_ga,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
738,pharynx,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
739,sleep,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
740,fri_c3_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
741,rmftsa_sleepdata,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
742,fri_c4_500_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
743,fri_c1_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
744,fri_c3_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
745,auto_price,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
746,fri_c1_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
747,servo,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
748,analcatdata_wildcat,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
749,fri_c3_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
750,pm10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
751,fri_c4_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
752,puma32H,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
753,wisconsin,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
754,fri_c0_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
755,sleuth_ex1605,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
756,autoPrice,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
757,meta,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
758,analcatdata_election2000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
759,analcatdata_olympic2000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
760,analcatdata_uktrainacc,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
761,cpu_act,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
762,fri_c2_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
763,fri_c0_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
764,analcatdata_apnea3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
765,analcatdata_apnea2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
766,fri_c1_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
767,analcatdata_apnea1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
768,fri_c3_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
769,fri_c1_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
770,strikes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
771,analcatdata_michiganacc,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
772,quake,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
773,fri_c0_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
774,disclosure_x_bias,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
775,fri_c2_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
776,fri_c0_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
777,sleuth_ex1714,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
778,bodyfat,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
779,fri_c1_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
780,rabe_265,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
782,rabe_266,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
783,fri_c3_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
784,newton_hema,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
785,wind_correlations,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
786,cleveland,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
787,witmer_census_1980,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
788,triazines,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
789,fri_c1_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
790,elusage,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
791,diabetes_numeric,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
792,fri_c2_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
793,fri_c3_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
794,fri_c2_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
795,disclosure_x_tampered,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
796,cpu,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
797,fri_c4_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
798,cholesterol,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
799,fri_c0_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
800,pyrim,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
801,chscase_funds,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
802,pbcseq,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
803,delta_ailerons,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
804,hutsof99_logis,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
805,fri_c4_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
806,fri_c3_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
807,kin8nm,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
808,fri_c0_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
810,pbc,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
811,rmftsa_ctoarrivals,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
812,fri_c1_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
813,fri_c3_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
814,chscase_vine2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
815,chscase_vine1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
816,puma8NH,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
817,diggle_table_a1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
818,diggle_table_a2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
819,delta_elevators,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
820,chatfield_4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
821,house_16H,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
823,houses,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
824,fri_c1_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
825,boston_corrected,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
826,sensory,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
827,disclosure_x_noise,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
828,fri_c4_100_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
829,fri_c1_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
830,fri_c2_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
831,autoMpg,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
832,fri_c3_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
833,bank32nh,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
834,fri_c4_250_100,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
835,analcatdata_vehicle,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
836,sleuth_case1102,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
837,fri_c1_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
838,fri_c4_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
839,kdd_el_nino-small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
840,autoHorse,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
841,stock,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
842,analcatdata_runshoes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
843,house_8L,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
844,breastTumor,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
845,fri_c0_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
846,elevators,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
847,wind,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
848,schlvote,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
849,fri_c0_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
850,fri_c0_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
851,tecator,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
852,analcatdata_gsssexsurvey,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
853,boston,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
854,fishcatch,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
855,fri_c4_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
857,bolts,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

SUMMARY:

Data from an experiment on the affects of machine adjustments on
the time to count bolts.  Data appear as the STATS (Issue 10) Challenge.

DATA:

Submitted by W. Robert Stephenson, Iowa State University
email: wrstephe@iastate.edu

A manufacturer of automotive accessories provides hardware, e.g. nuts,
bolts, washers and screws, to fasten the accessory to the car or truck.
Hardware is counted and packaged automatically.  Specifically, bolts
are dumped into a large metal dish.  A plate that forms the bottom of
the dish rotates counterclockwise.  This rotation forces bolts to the
outside of the dish and up along a narrow ledge.  Due to the vibration
of the dish caused by the spinning bottom plate, some bolts fall off
the ledge and back into the dish.  The ledge spirals up to a point
where the bolts are allowed to drop into a pan on a conveyor belt.
As a bolt drops, it passes by an electronic eye that counts it.  When
the electronic counter reaches the preset number of bolts, the
rotation is stopped and the conveyor belt is moved forward.

There are several adjustments on the machine that affect its operation.
These include; a speed setting that controls the speed of rotation
(SPEED1) of the plate at the bottom of the dish, a total number of
bolts (TOTAL) to be counted, a second speed setting (SPEED2) that is
used to change the speed of rotation (usually slowing it down) for the
last few bolts, the number of bolts to be counted at this second speed
(NUMBER2), and the sensitivity of the electronic eye (SENS).  The
sensitivity setting is to insure that the correct number of bolts are
counted.  Too few bolts packaged causes customer complaints.  Too many
bolts packaged increases costs.  For each run conducted in this
experiment the correct number of bolts was counted.  From an
engineering standpoint if the correct number of bolts is counted, the
sensitivity should not affect the time to count bolts.  The measured
response is the time (TIME), in seconds, it takes to count the desired
number of bolts.  In order to put times on a equal footing the
response to be analyzed is the time to count 20 bolts (T20BOLT).
Below are the data for 40 combinations of settings.  RUN is the order
in which the data were collected.

Analyze the data.  What adjustments have the greatest effect on the
time to count 20 bolts?  How would you adjust the machine to get
the shortest time to count 20 bolts?  Are there any unusual features
to the data?

Data

RUN   SPEED1   TOTAL   SPEED2   NUMBER2   SENS   TIME   T20BOLT


The data description and data may be freely used for non-commercial
purposes and can be freely distributed.  Copyright remains with the
author and STATS Magazine.


Information about the dataset
CLASSTYPE: numeric
CLASSINDEX: last"
858,hungarian,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
859,analcatdata_gviolence,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
860,vinnie,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
861,auto93,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
862,sleuth_ex2016,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
863,fri_c4_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
864,sleuth_ex2015,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
865,analcatdata_neavote,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
866,fri_c2_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
867,visualizing_livestock,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
868,fri_c4_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
869,fri_c2_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
870,fri_c1_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
871,pollen,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
873,fri_c3_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
874,rabe_131,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
875,analcatdata_chlamydia,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
876,fri_c1_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
877,fri_c2_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
878,fri_c4_100_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
879,fri_c2_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
880,mu284,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
881,mv,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
882,pollution,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
884,fri_c0_500_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
885,transplant,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
886,no2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
887,mbagrade,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
888,fri_c0_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
889,fri_c0_100_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
890,cloud,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
891,sleuth_case1202,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
892,sleuth_case1201,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
893,visualizing_hamster,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
894,rabe_148,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
895,chscase_geyser1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
896,fri_c3_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
897,colleges_aaup,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
898,hip,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
899,analcatdata_negotiation,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
900,chscase_census6,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
901,fried,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
902,sleuth_case2002,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
903,fri_c2_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
904,fri_c0_1000_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
905,chscase_adopt,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
906,chscase_census5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
907,chscase_census4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
908,chscase_census3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
909,chscase_census2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
910,fri_c1_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
911,fri_c2_250_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
912,fri_c2_1000_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
913,fri_c2_1000_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
914,balloon,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
915,plasma_retinol,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
916,fri_c3_100_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
917,fri_c1_1000_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
918,fri_c4_250_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
919,rabe_166,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
920,fri_c2_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
921,analcatdata_seropositive,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
922,fri_c2_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
923,visualizing_soil,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
924,humandevel,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
925,visualizing_galaxy,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
926,fri_c0_500_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
927,hutsof99_child_witness,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
928,rabe_97,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
929,rabe_176,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
930,colleges_usnews,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
931,disclosure_z,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
932,fri_c4_100_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
933,fri_c4_250_25,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
934,socmob,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
935,fri_c1_250_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
936,fri_c3_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
937,fri_c3_500_50,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
938,sleuth_ex1221,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
939,chscase_whale,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
940,water-treatment,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
941,lowbwt,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
942,chscase_health,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
943,fri_c0_500_10,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
944,echoMonths,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
945,kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
946,visualizing_ethanol,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N')."
947,arsenic-male-bladder,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
949,arsenic-female-bladder,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
950,arsenic-female-lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
951,arsenic-male-lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
952,prnn_fglass,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets for `Pattern Recognition and Neural Networks' by B.D. Ripley
=====================================================================

Cambridge University Press (1996)  ISBN  0-521-46086-7

The background to the datasets is described in section 1.4; this file
relates the computer-readable files to that description.



Cushing's syndrome
------------------

Data from Aitchison & Dunsmore (1975, Tables 11.1-3).

Data file Cushings.dat has four columns,

Label of the patient
Tetrhydrocortisone  (mg/24hr)
Pregnanetriol  (mg/24hr)
Type

The type of the last six patients (u1 to u6) should be
regarded as unknown.  (The code `o' indicates `other').



synthetic two-class problem
---------------------------

Data from Ripley (1994a).

This has two real-valued co-ordinates (xs and ys) and a class (xc)
which is 0 or 1.

Data file  synth.tr   has 250 rows of the training set
synth.te   has 1000 rows of the test set  (not used here)



viruses
-------

This is a dataset on 61 viruses with rod-shaped particles affecting
various crops (tobacco, tomato, cucumber and others) described by
{Fauquet et al. (1988) and analysed by Eslava-G\'omez (1989).  There
are 18 measurements on each virus,  the number of amino acid residues
per molecule of coat protein.

Data file  viruses.dat  has 61 rows of 18 counts
virus3.dat   has 38 rows corresponding to the distinct
Tobamoviruses.

The whole dataset is in order Hordeviruses (3), Tobraviruses (6),
Tobamoviruses (39) and `furoviruses' (13).



Leptograpsus crabs
------------------

Data from Campbell & Mahon (1974) on the morphology of rock crabs of
genus Leptograpsus.

There are 50 specimens of each sex of each of two colour forms.

Data file  crabs.dat has rows

sp	`species', coded B (blue form) or O (orange form)
sex	coded M or F
index	within each group of 50
FL	frontal lip of carapace (mm)
RW	rear width of carapace (mm)
CL	length along the midline of carapace (mm)
CW	maximum width of carapace (mm)
BD	body depth (mm)



Forensic glass
--------------

This example comes from forensic testing of glass collected by
B. German on 214 fragments of glass.  It is also contained in the
UCI machine-learning database collection (Murphy & Aha, 1995).

Data file fglass.dat has 214 rows with data for a single glass
fragment.

RI	refractive index
Na	% weight of sodium oxide(s)
Mg	% weight of magnesium oxide(s)
Al	% weight of aluminium oxide(s)
Si	% weight of silicon oxide(s)
K	% weight of potassium oxide(s)
Ca	% weight of calcium oxide(s)
Ba	% weight of barium oxide(s)
Fe	% weight of iron oxide(s)
type	coded 1 to 7

The type codes are:

1 (WinF) window float glass
2 (WinNF) window non-float glass
3 (Veh) vehicle glass
5 (Con)  containers
6 (Tabl) tableware
7 (Head) vehicle headlamp glass

The ten groups used for the cross-validation experiments (I believe)
are listed as row numbers in the file fglass.grp,



Diabetes in Pima Indians
------------------------

A population of women who were at least 21 years old, of Pima Indian heritage
and living near Phoenix, Arizona,  was tested for diabetes
according to World Health Organization criteria.  The data
were collected by the US National Institute of Diabetes and Digestive and
Kidney Diseases (Smith et al, 1988). This example is also contained in the
UCI machine-learning database collection (Murphy & Aha, 1995).

The data files have rows containing

npreg 	number of pregnancies
glu 	plasma glucose concentration in an oral glucose tolerance test
bp 	diastolic blood pressure (mm Hg)
skin 	triceps skin fold thickness (mm)
ins	serum insulin (micro U/ml)
bmi 	body mass index (weight in kg/(height in m)^2)
ped 	diabetes pedigree function
age 	in years
type	No / Yes

Data file pima.tr   has 200 rows of complete training data.
pima.te   has 332 rows of complete test data.
pima.tr2  has the 200 rows of pima.tr plus 100 incomplete rows.



Information about the dataset
CLASSTYPE: nominal
CLASSINDEX: last"
953,splice,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
954,spectrometer,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
955,tae,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
956,molecular-biology_promoters,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
957,braziltourism,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
958,segment,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
959,nursery,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
960,postoperative-patient-data,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
961,analcatdata_broadwaymult,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
962,mfeat-morphological,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
963,heart-h,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
964,pasture,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
965,zoo,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
966,analcatdata_halloffame,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
967,cars,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
968,analcatdata_birthday,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
969,iris,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
970,analcatdata_authorship,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
971,mfeat-fourier,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
972,squash-stored,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
973,wine,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
974,hayes-roth,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
975,autos,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
976,JapaneseVowels,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
977,letter,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
978,mfeat-factors,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
979,waveform-5000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
980,optdigits,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
981,kdd_internet_usage,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
982,heart-c,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
983,cmc,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
984,analcatdata_draft,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
985,squash-unstored,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
986,analcatdata_marketing,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
987,collins,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
988,fl2000,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
989,anneal,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
990,eucalyptus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
991,car,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
992,analcatdata_broadway,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
993,kdd_ipums_la_97-small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
994,vehicle,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
995,mfeat-zernike,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
996,prnn_fglass,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
997,balance-scale,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
998,analcatdata_bondrate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
999,audiology,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1000,hypothyroid,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1001,sponge,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1002,ipums_la_98-small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1003,primary-tumor,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1004,synthetic_control,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1005,glass,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1006,lymph,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1007,bridges,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1008,analcatdata_reviewer,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1009,white-clover,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1010,dermatology,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1011,ecoli,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1012,flags,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1013,analcatdata_challenger,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1014,analcatdata_dmft,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1015,confidence,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1016,vowel,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1017,arrhythmia,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1018,ipums_la_99-small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1019,pendigits,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1020,mfeat-karhunen,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1021,page-blocks,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1022,mfeat-pixel,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1023,soybean,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1024,cjs,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1025,analcatdata_germangss,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1026,grub-damage,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Binarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun."
1027,ESL,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: Employee Selection (Ordinal ESL)

2. Source Informaion:
Donor: Arie Ben David
MIS, Dept. of Technology Management
Holon Academic Inst. of Technology
52 Golomb St.
Holon 58102
Israel
abendav@hait.ac.il
Owner: Yoav Ganzah
Business Administration School
Tel Aviv Univerity
Ramat Aviv 69978
Israel

3. Past Usage:

4. Relevant Information
The ESL data set contains 488 profiles of applicants for certain industrial
jobs.  Expert psychologists of a recruiting company, based upon psychometric
test results and interviews with the candidates, determined the values of the
input attributes. The output is the an overall score corresponding to the
degree of fitness of the candidate to this type of job.


5. Number of Instances: 488

6. Number of Attributes: 4 input, 1 output.

7. Attribute Information: All input and output values are ORDINAL.

8. Missing Attribute Values: None.

9. Class Distribution:"
1028,SWD,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: Social Workers Decisions (Ordinal SWD)

2. Source Informaion:
Donor: Arie Ben David
MIS, Dept. of Technology Management
Holon Academic Inst. of Technology
52 Golomb St.
Holon 58102
Israel
abendav@hait.ac.il
Owner: Yoav Ganzah
Business Administration School
Tel Aviv Univerity
Ramat Aviv 69978
Israel

3. Past Usage:

4. Relevant Information
The SWD data set contains real-world assessments of qualified social workers
regarding the risk facing children if they stayed with their families at
home.  This evaluation of risk assessment is often presented to judicial
courts to help decide what is in the best interest of an alleged abused or
neglected child.


5. Number of Instances: 1000

6. Number of Attributes: 10 input, 1 output.

7. Attribute Information: All input and output values are ORDINAL.

8. Missing Attribute Values: None.

9. Class Distribution:"
1029,LEV,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: Lecturers Evaluation (Ordinal LEV)

2. Source Informaion:
   Donor: Arie Ben David
          MIS, Dept. of Technology Management 
          Holon Academic Inst. of Technology
          52 Golomb St.
          Holon 58102
          Israel
          abendav@hait.ac.il
   Owner: Yoav Ganzah
          Business Administration School
          Tel Aviv Univerity
          Ramat Aviv 69978
          Israel

3. Past Usage:

4. Relevant Information 
The LEV data set contains examples of anonymous lecturer evaluations, 
taken at the end of MBA courses. Before receiving the final grades, students
were asked to score their lecturers according to four attributes such as 
oral skills and contribution to their professional/general knowledge. 
The single output was a total evaluation of the lecturer’s performance."
1030,ERA,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: Employee Rejection\Acceptance  (Orinal ERA)

2. Source Informaion:
Donor: Arie Ben David
MIS, Dept. of Technology Management
Holon Academic Inst. of Technology
52 Golomb St.
Holon 58102
Israel
abendav@hait.ac.il
Owner: Yoav Ganzah
Business Administration School
Tel Aviv Univerity
Ramat Aviv 69978
Israel

3. Past Usage:

4. Relevant Information
The ERA data set was originally gathered during an academic decision-making
experiment aiming at determining which are the most important qualities of
candidates for a certain type of jobs. Unlike the ESL data set (enclosed)
which was collected from expert recruiters, this data set was collected
during a MBA academic course.
The input in the data set are features of a candidates such as past
experience, verbal skills, etc., and the output is the subjective judgment of
a decision-maker to which degree he or she tends to accept the applicant to
the job or to reject him altogether (the lowest score means total tendency to
reject an applicant and vice versa).

5. Number of Instances: 1000

6. Number of Attributes: 4 input, 1 output.

7. Attribute Information: All input and output values are ORDINAL.

8. Missing Attribute Values: None.

9. Class Distribution:"
1035,ESL,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

1. Title: Employee Selection (Ordinal ESL)

2. Source Informaion:
Donor: Arie Ben David
MIS, Dept. of Technology Management
Holon Academic Inst. of Technology
52 Golomb St.
Holon 58102
Israel
abendav@hait.ac.il
Owner: Yoav Ganzah
Business Administration School
Tel Aviv Univerity
Ramat Aviv 69978
Israel

3. Past Usage:

4. Relevant Information
The ESL data set contains 488 profiles of applicants for certain industrial
jobs.  Expert psychologists of a recruiting company, based upon psychometric
test results and interviews with the candidates, determined the values of the
input attributes. The output is the an overall score corresponding to the
degree of fitness of the candidate to this type of job.


5. Number of Instances: 488

6. Number of Attributes: 4 input, 1 output.

7. Attribute Information: All input and output values are ORDINAL.

8. Missing Attribute Values: None.

9. Class Distribution:"
1037,ada_prior,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)

Dataset from: http://www.agnostic.inf.ethz.ch/datasets.php

Modified by TunedIT (converted to ARFF format)


ADA is the marketing database

The task of ADA is to discover high revenue people from census data. This is a two-class classification problem. The raw data from the census bureau is known as the Adult database in the UCI machine-learning repository. The 14 original attributes (features) include age, workclass,  education, education,
marital status, occupation, native country, etc. It contains continuous, binary and categorical features. This dataset is from ""prior knowledge track"", i.e. has access to the original features and their identity.


Number of examples:
Pos_ex Neg_ex Tot_ex
Train  1029  3118  4147
Valid   103   312   415

This dataset contains samples from both training and validation datasets.

### Attribute information  
1. age Instance’s age (numeric)
2. workclass Instance’s work class (nominal)
3. fnlwgt Instance’s sampling weight (numeric)
4. education Instance’s education level (nominal)
5. educationNum Instance’s education level (numeric version)
6. maritalStatus Instance’s marital status (nominal)
7. occupation Instance’s occupation (nominal)
8. relationship Instance’s type of relationship (nominal)
9. race Instance’s race (nominal)
10. sex Instance’s sex (nominal)
11. capitalGain Instance’s capital gain (numeric)
12. capitalLoss Instance’s capital loss (numeric)
13. hoursPerWeek Instance’s number of working hours (numeric)
14. nativeCountry Instance’s native country (numeric)
15. label Class attribute (1: the instance earns more than 50K a year; -1 otherwise)"
1038,gina_agnostic,"**Author**: [Isabelle Guyon](isabelle@clopinet.com)  
**Source**: [Agnostic Learning vs. Prior Knowledge Challenge](http://www.agnostic.inf.ethz.ch)  
**Please cite**: None


Dataset from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch), which consisted of 5 different datasets (SYLVA, GINA, NOVA, HIVA, ADA). The purpose of the challenge was to check if the performance of domain-specific feature engineering (prior knowledge) can be met by algorithms that were trained on data without any domain-specific knowledge (agnostic). For the latter, the data was anonymised and preprocessed in a way that makes them uninterpretable. 

Modified by TunedIT (converted to ARFF format)



### Topic

The task of GINA is handwritten digit recognition. This is the agnostic version of a subset of the MNIST data set. We chose the problem of separating the odd numbers from even numbers. We use 2-digit numbers. Only the unit digit is informative for that task, therefore at least ½ of the features are distracters. This is a twoclass classification problem with sparse continuous input variables, in which each class is
composed of several clusters. It is a problems with heterogeneous classes.


### Source

The data set was constructed from the MNIST data that is made available by Yann
LeCun of the NEC Research Institute at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/). The digits have been size-normalized and centered in a fixed-size image of dimension 28x28. Examples are shown in the [documentation in chapter 3](http://clopinet.com/isabelle/Projects/agnostic/Dataset.pdf).


### Description 

To construct the “agnostic” dataset, we performed the following steps:
- We removed the pixels that were 99% of the time white. This reduced the original
feature set of 784 pixels to 485.
- The original resolution (256 gray levels) was kept.
- In spite of the fact that the data are rather sparse (about 30% of the values are
non-zero), we saved the data as a dense matrix because we found that it can be
compressed better in this way (to 19 MB.)
- The feature names are the (i,j) matrix coordinates of the pixels (in a 28x28
matrix.)
- We created 2 digit numbers by dividing the datasets into to parts and pairing the
digits at random.
- The task is to separate odd from even numbers. The digit of the tens being not
informative, the features of that digit act as distracters.
To construct the “prior” dataset, we went back to the original data and fetched the
“informative” digit in its original representation. Therefore, this data representation
consists in a vector of concatenating the lines of a 28x28 pixel map.

Data type: non-sparse  
Number of features: 970  
Number of examples and check-sums:  
Pos_ex Neg_ex Tot_ex Check_sum  
Train  1550  1603  3153 164947945.00  
Valid   155   160   315 16688946.00  


This dataset contains samples from both training and validation datasets."
1039,hiva_agnostic,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)

Dataset from: http://www.agnostic.inf.ethz.ch/datasets.php

Modified by TunedIT (converted to ARFF format)


HIVA is the HIV infection database


The task of HIVA is to predict which compounds are active against the AIDS HIV infection. The original data has 3 classes (active, moderately active, and inactive). We brought it back to a two-class classification problem (active vs. inactive). We represented the data as 2000 sparse binary input variables. The variables represent properties of the molecule inferred from its structure. The problem is therefore to relate structure to activity (a QSAR=quantitative structure-activity relationship problem) to screen new compounds before actually testing them (a HTS=high-throughput screening problem.)

Data type: non-sparse
Number of features: 1617
Number of examples and check-sum:
Pos_ex	Neg_ex	Tot_ex	Check_sum
Train	  135	 3710	 3845	564954.00
Valid	   14	  370	  384	56056.00


This dataset contains samples from both training and validation datasets."
1040,sylva_prior,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)

**Note: Derived from the covertype dataset**

Dataset from: http://www.agnostic.inf.ethz.ch/datasets.php

Modified by TunedIT (converted to ARFF format)


SYLVA is the ecology database


The task of SYLVA is to classify forest cover types. The forest cover type for 30 x 30 meter cells is obtained from US Forest Service (USFS) Region 2 Resource Information System &#40;RIS&#41; data. We brought it back to a two-class classification problem (classifying Ponderosa pine vs. everything else). The ""agnostic learning track"" data consists in 216 input variables. Each pattern is composed of 4 records: 2 true records matching the target and 2 records picked at random. Thus 1/2 of the features are distracters. The ""prior knowledge track"" data is identical to the ""agnostic learning track"" data, except that the distracters are removed and the identity of the features is revealed. For that track, the forest cover original ids are revealed for training data.

Data type: non-sparse
Number of features: 108
Number of examples and check-sums:
Pos_ex Neg_ex Tot_ex Check_sum
Train   805 12281 13086 118996108.00
Valid    81  1228  1309 11904801.00"
1041,gina_prior2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

**Note: Identical to the MNIST dataset?**

Datasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)

Dataset from: http://www.agnostic.inf.ethz.ch/datasets.php

Modified by TunedIT (converted to ARFF format)


GINA is digit recognition database

The task of GINA is handwritten digit recognition.

Data type: non-sparse
Number of features: 784
Number of examples and check-sum:
Tot_ex Check_sum
3468 90979365.00"
1042,gina_prior,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

**Note: derived from MNIST?**

Datasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)

Dataset from: http://www.agnostic.inf.ethz.ch/datasets.php

Modified by TunedIT (converted to ARFF format)


GINA is digit recognition database

The task of GINA is handwritten digit recognition. For the ""prior knowledge track"" we chose the problem of separating one-digit odd numbers from one-digit even numbers. The original pixel map representation is provided. This is a two class classification problem with sparse continuous input variables, in which each class is composed of several clusters. It is a problem with heterogeneous classes.

Data type: non-sparse
Number of features: 784
Number of examples and check-sum:
Pos_ex Neg_ex Tot_ex Check_sum
Train  1550  1603  3153 82735983.00
Valid   155   160   315 8243382.00

This dataset contains samples from both training and validation datasets."
1044,eye_movements,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/

Competition 1 (preprocessed data)
A straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.

The dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.


* Features are in columns, feature vectors in rows.
* Each assignment is a time sequence of 22-dimensional feature vectors.
* The first column is the line number, second the assignment number and the next 22 columns (3 to 24) are the different features. Columns 25 to 27 contain extra information about the example. The training data set contains the classification label in the 28th column: ""0"" for irrelevant, ""1"" for relevant and ""2"" for the correct answer.
* Each example (row) represents a single word. You are asked to return the classification of each read sentence.
* The 22 features provided are commonly used in psychological studies on eye movement. All of them are not necessarily relevant in this context.

The objective of the Challenge is to predict the classification labels (I, R, C).



Please see the technical report for information of eye movements, experimental setup, baseline methods and references:

Jarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. [PDF]



Modified by TunedIT (converted to ARFF format)


FEATURES

The values in columns marked with an asterisk (*) are same for all occurances of the word.

COL	NAME		DESCRIPTION
1	#line		Line number
2	#assg		Assignment Number
3	fixcount	Number of fixations to the word
4*	firstPassCnt	Number of fixations to the word when it is first encountered
5*	P1stFixation	'1' if fixation occured when the sentence the word was in was encountered the first time
6*	P2stFixation	'1' if fixation occured when the sentence the word was in was encountered the second time
7*	prevFixDur	Duration of previous fixation
8*	firstfixDur	Duration of the first fixation when the word is first encountered
9*	firstPassFixDur	Sum of durations of fixations when the word is first encountered
10*	nextFixDur	Duration of the next fixation when gaze initially moves from the word
11	firstSaccLen	Length of the first saccade
12	lastSaccLen	Distance between fixation on the word and the next fixation
13	prevFixPos	Distance between the first fixation preceding the word and the beginning ot the word
14	landingPos	Distance between the first fixation on the word and the beginning of the word
15	leavingPos	Distance between the last fixation on the word and the beginning of the word
16	totalFixDur	Sum of all durations of fixations to the word
17	meanFixDur	Mean duration of the fixations to the word
18*	nRegressFrom	Number of regressions leaving from the word
19*	regressLen	Sum of durations of regressions initiating from this word
20*	nextWordRegress	'1' if a regression initiated from the following word
21*	regressDur	Sum of durations of the fixations on the word during regression
22	pupilDiamMax	Maximum pupil diameter
23	pupilDiamLag	Maximum pupil diameter 0.5 - 1.5 seconds after the beginning of fixation
24	timePrtctg	First fixation duration divided by the total number of fixations
25	nWordsInTitle	Number of word in the sentence (title) this word is in
26	titleNo		Title number
27	wordNo		Word number (ordinal) in this title
28	label		Classification for training data ('0'=irrelevant, '1'=relevant, '2'=correct)"
1045,kc1-top5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

1. Title: Class-level data for KC1
This one includes a {DEF,NODEF} attribute (DL) to indicate
defectiveness. DL is equal to DEF if the module is in the Top5% in
defect count ranking, NODEF otherwise.

2. Sources
(a) Creator: A. Gunes Koru
(b) Date: February 21, 2005
(c) Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843

3. Donor: A. Gunes Koru

4. Past Usage: This data set was used for:

A. Gunes Koru and Hongfang Liu, ""An Investigation of the Effect
of Module Size on Defect Prediction Using Static Measures"", PROMISE -
Predictive Models in Software Engineering Workshop, ICSE 2005,
May 15th 2005, Saint Louis, Missouri, US.

We used several machine learning algorithms to predict the defective
modules in five NASA products, namely, CM1, JM1, KC1, KC2, and PC1.
A set of static measures were used as predictor variables. While doing
so, we observed that a large portion of the modules were small, as
measured by lines of code (LOC). When we experimented on the data
subsets created by partitioning according to module size, we obtained
higher prediction performance for the subsets that include larger
modules. We also performed defect prediction using class-level data
for KC1 rather than method-level data. In this case, the use of class-level
data resulted in improved prediction performance compared to using
method-level data. These findings suggest that quality assurance activities
can be guided even better if defect predictions are made by using
data that belong to larger modules.

5. Features:

The descriptions of the features are taken from
http://mdp.ivv.nasa.gov/mdp_glossary.html

Feature Used as the Response Variable:
======================================
DL: Defect level. DEF if the class is in the Top 5% in defect ranking, NODEF
otherwise.

Features at Class Level Originally
==================================

PERCENT_PUB_DATA:  The percentage of data that is public and protected data
in a class. In general, lower values indicate greater encapsulation. It is
measure of encapsulation.

ACCESS_TO_PUB_DATA: The amount of times that a class's public and protected
data is accessed. In general, lower values indicate greater encapsulation.
It is a measure of encapsulation.

COUPLING_BETWEEN_OBJECTS: The number of distinct non-inheritance-related
classes on which a class depends. If a class that is heavily dependent on
many classes outside of its hierarchy is introduced into a library, all the
classes upon which it depends need to be introduced as well. This may be
acceptable, especially if the classes which it references are already part
of a class library and are even more fundamental than the specified class.

DEPTH: The level for a class. For instance, if a parent has one child the
depth for the child is two. Depth indicates at what level a class is located
within its class hierarchy. In general, inheritance increases when depth
increases.

LACK_OF_COHESION_OF_METHODS: For each data field in a class, the percentage
of the methods in the class using that data field; the percentages are
averaged then subtracted from 100%. The locm metric indicates low or
high percentage of cohesion. If the percentage is low, the class is cohesive.
If it is high, it may indicate that the class could be split into separate
classes that will individually have greater cohesion.

NUM_OF_CHILDREN: The number of classes derived from a specified class.

DEP_ON_CHILD: Whether a class is dependent on a descendant.

FAN_IN: This is a count of calls by higher modules.

RESPONSE_FOR_CLASS: A count of methods implemented within a class plus the
number of methods accessible to an object class due to inheritance. In
general, lower values indicate greater polymorphism.

WEIGHTED_METHODS_PER_CLASS: A count of methods implemented within a class
(rather than all methods accessible within the class hierarchy). In general,
lower values indicate greater polymorphism.
Features Transformed to Class Level (Originally at Method Level)
================================================================

Transformation was achieved by obtaining min, max, sum, and avg values
over all the methods in a class. There this data set includes four
features for all of the following features that were originally at the
method level but transformed to the class level. For example, LOC_BLANK
has minLOC_BLANK, maxLOC_BLANK, avgLOC_BLANK, and maxLOC_BLANK.

LOC_BLANK: Lines with only white space or no text content.

BRANCH_COUNT: This metric is the number of branches for each module.
Branches are defined as those edges that exit from a decision node.
The greater the number of branches in a program's modules, the more
testing resource's required.

LOC_CODE_AND_COMMENT: Lines that contain both code and comment.

LOC_COMMENTS:  The number of lines in a module. This particular metric
includes all blank lines, comment lines, and source lines.

CYCLOMATIC_COMPLEXITY: It is a measure of the complexity of a modules
decision structure. It is the number of linearly independent paths.

DESIGN_COMPLEXITY: Design complexity is a measure of a module's decision
structure as it relates to calls to other modules. This quantifies the
testing effort related to integration.

ESSENTIAL_COMPLEXITY: Essential complexity is a measure of the degree to
which a module contains unstructured constructs.

LOC_EXECUTABLE:  Source lines of code that contain only code and white space.

HALSTEAD_CONTENT: Complexity of a given algorithm independent of the
language used to express the algorithm.

HALSTEAD_DIFFICULTY: Level of difficulty in the program.

HALSTEAD_EFFORT: Estimated mental effort required to develop the program.

HALSTEAD_ERROR_EST:  Estimated number of errors in the program.

HALSTEAD_LENGTH: This is a Halstead metric that includes the total number
of operator occurrences and total number of operand occurrences.

HALSTEAD_LEVEL: Level at which the program can be understood.

HALSTEAD_PROG_TIME: Estimated amount of time to implement the algorithm.

HALSTEAD_VOLUME: This is a Halstead metric that contains the minimum
number of bits required for coding the program.

NUM_OPERANDS: Variables and identifiers Constants (numeric literal/string)
Function names when used during calls.

NUM_UNIQUE_OPERANDS: Variables and identifiers Constants
(numeric literal/string) Function names when used during calls

NUM_UNIQUE_OPERATORS: Number of unique operators.

LOC_TOTAL: Total Lines of Code."
1046,mozilla4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promisedata.org/repository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
(c) 2007  A. Gunes Koru
Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843
This data set is distributed under the
Creative Commons Attribution-Share Alike 3.0 License
http://creativecommons.org/licenses/by-sa/3.0/

You are free:

* to Share -- copy, distribute and transmit the work
* to Remix -- to adapt the work

Under the following conditions:

Attribution. You must attribute the work in the manner specified by
the author or licensor (but not in any way that suggests that they endorse
you or your use of the work).

Share Alike. If you alter, transform, or build upon this work, you
may distribute the resulting work only under the same, similar or a
compatible license.

* For any reuse or distribution, you must make clear to others the
license terms of this work.
* Any of the above conditions can be waived if you get permission from
the copyright holder.
* Apart from the remix rights granted under this license, nothing in
this license impairs or restricts the author's moral rights.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


1. Title: Recurrent event (defect fix) and size data for Mozilla Classes
This one includes a binary attribute (event) to show defect fix.
The data is at the ""observation"" level. Each modification made to
a C++ class was entered as an observation. A newly added class
created an observation. The observation period was between
May 29, 2002 and Feb 22, 2006.

2. Sources
(a) Creator: A. Gunes Koru
(b) Date: February 23, 2007
(c) Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843

3. Donor: A. Gunes Koru

4. Past Usage: This data set was used for:

A. Gunes Koru, Dongsong Zhang, and Hongfang Liu, ""Modeling the
Effect of Size on Defect Proneness for Open-Source Software"",
Predictive Models in Software Engineering Workshop, PROMISE 2007,
May 20th 2007, Minneapolis, Minnesota, US.

Abstract:
Quality is becoming increasingly important with the continuous
adoption of open-source software.  Previous research has found that
there is generally a positive relationship between module size and
defect proneness. Therefore, in open-source software development, it
is important to monitor module size and understand its impact on
defect proneness. However, traditional approaches to quality
modeling, which measure specific system snapshots and obtain future
defect counts, are not well suited because open-source modules
usually evolve and their size changes over time. In this study, we
used Cox proportional hazards modeling with recurrent events to
study the effect of class size on defect-proneness in the Mozilla
product. We found that the effect of size was significant, and we
quantified this effect on defect proneness.

The full paper can be downloaded from A. Gunes Koru's Website
http://umbc.edu/~gkoru
by following the Publications link or from the Web site of PROMISE 2007.

5. Features:

This data set is used to create a conditional Cox Proportional
Hazards Model

id: A numeric identification assigned to each separate C++ class
(Note that the id's do not increment from the first to the last
data row)

start: A time infinitesimally greater than the time of the modification
that created this observation (practically, modification time). When a
class is introduced to a system, a new observation is entered with start=0

end: Either the time of the next modification, or the end of the
observation period, or the time of deletion, whichever comes first.

event: event is set to 1 if a defect fix takes place
at the time represented by 'end', or 0 otherwise.  A class deletion
is handled easily by entering a final observation whose event is set
to 1 if the class is deleted for corrective maintenance, or 0 otherwise.

size: It is a time-dependent covariate and its column carries the
number of source Lines of Code of the C++ classes
at time 'start'. Blank and comment lines are not counted.

state: Initially set to 0, and it becomes 1 after the class
experiences an event, and remains at 1 thereafter."
1047,usp05,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promisedata.org/repository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
(c) 2007  Jingzhou Li
(jingli@ucalgary.ca)
This data set is distributed under the
Creative Commons Attribution-Share Alike 3.0 License
http://creativecommons.org/licenses/by-sa/3.0/

You are free:

* to Share -- copy, distribute and transmit the work
* to Remix -- to adapt the work

Under the following conditions:

Attribution. You must attribute the work in the manner specified by
the author or licensor (but not in any way that suggests that they endorse
you or your use of the work).

Share Alike. If you alter, transform, or build upon this work, you
may distribute the resulting work only under the same, similar or a
compatible license.

* For any reuse or distribution, you must make clear to others the
license terms of this work.
* Any of the above conditions can be waived if you get permission from
the copyright holder.
* Apart from the remix rights granted under this license, nothing in
this license impairs or restricts the author's moral rights.


1. Title: USP05: Software effort estimation at project, feature and requirement levels

2. Source Information
-- Donor: Jingzhou Li (jingli@ucalgary.ca), Guenther Ruhe (ruhe@ucalgary.ca)
computer science department
University of Calgary, Canada
(403) 210-5440
-- Date: December 2005

3. Past Usage:
[1]. J.Z. Li, G. Ruhe, A. Al-Emran, M. M. Ritcher, A Flexible Method for Effort Estimation by Analogy, Empirical Software Engineering, Vol. 12, No. 1, 2007, pp 65-106.
[2]. J.Z. Li, G. Ruhe, ""A Comparative Study of Attribute Weighting Heuristics for Effort Estimation by Analogy"", Proceedings of the ACM-IEEE International Symposium on Empirical Software Engineering (ISESE'06), September 2006, Brazil.

4. Relevant Information:
-- This data set was splited into USP05-RQ nad USP05-FT for requirements and feature respectively. USP05-RQ and USP05-T were used for software effort estimation by analogy in the above two references.
-- This data set was collected from university student projects
-- The detailed description of the whole data set can be found in reference [1].

5. Number of Instances: 203 (6 projects, 121 requirements, 76 features)

6. Number of Attributes: 17 (including ID and Object Type, Effort is the actual effort)

7. Attribute Information:
1. ID: Three digit Object ID,
2. ObjType: Object type (PJ-project, FT-feature, RQ-requirement)
3. Effort: Actual effort in hours expended on tasks related to implementing the object by all participating persons.
4. Funct%: Percentage of Functionality of features or requirements ({1-Internal process, 2-Data entry/ Modification/ Deletion, 3-Output form(screen), 4-Data query from database/ file, 5-Printing, 6-Report, 7-Other})
5. IntComplx: Complexity of Internal Calculation (1-VeryLow, 2-Low, 3-Medium, 4-High, 5-VeryHigh )
6. DataFile: Number of Data Files/Database Tables Accessed (Positive integer)
7. DataEn: Number of Data Entry Items (Positive integer)
8. DataOut: Number of Data Output Items (Positive integer)
9. UFP: Unadjusted Function Point Count (Positive integer)
10. Lang: Language Used (C++, Java, VB, Java Script, VB Script,  SQL, Php, Perl, Asp, Html, XML, Others)
11. Tools: Development Tools and Platforms (VJ++, VB, Delphi, VisualCafe, JUnit,   PowerBuilder, BorlandC++, Others)
12. ToolExpr: Language and Tool Experience Level (Range of number of months of experience, e.g. [2, 5] for 2 to 5 months, as the minimum experience level is 2 and 5 the maximum in the team)
13. AppExpr: Applications Experience Level (1-VeryLow, 2-Low, 3-Medium, 4-High, 5-VeryHigh)
14. TeamSize: Team size for implementing the object (Range: [a, b], min-max number of persons, e.g. [2, 5])
15. DBMS: Database Systems (Oracle, Access, SQLServer, MySQL, Others)
16. Method: Methodology (OO, SA, SD, RAD, JAD, MVC, Others)
17. AppType: ype of System/Application Architecture (B/S, C/S, BC/S, Centered, Other)


8. Missing Attribute Values: 83

9. Data"
1048,jEdit_4.2_4.3,
1049,pc4,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc1.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**PC4 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1050,pc3,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc3.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**PC3 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1051,cocomo_numeric,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%-*- text -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
1. Title/Topic: cocomonasa/software cost estimation
2. Sources:

-- Creators: 60 NASA projects from different centers
for projects from the 1980s and 1990s.  Collected by
Jairus Hihn, JPL, NASA, Manager SQIP Measurement &
Benchmarking Element
Phone (818) 354-1248 (Jairus.M.Hihn@jpl.nasa.gov)

-- Donor: Tim Menzies (tim@barmag.net)

-- Date: December 2 2004
3. Past Usage
1. ""Validation Methods for Calibrating Software Effort
Models"", T. Menzies and D. Port and Z. Chen and
J. Hihn and S. Stukes, Proceedings ICSE 2005,
http://menzies.us/pdf/04coconut.pdf
-- Results
-- Given background knowledge on 60 prior projects,
a new cost model can be tuned to local data using
as little as 20 new projects.
-- A very simple calibration method (COCONUT) can
achieve PRED(30)=7% or PRED(20)=50% (after 20 projects).
These are results seen in 30 repeats of an incremental
cross-validation study.
-- Two cost models are compared; one based on just
lines of code and one using over a dozen ""effort
multipliers"". Just using lines of code loses 10 to 20
PRED(N) points.

3.1 Additional Usage:
2. ""Feature Subset Selection Can Improve Software Cost Estimation Accuracy""
Zhihao Chen, Tim Menzies, Dan Port and Barry Boehm
Proceedings PROMISE Workshop 2005,
http://www.etechstyle.com/chen/papers/05fsscocomo.pdf
P02, P03, P04 are used in this paper.
-- Results
-- To the best of our knowledge, this is the first report
of applying feature subset selection (FSS)
to software effort data.

-- FSS can dramatically improve cost estimation.

---T-tests are applied to the results to demonstrate
that always in our data sets, removing
attributes improves performance without increasing the
variance in model behavior.

4. Relevant Information

The COCOMO software cost model measures effort in calendar months
of 152 hours (and includes development and management hours).
COCOMO assumes that the effort grows more than linearly on
software size; i.e. months=a* KSLOC^b*c. Here, ""a"" and ""b"" are
domain-specific parameters; ""KSLOC"" is estimated directly or
computed from a function point analysis; and ""c"" is the product
of over a dozen ""effort multipliers"". I.e.

months=a*(KSLOC^b)*(EM1* EM2 * EM3 * ...)

The effort multipliers are as follows:

increase | acap | analysts capability
these to | pcap | programmers capability
decrease  | aexp | application experience
effort  | modp | modern programing practices
| tool | use of  software tools
| vexp | virtual machine experience
| lexp | language experience
----------+------+---------------------------
| sced | schedule constraint
----------+------+---------------------------
decrease | stor | main memory constraint
these to | data | data base size
decrease | time | time constraint for cpu
effort | turn | turnaround time
| virt | machine volatility
| cplx | process complexity
| rely | required software reliability

In COCOMO I, the exponent on KSLOC was a single value ranging from
1.05 to 1.2.  In COCOMO II, the exponent ""b"" was divided into a
constant, plus the sum of five ""scale factors"" which modeled
issues such as ``have we built this kind of system before?''.  The
COCOMO~II effort multipliers are similar but COCOMO~II dropped one
of the effort multiplier parameters; renamed some others; and
added a few more (for ""required level of reuse"", ""multiple-site
development"", and ""schedule pressure"").

The effort multipliers fall into three groups: those that are
positively correlated to more effort; those that are
negatively correlated to more effort; and a third group
containing just schedule information. In COCOMO~I, ""sced"" has a
U-shaped correlation to effort; i.e. giving programmers either
too much or too little time to develop a system can be
detrimental.

The numeric values of the effort multipliers are:

very				very	extra	productivity
low	low	nominal	high	high	high	range
---------------------------------------------------------------------
acap	1.46   	1.19   	1.00   	0.86   	0.71   		2.06
pcap	1.42.  	1.17   	1.00   	0.86   	0.70 		1.67
aexp   	1.29   	1.13   	1.00   	0.91   	0.82   		1.57
modp   	1.24.  	1.10 	1.00 	0.91 	0.82 		1.34
tool   	1.24 	1.10 	1.00 	0.91 	0.83 		1.49
vexp   	1.21 	1.10 	1.00 	0.90 	  		1.34
lexp   	1.14 	1.07 	1.00 	0.95 	  		1.20
sced   	1.23 	1.08 	1.00 	1.04 	1.10 	  	e
stor   	       	       	1.00   	1.06   	1.21   	1.56	-1.21
data   	    	 0.94 	1.00 	1.08 	1.16		-1.23
time   	  	    	1.00   	1.11   	1.30   	1.66	-1.30
turn   	       	0.87   	1.00   	1.07   	1.15   		-1.32
virt   	       	0.87   	1.00   	1.15   	1.30   		-1.49
rely   	0.75	 0.88	 1.00 	 1.15 	 1.40		-1.87
cplx   	0.70 	0.85 	1.00 	1.15 	1.30 	1.65	-2.36

These were learnt by Barry Boehm after a regression analysis of the
projects in the COCOMO I data set.
@Book{boehm81,
Author    =	 ""B. Boehm"",
Title     =	 ""Software Engineering Economics"",
Publisher =	 ""Prentice Hall"",
Year      =	 1981}

The last column of the above table shows max(E)/min(EM) and shows
the overall effect of a single effort multiplier. For example,
increasing ""acap"" (analyst experience) from very low to very
high will most decrease effort while increasing ""rely""
(required reliability) from very low to very high will most
increase effort.

There is much more to COCOMO that the above description. The
COCOMO~II text is over 500 pages long and offers
all the details needed to implement data capture and analysis of
COCOMO in an industrial context.
@Book{boehm00b,
Author = ""Barry Boehm and Ellis Horowitz and Ray Madachy and
Donald Reifer and Bradford K. Clark and Bert Steece
and A. Winsor Brown and Sunita Chulani and Chris Abts"",
Title = ""Software Cost Estimation with Cocomo II"",
Publisher = ""Prentice Hall"",
Year = 2000,
ibsn = ""0130266922""}

Included in that book is not just an effort model but other
models for schedule, risk, use of COTS, etc.  However, most
(?all) of the validation work on COCOMO has focused on the effort
model.
@article{chulani99,
author =	 ""S. Chulani and B. Boehm and B. Steece"",
title =	 ""Bayesian Analysis of Empirical Software Engineering
Cost Models"",
journal =	 ""IEEE Transaction on Software Engineering"",
volume =	 25,
number =	 4,
month =	 ""July/August"",
year =	 ""1999""}

The value of an effort predictor can be reported many ways
including MMRE and PRED(N).MMRE and PRED are computed from the
relative error, or RE, which is the relative size of the
difference between the actual and estimated value:

RE.i = (estimate.i - actual.i) / (actual.i)

Given a data set of of size ""D"", a ""Train""ing set of size
""(X=|Train|) <= D"", and a ""test"" set of size ""T=D-|Train|"", then
the mean magnitude of the relative error, or MMRE, is the
percentage of the absolute values of the relative errors,
averaged over the ""T"" items in the ""Test"" set; i.e.

MRE.i  = abs(RE.i)
MMRE.i = 100/T*( MRE.1 + MRE.2 + ... + MRE.T)

PRED(N) reports the average percentage of estimates that were
within N% of the actual values:

count=0
for(i=1;i<=T;i++) do if (MRE.i <= N/100) then count++ fi done
PRED(N) = 100/T * sum

For example, e.g. PRED(30)=50% means that half the estimates are
within 30% of the actual.  Shepperd and Schofield comment that
""MMRE is fairly conservative with a bias against overestimates
while Pred(25) will identify those prediction systems that are
generally accurate but occasionally wildly inaccurate"".
@article{shepperd97,
author=""M. Shepperd and C. Schofield"",
title=""Estimating Software Project Effort Using Analogies"",
journal=""IEEE Transactions on Software Engineering"",
volume=23,
number=12,
month=""November"",
year=1997,
note=""Available from
\url{http://www.utdallas.edu/~rbanker/SE_XII.pdf}""}

4.1 Further classification of the projects

4.1.1 Classify the projects into different project categories - P02, P03, P04.
(The criteria is unknown and they are disjoint.)

Category	sequence Original sequence_of_NASA
P01	1	NASA	26
P01	2	NASA	27
P01	3	NASA	28
P01	4	NASA	29
P01	5	NASA	30
P01	6	NASA	31
P01	7	NASA	32
P02	1	NASA	4
P02	2	NASA	5
P02	3	NASA	6
P02	4	NASA	7
P02	5	NASA	8
P02	6	NASA	9
P02	7	NASA	10
P02	8	NASA	11
P02	9	NASA	12
P02	10	NASA	13
P02	11	NASA	14
P02	12	NASA	15
P02	13	NASA	16
P02	14	NASA	17
P02	15	NASA	18
P02	16	NASA	19
P02	17	NASA	20
P02	18	NASA	21
P02	19	NASA	22
P02	20	NASA	23
P02	21	NASA	24
P02	22	NASA	25
P03	1	NASA	34
P03	2	NASA	35
P03	3	NASA	36
P03	4	NASA	37
P03	5	NASA	38
P03	6	NASA	39
P03	7	NASA	40
P03	8	NASA	41
P03	9	NASA	42
P03	10	NASA	43
P03	11	NASA	44
P03	12	NASA	45
P04	1	NASA	47
P04	2	NASA	48
P04	3	NASA	49
P04	4	NASA	50
P04	5	NASA	51
P04	6	NASA	52
P04	7	NASA	53
P04	8	NASA	54
P04	9	NASA	55
P04	10	NASA	56
P04	11	NASA	57
P04	12	NASA	58
P04	13	NASA	59
P04	14	NASA	60

4.1.2 Classify the projects into different task categories - T01, T02, T03.
(The criteria is unknown and they are disjoint.)
T01:sequencing  T02:avionics    T03:missionPlanning

Category	sequence Original sequence_of_NASA
T01	1	NASA	43
T01	2	NASA	41
T01	3	NASA	37
T01	4	NASA	34
T01	5	NASA	40
T01	6	NASA	38
T01	7	NASA	39
T01	8	NASA	36
T02	1	NASA	4
T02	2	NASA	6
T02	3	NASA	26
T02	4	NASA	27
T02	5	NASA	33
T02	6	NASA	32
T02	7	NASA	29
T02	8	NASA	30
T02	9	NASA	28
T02	10	NASA	7
T02	11	NASA	9
T02	12	NASA	10
T02	13	NASA	55
T02	14	NASA	31
T03	1	NASA	51
T03	2	NASA	52
T03	3	NASA	16
T03	4	NASA	17
T03	5	NASA	8
T03	6	NASA	50
T03	7	NASA	53
T03	8	NASA	45
T03	9	NASA	48
T03	10	NASA	47

4.1.3 Classify the projects into different Centers - C01, C02, C03.
(The criteria is unknown and they are disjoint.)
Category sequence Original sequence_of_NASA

C01	1	NASA	1
C01	2	NASA	2
C01	3	NASA	51
C01	4	NASA	52
C01	5	NASA	50
C01	6	NASA	53
C01	7	NASA	48
C01	8	NASA	47
C01	9	NASA	58
C01	10	NASA	59
C01	11	NASA	60
C01	12	NASA	49
C01	13	NASA	54
C02	1	NASA	45
C02	2	NASA	43
C02	3	NASA	41
C02	4	NASA	35
C02	5	NASA	34
C02	6	NASA	40
C02	7	NASA	38
C02	8	NASA	39
C02	9	NASA	36
C02	10	NASA	37
C02	11	NASA	42
C02	12	NASA	44
C03	1	NASA	4
C03	2	NASA	6
C03	3	NASA	26
C03	4	NASA	27
C03	5	NASA	33
C03	6	NASA	32
C03	7	NASA	29
C03	8	NASA	30
C03	9	NASA	28
C03	10	NASA	7
C03	11	NASA	9
C03	12	NASA	10
C03	13	NASA	31
C03	14	NASA	21
C03	15	NASA	14
C03	16	NASA	22
C03	17	NASA	3
C03	18	NASA	19
C03	19	NASA	16
C03	20	NASA	17
C03	21	NASA	8
C03	22	NASA	23
C03	23	NASA	20
C03	24	NASA	24
C03	25	NASA	12
C03	26	NASA	5
C03	27	NASA	13
C03	28	NASA	25
C03	29	NASA	15
C03	30	NASA	18
C03	31	NASA	11
5. Number of instances: 60
6. Number of attributes: 17 (15 discrete in the range Very_Low to
Extra_High; one lines of code measure, and one goal field
being the actual effort in person months).
7. Attribute information:
8. Missing attributes: none
9: Class distribution: the class value (ACT_EFFORT) is continuous.
After sorting all the instances on ACT_EFFORT, the following
distribution was found:
Instances     Range
---------     --------------
1..10         8.4 ..   42
11..20        48   ..   68
21..30        70   ..  117.6
31..40       120   ..  300
41..50       324   ..  571
51..60       750   .. 3240
Change log:
-----------

2005/04/04 Jelber Sayyad Shirabad (PROMISE Librarian) <promise@site.uottawa.ca>
1) Minor editorial changes, as well as moving the information provided by
Zhihao Chen to the new sections 3.1 and 4.1

2005/03/28 Zhihao Chen, CSE, USC, USA, <zhihaoch@cse.usc.edu>
1) Fix a mistake in line corresponding to cplx entry in the table of ""The numeric values of the effort multipliers""
""cplx   	0.70 	0.85 	1.00 	1.15 	1.30 	1.65	-1.86"" should be
""cplx   	0.70 	0.85 	1.00 	1.15 	1.30 	1.65	-2.36""

2) Additional information about various classifications of the projects are provided.

3) Additional usage information is provided"
1053,jm1,"**Author**: [Mike Chapman, Galaxy Global Corporation](Robert.Chapman@ivv.nasa.gov)  
**Source**: [PROMISE Repository](http://promise.site.uottawa.ca/SERepository)  
**Please cite**: please follow the acknowledgment guidelines posted on [the PROMISE repository web page](http://promise.site.uottawa.ca/SERepository).  

This is a PROMISE data set made publicly available in order to encourage repeatable, verifiable, refutable, and/or improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please follow the acknowledgment guidelines posted on [the PROMISE repository web page](http://promise.site.uottawa.ca/SERepository).

## Title/Topic
JM1/software defect prediction


## Sources
* **Creators:**  NASA, then the NASA Metrics Data Program, http://mdp.ivv.nasa.gov. 
* **Contacts:** 
  * Mike Chapman, Galaxy Global Corporation (Robert.Chapman@ivv.nasa.gov) +1-304-367-8341
  * Pat Callis, NASA, NASA project manager for MDP (Patrick.E.Callis@ivv.nasa.gov) +1-304-367-8309

* **Donor:** Tim Menzies (tim@barmag.net)

* **Date:**  December 2nd, 2004

## Past usage
**_How Good is Your Blind Spot Sampling Policy?_; 2003; Tim Menzies and Justin S. Di Stefano; 2004 IEEE Conference on High Assurance Software Engineering (http://menzies.us/pdf/03blind.pdf).**

### Results:
* Very simple learners (ROCKY) perform as well in this domain as more sophisticated methods (e.g. J48, model trees, model trees) for predicting detects
* Many learners have very low false alarm rates.
* Probability of detection (PD) rises with effort and rarely rises above it.
* High PDs are associated with high PFs (probability of failure)
* PD, PF, effort can change significantly while accuracy remains essentially stable
* With two notable exceptions, detectors learned from one data set (e.g. KC2) have nearly they same properties when applied to another (e.g. PC2, KC2). Exceptions:
* LinesOfCode measures generate wider inter-data-set variances;
* Precision's inter-data-set variances vary wildly

**_""Assessing Predictors of Software Defects""_, T. Menzies and J. DiStefano and A. Orrego and R. Chapman, 2004,**
**Proceedings, workshop on Predictive Software Models, Chicago, Available from http://menzies.us/pdf/04psm.pdf.**

### Results:
* From JM1, Naive Bayes generated PDs of 25% with PF of 20%
* Naive Bayes out-performs J48 for defect detection
* When learning on more and more data, little improvement is seen after processing 300 examples.
* PDs are much higher from data collected below the sub-sub-system level.
* Accuracy is a surprisingly uninformative measure of success for a defect detector. Two detectors with the same accuracy can have widely varying PDs and PFs.

## Relevant information
* JM1 is written in ""C"" and is a real-time predictive ground system: Uses simulations to generate predictions
* Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality. The nature of association is under dispute.

Notes on McCabe and Halstead follow.

* The McCabe and Halstead measures are ""module""-based where a ""module"" is the smallest unit of functionality. In C or Smalltalk, ""modules"" would be called ""function"" or ""method"" respectively.

* Defect detectors can be assessed according to the following measures:

    module actually has defects
    +-------------+------------+
    |     no      |     yes    |
    +-----+-------------+------------+
    classifier predicts no defects |  no |      a      |      b     |
    +-----+-------------+------------+
    classifier predicts some defects | yes |      c      |      d     |
    +-----+-------------+------------+


    accuracy                   = acc          = (a+d)/(a+b+c+d
    probability of detection   = pd  = recall = d/(b+d)
    probability of false alarm = pf           = c/(a+c)
    precision                  = prec         = d/(c+d)
    effort                     = amount of code selected by detector = (c.LOC + d.LOC)/(Total LOC)


Ideally, detectors have high PDs, low PFs, and low effort. This ideal state rarely happens:

* PD and effort are linked. The more modules that trigger the detector, the higher the PD. However, effort also gets increases
* High PD or low PF comes at the cost of high PF or low PD (respectively). This linkage can be seen in a standard receiver operator curve (ROC).  Suppose, for example, LOC> x is used as the detector (i.e. we assume large modules have more errors). LOC > x represents a family of detectors. At x=0, EVERY module is predicted to have errors. This detector has a high PD but also a high false alarm rate. At x=0, NO module is predicted to have errors. This detector has a low false alarm rate but won't detect anything at all. At 0<x PD=PF PF=0) PD=0) PD=1,PF> but does not reach it.
* The line pf=pd on the above graph represents the ""no information"" line. If pf=pd then the detector is pretty useless. The better the detector, the more it rises above PF=PD towards the ""sweet spot"".

NOTES ON MCCABE/HALSTEAD
========================
McCabe argued that code with complicated pathways are more error-prone.  His metrics therefore reflect the pathways within a code module.

    @Article{mccabe76,
    title  = ""A Complexity Measure"",
    author  = ""T.J. McCabe"",
    pages  = ""308--320"",
    journal = ""IEEE Transactions on Software Engineering"",
    year  = ""1976"",
    volume  = ""2"",
    month  = ""December"",
    number  = ""4""}

Halstead argued that code that is hard to read is more likely to be fault prone. Halstead estimates reading complexity by counting the number of concepts in a module; e.g. number of unique operators.

    @Book{halstead77,
    Author    = ""M.H. Halstead"",
    Title    = ""Elements of Software Science"",
    Publisher = ""Elsevier "",
    Year    = 1977}

We study these static code measures since they are useful, easy to use, and widely used:

* USEFUL: E.g. this data set can generate highly accurate predictors for defects
* EASY TO USE: Static code measures (e.g. lines of code, the McCabe/Halstead measures) can be automatically and cheaply collected.
* WIDELY USED: Many researchers use static measures to guide software quality predictions (see the reference list in the above ""blind spot"" paper. Verification and validation (V\&V) textbooks advise using static code complexity measures to decide which modules are worthy of manual inspections.  Further, we know of several large government software contractors that won't review software modules _unless_ tools like McCabe predict that they are fault prone.  Hence, defect detectors have a major economic impact when they may force programmers to rewrite code.

Nevertheless, the merits of these metrics has been widely criticized.  Static code measures are hardly a complete characterization of the internals of a function. Fenton offers an insightful example where the same functionality is achieved using different programming language constructs resulting in different static measurements for that module. Fenton uses this example to argue the uselessness of static code measures.

    @Book{fenton97,
    author    = ""N.E. Fenton and S.L. Pfleeger"",
    title     = {Software metrics: a Rigorous \& Practical Approach},
    publisher = {International Thompson Press},
    year      = {1997}}

An alternative interpretation of Fenton's example is that static measures can never be a definite and certain indicator of the presence of a fault.  Rather, defect detectors based on static measures are best viewed as probabilistic statements that the frequency of faults tends to increase in code modules that trigger the detector.  By definition, such probabilistic statements will are not categorical claims with some a non-zero false alarm rate. The research challenge for data miners is to ensure that these false alarms do not cripple their learned theories.

The McCabe metrics are a collection of four software metrics: essential complexity, cyclomatic complexity, design complexity and LOC, Lines of Code.

* Cyclomatic Complexity, or ""v(G)"", measures the number of ""linearly independent paths"". A set of paths is said to be linearly independent if no path in the set is a linear combination of any other paths in the set through a program's ""flowgraph"". A flowgraph is a directed graph where each node corresponds to a program statement, and each arc indicates the flow of control from one statement to another. ""v(G)"" is calculated by ""v(G) = e - n + 2"" where ""G"" is a program's flowgraph, ""e"" is the number of arcs in the flowgraph, and ""n"" is the number of nodes in the flowgraph. The standard McCabes rules (""v(G)"">10), are used to identify fault-prone module.
* Essential Complexity, or ""ev(G)$"" is the extent to which a flowgraph can be ""reduced"" by decomposing all the subflowgraphs of $G$ that are ""D-structured primes"". Such ""D-structured primes"" are also sometimes referred to as ""proper one-entry one-exit subflowgraphs"" (for a more thorough discussion of D-primes, see the Fenton text referenced above). ""ev(G)"" is calculated using ""ev(G)= v(G) - m"" where $m$ is the number of subflowgraphs of ""G"" that are D-structured primes.
* Design Complexity, or ""iv(G)"", is the cyclomatic complexity of a module's reduced flowgraph.  The flowgraph, ""G"", of a module is reduced to eliminate any complexity which does not influence the interrelationship between design modules.  According to McCabe, this complexity measurement reflects the modules calling patterns to its immediate subordinate modules.
* Lines of code is measured according to McCabe's line counting conventions.

The Halstead falls into three groups: the base measures, the derived measures, and lines of code measures.

* Base measures:
  * mu1             = number of unique operators
  * mu2             = number of unique operands
  * N1              = total occurrences of operators
  * N2              = total occurrences of operands
  * length     = N  = N1 + N2
  * vocabulary = mu = mu1 + mu2
  * Constants set for each function:
  * mu1' =  2 = potential operator count (just the function name and the ""return"" operator)
  * mu2'      = potential operand count. (the number of arguments to the module)

For example, the expression ""return max(w+x,x+y)"" has ""N1=4"" operators ""return, max, +,+)"", ""N2=4"" operands (w,x,x,y), ""mu1=3"" unique operators (return, max,+), and ""mu2=3"" unique operands (w,x,y).

* Derived measures:
  * P = volume = V = N * log2(mu) (the number of mental comparisons needed to write
a program of length N)
  * V* = volume on minimal implementation = (2 + mu2')*log2(2 + mu2')
  * L  = program length = V*/N
  * D  = difficulty = 1/L
  * L' = 1/D
  * I  = intelligence = L'*V'
  * E  = effort to write program = V/L
  * T  = time to write program = E/18 seconds

## Number of instances
10885

## Number of attributes
22 (5 different lines of code measure, 3 McCabe metrics, 4 base Halstead measures, 8 derived Halstead measures, a branch-count, and 1 goal field)

## Attribute Information
1. loc             : numeric % McCabe's line count of code
2. v(g)            : numeric % McCabe ""cyclomatic complexity""
3. ev(g)           : numeric % McCabe ""essential complexity""
4. iv(g)           : numeric % McCabe ""design complexity""
5. n               : numeric % Halstead total operators + operands
6. v               : numeric % Halstead ""volume""
7. l               : numeric % Halstead ""program length""
8. d               : numeric % Halstead ""difficulty""
9. i               : numeric % Halstead ""intelligence""
10. e               : numeric % Halstead ""effort""
11. b               : numeric % Halstead
12. t               : numeric % Halstead's time estimator
13. lOCode          : numeric % Halstead's line count
14. lOComment       : numeric % Halstead's count of lines of comments
15. lOBlank         : numeric % Halstead's count of blank lines
16. lOCodeAndComment: numeric
17. uniq_Op         : numeric % unique operators
18. uniq_Opnd       : numeric % unique operands
19. total_Op        : numeric % total operators
20. total_Opnd      : numeric % total operands
21: branchCount     : numeric % of the flow graph
22. defects         : {false,true} % module has/has not one or more reported defects

## Missing attributes
None

## Class Distribution
The class value (defects) is discrete
false: 2106 = 19.35%
true:  8779 = 80.65%"
1054,mc2,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/mc2.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**MC2 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. The specific type of software is unknown. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1055,cm1_req,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1056,mc1,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/mc1.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**MC1 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. The specific type of software is unknown. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1057,usp05-ft,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promisedata.org/repository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
(c) 2007  Jingzhou Li
(jingli@ucalgary.ca)
This data set is distributed under the
Creative Commons Attribution-Share Alike 3.0 License
http://creativecommons.org/licenses/by-sa/3.0/

You are free:

* to Share -- copy, distribute and transmit the work
* to Remix -- to adapt the work

Under the following conditions:

Attribution. You must attribute the work in the manner specified by
the author or licensor (but not in any way that suggests that they endorse
you or your use of the work).

Share Alike. If you alter, transform, or build upon this work, you
may distribute the resulting work only under the same, similar or a
compatible license.

* For any reuse or distribution, you must make clear to others the
license terms of this work.
* Any of the above conditions can be waived if you get permission from
the copyright holder.
* Apart from the remix rights granted under this license, nothing in
this license impairs or restricts the author's moral rights.

1. Title: USP05-FT: Software effort estimation at feature level

2. Source Information
-- Donor: Jingzhou Li (jingli@ucalgary.ca), Guenther Ruhe (ruhe@ucalgary.ca)
computer science department
University of Calgary, Canada
(403) 210-5440
-- Date: December 2005

3. Past Usage:
[1]. J.Z. Li, G. Ruhe, A. Al-Emran, M. M. Ritcher, ""A Flexible Method for Effort Estimation by Analogy"", Empirical Software Engineering, Vol. 12, No. 1, 2007, pp 65-106.
[2]. J.Z. Li, G. Ruhe, ""A Comparative Study of Attribute Weighting Heuristics for Effort Estimation by Analogy"", Proceedings of the ACM-IEEE International Symposium on Empirical Software Engineering (ISESE'06), September 2006, Brazil.

4. Relevant Information:
-- This data set was part of USP05 that was collected from university student projects about Web and client/server applications
-- The detailed description of the whole data set can be found in reference [1].

5. Number of Instances: 76 (features)

6. Number of Attributes: 15 (including ID, Effort is the actual effort)

7. Attribute Information:
1. ID: Three digit Object ID,
2. Effort: Actual effort in hours expended on tasks related to implementing the object by all participating persons.
3. IntComplx: Complexity of Internal Calculation (1-VeryLow, 2-Low, 3-Medium, 4-High, 5-VeryHigh )
4. DataFile: Number of Data Files/Database Tables Accessed (Positive integer)
5. DataEn: Number of Data Entry Items (Positive integer)
6. DataOut: Number of Data Output Items (Positive integer)
7. UFP: Unadjusted Function Point Count (Positive integer)
8. Lang: Language Used (C++, Java, VB, Java Script, VB Script,  SQL, Php, Perl, Asp, Html, XML, Others)
9. Tools: Development Tools and Platforms (VJ++, VB, Delphi, VisualCafe, JUnit,   PowerBuilder, BorlandC++, Others)
10. ToolExpr: Language and Tool Experience Level (Range of number of months of experience, e.g. [2, 5] for 2 to 5 months, as the minimum experience level is 2 and 5 the maximum in the team)
11. AppExpr: Applications Experience Level (1-VeryLow, 2-Low, 3-Medium, 4-High, 5-VeryHigh)
12. TeamSize: Team size for implementing the object (Range: [a, b], min-max number of persons, e.g. [2, 5])
13. DBMS: Database Systems (Oracle, Access, SQLServer, MySQL, Others)
14. Method: Methodology (OO, SA, SD, RAD, JAD, MVC, Others)
15. AppType: Type of System/Application Architecture (B/S, C/S, BC/S, Centered, Other)


8. Missing Attribute Values: 37

9. Data"
1058,humans_numeric,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

1. Title: Assessing the Reliability of a Human Estimator
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promisedata.org/repository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
(c) 2007 : Gary Boetticher  : boetticher AT uhcl DOT edu Phone: +1 (281) 283 8305
This data set is distributed under the
Creative Commons Attribution-Share Alike 3.0 License
http://creativecommons.org/licenses/by-sa/3.0/

You are free:

* to Share -- copy, distribute and transmit the work
* to Remix -- to adapt the work

Under the following conditions:

Attribution. You must attribute the work in the manner specified by
the author or licensor (but not in any way that suggests that they endorse
you or your use of the work).

Share Alike. If you alter, transform, or build upon this work, you
may distribute the resulting work only under the same, similar or a
compatible license.

* For any reuse or distribution, you must make clear to others the
license terms of this work.
* Any of the above conditions can be waived if you get permission from
the copyright holder.
* Apart from the remix rights granted under this license, nothing in
this license impairs or restricts the author's moral rights.


2. Sources
(a) Creator: Gary D. Boetticher
(b) Date: February 20, 2007
(c) Contact: boetticher AT uhcl DOT edu Phone: +1 (281) 283 8305

3. Donor: Gary D. Boetticher

4. Past Usage: This data was used for:

Boetticher, G., Lokhandwala, N., James C. Helm, Understanding the Human
Estimator, Second International Predictive Models in Software Engineering
(PROMISE) Workshop co-located at the 22nd IEEE International Conference on
Software Maintenance, Philadelphia, PA, September, 2006. More information is
available at http://nas.cl.uh.edu/boetticher/research.html

Since PROMISE 2006, the data set expanded by about 50 percent. The additional
tuples allowed us to divide the data into 3 major categories. Those who severely
underestimate (first 25 tuples). Those who accurately estimate (next 25 tuples).
And those who severely overestimate (last 25 tuples). The PROMISE 2007 experiments
compare the underestimators with the accurate estimators and the overestimators with
the accurate estimators.

5. Number of Instances: 75

6. Number of Attributes: 14 independent variables and 1 dependent variable

7. Attribute Information:

Numeric Degree:  This attribute refers to the level of education of the participant.
2=High School, 3=Bachelors, 4=Masters,5=Ph.D.

TechUGCourses: This refers to the number of technical undergraduate courses that
the participant has taken.

TechGCourses: This refers to the number of technical graduate courses that
the participant has taken.

MgmtUGCourses: This refers to the number of management undergraduate courses that
the participant has taken.

MgmtGCourses: This refers to the number of management graduate courses that
the participant has taken.

Total Workshops: This refers to the total number of workshops that
the participant has attended.

Total Conferences: This refers to the total number of conferences that
the participant has attended.

TotalLangExp: This refers to the total number of languages and experience in those
languages that the participant has.

Hardware Proj Mgmt Exp: This corresponds to the total amount of time that the
respondant has been estimating hardware projects.

Software Proj Mgmt Exp: This corresponds to the total amount of time that the
respondant has been estimating software projects.

No Of Hardware Proj Estimated: This refers to the total number of hardware projects
that the participant has estimated.

No Of Software Proj Estimated: This refers to the total number of software projects
that the participant has estimated.

Domain Exp: The domain experience refers to how much experience the participant has
in the oil and gas industry.

Procurement Industry Exp: The procurement industry experience refers to the amount
of time, in years, that the participant has regarding
procurement.

ABS((TotalEstimates-TotalActual)/TotalActual): This is the class variable. It
represents the overall relative error for the participant's
estimates."
1059,ar1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, refutable, verifiable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please follow
the acknowledgment guidelines posted on the PROMISE repository web page
http://promise.site.uottowa.ca/SERepository.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
--Title: AR1 /Software Defect Prediction
--Date: February, 4th, 2009
--Data from a Turkish white-goods manufacturer
--Donated by: Software Research Laboratory (Softlab),
Bogazici University, Istanbul, Turkey
--Website: http://softlab.boun.edu.tr
--Contact address: ayse.tosun@boun.edu.tr, bener@boun.edu.tr

--Description:
Embedded software in a white-goods product.
Implemented in C.
Consists of 121 modules (9 defective / 112 defect-free)
29 static code attributes (McCabe, Halstead and LOC measures) and 1 defect information(false/true)
Function/method level static code attributes are collected using
Prest Metrics Extraction and Analysis Tool [1].
[1] Prest Metrics Extraction and Analysis Tool, available at http://softlab.boun.edu.tr/?q=resources&i=tools."
1060,ar3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1061,ar4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1062,ar5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1063,kc2,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/kc2.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**KC2 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. Data from software for science data processing. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Attribute Information  

1. loc             : numeric % McCabe's line count of code
2. v(g)            : numeric % McCabe ""cyclomatic complexity""
3. ev(g)           : numeric % McCabe ""essential complexity""
4. iv(g)           : numeric % McCabe ""design complexity""
5. n               : numeric % Halstead total operators + operands
6. v               : numeric % Halstead ""volume""
7. l               : numeric % Halstead ""program length""
8. d               : numeric % Halstead ""difficulty""
9. i               : numeric % Halstead ""intelligence""
10. e               : numeric % Halstead ""effort""
11. b               : numeric % Halstead 
12. t               : numeric % Halstead's time estimator
13. lOCode          : numeric % Halstead's line count
14. lOComment       : numeric % Halstead's count of lines of comments
15. lOBlank         : numeric % Halstead's count of blank lines
16. lOCodeAndComment: numeric
17. uniq_Op         : numeric % unique operators
18. uniq_Opnd       : numeric % unique operands
19. total_Op        : numeric % total operators
20. total_Opnd      : numeric % total operands
21. branchCount     : numeric % of the flow graph
22. problems        : {false,true} % module has/has not one or more reported defects

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1064,ar6,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, refutable, verifiable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please follow
the acknowledgment guidelines posted on the PROMISE repository web page
http://promise.site.uottowa.ca/SERepository.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
--Title: AR6 /Software Defect Prediction
--Date: February, 4th, 2009
--Data from a Turkish white-goods manufacturer
--Donated by: Software Research Laboratory (Softlab),
Bogazici University, Istanbul, Turkey
--Website: http://softlab.boun.edu.tr
--Contact address: ayse.tosun@boun.edu.tr, bener@boun.edu.tr

--Description:
Embedded software in a white-goods product.
Implemented in C.
Consists of 101 modules (15 defective / 86 defect-free)
29 static code attributes (McCabe, Halstead and LOC measures) and 1 defect information(false/true)
Function/method level static code attributes are collected using
Prest Metrics Extraction and Analysis Tool [1].
[1] Prest Metrics Extraction and Analysis Tool, available at http://softlab.boun.edu.tr/?q=resources&i=tools."
1065,kc3,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/kc3.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**KC3 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. The specific type of software is unknown. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Attribute Information  

1. loc             : numeric % McCabe's line count of code
2. v(g)            : numeric % McCabe ""cyclomatic complexity""
3. ev(g)           : numeric % McCabe ""essential complexity""
4. iv(g)           : numeric % McCabe ""design complexity""
5. n               : numeric % Halstead total operators + operands
6. v               : numeric % Halstead ""volume""
7. l               : numeric % Halstead ""program length""
8. d               : numeric % Halstead ""difficulty""
9. i               : numeric % Halstead ""intelligence""
10. e               : numeric % Halstead ""effort""
11. b               : numeric % Halstead 
12. t               : numeric % Halstead's time estimator
13. lOCode          : numeric % Halstead's line count
14. lOComment       : numeric % Halstead's count of lines of comments
15. lOBlank         : numeric % Halstead's count of blank lines
16. lOCodeAndComment: numeric
17. uniq_Op         : numeric % unique operators
18. uniq_Opnd       : numeric % unique operands
19. total_Op        : numeric % total operators
20. total_Opnd      : numeric % total operands
21. branchCount     : numeric % of the flow graph
22. problems        : {false,true} % module has/has not one or more reported defects

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1066,kc1-binary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

1. Title: Class-level data for KC1
This one includes a {_TRUE,FALSE} attribute (DL) to indicate defectiveness.

2. Sources
(a) Creator: A. Gunes Koru
(b) Date: February 21, 2005
(c) Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843

3. Donor: A. Gunes Koru

4. Past Usage: This data was used for:

A. Gunes Koru and Hongfang Liu, ""An Investigation of the Effect
of Module Size on Defect Prediction Using Static Measures"", PROMISE -
Predictive Models in Software Engineering Workshop, ICSE 2005,
May 15th 2005, Saint Louis, Missouri, US.

We used several machine learning algorithms to predict the defective
modules in five NASA products, namely, CM1, JM1, KC1, KC2, and PC1.
A set of static measures were used as predictor variables. While doing
so, we observed that a large portion of the modules were small, as
measured by lines of code (LOC). When we experimented on the data
subsets created by partitioning according to module size, we obtained
higher prediction performance for the subsets that include larger
modules. We also performed defect prediction using class-level data
for KC1 rather than method-level data. In this case, the use of class-level
data resulted in improved prediction performance compared to using
method-level data. These findings suggest that quality assurance activities
can be guided even better if defect predictions are made by using
data that belong to larger modules.

5. Features:

The descriptions of the features are taken from
http://mdp.ivv.nasa.gov/mdp_glossary.html

Feature Used as the Response Variable:
======================================
DL: Defect level. _TRUE if the class contains one or more defects,
false otherwise.

Features at Class Level Originally
==================================

PERCENT_PUB_DATA:  The percentage of data that is public and protected data
in a class. In general, lower values indicate greater encapsulation. It is
measure of encapsulation.

ACCESS_TO_PUB_DATA: The amount of times that a class's public and protected
data is accessed. In general, lower values indicate greater encapsulation.
It is a measure of encapsulation.

COUPLING_BETWEEN_OBJECTS: The number of distinct non-inheritance-related
classes on which a class depends. If a class that is heavily dependent on
many classes outside of its hierarchy is introduced into a library, all the
classes upon which it depends need to be introduced as well. This may be
acceptable, especially if the classes which it references are already part
of a class library and are even more fundamental than the specified class.

DEPTH: The level for a class. For instance, if a parent has one child the
depth for the child is two. Depth indicates at what level a class is located
within its class hierarchy. In general, inheritance increases when depth
increases.

LACK_OF_COHESION_OF_METHODS: For each data field in a class, the percentage
of the methods in the class using that data field; the percentages are
averaged then subtracted from 100%. The locm metric indicates low or
high percentage of cohesion. If the percentage is low, the class is cohesive.
If it is high, it may indicate that the class could be split into separate
classes that will individually have greater cohesion.

NUM_OF_CHILDREN: The number of classes derived from a specified class.

DEP_ON_CHILD: Whether a class is dependent on a descendant.

FAN_IN: This is a count of calls by higher modules.

RESPONSE_FOR_CLASS: A count of methods implemented within a class plus the
number of methods accessible to an object class due to inheritance. In
general, lower values indicate greater polymorphism.

WEIGHTED_METHODS_PER_CLASS: A count of methods implemented within a class
(rather than all methods accessible within the class hierarchy). In general,
lower values indicate greater polymorphism.
Features Transformed to Class Level (Originally at Method Level)
================================================================

Transformation was achieved by obtaining min, max, sum, and avg values
over all the methods in a class. There this data set includes four
features for all of the following features that were originally at the
method level but transformed to the class level. For example, LOC_BLANK
has minLOC_BLANK, maxLOC_BLANK, avgLOC_BLANK, and maxLOC_BLANK.

LOC_BLANK: Lines with only white space or no text content.

BRANCH_COUNT: This metric is the number of branches for each module.
Branches are defined as those edges that exit from a decision node.
The greater the number of branches in a program's modules, the more
testing resource's required.

LOC_CODE_AND_COMMENT: Lines that contain both code and comment.

LOC_COMMENTS:  The number of lines in a module. This particular metric
includes all blank lines, comment lines, and source lines.

CYCLOMATIC_COMPLEXITY: It is a measure of the complexity of a modules
decision structure. It is the number of linearly independent paths.

DESIGN_COMPLEXITY: Design complexity is a measure of a module's decision
structure as it relates to calls to other modules. This quantifies the
testing effort related to integration.

ESSENTIAL_COMPLEXITY: Essential complexity is a measure of the degree to
which a module contains unstructured constructs.

LOC_EXECUTABLE:  Source lines of code that contain only code and white space.

HALSTEAD_CONTENT: Complexity of a given algorithm independent of the
language used to express the algorithm.

HALSTEAD_DIFFICULTY: Level of difficulty in the program.

HALSTEAD_EFFORT: Estimated mental effort required to develop the program.

HALSTEAD_ERROR_EST:  Estimated number of errors in the program.

HALSTEAD_LENGTH: This is a Halstead metric that includes the total number
of operator occurrences and total number of operand occurrences.

HALSTEAD_LEVEL: Level at which the program can be understood.

HALSTEAD_PROG_TIME: Estimated amount of time to implement the algorithm.

HALSTEAD_VOLUME: This is a Halstead metric that contains the minimum
number of bits required for coding the program.

NUM_OPERANDS: Variables and identifiers Constants (numeric literal/string)
Function names when used during calls.

NUM_UNIQUE_OPERANDS: Variables and identifiers Constants
(numeric literal/string) Function names when used during calls

NUM_UNIQUE_OPERATORS: Number of unique operators.

LOC_TOTAL: Total Lines of Code."
1067,kc1,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/kc1.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**KC1 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. Data from software for storage management for receiving and processing ground data. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Attribute Information  

1. loc             : numeric % McCabe's line count of code
2. v(g)            : numeric % McCabe ""cyclomatic complexity""
3. ev(g)           : numeric % McCabe ""essential complexity""
4. iv(g)           : numeric % McCabe ""design complexity""
5. n               : numeric % Halstead total operators + operands
6. v               : numeric % Halstead ""volume""
7. l               : numeric % Halstead ""program length""
8. d               : numeric % Halstead ""difficulty""
9. i               : numeric % Halstead ""intelligence""
10. e               : numeric % Halstead ""effort""
11. b               : numeric % Halstead 
12. t               : numeric % Halstead's time estimator
13. lOCode          : numeric % Halstead's line count
14. lOComment       : numeric % Halstead's count of lines of comments
15. lOBlank         : numeric % Halstead's count of blank lines
16. lOCodeAndComment: numeric
17. uniq_Op         : numeric % unique operators
18. uniq_Opnd       : numeric % unique operands
19. total_Op        : numeric % total operators
20. total_Opnd      : numeric % total operands
21. branchCount     : numeric % of the flow graph
22. problems        : {false,true} % module has/has not one or more reported defects

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1068,pc1,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc1.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  

**PC1 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Attribute Information  

1. loc             : numeric % McCabe's line count of code
2. v(g)            : numeric % McCabe ""cyclomatic complexity""
3. ev(g)           : numeric % McCabe ""essential complexity""
4. iv(g)           : numeric % McCabe ""design complexity""
5. n               : numeric % Halstead total operators + operands
6. v               : numeric % Halstead ""volume""
7. l               : numeric % Halstead ""program length""
8. d               : numeric % Halstead ""difficulty""
9. i               : numeric % Halstead ""intelligence""
10. e               : numeric % Halstead ""effort""
11. b               : numeric % Halstead 
12. t               : numeric % Halstead's time estimator
13. lOCode          : numeric % Halstead's line count
14. lOComment       : numeric % Halstead's count of lines of comments
15. lOBlank         : numeric % Halstead's count of blank lines
16. lOCodeAndComment: numeric
17. uniq_Op         : numeric % unique operators
18. uniq_Opnd       : numeric % unique operands
19. total_Op        : numeric % total operators
20. total_Opnd      : numeric % total operands
21. branchCount     : numeric % of the flow graph
22. branchCount     : numeric % of the flow graph
23. defects         : {false,true} % module has/has not one or more reported defects

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1069,pc2,"**Author**: Mike Chapman, NASA  
**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc2.html) - 2004  
**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  
  
**PC2 Software defect prediction**  
One of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.

### Relevant papers  

- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)
Data Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.

- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance
Software Engineering.

- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects"", Workshop on Predictive Software Models, Chicago"
1070,kc1-numeric,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

1. Title: Class-level data for KC1
This one includes a numeric attribute (NUMDEFECTS) to indicate defectiveness.

2. Sources
(a) Creator: A. Gunes Koru
(b) Date: February 21, 2005
(c) Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843

3. Donor: A. Gunes Koru

4. Past Usage: This data set was used for:

A. Gunes Koru and Hongfang Liu, ""An Investigation of the Effect
of Module Size on Defect Prediction Using Static Measures"", PROMISE -
Predictive Models in Software Engineering Workshop, ICSE 2005,
May 15th 2005, Saint Louis, Missouri, US.

We used several machine learning algorithms to predict the defective
modules in five NASA products, namely, CM1, JM1, KC1, KC2, and PC1.
A set of static measures were used as predictor variables. While doing
so, we observed that a large portion of the modules were small, as
measured by lines of code (LOC). When we experimented on the data
subsets created by partitioning according to module size, we obtained
higher prediction performance for the subsets that include larger
modules. We also performed defect prediction using class-level data
for KC1 rather than method-level data. In this case, the use of class-level
data resulted in improved prediction performance compared to using
method-level data. These findings suggest that quality assurance activities
can be guided even better if defect predictions are made by using
data that belong to larger modules.

5. Features:

The descriptions of the features are taken from
http://mdp.ivv.nasa.gov/mdp_glossary.html

Feature Used as the Response Variable:
======================================
NUMDEFECTS: The number of defects recorded for the class,

Features at Class Level Originally
==================================

PERCENT_PUB_DATA:  The percentage of data that is public and protected data
in a class. In general, lower values indicate greater encapsulation. It is
measure of encapsulation.

ACCESS_TO_PUB_DATA: The amount of times that a class's public and protected
data is accessed. In general, lower values indicate greater encapsulation.
It is a measure of encapsulation.

COUPLING_BETWEEN_OBJECTS: The number of distinct non-inheritance-related
classes on which a class depends. If a class that is heavily dependent on
many classes outside of its hierarchy is introduced into a library, all the
classes upon which it depends need to be introduced as well. This may be
acceptable, especially if the classes which it references are already part
of a class library and are even more fundamental than the specified class.

DEPTH: The level for a class. For instance, if a parent has one child the
depth for the child is two. Depth indicates at what level a class is located
within its class hierarchy. In general, inheritance increases when depth
increases.

LACK_OF_COHESION_OF_METHODS: For each data field in a class, the percentage
of the methods in the class using that data field; the percentages are
averaged then subtracted from 100%. The locm metric indicates low or
high percentage of cohesion. If the percentage is low, the class is cohesive.
If it is high, it may indicate that the class could be split into separate
classes that will individually have greater cohesion.

NUM_OF_CHILDREN: The number of classes derived from a specified class.

DEP_ON_CHILD: Whether a class is dependent on a descendant.

FAN_IN: This is a count of calls by higher modules.

RESPONSE_FOR_CLASS: A count of methods implemented within a class plus the
number of methods accessible to an object class due to inheritance. In
general, lower values indicate greater polymorphism.

WEIGHTED_METHODS_PER_CLASS: A count of methods implemented within a class
(rather than all methods accessible within the class hierarchy). In general,
lower values indicate greater polymorphism.
Features Transformed to Class Level (Originally at Method Level)
================================================================

Transformation was achieved by obtaining min, max, sum, and avg values
over all the methods in a class. There this data set includes four
features for all of the following features that were originally at the
method level but transformed to the class level. For example, LOC_BLANK
has minLOC_BLANK, maxLOC_BLANK, avgLOC_BLANK, and maxLOC_BLANK.

LOC_BLANK: Lines with only white space or no text content.

BRANCH_COUNT: This metric is the number of branches for each module.
Branches are defined as those edges that exit from a decision node.
The greater the number of branches in a program's modules, the more
testing resource's required.

LOC_CODE_AND_COMMENT: Lines that contain both code and comment.

LOC_COMMENTS:  The number of lines in a module. This particular metric
includes all blank lines, comment lines, and source lines.

CYCLOMATIC_COMPLEXITY: It is a measure of the complexity of a modules
decision structure. It is the number of linearly independent paths.

DESIGN_COMPLEXITY: Design complexity is a measure of a module's decision
structure as it relates to calls to other modules. This quantifies the
testing effort related to integration.

ESSENTIAL_COMPLEXITY: Essential complexity is a measure of the degree to
which a module contains unstructured constructs.

LOC_EXECUTABLE:  Source lines of code that contain only code and white space.

HALSTEAD_CONTENT: Complexity of a given algorithm independent of the
language used to express the algorithm.

HALSTEAD_DIFFICULTY: Level of difficulty in the program.

HALSTEAD_EFFORT: Estimated mental effort required to develop the program.

HALSTEAD_ERROR_EST:  Estimated number of errors in the program.

HALSTEAD_LENGTH: This is a Halstead metric that includes the total number
of operator occurrences and total number of operand occurrences.

HALSTEAD_LEVEL: Level at which the program can be understood.

HALSTEAD_PROG_TIME: Estimated amount of time to implement the algorithm.

HALSTEAD_VOLUME: This is a Halstead metric that contains the minimum
number of bits required for coding the program.

NUM_OPERANDS: Variables and identifiers Constants (numeric literal/string)
Function names when used during calls.

NUM_UNIQUE_OPERANDS: Variables and identifiers Constants
(numeric literal/string) Function names when used during calls

NUM_UNIQUE_OPERATORS: Number of unique operators.

LOC_TOTAL: Total Lines of Code."
1071,mw1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%-*- text -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE data set made publicly available in order to encourage
repeatable, verifiable, refutable, and/or improvable predictive models
of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
1. Title/Topic: MW1/software defect prediction

(c) 2007 : Tim Menzies  : tim@menzies.us
This data set is distributed under the
Creative Commons Attribution-Share Alike 3.0 License
http://creativecommons.org/licenses/by-sa/3.0/

You are free:

* to Share -- copy, distribute and transmit the work
* to Remix -- to adapt the work

Under the following conditions:

Attribution. You must attribute the work in the manner specified by
the author or licensor (but not in any way that suggests that they endorse
you or your use of the work).

Share Alike. If you alter, transform, or build upon this work, you
may distribute the resulting work only under the same, similar or a
compatible license.

* For any reuse or distribution, you must make clear to others the
license terms of this work.
* Any of the above conditions can be waived if you get permission from
the copyright holder.
* Apart from the remix rights granted under this license, nothing in
this license impairs or restricts the author's moral rights.
For more deatils on this data set, see
http://promisedata.org/repository/data/kc2/kc2.arff"
1072,qqdefects_numeric,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promisedata.org/repository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
(c) 2007  Norman Fenton
This data set is distributed under the
Creative Commons Attribution-Share Alike 3.0 License
http://creativecommons.org/licenses/by-sa/3.0/

You are free:

* to Share -- copy, distribute and transmit the work
* to Remix -- to adapt the work

Under the following conditions:

Attribution. You must attribute the work in the manner specified by
the author or licensor (but not in any way that suggests that they endorse
you or your use of the work).

Share Alike. If you alter, transform, or build upon this work, you
may distribute the resulting work only under the same, similar or a
compatible license.

* For any reuse or distribution, you must make clear to others the
license terms of this work.
* Any of the above conditions can be waived if you get permission from
the copyright holder.
* Apart from the remix rights granted under this license, nothing in
this license impairs or restricts the author's moral rights.

Qualitative and quantitative data about 31 projects completed in a
consumer electronics company (one row per project).
There
is a mixture of qualitative attributes (these are measured on a 5
point ranked scale VL, L, M, H, VH) and quantitative attributes
whose scale is stated.
from..
Title:
Project Data Incorporating Qualitative Factors for Improved Software Defect;
Author(s):
Norman Fenton and Martin Neil and William Marsh and Peter Hearty and Lukasz Radlinski and Paul Krause;
Published in:
in Proceedings of the PROMISE workshop;
Year:
2007;
attributes:
S1	Relevant Experience of Spec & Doc Staff
S2	Quality of Documentation inspected
S3	Regularity of Spec & Doc Reviews
S4	Standard Procedures Followed
S5	Quality of Documentation inspected
S6	Spec Defects Discovered in Review
S7	Requirements Stability
F1	Complexity of new functionality
F2	Scale of New functionality implemented
F3	Total no. of Inputs and Outputs
D1	Relevant Development Staff Experience
D2	Programmer capability
D3	Defined processes followed
D4	Development Staff motivation
T1	Testing Process Well Defined
T2	Testing Staff Experience
T3	Testing Staff Experience
T4	Quality of Documented Test Cases
P1	Dev. Staff Training Quality
P2	Requirements Management
P3	Project Planning
P4	Scale of Distributed Communication
P5	Stake-holder involvement
P6	Stake-holder involvement
P7	Vendor Management
P8	Internal communication/interaction
P9	Process Maturity
E	Total Effort
K	KLOC
L	Language
TD	Testing Defects (Pre+ Post)"
1073,jEdit_4.0_4.2,
1075,datatrieve,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
1. Title/Topic: The transition of the DATATRIEVE product from version 6.0 to
version 6.1

2. Sources:
-- Creators: DATATRIEVETM project carried out at Digital Engineering Italy
-- Donor: Guenther Ruhe
-- Date:  January 15, 2005
3. Past usage:

A hybrid approach to analyze empirical software engineering data
and its application to predict module fault-proneness in maintenance
Source 	Journal of Systems and Software archive
Volume 53 ,  Issue 3  (September 2000) table of contents
Pages: 225 - 237
Year of Publication: 2000
ISSN:0164-1212
Authors
Sandro Morasca
Gunther Ruhe
4. Relevant information:

The DATATRIEVE product was undergoing both adaptive (DATATRIEVE was being transferred
from platform OpenVMS/VAX to platform OpenVMS/Alpha) and corrective maintenance
(failures reported from customers were being fixed) at the Gallarate (Italy)
site of Digital Engineering.

The DATATRIEVE product was originally developed in the BLISS language. BLISS is an
expression language. It is block-structured, with exception handling facilities, coroutines,
and a macro system. It was one of the first non-assembly languages for operating system
implementation.. Some parts were later added or rewritten in the C language. Therefore, the
overall structure of DATATRIEVE is composed of C functions and BLISS subroutines.

The empirical study of this data set reports only the BLISS part, by far the bigger one.
In what follows, we will use the term ""module"" to refer to a BLISS module, i.e., a set of
declarations and subroutines usually belonging to one file. More than 100 BLISS modules
have been studied. It was important to the DATATRIEVE team to better understand how the
characteristics of the modules and transition process were correlated with the code quality.

The objective of the data analysis was to study whether it was possible to classify modules as
non-faulty or faulty, based on a set of measures collected on the project.

5. Number of records: 130
6. Number of attributes: 9
8 condition attributes
1 decision attribute
7. Attribute Information:

1. LOC6_0: number of lines of code of module m in version 6.0.
2. LOC6_1: number of lines of code of module m in version 6.1.
3. AddedLOC: number of lines of code that were added to module m in version 6.1, i.e., they
were not present in module m in version 6.0.
4. DeletedLOC: number of lines of code that were deleted from module m in version 6.0, i.e.,
they were no longer present in module m in version 6.1.
5. DifferentBlocks: number of different blocks module m in between versions 6.0 and 6.1.
6. ModificationRate: rate of modification of module m, i.e.,
(AddedLOC + DeletedLOC) / (LOC6.0 + AddedLOC).
7. ModuleKnowledge: subjective variable that expresses the project team's knowledge on
module m (low or high)
8. ReusedLOC: number of lines of code of module m in version 6.0 reused in module m in
version 6.1.
9. Faulty6_1: its value is 0 for all those modules in which no faults were found;
its value is 1 for all other modules.

8. Missing attributes: none

9. Class Distribution:
0:   119 = 91.54%
1:   11  =  8.46%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
1076,nasa_numeric,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

%-*- text -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a PROMISE Software Engineering Repository data set made publicly
available in order to encourage repeatable, verifiable, refutable, and/or
improvable predictive models of software engineering.

If you publish material based on PROMISE data sets then, please
follow the acknowledgment guidelines posted on the PROMISE repository
web page http://promise.site.uottawa.ca/SERepository .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
1. Title/Topic: COCOMO NASA 2 / Software cost estimation
2. Sources:

-- 93 NASA projects from different centers
for projects from the following years:

n year
--- ----
1 1971
1 1974
2 1975
2 1976
10 1977
4 1978
19 1979
11 1980
13 1982
7 1983
7 1984
6 1985
8 1986
2 1987

Collected by
Jairus Hihn, JPL, NASA, Manager SQIP Measurement &
Benchmarking Element
Phone (818) 354-1248 (Jairus.M.Hihn@jpl.nasa.gov)

-- Donor: Tim Menzies (tim@menzies.us)

-- Date: Feb 8 2006

3. Past Usage
None with this specific data set. But for older work on similar data, see:

1. ""Validation Methods for Calibrating Software Effort
Models"", T. Menzies and D. Port and Z. Chen and
J. Hihn and S. Stukes, Proceedings ICSE 2005,
http://menzies.us/pdf/04coconut.pdf
-- Results
-- Given background knowledge on 60 prior projects,
a new cost model can be tuned to local data using
as little as 20 new projects.
-- A very simple calibration method (COCONUT) can
achieve PRED(30)=7% or PRED(20)=50% (after 20 projects).
These are results seen in 30 repeats of an incremental
cross-validation study.
-- Two cost models are compared; one based on just
lines of code and one using over a dozen ""effort
multipliers"". Just using lines of code loses 10 to 20
PRED(N) points.

3.1 Additional Usage:
2. ""Feature Subset Selection Can Improve Software Cost Estimation Accuracy""
Zhihao Chen, Tim Menzies, Dan Port and Barry Boehm
Proceedings PROMISE Workshop 2005,
http://www.etechstyle.com/chen/papers/05fsscocomo.pdf
P02, P03, P04 are used in this paper.
-- Results
-- To the best of our knowledge, this is the first report
of applying feature subset selection (FSS)
to software effort data.

-- FSS can dramatically improve cost estimation.

---T-tests are applied to the results to demonstrate
that always in our data sets, removing
attributes improves performance without increasing the
variance in model behavior.

4. Relevant Information

The COCOMO software cost model measures effort in calendar months
of 152 hours (and includes development and management hours).
COCOMO assumes that the effort grows more than linearly on
software size; i.e. months=a* KSLOC^b*c. Here, ""a"" and ""b"" are
domain-specific parameters; ""KSLOC"" is estimated directly or
computed from a function point analysis; and ""c"" is the product
of over a dozen ""effort multipliers"". I.e.

months=a*(KSLOC^b)*(EM1* EM2 * EM3 * ...)

The effort multipliers are as follows:

increase | acap | analysts capability
these to | pcap | programmers capability
decrease  | aexp | application experience
effort  | modp | modern programing practices
| tool | use of  software tools
| vexp | virtual machine experience
| lexp | language experience
----------+------+---------------------------
| sced | schedule constraint
----------+------+---------------------------
decrease | stor | main memory constraint
these to | data | data base size
decrease | time | time constraint for cpu
effort | turn | turnaround time
| virt | machine volatility
| cplx | process complexity
| rely | required software reliability

In COCOMO I, the exponent on KSLOC was a single value ranging from
1.05 to 1.2.  In COCOMO II, the exponent ""b"" was divided into a
constant, plus the sum of five ""scale factors"" which modeled
issues such as ``have we built this kind of system before?''.  The
COCOMO~II effort multipliers are similar but COCOMO~II dropped one
of the effort multiplier parameters; renamed some others; and
added a few more (for ""required level of reuse"", ""multiple-site
development"", and ""schedule pressure"").

The effort multipliers fall into three groups: those that are
positively correlated to more effort; those that are
negatively correlated to more effort; and a third group
containing just schedule information. In COCOMO~I, ""sced"" has a
U-shaped correlation to effort; i.e. giving programmers either
too much or too little time to develop a system can be
detrimental.

The numeric values of the effort multipliers are:

very				very	extra	productivity
low	low	nominal	high	high	high	range
---------------------------------------------------------------------
acap	1.46   	1.19   	1.00   	0.86   	0.71   		2.06
pcap	1.42.  	1.17   	1.00   	0.86   	0.70 		1.67
aexp   	1.29   	1.13   	1.00   	0.91   	0.82   		1.57
modp   	1.24.  	1.10 	1.00 	0.91 	0.82 		1.34
tool   	1.24 	1.10 	1.00 	0.91 	0.83 		1.49
vexp   	1.21 	1.10 	1.00 	0.90 	  		1.34
lexp   	1.14 	1.07 	1.00 	0.95 	  		1.20
sced   	1.23 	1.08 	1.00 	1.04 	1.10 	  	e
stor   	       	       	1.00   	1.06   	1.21   	1.56	-1.21
data   	    	 0.94 	1.00 	1.08 	1.16		-1.23
time   	  	    	1.00   	1.11   	1.30   	1.66	-1.30
turn   	       	0.87   	1.00   	1.07   	1.15   		-1.32
virt   	       	0.87   	1.00   	1.15   	1.30   		-1.49
rely   	0.75	 0.88	 1.00 	 1.15 	 1.40		-1.87
cplx   	0.70 	0.85 	1.00 	1.15 	1.30 	1.65	-2.36

These were learnt by Barry Boehm after a regression analysis of the
projects in the COCOMO I data set.
@Book{boehm81,
Author    =	 ""B. Boehm"",
Title     =	 ""Software Engineering Economics"",
Publisher =	 ""Prentice Hall"",
Year      =	 1981}

The last column of the above table shows max(E)/min(EM) and shows
the overall effect of a single effort multiplier. For example,
increasing ""acap"" (analyst experience) from very low to very
high will most decrease effort while increasing ""rely""
(required reliability) from very low to very high will most
increase effort.

There is much more to COCOMO that the above description. The
COCOMO~II text is over 500 pages long and offers
all the details needed to implement data capture and analysis of
COCOMO in an industrial context.
@Book{boehm00b,
Author = ""Barry Boehm and Ellis Horowitz and Ray Madachy and
Donald Reifer and Bradford K. Clark and Bert Steece
and A. Winsor Brown and Sunita Chulani and Chris Abts"",
Title = ""Software Cost Estimation with Cocomo II"",
Publisher = ""Prentice Hall"",
Year = 2000,
ibsn = ""0130266922""}

Included in that book is not just an effort model but other
models for schedule, risk, use of COTS, etc.  However, most
(?all) of the validation work on COCOMO has focused on the effort
model.
@article{chulani99,
author =	 ""S. Chulani and B. Boehm and B. Steece"",
title =	 ""Bayesian Analysis of Empirical Software Engineering
Cost Models"",
journal =	 ""IEEE Transaction on Software Engineering"",
volume =	 25,
number =	 4,
month =	 ""July/August"",
year =	 ""1999""}

The value of an effort predictor can be reported many ways
including MMRE and PRED(N).MMRE and PRED are computed from the
relative error, or RE, which is the relative size of the
difference between the actual and estimated value:

RE.i = (estimate.i - actual.i) / (actual.i)

Given a data set of of size ""D"", a ""Train""ing set of size
""(X=|Train|) <= D"", and a ""test"" set of size ""T=D-|Train|"", then
the mean magnitude of the relative error, or MMRE, is the
percentage of the absolute values of the relative errors,
averaged over the ""T"" items in the ""Test"" set; i.e.

MRE.i  = abs(RE.i)
MMRE.i = 100/T*( MRE.1 + MRE.2 + ... + MRE.T)

PRED(N) reports the average percentage of estimates that were
within N% of the actual values:

count=0
for(i=1;i<=T;i++) do if (MRE.i <= N/100) then count++ fi done
PRED(N) = 100/T * sum

For example, e.g. PRED(30)=50% means that half the estimates are
within 30% of the actual.  Shepperd and Schofield comment that
""MMRE is fairly conservative with a bias against overestimates
while Pred(25) will identify those prediction systems that are
generally accurate but occasionally wildly inaccurate"".
@article{shepperd97,
author=""M. Shepperd and C. Schofield"",
title=""Estimating Software Project Effort Using Analogies"",
journal=""IEEE Transactions on Software Engineering"",
volume=23,
number=12,
month=""November"",
year=1997,
note=""Available from
\url{http://www.utdallas.edu/~rbanker/SE_XII.pdf}""}

5. Number of instances: 93
6. Number of attributes: 24
- 15 standard COCOMO-I discrete  attributes in the range Very_Low to
Extra_High
- 7 others describing the project;
- one lines of code measure,
- one goal field being the actual effort in person months.
7. Attribute information:
Unique id
project name
cagetory of application
flight or ground system?
which nasa center?
year of development
development mode
cocomo attributes: described above in section 4
equivalent physical 1000 lines of source code
development effort in months (one month =152 hours and includes development and management hours)
Section 8. Missing attributes: none
Section 9: Distribution of class values

#  development months
== ==================
46    0 - 499
28  500 - 999
7 1000 - 1499
3 1500 - 1999
3 2000 - 2499
3 2500 - 2999
0 3000 - 3999
1 4000 - 4499
1 4500 - 4999
0 5000 - 7999
1 8000"
1077,rsctc2010_1,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. Example datasets for 6 different problems of DNA microarray data analysis and classification. All datasets contain gene expression data characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. 

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1078,rsctc2010_2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. Example datasets for 6 different problems of DNA microarray data analysis and classification. All datasets contain gene expression data characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. 

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1079,rsctc2010_3,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. Example datasets for 6 different problems of DNA microarray data analysis and classification. All datasets contain gene expression data characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. 

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1080,rsctc2010_4,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. Example datasets for 6 different problems of DNA microarray data analysis and classification. All datasets contain gene expression data characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. 

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1081,rsctc2010_5,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. Example datasets for 6 different problems of DNA microarray data analysis and classification. All datasets contain gene expression data characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. 

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1082,rsctc2010_6,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. Example datasets for 6 different problems of DNA microarray data analysis and classification. All datasets contain gene expression data characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. 

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1083,mouseType,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. All datasets contain between 100 and 400 samples, characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. Attributes are normalized in some way - in test data you should expect similar distributions of attribute values as in the example data.

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1084,BurkittLymphoma,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. All datasets contain between 100 and 400 samples, characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. Attributes are normalized in some way - in test data you should expect similar distributions of attribute values as in the example data.

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1085,anthracyclineTaxaneChemotherapy,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. All datasets contain between 100 and 400 samples, characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. Attributes are normalized in some way - in test data you should expect similar distributions of attribute values as in the example data.

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1086,ovarianTumour,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. All datasets contain between 100 and 400 samples, characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. Attributes are normalized in some way - in test data you should expect similar distributions of attribute values as in the example data.

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1087,hepatitisC,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. All datasets contain between 100 and 400 samples, characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. Attributes are normalized in some way - in test data you should expect similar distributions of attribute values as in the example data.

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1088,variousCancers_final,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data from the RSCTC 2010 Discovery Challenge. All datasets contain between 100 and 400 samples, characterized by values of 20,000 - 65,000 attributes. Samples are assigned to several (2-10) classes. All attributes are numeric and represent measurements from DNA microarrays. Attributes are normalized in some way - in test data you should expect similar distributions of attribute values as in the example data.

Source: http://tunedit.org/challenge/RSCTC-2010-A"
1089,USCrime,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/USCrime.html

US Crime

Reference:   Vandaele, W. (1978) Participation in illegitimate activities:  Erlich revisited.  In Deterrence and incapacitation, Blumstein, A., Cohen, J. and Nagin, D., eds., Washington, D.C.:  National Academy of Sciences, 270-335.
Methods:  A Primer, New York:  Chapman & Hall, 11.
Also found in:  Hand, D.J., et al. (1994) A Handbook of Small Data Sets, London:  Chapman & Hall, 101-103.
Authorization:   Contact author
Description:   These data are crime-related and demographic statistics for 47 US states in 1960.  The data were collected from the FBI's Uniform Crime Report and other government agencies to determine how the variable crime rate depends on the other variables measured in the study.
Number of cases:   47
Variable Names:

R:   Crime rate:  # of offenses reported to police per million population
Age:   The number of males of age 14-24 per 1000 population
S:   Indicator variable for Southern states (0 = No, 1 = Yes)
Ed:   Mean # of years of schooling x 10 for persons of age 25 or older
Ex0:   1960 per capita expenditure on police by state and local government
Ex1:   1959 per capita expenditure on police by state and local government
LF:   Labor force participation rate per 1000 civilian urban males age 14-24
M:   The number of males per 1000 females
N:   State population size in hundred thousands
NW:   The number of non-whites per 1000 population
U1:   Unemployment rate of urban males per 1000 of age 14-24
U2:   Unemployment rate of urban males per 1000 of age 35-39
W:   Median value of transferable goods and assets or family income in tens of $
X:   The number of families per 1000 earning below 1/2 the median income"
1090,MercuryinBass,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/MercuryinBass.html

Mercury Contamination in Bass

Reference:    Lange, Royals, & Connor. (1993). Transactions of the American Fisheries Society .
Authorization:   contact authors
Description:   Largemouth bass were studied in 53 different Florida lakes to examine the factors that influence the level of mercury contamination.  Water samples were collected from the surface of the middle of each lake in August 1990 and then again in March 1991. The pH level, the amount of chlorophyll, calcium, and alkalinity were measured in each sample. The average of the August and March values were used in the analysis. Next, a sample of fish was taken from each lake with sample sizes ranging from 4 to 44 fish. The age of each fish and mercury concentration in the muscle tissue was measured. (Note: Since fish absorb mercury over time, older fish will tend to have higher concentrations). Thus, to make a fair comparison of the fish in different lakes, the investigators used a regression estimate of the expected mercury concentration in a three year old fish as the standardized value for each lake. Finally, in 10 of the 53 lakes, the age of the individual fish could not be determined and the average mercury concentration ofthe sampled fish was used instead of the standardized value.
Number of cases:   53
Variable Names:

ID:   ID number
Lake:   Name of the lake
Alkalinity:   Alkalinity (mg/L as Calcium Carbonate)
pH:   pH
Calcium:   Calcium (mg/l)
Chlorophyll:   Chlorophyll (mg/l)
Avg_Mercury:   Average mercury concentration (parts per million) in the muscle tissue of the fish sampled from that lake
No.samples:   How many fish were sampled from the lake
min:   Minimum mercury concentration amongst the sampled fish
max:   Maximum mercury concentration amongst the sampled fish
3_yr_Standard_mercury :   Regression estimate of the mercury concentration in a 3 year old fish from the lake (or = Avg Mercury when age data was not available)
age_data:   Indicator of the availability of age data on fish sampled"
1091,SMSA,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/SMSA.html

Air Pollution and Mortality

Reference:   U.S. Department of Labor Statistics
Authorization:   free use
Description:   Properties of 60 Standard Metropolitan Statistical Areas (a standard Census Bureau designation of the region around a city) in the United States, collected from a variety of sources.
The data include information on the social and economic conditions in these areas, on their climate, and some indices of air pollution potentials.
Number of cases:   60
Variable Names:

city:   City name
JanTemp:   Mean January temperature (degrees Farenheit)
JulyTemp:   Mean July temperature (degrees Farenheit)
RelHum:   Relative Humidity
Rain:   Annual rainfall (inches)
Mortality:   Age adjusted mortality
Education:   Median education
PopDensity:   Population density
%NonWhite:   Percentage of non whites
%WC:   Percentage of white collar workers
pop:   Population
pop/house:   Population per household
income:   Median income
HCPot:   HC pollution potential
NOxPot:   Nitrous Oxide pollution potential
SO2Pot:   Sulfur Dioxide pollution potential
NOx:   Nitrous Oxide"
1092,Crash,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/Crash.html

Crash Test Dummies

Reference:   National Transportation Safety Administration
Authorization:   free use
Description:   Data based on trials in which stock automobiles are crashed into a wall at 35MPH with dummies in the driver and front passenger seat.


Number of cases:   352
Variable Names:

make:   Car make
Model:   Model of that car
carID:   Usually the combination of make and model
carID_&_Year:   Full ID of the car
Head_IC:   Head injury criterion
Chest_decel:   Chest deceleration
L_Leg:   Left femur load
R_Leg:   Right femur load
D/P:   Whether the dummy is in the Driver or Passenger seat
Protection:   Kind of protection (seat belt, air bag, etc.)
Doors:   Number of doors on the car
Year:   Year of the car
Wt:   Weight in pounds
Size:   A categorical variable to classify the cars to a type (light, minivan)"
1093,Brainsize,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/Brainsize.html

Brain Size and Intelligence

Reference:   Willerman, L., Schultz, R., Rutledge, J. N., and Bigler, E. (1991), ""In Vivo  Brain Size and Intelligence,"" Intelligence, 15, 223-228.

Authorization:   Contact authors
Description:   Willerman et al. (1991) collected a sample of  40 right-handed Anglo introductory psychology students at a large southwestern university. Subjects took  four subtests (Vocabulary, Similarities, Block Design, and Picture Completion) of the Wechsler (1981) Adult Intelligence Scale-Revised.   The researchers used Magnetic Resonance Imaging (MRI) to determine the brain size of the subjects.  Information about gender and body size (height and weight) are also included.  The researchers withheld the weights of two subjects and the height of one subject for reasons of confidentiality.

Number of cases:   40
Variable Names:

Gender:   Male or Female
FSIQ:   Full Scale IQ scores based on the four Wechsler (1981) subtests
VIQ:   Verbal IQ scores based on the four Wechsler (1981) subtests
PIQ:   Performance IQ scores based on the four Wechsler (1981) subtests
Weight:   body weight in pounds
Height:   height in inches
MRI_Count:   total pixel Count from the 18 MRI scans"
1094,Acorns,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/Acorns.html

Acorn Size Oak Distribution

Reference:   Aizen and Patterson.  (1990). Journal of Biogeography, volume 17,  p. 327-332.
Authorization:   contact authors
Description:   Interest lies is the relationship between the size of the acorn and the geographic range of the oak tree species.  Note that the Quercus tomentella Engelm species in the California region grows only on the Channel Islands (total area 1014 sq. km) and the island of Guadalupe (total area 265 sq. km).  All other species grow on the Continental United States.
Number of cases:   39
Variable Names:

Species:   Latin name of the species
Region:   Atlantic or California region
Range:   The geographic area covered by the species in km2x100
Acorn_size:   Acorn size (cm3)
Tree_height:   Tree Height (m)"
1096,FacultySalaries,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/FacultySalaries.html

Professors' Pay

Reference:   ""Faculty Compensation and Benefits Committee."" (1993, April).  Ohio State University
Authorization:   free use
Description:   Average salaries for professors at the top 50 universities of the Association of American Universities.  Salaries of full, associate and assistant professors at these universities are provided.  1992-1993 data from Clark University are not available; 1991-1992 salaries were substituted.
* Note that the ""Big Ten"" has 11 schools in it (since Penn State joined the original 10 schools)
Number of cases:   50
Variable Names:

University:   Name of the university
CIC.institutions:   1 if in the Committee on Institutional Cooperation (the Big Ten* plus University of Chicago); 0 if the university is not in the CIC
average.salary:   Average salary for all professors at the university assuming that the proportions of faculty in each rank are the same as those proportions at the Ohio State University
full.prof.salary:   Average salary for full professors at the university in 1992
assoc.prof.salary:   Average salary for associate professors at the university in 1992
asst.prof.salary:   Average salary for assistant professors at the university in 1992"
1097,ICU,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/ICU.html

Reference:
Authorization:   Contact authors
Description:   The data consist of 200 subjects from a larger study on the survival of patients following admission to an adult intensive care unit (ICU).  The study used logistic regression to predict the probability of survival for these patients until their discharge from the hospital.  The dependent variable is the binary variable Vital Status (STA).  Nineteen possible predictor variables, both discrete and continuous, were also observed.

Number of cases:   200
Variable Names:

ID:   ID number of the patient
STA:   Vital status (0 = Lived, 1 = Died)
AGE:   Patient's age in years
SEX:   Patient's sex (0 = Male, 1 = Female)
RACE:   Patient's race (1 = White, 2 = Black, 3 = Other)
SER:   Service at ICU admission (0 = Medical, 1 = Surgical)
CAN:   Is cancer part of the present problem? (0 = No, 1 = Yes)
CRN:   History of chronic renal failure (0 = No, 1 = Yes)
INF:"
1098,pubexpendat,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/pubexpendat.html

State Public Expenditures
State Spending and Ability to Pay


Reference:  U.S. Department of Commerce, Bureau of the Census, Government Finances
in 1960, Census of Population, 1960,  Census of Manufactures, 1958,  Statistical
Abstract of the United States, 1961.
U.S. Department of Agriculture, Agricultural Statistics, 1961.
U.S. Department of the Interior, Minerals Yearbook, 1960.


Authorization:   free use
Description:  Per capita state and local public expenditures and associated state demographic and
economic characteristics, 1960.

Number of cases:   48

Variable Names:

EX: Per capita state and local public expenditures ($)
ECAB: Economic ability index, in which income, retail sales, and the value of
output (manufactures, mineral, and agricultural) per capita are
equally weighted.
MET: Percentage of population living in standard metropolitan areas
GROW: Percent change in population, 1950-1960
YOUNG: Percent of population aged 5-19 years
OLD: Percent of population over 65 years of age
WEST: Western state (1) or not (0)"
1099,EgyptianSkulls,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/EgyptianSkulls.html

Egyptian Skull Development

Reference:   Thomson, A. and Randall-Maciver, R. (1905) Ancient Races of the Thebaid, Oxford:  Oxford University Press.
Also found in:  Hand, D.J., et al. (1994) A Handbook of Small Data Sets, New York:  Chapman & Hall, pp. 299-301.
Manly, B.F.J. (1986) Multivariate Statistical Methods, New York:  Chapman & Hall.
Authorization:   Contact Authors
Description:   Four measurements of male Egyptian skulls from 5 different time periods.  Thirty skulls are measured from each time period.


Number of cases:   150
Variable Names:

MB:   Maximal Breadth of Skull
BH:   Basibregmatic Height of Skull
BL:   Basialveolar Length of Skull
NH:   Nasal Height of Skull
Year:   Approximate Year of Skull Formation (negative = B.C., positive = A.D.)"
1100,PopularKids,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.
Source: TunedIT: http://tunedit.org/repo/DASL

DASL file http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html

Students' Goals
,

What Makes Kids Popular

Reference:   Chase, M. A., and Dummer, G. M. (1992), ""The Role of Sports as a Social Determinant for Children,"" Research Quarterly for Exercise and Sport, 63, 418-424

Authorization:   Contact authors
Description:        Subjects were students in grades 4-6 from three school districts in Ingham and Clinton Counties, Michigan.  Chase and Dummer stratified their sample, selecting students from urban, suburban, and rural school districts with approximately 1/3 of their sample coming from each district.  Students indicated whether good grades, athletic ability, or popularity was most important to them.  They also ranked four factors:  grades, sports, looks, and money, in order of their importance for popularity.  The questionnaire also asked for gender, grade level, and other demographic information.
Number of cases:   478
Variable Names:

Gender:   Boy or girl
Grade:   4, 5 or 6
Age:   Age in years
Race:   White, Other
Urban/Rural:   Rural, Suburban, or Urban school district
School:   Brentwood Elementary, Brentwood Middle, Ridge, Sand, Eureka, Brown, Main, Portage, Westdale Middle
Goals:   Student's choice in the personal goals question where options were 1 = Make Good Grades,  2 = Be Popular,  3 = Be Good in Sports
Grades:   Rank of ""make good grades""  (1=most important for popularity, 4=least important)
Sports:   Rank of ""being good at sports""  (1=most important for popularity, 4=least important)
Looks:   Rank of ""being handsome or pretty""  (1=most important for popularity, 4=least important)
Money:   Rank of ""having lots of money""  (1=most important for popularity, 4=least important)"
1101,lymphoma_2classes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1102,lymphoma_9classes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1103,yeast_gene,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Systematic determination of genetic network architecture.

Nature Genetics, 1999 Jul;22(3):281-5.
Data also used in Biclustering of Expression Data, by Yizong Cheng and George M. Church (web supplement)

S. Tavazoie, J.D. Hughes, M.J. Campbell, R.J. Cho, G.M. Church.
Dataset (17 instances x 1884 genes) in ARFF format, no labelled classes"
1104,leukemia,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring.

Science, VOL 286, pp. 531-537, 15 October 1999.
Web supplement to the article

T.R. Golub, D. K. Slonim, P. Tamayo, C. Huard, M. Gaasenbeek, J. P. Mesirov, H. Coller, M. L. Loh, J. R. Downing, M. A. Caligiuri, C. D. Bloomfield, E. S. Lander.

Original training test consists of 38 first instances."
1106,GCM,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Multiclass cancer diagnosis using 16063 tumor gene expression signatures.
PNAS, VOL 98, no 26, pp. 15149-15154, December 18, 2001.

S. Ramaswamy, P. Tamayo, R. Rifkin, S. Mukherjee, C.-H. Yeang, M. Angelo, C. Ladd, M. Reich, E. Latulippe, J.P. Mesirov, T. Poggio, W. Gerald, M. Loda, E.S. Lander and T.R. Golub.

Original split: 144 first instances for training, remainder for testing"
1107,tumors_C,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Embryonal tumours of the central nervous system

Prediction of Central Nervous System Embryonal Tumour Outcome based on Gene Expression.
Nature, VOL 415, pp. 436-442, 24 January 2002.

Scott L. Pomeroy, Pablo Tamayo, Michelle Gaasenbeek, Lisa M. Sturla, Michael Angelo, Margaret E. McLaughlin, John Y. H. Kim, Liliana C. Goumnerova, Peter M. Black, Ching Lau, Jeffrey C. Allen, David Zagzag, James M. Olson, Tom Curran, Cynthia Wetmore, Jaclyn A. Biegel, Tomaso Poggio, Shayan Mukherjee, Ryan Rifkin, Andrea Califano, Gustavo Stolovitzky, David N. Louis, Jill P. Mesirov, Eric S. Lander & Todd R. Golub"
1109,lymphoma_11classes,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1110,KDDCup99_full,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets from ACM KDD Cup (http://www.sigkdd.org/kddcup/index.php)

Data set for KDD Cup 1999

Modified by TunedIT (converted to ARFF format)

http://www.sigkdd.org/kddcup/index.php?section=1999&method=info
This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ""good"" normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment.
The training and test datasets are also available in the UC Irvine KDD archive.




KDD Cup 1999: Tasks

This document is adapted from the paper Cost-based Modeling and Evaluation for Data Mining With Application to Fraud and Intrusion Detection: Results from the JAM Project by Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and Philip K. Chan.

Intrusion Detector Learning

Software to detect network intrusions protects a computer network from unauthorized users, including perhaps insiders. The intrusion detector learning task is to build a predictive model (i.e. a classifier) capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ``good'' normal connections.

The 1998 DARPA Intrusion Detection Evaluation Program was prepared and managed by MIT Lincoln Labs. The objective was to survey and evaluate research in intrusion detection. A standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment, was provided. The 1999 KDD intrusion detection contest uses a version of this dataset.

Lincoln Labs set up an environment to acquire nine weeks of raw TCP dump data for a local-area network (LAN) simulating a typical U.S. Air Force LAN. They operated the LAN as if it were a true Air Force environment, but peppered it with multiple attacks.

The raw training data was about four gigabytes of compressed binary TCP dump data from seven weeks of network traffic. This was processed into about five million connection records. Similarly, the two weeks of test data yielded around two million connection records.

A connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol. Each connection is labeled as either normal, or as an attack, with exactly one specific attack type. Each connection record consists of about 100 bytes.

Attacks fall into four main categories:

* DOS: denial-of-service, e.g. syn flood;
* R2L: unauthorized access from a remote machine, e.g. guessing password;
* U2R: unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;
* probing: surveillance and other probing, e.g., port scanning.

It is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data. This makes the task more realistic. Some intrusion experts believe that most novel attacks are variants of known attacks and the ""signature"" of known attacks can be sufficient to catch novel variants. The datasets contain a total of 24 training attack types, with an additional 14 types in the test data only.

Derived Features

Stolfo et al. defined higher-level features that help in distinguishing normal connections from attacks. There are several categories of derived features.

The ``same host'' features examine only the connections in the past two seconds that have the same destination host as the current connection, and calculate statistics related to protocol behavior, service, etc.

The similar ``same service'' features examine only the connections in the past two seconds that have the same service as the current connection.

""Same host"" and ""same service"" features are together called time-based traffic features of the connection records.

Some probing attacks scan the hosts (or ports) using a much larger time interval than two seconds, for example once per minute. Therefore, connection records were also sorted by destination host, and features were constructed using a window of 100 connections to the same host instead of a time window. This yields a set of so-called host-based traffic features.

Unlike most of the DOS and probing attacks, there appear to be no sequential patterns that are frequent in records of R2L and U2R attacks. This is because the DOS and probing attacks involve many connections to some host(s) in a very short period of time, but the R2L and U2R attacks are embedded in the data portions of packets, and normally involve only a single connection.

Useful algorithms for mining the unstructured data portions of packets automatically are an open research question. Stolfo et al. used domain knowledge to add features that look for suspicious behavior in the data portions, such as the number of failed login attempts. These features are called ``content'' features.

A complete listing of the set of features defined for the connection records is given in the three tables below. The data schema of the contest dataset is available in machine-readable form.

feature name 	description 	type
duration 	length (number of seconds) of the connection 	continuous
protocol_type 	type of the protocol, e.g. tcp, udp, etc. 	discrete
service 	network service on the destination, e.g., http, telnet, etc. 	discrete
src_bytes 	number of data bytes from source to destination 	continuous
dst_bytes 	number of data bytes from destination to source 	continuous
flag 	normal or error status of the connection 	discrete
land 	1 if connection is from/to the same host/port; 0 otherwise 	discrete
wrong_fragment 	number of ``wrong'' fragments 	continuous
urgent 	number of urgent packets 	continuous

Table 1: Basic features of individual TCP connections.

feature name 	description 	type
hot 	number of ``hot'' indicators 	continuous
num_failed_logins 	number of failed login attempts 	continuous
logged_in 	1 if successfully logged in; 0 otherwise 	discrete
num_compromised 	number of ``compromised'' conditions 	continuous
root_shell 	1 if root shell is obtained; 0 otherwise 	discrete
su_attempted 	1 if ``su root'' command attempted; 0 otherwise 	discrete
num_root 	number of ``root'' accesses 	continuous
num_file_creations 	number of file creation operations 	continuous
num_shells 	number of shell prompts 	continuous
num_access_files 	number of operations on access control files 	continuous
num_outbound_cmds 	number of outbound commands in an ftp session 	continuous
is_hot_login 	1 if the login belongs to the ``hot'' list; 0 otherwise 	discrete
is_guest_login 	1 if the login is a ``guest''login; 0 otherwise 	discrete

Table 2: Content features within a connection suggested by domain knowledge.

feature name 	description 	type
count 	number of connections to the same host as the current connection in the past two seconds 	continuous
Note: The following features refer to these same-host connections.
serror_rate 	% of connections that have ``SYN'' errors 	continuous
rerror_rate 	% of connections that have ``REJ'' errors 	continuous
same_srv_rate 	% of connections to the same service 	continuous
diff_srv_rate 	% of connections to different services 	continuous
srv_count 	number of connections to the same service as the current connection in the past two seconds 	continuous
Note: The following features refer to these same-service connections.
srv_serror_rate 	% of connections that have ``SYN'' errors 	continuous
srv_rerror_rate 	% of connections that have ``REJ'' errors 	continuous
srv_diff_host_rate 	% of connections to different hosts 	continuous

Table 3: Traffic features computed using a two-second time window.




http://www.sigkdd.org/kddcup"
1111,KDDCup09_appetency,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets from ACM KDD Cup (http://www.sigkdd.org/kddcup/index.php)

KDD Cup 2009
http://www.kddcup-orange.com

Converted to ARFF format by TunedIT
Customer Relationship Management (CRM) is a key element of modern marketing strategies. The KDD Cup 2009 offers the opportunity to work on large marketing databases from the French Telecom company Orange to predict the propensity of customers to switch provider (churn), buy new products or services (appetency), or buy upgrades or add-ons proposed to them to make the sale more profitable (up-selling).
The most practical way, in a CRM system, to build knowledge on customer is to produce scores. A score (the output of a model) is an evaluation for all instances of a target variable to explain (i.e. churn, appetency or up-selling). Tools which produce scores allow to project, on a given population, quantifiable information. The score is computed using input variables which describe instances. Scores are then used by the information system (IS), for example, to personalize the customer relationship. An industrial customer analysis platform able to build prediction models with a very large number of input variables has been developed by Orange Labs. This platform implements several processing methods for instances and variables selection, prediction and indexation based on an efficient model combined with variable selection regularization and model averaging method. The main characteristic of this platform is its ability to scale on very large datasets with hundreds of thousands of instances and thousands of variables. The rapid and robust detection of the variables that have most contributed to the output prediction can be a key factor in a marketing application.
Appetency: In our context, the appetency is the propensity to buy a service or a product.
The training set contains 50,000 examples.
The first predictive 190 variables are numerical and the last 40 predictive variables are categorical.
The last target variable is binary {-1,1}."
1112,KDDCup09_churn,"**Author**: Orange Telecom  
**Source**: [ACM KDD Cup](http://www.sigkdd.org/kddcup/index.php) - 2009  
**Please cite**: 

The KDD Cup 2009 offers the opportunity to work on large marketing databases from the French Telecom company Orange to predict the propensity of customers to switch provider (churn). 

Churn (wikipedia definition): Churn rate is also sometimes called attrition rate. It is one of two primary factors that determine
the steady-state level of customers a business will support. In its broadest sense, churn rate is a measure of the number
of individuals or items moving into or out of a collection over a specific period of time.

The term is used in many contexts, but is most widely applied in business with respect to a contractual customer base. For instance, it is an important factor for any business with a subscriber-based service model, including mobile telephone networks and pay TV operators. The term is also used to refer to participant turnover in peer-to-peer networks.

The training set contains 50,000 examples.
The first predictive 190 variables are numerical and the last 40 predictive variables are categorical.
The last target variable is binary {-1,1}."
1113,KDDCup99,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

This is a 10% stratified subsample of the data from the 1999 ACM KDD Cup (http://www.sigkdd.org/kddcup/index.php).

Modified by TunedIT (converted to ARFF format)

http://www.sigkdd.org/kddcup/index.php?section=1999&method=info
This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ""good"" normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment.
The training and test datasets are also available in the UC Irvine KDD archive.




KDD Cup 1999: Tasks

This document is adapted from the paper Cost-based Modeling and Evaluation for Data Mining With Application to Fraud and Intrusion Detection: Results from the JAM Project by Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and Philip K. Chan.

Intrusion Detector Learning

Software to detect network intrusions protects a computer network from unauthorized users, including perhaps insiders. The intrusion detector learning task is to build a predictive model (i.e. a classifier) capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ``good'' normal connections.

The 1998 DARPA Intrusion Detection Evaluation Program was prepared and managed by MIT Lincoln Labs. The objective was to survey and evaluate research in intrusion detection. A standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment, was provided. The 1999 KDD intrusion detection contest uses a version of this dataset.

Lincoln Labs set up an environment to acquire nine weeks of raw TCP dump data for a local-area network (LAN) simulating a typical U.S. Air Force LAN. They operated the LAN as if it were a true Air Force environment, but peppered it with multiple attacks.

The raw training data was about four gigabytes of compressed binary TCP dump data from seven weeks of network traffic. This was processed into about five million connection records. Similarly, the two weeks of test data yielded around two million connection records.

A connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol. Each connection is labeled as either normal, or as an attack, with exactly one specific attack type. Each connection record consists of about 100 bytes.

Attacks fall into four main categories:

* DOS: denial-of-service, e.g. syn flood;
* R2L: unauthorized access from a remote machine, e.g. guessing password;
* U2R: unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;
* probing: surveillance and other probing, e.g., port scanning.

It is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data. This makes the task more realistic. Some intrusion experts believe that most novel attacks are variants of known attacks and the ""signature"" of known attacks can be sufficient to catch novel variants. The datasets contain a total of 24 training attack types, with an additional 14 types in the test data only.

Derived Features

Stolfo et al. defined higher-level features that help in distinguishing normal connections from attacks. There are several categories of derived features.

The ``same host'' features examine only the connections in the past two seconds that have the same destination host as the current connection, and calculate statistics related to protocol behavior, service, etc.

The similar ``same service'' features examine only the connections in the past two seconds that have the same service as the current connection.

""Same host"" and ""same service"" features are together called time-based traffic features of the connection records.

Some probing attacks scan the hosts (or ports) using a much larger time interval than two seconds, for example once per minute. Therefore, connection records were also sorted by destination host, and features were constructed using a window of 100 connections to the same host instead of a time window. This yields a set of so-called host-based traffic features.

Unlike most of the DOS and probing attacks, there appear to be no sequential patterns that are frequent in records of R2L and U2R attacks. This is because the DOS and probing attacks involve many connections to some host(s) in a very short period of time, but the R2L and U2R attacks are embedded in the data portions of packets, and normally involve only a single connection.

Useful algorithms for mining the unstructured data portions of packets automatically are an open research question. Stolfo et al. used domain knowledge to add features that look for suspicious behavior in the data portions, such as the number of failed login attempts. These features are called ``content'' features.

A complete listing of the set of features defined for the connection records is given in the three tables below. The data schema of the contest dataset is available in machine-readable form.

feature name  description  type
duration  length (number of seconds) of the connection  continuous
protocol_type  type of the protocol, e.g. tcp, udp, etc.  discrete
service  network service on the destination, e.g., http, telnet, etc.  discrete
src_bytes  number of data bytes from source to destination  continuous
dst_bytes  number of data bytes from destination to source  continuous
flag  normal or error status of the connection  discrete
land  1 if connection is from/to the same host/port; 0 otherwise  discrete
wrong_fragment  number of ``wrong'' fragments  continuous
urgent  number of urgent packets  continuous

Table 1: Basic features of individual TCP connections.

feature name  description  type
hot  number of ``hot'' indicators  continuous
num_failed_logins  number of failed login attempts  continuous
logged_in  1 if successfully logged in; 0 otherwise  discrete
num_compromised  number of ``compromised'' conditions  continuous
root_shell  1 if root shell is obtained; 0 otherwise  discrete
su_attempted  1 if ``su root'' command attempted; 0 otherwise  discrete
num_root  number of ``root'' accesses  continuous
num_file_creations  number of file creation operations  continuous
num_shells  number of shell prompts  continuous
num_access_files  number of operations on access control files  continuous
num_outbound_cmds  number of outbound commands in an ftp session  continuous
is_hot_login  1 if the login belongs to the ``hot'' list; 0 otherwise  discrete
is_guest_login  1 if the login is a ``guest''login; 0 otherwise  discrete

Table 2: Content features within a connection suggested by domain knowledge.

feature name  description  type
count  number of connections to the same host as the current connection in the past two seconds  continuous
Note: The following features refer to these same-host connections.
serror_rate  % of connections that have ``SYN'' errors  continuous
rerror_rate  % of connections that have ``REJ'' errors  continuous
same_srv_rate  % of connections to the same service  continuous
diff_srv_rate  % of connections to different services  continuous
srv_count  number of connections to the same service as the current connection in the past two seconds  continuous
Note: The following features refer to these same-service connections.
srv_serror_rate  % of connections that have ``SYN'' errors  continuous
srv_rerror_rate  % of connections that have ``REJ'' errors  continuous
srv_diff_host_rate  % of connections to different hosts  continuous

Table 3: Traffic features computed using a two-second time window.




http://www.sigkdd.org/kddcup"
1114,KDDCup09_upselling,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Datasets from ACM KDD Cup (http://www.sigkdd.org/kddcup/index.php)

KDD Cup 2009
http://www.kddcup-orange.com

Converted to ARFF format by TunedIT
Customer Relationship Management (CRM) is a key element of modern marketing strategies. The KDD Cup 2009 offers the opportunity to work on large marketing databases from the French Telecom company Orange to predict the propensity of customers to switch provider (churn), buy new products or services (appetency), or buy upgrades or add-ons proposed to them to make the sale more profitable (up-selling).
The most practical way, in a CRM system, to build knowledge on customer is to produce scores. A score (the output of a model) is an evaluation for all instances of a target variable to explain (i.e. churn, appetency or up-selling). Tools which produce scores allow to project, on a given population, quantifiable information. The score is computed using input variables which describe instances. Scores are then used by the information system (IS), for example, to personalize the customer relationship. An industrial customer analysis platform able to build prediction models with a very large number of input variables has been developed by Orange Labs. This platform implements several processing methods for instances and variables selection, prediction and indexation based on an efficient model combined with variable selection regularization and model averaging method. The main characteristic of this platform is its ability to scale on very large datasets with hundreds of thousands of instances and thousands of variables. The rapid and robust detection of the variables that have most contributed to the output prediction can be a key factor in a marketing application.
Up-selling (wikipedia definition): Up-selling is a sales technique whereby a salesman attempts to have the customer purchase more expensive
items, upgrades, or other add-ons in an attempt to make a more profitable sale.
Up-selling usually involves marketing more profitable services or products, but up-selling can also be simply exposing the customer
to other options he or she may not have considered previously.
Up-selling can imply selling something additional, or selling something that is more profitable or otherwise preferable for the seller instead of the original sale.
The training set contains 50,000 examples.
The first predictive 190 variables are numerical and the last 40 predictive variables are categorical.
The last target variable is binary {-1,1}."
1115,teachingAssistant,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Dataset from the MLRR repository: http://axon.cs.byu.edu:5000/"
1116,musk,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Dataset from the MLRR repository: http://axon.cs.byu.edu:5000/

More infos: https://archive.ics.uci.edu/ml/datasets/Musk+(Version+2)"
1117,desharnais,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Dataset from the MLRR repository: http://axon.cs.byu.edu:5000/"
1119,adult-census,"**Author**: Ronny Kohavi and Barry Becker  
**Source**: [MLRR](http://axon.cs.byu.edu:5000/)    
**Please cite**: Ron Kohavi, ""Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  

Dataset from the MLRR repository: http://axon.cs.byu.edu:5000/

**Note: this dataset is identical to the version stored in UCI, but only includes the training data, not the test data. See [adult (2)](http://openml.org/d/1590) for the complete data.**"
1120,MagicTelescope,"**Author**: R. K. Bock. Major Atmospheric Gamma Imaging Cherenkov Telescope project (MAGIC)  
Donated by P. Savicky, Institute of Computer Science, AS of CR, Czech Republic  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope)  
**Please cite**: Bock, R.K., Chilingarian, A., Gaug, M., Hakl, F., Hengstebeck, T., Jirina, M., Klaschka, J., Kotrc, E., Savicky, P., Towers, S., Vaicilius, A., Wittek W. (2004). 
Methods for multidimensional event classification: a case study using images from a Cherenkov gamma-ray telescope. Nucl.Instr.Meth. A, 516, pp. 511-528.  

The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background). 

Typically, the image of a shower after some pre-processing is an elongated cluster. Its long axis is oriented towards the camera center if the shower axis is parallel to the telescope's optical axis, i.e. if the telescope axis is directed towards a point source. A principal component analysis is performed in the camera plane, which results in a correlation axis and defines an ellipse. If the depositions were distributed as a bivariate Gaussian, this would be an equidensity ellipse. The characteristic parameters of this ellipse (often called Hillas parameters) are among the image parameters that can be used for discrimination. The energy depositions are typically asymmetric along the major axis, and this asymmetry can also be used in discrimination. There are, in addition, further discriminating characteristics, like the extent of the cluster in the image plane, or the total sum of depositions. 

The data set was generated by a Monte Carlo program, Corsika, described in: 
D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers, Forschungszentrum Karlsruhe FZKA 6019 (1998).
The program was run with parameters allowing to observe events with energies down to below 50 GeV.

Attribute Information:

1. fLength: continuous # major axis of ellipse [mm] 
2. fWidth: continuous # minor axis of ellipse [mm] 
3. fSize: continuous # 10-log of sum of content of all pixels [in #phot] 
4. fConc: continuous # ratio of sum of two highest pixels over fSize [ratio] 
5. fConc1: continuous # ratio of highest pixel over fSize [ratio] 
6. fAsym: continuous # distance from highest pixel to center, projected onto major axis [mm] 
7. fM3Long: continuous # 3rd root of third moment along major axis [mm] 
8. fM3Trans: continuous # 3rd root of third moment along minor axis [mm] 
9. fAlpha: continuous # angle of major axis with vector to origin [deg] 
10. fDist: continuous # distance from origin to center of ellipse [mm] 
11. class: g,h # gamma (signal), hadron (background) 

g = gamma (signal): 12332 
h = hadron (background): 6688 

For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events. 

The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments."
1121,badges2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Dataset from the MLRR repository: http://axon.cs.byu.edu:5000/"
1122,AP_Breast_Prostate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1123,AP_Endometrium_Breast,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1124,AP_Omentum_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1125,AP_Omentum_Prostate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1126,AP_Colon_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1127,AP_Breast_Omentum,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1128,OVA_Breast,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1129,AP_Uterus_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1130,OVA_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1131,AP_Prostate_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1132,AP_Omentum_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1133,AP_Endometrium_Colon,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1134,OVA_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1135,AP_Colon_Prostate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1136,AP_Lung_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1137,AP_Colon_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1138,OVA_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1139,OVA_Omentum,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1140,AP_Ovary_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1141,AP_Endometrium_Prostate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1142,OVA_Endometrium,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1143,AP_Colon_Omentum,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1144,AP_Prostate_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1145,AP_Breast_Colon,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1146,OVA_Prostate,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1147,AP_Omentum_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1148,AP_Breast_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1149,AP_Ovary_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1150,AP_Breast_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1151,AP_Endometrium_Omentum,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1152,AP_Prostate_Ovary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1153,AP_Colon_Ovary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1154,AP_Endometrium_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1155,AP_Prostate_Lung,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1156,AP_Omentum_Ovary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1157,AP_Endometrium_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1158,AP_Breast_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1159,AP_Endometrium_Ovary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1160,AP_Colon_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1161,OVA_Colon,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1162,AP_Ovary_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1163,AP_Lung_Kidney,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1164,AP_Endometrium_Uterus,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1165,AP_Breast_Ovary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1166,OVA_Ovary,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

GEMLeR provides a collection of gene expression datasets that can be used for benchmarking gene expression oriented machine learning algorithms. They can be used for estimation of different quality metrics (e.g. accuracy, precision, area under ROC curve, etc.) for classification, feature selection or clustering algorithms.

This repository was inspired by an increasing need in machine learning / bioinformatics communities for a collection of microarray classification problems that could be used by different researches. This way many different classification or feature selection techniques can finally be compared to eachother on the same set of problems.

Origin of data

Each gene expression sample in GEMLeR repository comes from a large publicly available expO (Expression Project For Oncology) repository by International Genomics Consortium.

The goal of expO and its consortium supporters is to procure tissue samples under standard conditions and perform gene expression analyses on a clinically annotated set of deidentified tumor samples. The tumor data is updated with clinical outcomes and is released into the public domain without intellectual property restriction. The availability of this information translates into direct benefits for patients, researchers and pharma alike.

Source: expO website
Although there are various other sources of gene expression data available, a decision to use data from expO repository was made because of:
- consistency of tissue samples processing procedure
- same microarray platform used for all samples
- availability of additional information for combined genotype-phenotype studies
- availability of a large number of samples for different tumor types

In case of publishing material based on GEMLeR datasets, then, please note the assistance you received by using this repository. This will help others to obtain the same datasets and replicate your experiments. Please cite as follows when referring to this repository:

Stiglic, G., & Kokol, P. (2010). Stability of Ranked Gene Lists in Large Microarray Analysis Studies. Journal of biomedicine biotechnology, 2010, 616358.

You are also welcome to acknowledge the contribution of expO (Expression Project For Oncology) and International Genomics Consortium for providing their gene expression samples to the public."
1167,pc1_req,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:"
1168,electricity_prices_ICON,"**Author**: H. Simonis, B. O’Sullivan, D. Mehta, B. Hurley, M. De Cauwer  
**Source**: [ICON Challenge](http://iconchallenge.insight-centre.org/) - 2014  
**Please cite**:   

**ICON Challenge on Forecasting and Scheduling**  
We consider the following problem: You are running a cloud computing service, where customers contract to run computing services (tasks). Each task has a duration, an earliest start and latest end, and resource requirements for CPU, Memory and I/O attributes. The tasks can be scheduled on one of multiple servers, each server has a limited capacity for the CPU, memory and I/O attributes. Multiple tasks can run concurrently on the same machine if the total resource consumption for all attributes is below the respective capacity. All tasks must be scheduled within their release and due dates, these dates are set so that no task stretches over midnight between two days. Tasks can not be interrupted, once started, they must run for their given duration. If a machine is used by a task, it must be running at that time. In addition to the cost of running the allocated tasks, the machine consumes some idle power if it is on. Every time a machine is switched on or off, a start-up resp. shut-down cost must be paid. All machines are off at the beginning of the planning period, all machines must be off at the end of the planning period.

The price of electricity for the data centre is a real-time price, and varies throughout the day. The actual price is not known in advance, a forecast must be used to generate a schedule. The total cost of the schedule is determined after the fact by applying the actual price of electricity to the energy consumption in each time period. One forecast of the price is given by the organizers. However there may be a large discrepancy between the forecast and actual price, offering the opportunity to generate better forecasts based on historical data for demand and prices, and previous forecast information. Note that a forecast with a low error is not automatically guaranteed to lead to a schedule with a low overall cost.
￼￼￼￼￼￼￼
In the forecast problem, we have to predict the actual electricity price for one day into the future based on historical and forecasted data. The historical data is available from September 2011 onwards. Missing values are marked with ?. The following fields are defined:
>
**DateTime** String, defines date and time of sample  
**Holiday** String, gives name of holiday if day is a bank holiday  
**HolidayFlag** integer, 1 if day is a bank holiday, zero otherwise  
**DayOfWeek** integer (0-6), 0 monday, day of week  
**WeekOfYear** integer, running week within year of this date  
**Day** integer, day of the date  
**Month** integer, month of the date  
**Year** integer, year of the date  
**PeriodOfDay** integer, denotes half hour period of day (0-47)  
**ForecastWindProduction** the forecasted wind production for this period  
**SystemLoadEA** the national load forecast for this period  
**SMPEA** the price forecast for this period  
**ORKTemperature** the actual temperature measured at Cork airport  
**ORKWindspeed** the actual windspeed measured at Cork airport  
**CO2Intensity** the actual CO2 intensity in (g/kWh) for the electricity produced  
**ActualWindProduction** the actual wind energy production for this period  
**SystemLoadEP2** the actual national system load for this period  
**SMPEP2** the actual price of this time period, the value to be forecasted  

The last four fields are only available for historical data, i.e. they can not be used to make the forecast."
1169,airlines,"**Author**: Albert Bifet, Elena Ikonomovska  
**Source**: [Data Expo competition](http://kt.ijs.si/elena_ikonomovska/data.html) - 2009  
**Please cite**:   

Airlines Dataset Inspired in the regression dataset from Elena Ikonomovska. The task is to predict whether a given flight will be delayed, given the information of the scheduled departure."
1177,BNG(primary-tumor),
1178,BNG(solar-flare),
1179,BNG(solar-flare),
1180,BNG(spect_test),
1181,BNG(spectf_test),
1182,BNG(adult),
1183,BNG(satimage),
1184,BNG(baseball),
1185,BNG(wine),
1186,BNG(eucalyptus),
1187,BNG(wisconsin),
1188,BNG(cleveland),
1189,BNG(auto_price),
1190,BNG(cpu_act),
1191,BNG(pbc),
1192,BNG(autoHorse),
1193,BNG(lowbwt),
1194,BNG(cholesterol),
1195,BNG(autoPrice),
1196,BNG(pharynx),"**Author**:   
**Please cite**:   

Juan J. Rodriguez, Ludmila I. Kuncheva, Carlos J. Alonso (2006). Rotation Forest: A new classifier ensemble method. IEEE Transactions on Pattern Analysis and Machine Intelligence. 28(10):1619-1630. URL http://doi.ieeecomputersociety.org/10.1109/TPAMI.2006.211."
1197,BNG(2dplanes),
1198,BNG(elevators),
1199,BNG(echoMonths),
1200,BNG(stock),
1201,BNG(breastTumor),
1202,BNG(cpu_small),
1203,BNG(pwLinear),
1204,BNG(wine_quality),
1205,BNG(Australian),
1206,BNG(satellite_image),
1207,BNG(Ailerons),
1208,BNG(libras_move),
1209,BNG(vowel),
1210,BNG(puma32H),
1211,BNG(SPECT),
1212,BNG(SPECTF),
1213,BNG(mv),
1214,BNG(JapaneseVowels),
1216,Click_prediction_small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Data on predicting clicks on ads in a search engine."
1217,Click_prediction_small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Even smaller sample of version 1"
1218,Click_prediction_small,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Balanced version of click prediction data"
1219,Click_prediction_small,"**Author**: Tencent Inc.  
**Source**: [KDD Cup](https://www.kddcup2012.org/) - 2012 Track 2, [Kaggle](https://www.kaggle.com/c/kddcup2012-track2)  
**Please cite**:   

This data is derived from the 2012 KDD Cup. The data is subsampled to 1% of the original number of instances, downsampling the majority class (click=0) so that the target feature is reasonably balanced (5 to 1).

The data is about advertisements shown alongside search results in a search engine, and whether or not people clicked on these ads. 
The task is to build the best possible model to predict whether a user will click on a given ad.

A search session contains information on user id, the query issued by the user, ads displayed to the user, and target feature indicating whether a user clicked at least one of the ads in this session. The number of ads displayed to a user in a session is called 'depth'. The order of an ad in the displayed list is called 'position'.  An ad is displayed as a short text called 'title', followed by a slightly longer text called 'description', and a URL  called 'display URL'.   
To construct this dataset each session was split into multiple instances. Each instance describes an ad displayed under a certain setting  ('depth', 'position').  Instances with the same user id, ad id, query, and setting are merged. Each ad and each user have some additional properties located in separate data files that can be looked up using ids in the instances.

The dataset has the following features:  
* Click - binary variable indicating whether a user clicked on at least one ad. 
* Impression - the number of search sessions in which AdID was impressed by UserID who issued Query.
* Url_hash - URL is hashed for anonymity
* AdID 
* AdvertiserID - some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others' ads.
* Depth - number of ads displayed to a user in a session
* Position - order of an ad in the displayed list
* QueryID - is the key of the data file 'queryid_tokensid.txt'. (follow the link to the original KDD Cup page, track 2)
* KeywordID - is the key of  'purchasedkeyword_tokensid.txt' (follow the link to the original KDD Cup page, track 2)
* TitleID - is the key of 'titleid_tokensid.txt'
* DescriptionID - is the key of 'descriptionid_tokensid.txt' (follow the link to the original KDD Cup page, track 2)
* UserID - is also the key of 'userid_profile.txt' (follow the link to the original KDD Cup page, track 2). 0 is a special value denoting that the user could be identified."
1220,Click_prediction_small,"**Author**: Tencent Inc.  
**Source**: [KDD Cup](https://www.kddcup2012.org/) - 2012  
**Please cite**:   

**0.1% balanced subsample of the original KDD dataset**  

This data is derived from the 2012 KDD Cup. The data is subsampled to 0.1% of the original number of instances, downsampling the majority class (click=0) so that the target feature is reasonably balanced (5 to 1).

The data is about advertisements shown alongside search results in a search engine, and whether or not people clicked on these ads. 
The task is to build the best possible model to predict whether a user will click on a given ad.

A search session contains information on user id, the query issued by the user, ads displayed to the user, and target feature indicating whether a user clicked at least one of the ads in this session. The number of ads displayed to a user in a session is called ‘depth’. The order of an ad in the displayed list is called ‘position’.  An ad is displayed as a short text called ‘title’, followed by a slightly longer text called ’description’, and a URL  called ‘display URL’.   
To construct this dataset each session was split into multiple instances. Each instance describes an ad displayed under a certain setting  (‘depth’, ‘position’).  Instances with the same user id, ad id, query, and setting are merged. Each ad and each user have some additional properties located in separate data files that can be looked up using ids in the instances.

The dataset has the following features:  
* Click – binary variable indicating whether a user clicked on at least one ad. 
* Impression - the number of search sessions in which AdID was impressed by UserID who issued Query.
* Url_hash - URL is hashed for anonymity
* AdID 
* AdvertiserID - some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others’ ads.
* Depth - number of ads displayed to a user in a session
* Position - order of an ad in the displayed list
* QueryID - is the key of the data file 'queryid_tokensid.txt'. (follow the link to the original KDD Cup page, track 2)
* KeywordID - is the key of  'purchasedkeyword_tokensid.txt' (follow the link to the original KDD Cup page, track 2)
* TitleID - is the key of 'titleid_tokensid.txt'
* DescriptionID - is the key of 'descriptionid_tokensid.txt' (follow the link to the original KDD Cup page, track 2)
* UserID – is also the key of 'userid_profile.txt' (follow the link to the original KDD Cup page, track 2). 0 is a special value denoting that the user could be identified."
1222,letter-challenge-unlabeled.arff,
1226,Click_prediction_small,"**Author**: Tencent Inc.  
**Source**: [KDD Cup](https://www.kddcup2012.org/) - 2012  
**Please cite**:   

**This data set is the same as version 4, but has additional unlabeled data attached to it. This is meant for a machine learning challenge. The complete labeled version of this dataset is version 6 (but this version is kept private for the duration of the challenge).**

This data is derived from the 2012 KDD Cup. The data is subsampled to 1% of the original number of instances, downsampling the majority class (click=0) so that the target feature is reasonably balanced (5 to 1).

The data is about advertisements shown alongside search results in a search engine, and whether or not people clicked on these ads. 
The task is to build the best possible model to predict whether a user will click on a given ad.

A search session contains information on user id, the query issued by the user, ads displayed to the user, and target feature indicating whether a user clicked at least one of the ads in this session. The number of ads displayed to a user in a session is called ‘depth’. The order of an ad in the displayed list is called ‘position’.  An ad is displayed as a short text called ‘title’, followed by a slightly longer text called ’description’, and a URL  called ‘display URL’.   
To construct this dataset each session was split into multiple instances. Each instance describes an ad displayed under a certain setting  (‘depth’, ‘position’).  Instances with the same user id, ad id, query, and setting are merged. Each ad and each user have some additional properties located in separate data files that can be looked up using ids in the instances.

The dataset has the following features:  
* Click – binary variable indicating whether a user clicked on at least one ad. 
* Impression - the number of search sessions in which AdID was impressed by UserID who issued Query.
* Url_hash - URL is hashed for anonymity
* AdID 
* AdvertiserID - some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others’ ads.
* Depth - number of ads displayed to a user in a session
* Position - order of an ad in the displayed list
* QueryID - is the key of the data file 'queryid_tokensid.txt'. (follow the link to the original KDD Cup page, track 2)
* KeywordID - is the key of  'purchasedkeyword_tokensid.txt' (follow the link to the original KDD Cup page, track 2)
* TitleID - is the key of 'titleid_tokensid.txt'
* DescriptionID - is the key of 'descriptionid_tokensid.txt' (follow the link to the original KDD Cup page, track 2)
* UserID – is also the key of 'userid_profile.txt' (follow the link to the original KDD Cup page, track 2). 0 is a special value denoting that the user could be identified."
1228,nki70.arff,
1233,eating,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

eating"
1235,Agrawal1,
1236,Stagger1,
1237,Stagger2,
1238,Stagger3,
1240,AirlinesCodrnaAdult,
1241,codrnaNorm,"Normalized form of codrna (351)

**Author**: Andrew V Uzilov"",""Joshua M Keegan"",""David H Mathews.  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets) -   
**Please cite**: [AVU06a]
Andrew V Uzilov, Joshua M Keegan, and David H Mathews. 
Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change. 
BMC Bioinformatics, 7(173), 2006.  

This is the cod-rna dataset, retrieved 2014-11-14 from the libSVM site. Additional to the preprocessing done there (see LibSVM site for details), this dataset was created as follows: 
-join test, train and rest datasets   
-normalize each file columnwise according to the following rules:    
-If a column only contains one value (constant feature), it will set to zero and thus removed by sparsity.    
-If a column contains two values (binary feature), the value occuring more often will be set to zero, the other to one.    
-If a column contains more than two values (multinary/real feature), the column is divided by its std deviation.    

NOTE: please keep in mind that cod-rna has many duplicated data points, within each file &#40;train,test,rest&#41; and also accross these files. these duplicated points have not been removed!"
1242,vehicleNorm,"Normalized version of vehicle dataset (http://www.openml.org/d/54)

**Author**:  Peter Mowforth  
**Source**: UCI -   
**Please cite**: Siebert,JP. Turing Institute Research Memorandum TIRM-87-018 ""Vehicle Recognition Using Rule Based Methods"" (March 1987)  

 NAME
         vehicle silhouettes
 
 PURPOSE
         to classify a given silhouette as one of four types of vehicle,
         using  a set of features extracted from the silhouette. The
         vehicle may be viewed from one of many different angles.  
 
 PROBLEM TYPE
         classification
         
 SOURCE
         Drs.Pete Mowforth and Barry Shepherd
         Turing Institute
         George House
         36 North Hanover St.
         Glasgow
         G1 2AD
 
 CONTACT
         Alistair Sutherland
         Statistics Dept.
         Strathclyde University
         Livingstone Tower
         26 Richmond St.
         GLASGOW G1 1XH
         Great Britain
         
         Tel: 041 552 4400 x3033
         
         Fax: 041 552 4711 
         
         e-mail: alistair@uk.ac.strathclyde.stams
 
 HISTORY
         This data was originally gathered at the TI in 1986-87 by
         JP Siebert. It was partially financed by Barr and Stroud Ltd.
         The original purpose was to find a method of distinguishing
         3D objects within a 2D image by application of an ensemble of
         shape feature extractors to the 2D silhouettes of the objects.
         Measures of shape features extracted from example silhouettes
         of objects to be discriminated were used to generate a class-
         ification rule tree by means of computer induction.
          This object recognition strategy was successfully used to 
         discriminate between silhouettes of model cars, vans and buses
         viewed from constrained elevation but all angles of rotation.
          The rule tree classification performance compared favourably
         to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neigh-
         bour) statistical classifiers in terms of both error rate and
         computational efficiency. An investigation of these rule trees
         generated by example indicated that the tree structure was 
         heavily influenced by the orientation of the objects, and grouped
         similar object views into single decisions.
 
 DESCRIPTION
          The features were extracted from the silhouettes by the HIPS
         (Hierarchical Image Processing System) extension BINATTS, which 
         extracts a combination of scale independent features utilising
         both classical moments based measures such as scaled variance,
         skewness and kurtosis about the major/minor axes and heuristic
         measures such as hollows, circularity, rectangularity and
         compactness.
          Four ""Corgie"" model vehicles were used for the experiment:
         a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400.
         This particular combination of vehicles was chosen with the 
         expectation that the bus, van and either one of the cars would
         be readily distinguishable, but it would be more difficult to
         distinguish between the cars.
          The images were acquired by a camera looking downwards at the
         model vehicle from a fixed angle of elevation (34.2 degrees
         to the horizontal). The vehicles were placed on a diffuse
         backlit surface (lightbox). The vehicles were painted matte black
         to minimise highlights. The images were captured using a CRS4000
         framestore connected to a vax 750. All images were captured with
         a spatial resolution of 128x128 pixels quantised to 64 greylevels.
         These images were thresholded to produce binary vehicle silhouettes,
         negated (to comply with the processing requirements of BINATTS) and
         thereafter subjected to shrink-expand-expand-shrink HIPS modules to
         remove ""salt and pepper"" image noise.
          The vehicles were rotated and their angle of orientation was measured
         using a radial graticule beneath the vehicle. 0 and 180 degrees
         corresponded to ""head on"" and ""rear"" views respectively while 90 and
         270 corresponded to profiles in opposite directions. Two sets of
         60 images, each set covering a full 360 degree rotation, were captured
         for each vehicle. The vehicle was rotated by a fixed angle between 
         images. These datasets are known as e2 and e3 respectively.
          A further two sets of images, e4 and e5, were captured with the camera 
         at elevations of 37.5 degs and 30.8 degs respectively. These sets
         also contain 60 images per vehicle apart from e4.van which contains
         only 46 owing to the difficulty of containing the van in the image
         at some orientations.
 
 ATTRIBUTES
         
         COMPACTNESS     (average perim)**2/area
         
         CIRCULARITY     (average radius)**2/area
         
         DISTANCE CIRCULARITY    area/(av.distance from border)**2
         
         RADIUS RATIO    (max.rad-min.rad)/av.radius
         
         PR.AXIS ASPECT RATIO    (minor axis)/(major axis)
         
         MAX.LENGTH ASPECT RATIO (length perp. max length)/(max length)
         
         SCATTER RATIO   (inertia about minor axis)/(inertia about major axis)
         
         ELONGATEDNESS           area/(shrink width)**2
         
         PR.AXIS RECTANGULARITY  area/(pr.axis length*pr.axis width)
         
         MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this)
         
         SCALED VARIANCE         (2nd order moment about minor axis)/area
         ALONG MAJOR AXIS
         
         SCALED VARIANCE         (2nd order moment about major axis)/area
         ALONG MINOR AXIS 
         
         SCALED RADIUS OF GYRATION       (mavar+mivar)/area
         
         SKEWNESS ABOUT  (3rd order moment about major axis)/sigma_min**3
         MAJOR AXIS
         
         SKEWNESS ABOUT  (3rd order moment about minor axis)/sigma_maj**3
         MINOR AXIS
                 
         KURTOSIS ABOUT  (4th order moment about major axis)/sigma_min**4
         MINOR AXIS  
                 
         KURTOSIS ABOUT  (4th order moment about minor axis)/sigma_maj**4
         MAJOR AXIS
         
         HOLLOWS RATIO   (area of hollows)/(area of bounding polygon)
         
          Where sigma_maj**2 is the variance along the major axis and
         sigma_min**2 is the variance along the minor axis, and
         
         area of hollows= area of bounding poly-area of object 
         
          The area of the bounding polygon is found as a side result of
         the computation to find the maximum length. Each individual
         length computation yields a pair of calipers to the object
         orientated at every 5 degrees. The object is propagated into
         an image containing the union of these calipers to obtain an
         image of the bounding polygon. 
         
 NUMBER OF CLASSES
 
         4       OPEL, SAAB, BUS, VAN
 
 NUMBER OF EXAMPLES
 
                 Total no. = 946
                 
                 No. in each class
                 
                   opel 240
                   saab 240
                   bus  240
                   van  226
                 
                 
                 100 examples are being kept by Strathclyde for validation.
                 So StatLog partners will receive 846 examples.
 
 NUMBER OF ATTRIBUTES
 
                 No. of atts. = 18"
1245,lungcancer_shedden,"**Author**: Kerby Shedden et al.  
Michel Lang  
**Source**: Unknown - Date unknown  
**Please cite**: Shedden, K., Taylor, J. M. G., Enkemann, S. A., Tsao, M. S., Yeatman, T. J., Gerald, W. L., … Sharma, A. (2008). Gene Expression-Based Survival Prediction in Lung Adenocarcinoma: A Multi-Site, Blinded Validation Study: Director’s Challenge Consortium for the Molecular Classification of Lung Adenocarcinoma. Nature Medicine, 14(8), 822–827. doi:10.1038/nm.1790

fRMA-normalized. Only ""Kratz-genes""*.

\* (see: A practical molecular assay to predict survival in resected non-squamous, non-small-cell lung cancer: development and international validation studies
Kratz, Johannes R et al.
The Lancet , Volume 379 , Issue 9818 , 823 - 832)"
1351,"BNG(anneal,1000,1)",
1352,"BNG(anneal,1000,5)",
1353,"BNG(anneal,1000,10)",
1354,"BNG(anneal,5000,1)",
1355,"BNG(anneal,5000,5)",
1356,"BNG(anneal,5000,10)",
1357,"BNG(anneal,10000,1)",
1358,"BNG(anneal,10000,5)",
1359,"BNG(anneal,10000,10)",
1360,"BNG(anneal.ORIG,1000,1)",
1361,"BNG(anneal.ORIG,1000,5)",
1362,"BNG(anneal.ORIG,1000,10)",
1363,"BNG(anneal.ORIG,5000,1)",
1364,"BNG(anneal.ORIG,5000,5)",
1365,"BNG(anneal.ORIG,5000,10)",
1366,"BNG(anneal.ORIG,10000,1)",
1367,"BNG(anneal.ORIG,10000,5)",
1368,"BNG(anneal.ORIG,10000,10)",
1369,"BNG(kr-vs-kp,1000,1)",
1370,"BNG(kr-vs-kp,1000,5)",
1371,"BNG(kr-vs-kp,1000,10)",
1372,"BNG(kr-vs-kp,5000,1)",
1373,"BNG(kr-vs-kp,5000,5)",
1374,"BNG(kr-vs-kp,5000,10)",
1375,"BNG(kr-vs-kp,10000,1)",
1376,"BNG(kr-vs-kp,10000,5)",
1377,"BNG(kr-vs-kp,10000,10)",
1378,"BNG(letter,1000,1)",
1379,"BNG(letter,1000,5)",
1380,"BNG(letter,1000,10)",
1381,"BNG(letter,5000,1)",
1382,"BNG(letter,5000,5)",
1383,"BNG(letter,5000,10)",
1384,"BNG(letter,10000,1)",
1385,"BNG(letter,10000,5)",
1386,"BNG(letter,10000,10)",
1387,"BNG(audiology,1000,1)",
1388,"BNG(audiology,1000,5)",
1389,"BNG(audiology,1000,10)",
1390,"BNG(audiology,5000,1)",
1391,"BNG(audiology,5000,5)",
1392,"BNG(audiology,5000,10)",
1393,"BNG(autos,1000,1)",
1394,"BNG(autos,1000,5)",
1395,"BNG(autos,1000,10)",
1396,"BNG(autos,5000,1)",
1397,"BNG(autos,5000,5)",
1398,"BNG(autos,5000,10)",
1399,"BNG(autos,10000,1)",
1400,"BNG(autos,10000,5)",
1401,"BNG(autos,10000,10)",
1402,"BNG(lymph,1000,1)",
1403,"BNG(lymph,1000,5)",
1404,"BNG(lymph,1000,10)",
1405,"BNG(lymph,5000,1)",
1406,"BNG(lymph,5000,5)",
1407,"BNG(lymph,5000,10)",
1408,"BNG(lymph,10000,1)",
1409,"BNG(lymph,10000,5)",
1410,"BNG(lymph,10000,10)",
1412,lungcancer_GSE31210,"**Author**: Okayama et al.  
Michel Lang  
**Source**: Unknown - Date unknown  
**Please cite**: Okayama H, Kohno T, Ishii Y, Shimada Y et al. Identification of genes upregulated in ALK-positive and EGFR/KRAS/ALK-negative lung adenocarcinomas. Cancer Res 2012 Jan 1;72(1):100-11.  

fRMA-normalized. Only ""Kratz-genes""*.

\* (see: A practical molecular assay to predict survival in resected non-squamous, non-small-cell lung cancer: development and international validation studies Kratz, Johannes R et al. The Lancet , Volume 379 , Issue 9818 , 823 - 832)"
1413,MyIris,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

MyExampleIris"
1414,Kaggle_bike_sharing_demand_challange,"**Author**: Niels Rood  
**Source**: [original](http://www.kaggle.com/c/bike-sharing-demand/data) - 2015-02-11  
**Please cite**:   

Modified version of the training dataset of the Bike Sharing Demand challenge running on Kaggle (http://www.kaggle.com/c/bike-sharing-demand/)

If you use the problem in publication, please cite:

Fanaee-T, Hadi, and Gama, Joao, Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg."
1419,contact-lenses,
1420,cpu.with.vendor,
1424,a3a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1425,a4a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: http://archive.ics.uci.edu/ml/datasets/Adult  

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1426,a5a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: http://archive.ics.uci.edu/ml/datasets/Adult  

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1427,a6a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: http://archive.ics.uci.edu/ml/datasets/Adult  

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1428,a7a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: http://archive.ics.uci.edu/ml/datasets/Adult  

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1429,a8a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: http://archive.ics.uci.edu/ml/datasets/Adult  

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1430,a9a,"**Author**: Ronny Kohavi"",""Barry Becker  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: http://archive.ics.uci.edu/ml/datasets/Adult  

#Dataset from the LIBSVM data repository.

Preprocessing: The original Adult data set has 14 features, among which six are continuous and eight are categorical. In this data set, continuous features are discretized into quantiles, and each quantile is represented by a binary feature. Also, a categorical feature with m categories is converted to m binary features. Details on how each feature is converted can be found in the beginning of each file from this page. 
http://research.microsoft.com/en-us/um/people/jplatt/adult.zip"
1432,colon-cancer,"**Author**: U. Alon"",""N. Barkai"",""D. A. Notterman"",""K. Gish"",""S.Ybarra"",""D.Mack"",""and A. J. Levine.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: U. Alon, N. Barkai, D. A. Notterman, K. Gish, S.Ybarra, D.Mack, and A. J. Levine.
Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays.
Cell Biology, 96:6745-6750, 1999.  

#Dataset from the LIBSVM data repository

Preprocessing: Instance-wise normalization to mean zero and variance one. Then feature-wise normalization to mean zero and variance one"
1433,svmguide1,"**Author**: Chih-Wei Hsu"",""Chih-Chung Chang"",""and Chih-Jen Lin.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.
A practical guide to support vector classification.
Technical report, Department of Computer Science, National Taiwan University, 2003.  

#Dataset from the LIBSVM data repository
Preprocessing: Original data: an astroparticle application from Jan Conrad of Uppsala University, Sweden."
1434,duke-breast-cancer,"**Author**: Shirish Krishnaj Shevade and S. Sathiya Keerthi.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: Shirish Krishnaj Shevade and S. Sathiya Keerthi.
A simple and efficient algorithm for gene selection using sparse logistic regression.
Bioinformatics, 19(17):2246-2253, 2003.  

#Dataset from the LIBSVM data repository.

Preprocessing: Instance-wise normalization to mean zero and variance one. Then feature-wise normalization to mean zero and variance one. The original dataset consists of 49 instances. Five are removed since the classification results using immunohistochemistry and protein immunoblotting assay confilcted. Of the remaining, two instances were rejected due to failed array hybridization. The rest data are further splited into training (38), and validation (4)."
1435,fourclass,"**Author**: Tin Kam Ho and Eugene M. Kleinberg.  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: Tin Kam Ho and Eugene M. Kleinberg.
Building projectable classifiers of arbitrary complexity.
In Proceedings of the 13th International Conference on Pattern Recognition, pages 880-885, Vienna, Austria, August 1996.  

#Dataset from the LIBSVM data repository.

Preprocessing: transform to two-class"
1436,german.numer,
1441,KungChi3,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

Kung chi"
1442,MegaWatt1,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

Mega watt"
1443,PizzaCutter1,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

Pizza cutter"
1444,PizzaCutter3,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

Pizza cutter 3"
1446,CostaMadre1,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

Costa madre 1"
1447,CastMetal1,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

cast metal 1"
1448,KnuggetChase3,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

knugget chase 3"
1449,MeanWhile1,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

Mean While 1"
1450,MindCave2,"**Author**:   
**Source**: Unknown - Date unknown  
**Please cite**:   

Mind Cave 2"
1451,PieChart1,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

pie chart 1"
1452,PieChart2,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

pie chart 2"
1453,PieChart3,"**Author**: Hans Bauer Jesus"",""Deter Bergman  
**Source**: Unknown - Date unknown  
**Please cite**:   

pie chart 3"
1455,acute-inflammations,"**Author**: Jacek Czerniak     
**Source**: UCI     
**Please cite**:  J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive diagnosis of urinary system diseases, Artificial Intelligence and Security in Computing Systems, ACS'2002 9th International Conference Proceedings, Kluwer Academic Publishers,2003, pp. 41-51.


* Abstract: 

The data was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of the urinary system.

* Source:   
  
Jacek Czerniak, Ph.D., Assistant Professor
Systems Research Institute
Polish Academy of Sciences
Laboratory of Intelligent Systems
ul. Newelska 6, Room 218
01-447 Warszawa, Poland
e-mail: jacek.czerniak 'at' ibspan.waw.pl or jczerniak 'at' ukw.edu.pl 


* Data Set Information:
 
The main idea of this data set is to prepare the algorithm of the expert system, which will perform the presumptive diagnosis of two diseases of urinary system. It will be the example of diagnosing of the acute inflammations of urinary bladder and acute nephritises. For better understanding of the problem let us consider definitions of both diseases given by medics. Acute inflammation of urinary bladder is characterised by sudden occurrence of pains in the abdomen region and the urination in form of constant urine pushing, micturition pains and sometimes lack of urine keeping. Temperature of the body is rising, however most often not above 38C. The excreted urine is turbid and sometimes bloody. At proper treatment, symptoms decay usually within several days. However, there is inclination to returns. At persons with acute inflammation of urinary bladder, we should expect that the illness will turn into protracted form.

Acute nephritis of renal pelvis origin occurs considerably more often at women than at men. It begins with sudden fever, which reaches, and sometimes exceeds 40C. The fever is accompanied by shivers and one- or both-side lumbar pains, which are sometimes very strong. Symptoms of acute inflammation of urinary bladder appear very often. Quite not infrequently there are nausea and vomiting and spread pains of whole abdomen.

The data was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two  diseases of urinary system. The basis for rules detection was Rough Sets Theory. Each instance represents an potential patient. Each line of the data file starts with a digit which tells the temperature of patient.
  
-- Attribute lines:   
For example, '35,9 no no yes yes yes yes no'   
Where:   
'35,9' Temperature of patient   
'no' Occurrence of nausea   
'no' Lumbar pain   
'yes' Urine pushing (continuous need for urination)   
'yes' Micturition pains   
'yes' Burning of urethra, itch, swelling of urethra outlet   
'yes' decision: Inflammation of urinary bladder   
'no' decision: Nephritis of renal pelvis origin    

*  Attribute Information:
  
a1 Temperature of patient { 35C-42C }    
a2 Occurrence of nausea { yes, no }   
a3 Lumbar pain { yes, no }   
a4 Urine pushing (continuous need for urination) { yes, no }   
a5 Micturition pains { yes, no }   
a6 Burning of urethra, itch, swelling of urethra outlet { yes, no }   
d1 decision: Inflammation of urinary bladder { yes, no }   
d2 decision: Nephritis of renal pelvis origin { yes, no }   


* Relevant Papers:

J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive diagnosis of urinary system diseases, Artificial Intelligence and Security in Computing Systems, ACS'2002 9th International Conference Proceedings, Kluwer Academic Publishers,2003, pp. 41-51"
1456,appendicitis,"**Author**: S. M. Weiss,C. A. Kulikowski  
**Source**: KEEL
**Please cite**:   

A copy of the data set proposed in: S. M. Weiss, and C. A. Kulikowski,  Computer Systems That Learn (1991)."
1457,amazon-commerce-reviews,"**Author**: Zhi Liu  
**Source**: UCI
**Please cite**:   

Dataset creator and donator: Zhi Liu, e-mail: liuzhi8673 '@' gmail.com, institution: National Engineering Research Center for E-Learning, Hubei Wuhan, China

Data Set Information:
 
dataset are derived from the customers reviews in Amazon Commerce Website for authorship identification. Most previous studies conducted the identification experiments for two to ten authors. But in the online context, reviews to be identified usually have more potential authors, and normally classification algorithms are not adapted to large number of target classes. To examine the robustness of classification algorithms, we identified 50 of the most active users (represented by a unique ID and username) who frequently posted reviews in these newsgroups. The number of reviews we collected for each author is 30.

Attribute Information:
 
attribution includes authors' linguistic style such as usage of digit, punctuation, words and sentences' length and usage frequency of words and so on"
1458,arcene,"**Author**:   
**Source**: UCI
**Please cite**:   

ARCENE's task is to distinguish cancer versus normal patterns from mass-spectrometric data. This is a two-class classification problem with continuous input variables. This dataset is one of 5 datasets of the NIPS 2003 feature selection challenge.

Source:
 a. Original owners 
The data were obtained from two sources: The National Cancer Institute (NCI) and the Eastern Virginia Medical School (EVMS). All the data consist of mass-spectra obtained with the SELDI technique. The samples include patients with cancer (ovarian or prostate cancer), and healthy or control patients. 

b. Donor of database 
This version of the database was prepared for the NIPS 2003 variable and feature selection benchmark by Isabelle Guyon, 955 Creston Road, Berkeley, CA 94708, USA (isabelle '@' clopinet.com). 

Data Set Information:
ARCENE was obtained by merging three mass-spectrometry datasets to obtain enough training and test data for a benchmark. The original features indicate the abundance of proteins in human sera having a given mass value. Based on those  features one must separate cancer patients from healthy patients. We added a 
 number of distractor feature called 'probes' having no predictive power. The order  of the features and patterns were randomized. This dataset is one of five datasets used in the NIPS 2003 feature selection challenge."
1459,artificial-characters,"**Author**: H. Altay Guvenir, Burak Acar, Haldun Muderrisoglu    
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Artificial+Characters) - 1992  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  

This database has been artificially generated. It describes the structure of the capital letters A, C, D, E, F, G, H, L, P, R, indicated by a number 1-10, in that order (A=1,C=2,...). Each letter's structure is described by a set of segments (lines) which resemble the way an automatic program would segment an image. The dataset consists of 600 such descriptions per letter. 

Originally, each 'instance' (letter) was stored in a separate file, each consisting of between 1 and 7 segments, numbered 0,1,2,3,... Here they are merged. That means that the first 5 instances describe the first 5 segments of the first segmentation of the first letter (A). Also, the training set (100 examples) and test set (the rest) are merged. The next 7 instances describe another segmentation (also of the letter A) and so on.

### Attribute Information  

* V1: object number, the number of the segment (0,1,2,..,7)  
* V2-V5: the initial and final coordinates of a segment in a cartesian plane (XX1,YY1,XX2,YY2).  
* V6: size, this is the length of a segment computed by using the geometric distance between two points A(X1,Y1) and B(X2,Y2).
* V7: diagonal, this is the length of the diagonal of the smallest rectangle which includes the picture of the character. The value of this attribute is the same in each object.

### Relevant Papers  

M. Botta, A. Giordana, L. Saitta: ""Learning Fuzzy Concept Definitions"", IEEE-Fuzzy Conference, 1993.  
M. Botta, A. Giordana: ""Learning Quantitative Feature in a Symbolic Environment"", LNAI 542, 1991, pp. 296-305."
1460,banana,"**Author**:   
**Source**: KEEL
**Please cite**:   

An artificial data set where instances belongs to several clusters with a banana shape. There are two attributes At1 and At2 corresponding to the x and y axis, respectively. The class label (-1 and 1) represents one of the two banana shapes in the dataset."
1461,bank-marketing,"**Author**: Paulo Cortez, Sérgio Moro
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/bank+marketing)
**Please cite**: S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.       

**Bank Marketing**  
The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed. 

The classification goal is to predict if the client will subscribe a term deposit (variable y).

### Attribute information  
For more information, read [Moro et al., 2011].

Input variables:

- bank client data:

1 - age (numeric) 

2 - job : type of job (categorical: ""admin."",""unknown"",""unemployed"",""management"",""housemaid"",""entrepreneur"", ""student"",""blue-collar"",""self-employed"",""retired"",""technician"",""services"") 

3 - marital : marital status (categorical: ""married"",""divorced"",""single""; note: ""divorced""  means divorced or widowed) 

4 - education (categorical: ""unknown"",""secondary"",""primary"",""tertiary"") 

5 - default: has credit in default? (binary: ""yes"",""no"") 

6 - balance: average yearly balance, in euros (numeric) 

7 - housing: has housing loan? (binary: ""yes"",""no"") 

8 - loan: has personal loan? (binary: ""yes"",""no"")

- related with the last contact of the current campaign:

9 - contact: contact communication type (categorical: ""unknown"",""telephone"",""cellular"")

10 - day: last contact day of the month (numeric)

11 - month: last contact month of year (categorical: ""jan"", ""feb"", ""mar"", ..., ""nov"", ""dec"")

12 - duration: last contact duration, in seconds (numeric)

- other attributes:

13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)

14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted) 

15 - previous: number of contacts performed before this campaign and for this client (numeric) 

16 - poutcome: outcome of the previous marketing campaign (categorical: ""unknown"",""other"",""failure"",""success"")
 
- output variable (desired target):

17 - y - has the client subscribed a term deposit? (binary: ""yes"",""no"")"
1462,banknote-authentication,"Author: Volker Lohweg (University of Applied Sciences, Ostwestfalen-Lippe)  
Source: [UCI](https://archive.ics.uci.edu/ml/datasets/banknote+authentication) - 2012  
Please cite: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html) 

Dataset about distinguishing genuine and forged banknotes. Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. A Wavelet Transform tool was used to extract features from these images.

### Attribute Information  

V1. variance of Wavelet Transformed image (continuous)  
V2. skewness of Wavelet Transformed image (continuous)  


Class (target). Presumably 1 for genuine and 2 for forged"
1463,blogger,"**Author**:   
**Source**: UCI
**Please cite**:   

Source:
 
http://www.ijcaonline.org/archives/volume47/number18/7291-0509
 
 
Data Set Information:
 
In this paper, we look for to recognize the causes of users tend to cyber space in Kohkiloye and Boyer Ahmad Province in Iran. Collecting information to form database is done by questionnaire. This questionnaire is provided as oral, written and also programming of a website which includes an internet questionnaire and the users can answer the questions as they wish. They entered their used websites, blogs and social networks during the day. After collecting questionnaires, the wed addresses are gathered to get expected results. And finally, their trustfulness is checked by analyzing their used web pages. As the results were same, for getting better and noiseless response, they will put in database.
  
Attribute Information:
 
We considered the following parameters as questions: age,  education, political attitudes, blog topic, and the type of the identity in internet, the influence of manager inefficiency on tendency, the effect of inefficient media on tendency, the effects of social and political conditions on tendency and finally the effect of poverty in the province on tendency. The noisy or too detailed data in database makes us far from to get proper and suitable answers of algorithms [8]. We preprocessed the data and eliminated some non-relevant data. Finally the followings are considered as the main fields which include: education, political caprice, topics, local media turnover (LMT) and local, political and social space (LPSS). 

The collected data are shown in Table 1. In order to get correct answer, we classify bloggers to two groups: professional bloggers and seasonal (temporary) bloggers. Professional bloggers are those who adopt blog as an effective digital media and interested in digital writing in continuous time intervals. Seasonal (temporary) bloggers are not professional and follow blogging in discrete time periods. In this study, we review the tendency factors considering whether these people are among professional bloggers (Pro Bloggers, PB) and then, consider the other factors according to it."
1464,blood-transfusion-service-center,"**Author**: Prof. I-Cheng Yeh  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center)  
**Please cite**: Yeh, I-Cheng, Yang, King-Jang, and Ting, Tao-Ming, ""Knowledge discovery on RFM model using Bernoulli sequence"", Expert Systems with Applications, 2008.   

**Blood Transfusion Service Center Data Set**  
Data taken from the Blood Transfusion Service Center in Hsin-Chu City in Taiwan -- this is a classification problem.

To demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build an FRMTC model, we selected 748 donors at random from the donor database. 

### Attribute Information  
* V1: Recency - months since last donation
* V2: Frequency - total number of donation
* V3: Monetary - total blood donated in c.c.
* V4: Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood).

The target attribute is a binary variable representing whether he/she donated blood in March 2007 (2 stands for donating blood; 1 stands for not donating blood)."
1465,breast-tissue,"**Author**: JP Marques de Sá, J Jossinet  
**Source**: UCI    
**Please cite**:     

* Source:
  
JP Marques de Sá, INEB-Instituto de Engenharia Biomédica, Porto, Portugal; e-mail: jpmdesa '@' gmail.com 
J Jossinet, inserm, Lyon, France

* Data Set Information:
  
Impedance measurements were made at the frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHz Impedance measurements of freshly excised breast tissue were made at the following frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHz. These measurements plotted in the (real, -imaginary) plane constitute the impedance spectrum from where the breast tissue features are computed. 

The dataset can be used for predicting the classification of either the original 6 classes or of 4 classes by merging together the fibro-adenoma, mastopathy and glandular classes whose discrimination is not important (they cannot be accurately discriminated anyway).

  
* Attribute Information:
  
I0 Impedivity (ohm) at zero frequency 
PA500 phase angle at 500 KHz 
HFS high-frequency slope of phase angle 
DA impedance distance between spectral ends 
AREA area under spectrum 
A/DA area normalized by DA 
MAX IP maximum of the spectrum 
DR distance between I0 and real part of the maximum frequency point 
P length of the spectral curve 
Class car(carcinoma), fad + mas + gla, con (connective), adi (adipose)."
1466,cardiotocography,"**Author**: J. P. Marques de Sá, J. Bernardes, D. Ayers de Campos.  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Cardiotocography)  
**Please cite**: Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318, [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)

2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.

### Attribute Information:  
LB - FHR baseline (beats per minute)  
AC - # of accelerations per second  
FM - # of fetal movements per second  
UC - # of uterine contractions per second  
DL - # of light decelerations per second  
DS - # of severe decelerations per second  
DP - # of prolongued decelerations per second  
ASTV - percentage of time with abnormal short term variability  
MSTV - mean value of short term variability  
ALTV - percentage of time with abnormal long term variability  
MLTV - mean value of long term variability  
Width - width of FHR histogram  
Min - minimum of FHR histogram  
Max - Maximum of FHR histogram  
Nmax - # of histogram peaks  
Nzeros - # of histogram zeros  
Mode - histogram mode  
Mean - histogram mean  
Median - histogram median  
Variance - histogram variance  
Tendency - histogram tendency  
CLASS - FHR pattern class code (1 to 10)  
NSP - fetal state class code (N=normal; S=suspect; P=pathologic)  

### Relevant Papers:
Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318"
1467,climate-model-simulation-crashes,"**Author**: D. Lucas, R. Klein, J. Tannahill, D. Ivanova, S. Brandon, D. Domyancic, Y. Zhang.

**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/climate+model+simulation+crashes)

**Please Cite**:
Lucas, D. D., Klein, R., Tannahill, J., Ivanova, D., Brandon, S., Domyancic, D., and Zhang, Y.: Failure analysis of parameter-induced simulation crashes in climate models, Geosci. Model Dev. Discuss., 6, 585-623, [Web Link](http://www.geosci-model-dev-discuss.net/6/585/2013/gmdd-6-585-2013.html), 2013.


Source:

D. Lucas (ddlucas .at. alum.mit.edu), Lawrence Livermore National Laboratory; R. Klein (rklein .at. astron.berkeley.edu), Lawrence Livermore National Laboratory & U.C. Berkeley; J. Tannahill (tannahill1 .at. llnl.gov), Lawrence Livermore National Laboratory; D. Ivanova (ivanova2 .at. llnl.gov), Lawrence Livermore National Laboratory; S. Brandon (brandon1 .at. llnl.gov), Lawrence Livermore National Laboratory; D. Domyancic (domyancic1 .at. llnl.gov), Lawrence Livermore National Laboratory; Y. Zhang (zhang24 .at. llnl.gov), Lawrence Livermore National Laboratory .

This data was constructed using LLNL's UQ Pipeline, was created under the auspices of the US Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344, was funded by LLNL's Uncertainty Quantification Strategic Initiative Laboratory Directed Research and Development Project under tracking code 10-SI-013, and is released under UCRL number LLNL-MISC-633994.


Data Set Information:

This dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles. Ensemble members were constructed using a Latin hypercube method in LLNL's UQ Pipeline software system to sample the uncertainties of 18 model parameters within the Parallel Ocean Program (POP2) component of the Community Climate System Model (CCSM4). Three separate Latin hypercube ensembles were conducted, each containing 180 ensemble members. 46 out of the 540 simulations failed for numerical reasons at combinations of parameter values. The goal is to use classification to predict simulation outcomes (fail or succeed) from input parameter values, and to use sensitivity analysis and feature selection to determine the causes of simulation crashes. Further details about the data and methods are given in the publication 'Failure Analysis of Parameter-Induced Simulation Crashes in Climate Models,' Geoscientific Model Development [(Web Link)](doi:10.5194/gmdd-6-585-2013).


Attribute Information:

The goal is to predict climate model simulation outcomes (column 21, fail or succeed) given scaled values of climate model input parameters (columns 3-20). 

- Column 1: Latin hypercube study ID (study 1 to study 3) 

- Column 2: simulation ID (run 1 to run 180) 

- Columns 3-20: values of 18 climate model parameters scaled in the interval [0, 1] 

- Column 21: simulation outcome (0 = failure, 1 = success)

Relevant Papers:

Lucas, D. D., Klein, R., Tannahill, J., Ivanova, D., Brandon, S., Domyancic, D., and Zhang, Y.: Failure analysis of parameter-induced simulation crashes in climate models, Geosci. Model Dev. Discuss., 6, 585-623, [Web Link](http://www.geosci-model-dev-discuss.net/6/585/2013/gmdd-6-585-2013.html), 2013."
1468,cnae-9,"**Author**: Patrick Marques Ciarelli, Elias Oliviera   
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/CNAE-9) - 2010  
**Please cite**:   

### Description

This is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a subset of 9 categories.

### Source
```
Patrick Marques Ciarelli, pciarelli '@' lcad.inf.ufes.br, Department of Electrical Engineering, Federal University of Espirito Santo 
Elias Oliveira, elias '@' lcad.inf.ufes.br, Department of Information Science, Federal University of Espirito Santo
```

### Data Set Information

This is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a 
subset of 9 categories cataloged in a table called National Classification of Economic Activities (Classificação Nacional de 
Atividade Econômicas - CNAE). The original texts were preprocessed to obtain the current data set: initially, it was kept only letters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally, 
each document was represented as a vector, where the weight of each word is its frequency in the document. 
This data set is highly sparse (99.22% of the matrix is filled with zeros).

### Attribute Information

In the dataset there are 857 attributes, 1 attributes with the class of instance and 856 with word frequency:
 ```
1. category: range 1 - 9 (integer)   
2. 857. word frequency: (integer)
```

### Relevant Papers

Patrick Marques Ciarelli, Elias Oliveira, 'Agglomeration and Elimination of Terms for Dimensionality Reduction', 
Ninth International Conference on Intelligent Systems Design and Applications, pp.547-552, 2009 

Patrick Marques Ciarelli, Elias Oliveira, Evandro O. T. Salles, 'An Evolving System Based on Probabilistic Neural Network', 
Brazilian Symposium on Artificial Neural Network, 2010"
1471,eeg-eye-state,"**Author**: Oliver Roesler  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State), Baden-Wuerttemberg, Cooperative State University (DHBW), Stuttgart, Germany  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  

All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analyzing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.

The features correspond to 14 EEG measurements from the headset, originally labeled AF3, F7, F3, FC5, T7, P, O1, O2, P8, T8, FC6, F4, F8, AF4, in that order."
1472,energy-efficiency,"**Author**: Angeliki Xifara, Athanasios Tsanas 

**Source**: UCI

**Please cite**:   

Source:
  
The dataset was created by Angeliki Xifara (angxifara @ gmail.com, Civil/Structural Engineer) and was processed by Athanasios Tsanas (tsanasthanasis @ gmail.com, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).

Data Set Information:
  
We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.
 
Attribute Information:
 
The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses. 

Specifically: 
X1  Relative Compactness 
X2  Surface Area 
X3  Wall Area 
X4  Roof Area 
X5  Overall Height 
X6  Orientation 
X7  Glazing Area 
X8  Glazing Area Distribution 
y1  Heating Load 
y2  Cooling Load"
1473,fertility,"**Author**: David Gil, Jose Luis Girela
   
**Source**: UCI

**Please cite**: David Gil, Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres, and Magnus Johnsson. Predicting seminal quality with artificial intelligence methods. Expert Systems with Applications, 39(16):12564 - 12573, 2012  

Source:

David Gil, 
dgil '@' dtic.ua.es, 
Lucentia Research Group, Department of Computer Technology, University of Alicante 

Jose Luis Girela, 
girela '@' ua.es, 
Department of Biotechnology, University of Alicante

Attribute Information:

Season in which the analysis was performed. 1) winter, 2) spring, 3) Summer, 4) fall. (-1, -0.33, 0.33, 1) 
Age at the time of analysis. 18-36 (0, 1) 
Childish diseases (ie , chicken pox, measles, mumps, polio) 1) yes, 2) no. (0, 1) 
Accident or serious trauma 1) yes, 2) no. (0, 1) 
Surgical intervention 1) yes, 2) no. (0, 1) 
High fevers in the last year 1) less than three months ago, 2) more than three months ago, 3) no. (-1, 0, 1) 
Frequency of alcohol consumption 1) several times a day, 2) every day, 3) several times a week, 4) once a week, 5) hardly ever or never (0, 1) 
Smoking habit 1) never, 2) occasional 3) daily. (-1, 0, 1) 
Number of hours spent sitting per day ene-16 (0, 1) 
Output: Diagnosis normal (N), altered (O)"
1475,first-order-theorem-proving,"**Author**: James P Bridge, Sean B Holden and Lawrence C Paulson 
  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/First-order+theorem+proving)  

**Please cite**: James P Bridge, Sean B Holden and Lawrence C Paulson . Machine learning for first-order theorem proving: learning to select a good heuristic. Journal of Automated Reasoning, Springer 2012/13. 

Source:

James P Bridge, Sean B Holden and Lawrence C Paulson 

University of Cambridge 
Computer Laboratory 
William Gates Building 
15 JJ Thomson Avenue 
Cambridge CB3 0FD 
UK 

+44 (0)1223 763500 
forename.surname '@' cl.cam.ac.uk


Data Set Information:

See the file dataset file.


Attribute Information:

The attributes are a mixture of static and dynamic features derived from theorems to be proved. See the paper for full details."
1476,gas-drift,"**Author**: Alexander Vergara  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/gas+sensor+array+drift+dataset) - 2012    
**Please cite**: Alexander Vergara, Shankar Vembu, Tuba Ayhan, Margaret A. Ryan, Margie L. Homer, Ramón Huerta. Chemical gas sensor drift compensation using classifier ensembles, Sensors and Actuators B: Chemical (2012) doi: 10.1016/j.snb.2012.01.074.   

### Description
Gas Sensor Array Drift Dataset Data Set

### Sources
```
(a) Creators: Alexander Vergara (vergara '@' ucsd.edu) 
BioCircutis Institute 
University of California San Diego 
San Diego, California, USA 

(b) Donors: Alexander Vergara (vergara '@' ucsd.edu) 
Ramon Huerta (rhuerta '@' ucsd.edu) 
```

### Dataset Information

This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations.  
The goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection. 

The primary purpose of providing this dataset is to make it freely accessible online to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.

The dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. 

Being completely operated by a fully computerized environment controlled by a LabVIEW's National Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.

The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv. An extension of this dataset with the concentration values is available at [Gas Sensor Array Drift Dataset at Different Concentrations Data Set](http://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset+at+Different+Concentrations).


### Attribute Information

The response of the said sensors is read-out in the form of the resistance across the active layer of each sensor. Hence each measurement produced a 16-channel time series, each of which represented by an aggregate of features reflecting all the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. 

In particular, two distinct types of features were considered in the creation of this dataset: 
(i) The so-called steady-state feature (Î”R), defined as the difference of the maximal resistance change and the baseline and its normalized version expressed by the ratio of the maximal resistance and the baseline values when the chemical vapor is present in the test chamber; and 
(ii) an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement procedure under controlled conditions, namely the exponential moving average (emaÎ±). These aggregate of features is a transform, borrowed from the field of econometrics originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the said transient portion into a real scalar, by estimating the maximum value â€”minimum for the decaying portion of the sensor responseâ€” of its exponential moving average (emaÎ±), with an initial condition set to zero and a scalar smoothing parameter of the operator, Î±, that defines both the quality of the feature and the time of its occurrence along the time series the scalar, set to range between 0 and 1. In particular, three different values for Î± were set to obtain three different feature values from the pre-recorded rising portion of the sensor response and three additional features with the same Î± values but for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. 

For a more detailed analysis and discussion on these features as well as a graphical illustration of them please refer to Section 2.3 and Figure 2, respectively of the annotated manuscript.

Once the abovementioned features are calculated, one is to form a feature vector containing the 8 features extracted from each particular sensor multiplied by the 16 sensors considered here. In the end, there is a resulting 128-dimensional feature vector containing all the features indicated above.

There are six possible classes: 
```
1: Ethanol 
2: Ethylene  
3: Ammonia 
4: Acetaldehyde 
5: Acetone 
6: Toluene
```
### Relevant Papers

Alexander Vergara, Shankar Vembu, Tuba Ayhan, Margaret A. Ryan, Margie L. Homer and Ramón Huerta, Chemical gas sensor drift compensation using classifier ensembles, Sensors and Actuators B: Chemical (2012) doi: 10.1016/j.snb.2012.01.074."
1477,gas-drift-different-concentrations,"**Author**: Alexander Vergara

**Source**: UCI

**Please cite**: 
A Vergara, S Vembu, T Ayhan, M Ryan, M Homer, R Huerta. ""Chemical gas sensor drift compensation using classifier ensembles."" Sensors and Actuators B: Chemical 166 (2012): 320-329.

I Rodriguez-Lujan, J Fonollosa, A Vergara, M Homer, R Huerta. ""On the calibration of sensor arrays for pattern recognition using the minimal number of experiments."" Chemometrics and Intelligent Laboratory Systems 130 (2014): 123-134.


Source:

Creators: Alexander Vergara (vergara '@' ucsd.edu) 
BioCircutis Institute 
University of California San Diego 
San Diego, California, USA 
Donors of the Dataset: 
Alexander Vergara (vergara '@' ucsd.edu) 
Jordi Fonollosa (fonollosa '@'ucsd.edu) 
Irene Rodriguez-Lujan (irrodriguezlujan '@' ucsd.edu) 
Ramon Huerta (rhuerta '@' ucsd.edu)


Data Set Information:

This data set contains 13,910 measurements from 16 chemical sensors exposed to 6 gases at different concentration levels. This dataset is an extension of the Gas Sensor Array Drift Dataset ([Web Link]), providing now the information about the concentration level at which the sensors were exposed for each measurement. The primary purpose of making this dataset freely accessible on-line is to provide an extensive dataset to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks, including sensor drift, classification, regression, among others. 

The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded. Citation of both Vergara et al. 'Chemical gas sensor drift compensation using classifier ensembles' and Rodriguez-Lujan et al. â€œOn the calibration of sensor arrays for pattern recognition using the minimal number of experimentsâ€ is required (see below). 

The dataset was gathered during the period of January 2008 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors. See reference 1 for more details on the experimental setup. 

The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, dosed at a wide variety of concentration levels in the intervals (50,1000), (5,500), (12,1000), (10,300), (10,600), and (10,100) ppmv, respectively.


Attribute Information:

The responses of the said sensors are read in the form of the resistance across the active layer of each sensor; hence, each measurement produced a 16-channel time series, each represented by an aggregate of features reflecting the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) the so-called steady-state feature (DR), defined as the maximal resistance change with respect to the baseline and its DR normalized version (DR divided by the acquired value when the chemical vapor is present in the test chamber). And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement. This aggregate of features is a transformation, borrowed from the field of econometrics and originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the transient portion of the sensor response into a real scalar by estimating the maximum/minimum value y[k] for the rising/decaying portion of the exponential moving average of the sensor response: 

y[k] = (1-Alfa) y[k-1]+Alfa(R[k]-R[k-1]) 

where R[k] is the sensor resistance measured at time k and Alfa is a scalar smoothing parameter between 0 and 1. 

In particular, three different values for Alfa=0.1, 0.01, 0.001 were set to obtain three different feature values from the rising portion of the sensor response and three additional features with the same Alfa values for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. 

Thus, each feature vector contains the 8 features extracted from each particular sensor, resulting in a 128-dimensional feature vector (8 features x 16 sensors) containing all the features and organized as follows: 
DR_1, |DR|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, DR_2, |DR|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., DR_16, |DR|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16 
where: DR_j and |DR|_j are the R and the normalized R features, respectively. EMAi0.001_j, EMAi0.01_j, and EMAi0.1_j, are the emaR of the rising transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. EMAd0.001_j, EMAd0.01_j, and EMAd0.1_j, are emaR of the decaying transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. The index j=1â€¦16 represents the number of the sensor, forming thus the 128-dimensional feature vector. 

For processing purposes, the dataset is organized into ten batches, each containing the number of measurements per class and month indicated in the tables below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each batch. 

Batch ID Month IDs 
Batch 1 Months 1 and 2 
Batch 2 Months 3, 4, 8, 9 and 10 
Batch 3 Months 11, 12, and 13 
Batch 4 Months 14 and 15 
Batch 5 Month 16 
Batch 6 Months 17, 18, 19, and 20 
Batch 7 Month 21 
Batch 8 Months 22 and 23 
Batch 9 Months 24 and 30 
Batch 10 Month 36 

Batch ID: Ethanol, Ethylene, Ammonia, Acetaldehyde, Acetone, Toluene 
Batch 1: 83, 30, 70, 98, 90, 74 
Batch 2: 100, 109, 532, 334, 164, 5 
Batch 3: 216, 240, 275, 490, 365, 0 
Batch 4: 12, 30, 12, 43, 64, 0 
Batch 5: 20, 46, 63, 40, 28, 0 
Batch 6: 110, 29, 606, 574, 514, 467 
Batch 7: 360, 744, 630, 662, 649, 568 
Batch 8: 40, 33, 143, 30, 30, 18 
Batch 9: 100, 75, 78, 55, 61, 101 
Batch 10: 600, 600, 600, 600, 600, 600 


The dataset is organized in files, each representing a different batch. Within the files, each line represents a measurement. The first character (1-6) codes the analyte, followed by the concentration level: 

1: Ethanol; 2: Ethylene; 3: Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene 

The data format follows the same coding style as in libsvm format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 
1;10.000000 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 â€¦ 128:-2.654529 

The number 1 stands for the class number (in this case Ethanol), the gas concentration level was 10ppmv, and the remaining 128 columns list the actual feature values for each measurement recording organized as described above."
1478,har,"**Author**: Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto and Xavier Parra  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)  
**Please cite**: Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.   

**Human Activity Recognition**  
Human Activity Recognition (HAR) database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. This dataset version contains all the training and testing examples provided in the original data repository.

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers were selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low-frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.


### Attribute Information  
For each record in the dataset it is provided: 
* Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.  
* Triaxial Angular velocity from the gyroscope.  
* A 561-feature vector with time and frequency domain variables.  
* It's activity label.  

### Relevant Papers  

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012 

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz. Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care. Volume 19, Issue 9. May 2013

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assisted Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. Proceedings. Lecture Notes in Computer Science 2012, pp 216-223. 

Jorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu Català. Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013."
1479,hill-valley,"**Author**: Lee Graham, Franz Oppacher  
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/hill-valley)  
**Please cite**:   

Each record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y coordinate, the points will create either a Hill (a “bump” in the terrain) or a Valley (a “dip” in the terrain). 
See the original source for some examples of these graphs. 

In the original form, there are six files. This is the non-noisy version, with training and test sets merged. 

### Attribute Information:

1-100: Labeled “X##”. Floating point values (numeric), the Y-values of the graphs.  
101: Labeled “class”. Binary {0, 1} representing {valley, hill}"
1480,ilpd,"**Author**: Bendi Venkata Ramana, M. Surendra Prasad Babu, N. B. Venkateswarlu  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)) - 2012  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  

**Indian Liver Patient Dataset**  
This data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. The class label divides the patients into 2 groups (liver patient or not). This data set contains 441 male patient records and 142 female patient records. 

### Attribute Information  
V1. Age of the patient. Any patient whose age exceeded 89 is listed as being of age ""90"".  
V2. Gender of the patient  
V3. Total Bilirubin  
V4. Direct Bilirubin  
V5. Alkphos Alkaline Phosphatase  
V6. Sgpt Alanine Aminotransferase  
V7. Sgot Aspartate Aminotransferase   
V8. Total Proteins  
V9. Albumin  
V10. A/G Ratio Albumin and Globulin Ratio  

A feature indicating a train-test split has been removed.  

### Relevant Papers  
1. Bendi Venkata Ramana, Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu, A Critical Comparative Study of Liver Patients from USA and INDIA: An Exploratory Analysis, International Journal of Computer Science Issues, ISSN:1694-0784, May 2012. 
2. Bendi Venkata Ramana, Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu, A Critical Study of Selected Classification Algorithms for Liver Disease Diagnosis, International Journal of Database Management Systems (IJDMS), Vol.3, No.2, ISSN : 0975-5705, PP 101-114, May 2011."
1481,kr-vs-k,"**Author**:   
**Source**: KEEL 
**Please cite**:   

Abstract:

A chess endgame data set representing the positions on the board of the white king, the white rook, and the black king. The task is to determine the optimum number of turn required for white to win the game, which can be a draw if it takes more than sixteen turns.

Attributes Details:


1. White_king_col {a, b, c, d, e, f, g, h}
2. White_king_row {1, 2, 3, 4, 5, 6, 7, 8}
3. White_rook_col {a, b, c, d, e, f, g, h}
4. White_rook_row {1, 2, 3, 4, 5, 6, 7, 8}
5. Black_king_col {a, b, c, d, e, f, g, h}
6. Black_king_row {1, 2, 3, 4, 5, 6, 7, 8}
7. Class - Game {draw, zero, one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen}"
1482,leaf,"**Author**: Pedro F.B. Silva, Andre R.S. Marcal, Rubim M. Almeida da Silva    

**Source**: UCI 

**Please cite**: 'Evaluation of Features for Leaf Discrimination', Pedro F.B. Silva, Andre R.S. Marcal, Rubim M. Almeida da Silva (2013). Springer Lecture Notes in Computer Science, Vol. 7950, 197-204.
 

Abstract: 

This dataset consists in a collection of shape and texture features extracted from digital images of leaf specimens originating from a total of 40 different plant species.

Source:

This dataset was created by Pedro F. B. Silva and Andre R. S. Marcal using leaf specimens collected by Rubim Almeida da Silva at the Faculty of Science, University of Porto, Portugal.


Data Set Information:

For further details on this dataset and/or its attributes, please read the 'ReadMe.pdf' file included and/or consult the Master's Thesis 'Development of a System for Automatic Plant Species Recognition' available at [Web Link].


Attribute Information:

1. Class (Species) 
2. Specimen Number 
3. Eccentricity 
4. Aspect Ratio 
5. Elongation 
6. Solidity 
7. Stochastic Convexity 
8. Isoperimetric Factor 
9. Maximal Indentation Depth 
10. Lobedness 
11. Average Intensity 
12. Average Contrast 
13. Smoothness 
14. Third moment 
15. Uniformity 
16. Entropy"
1483,ldpa,"**Author**:   

**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Localization+Data+for+Person+Activity)

**Please cite**:  B. Kaluza, V. Mirchevska, E. Dovgan, M. Lustrek, M. Gams, An Agent-based Approach to Care in Independent Living, International Joint Conference on Ambient Intelligence (AmI-10), Malaga, Spain, In press

Dataset Title: 

Localization Data for Person Activity Data Set

Abstract: 

Data contains recordings of five people performing different activities. Each person wore four sensors (tags) while performing the same scenario five times.

Source:

- Creators: Mitja Lustrek (mitja.lustrek '@' ijs.si), Bostjan Kaluza (bostjan.kaluza '@' ijs.si), Rok Piltaver (rok.piltaver '@' ijs.si), Jana Krivec (jana.krivec '@' ijs.si), Vedrana Vidulin (vedrana.vidulin '@' ijs.si) 
- Jozef Stefan Institute, Jamova cesta 39, 1000 Ljubljana, Slovenija 
- Donor: Bozidara Cvetkovic (boza.cvetkovic '@' ijs.si) 
- Jozef Stefan Institute, Jamova cesta 39, 1000 Ljubljana, Slovenija 
- Date received: October, 2010

Data Set Information:

People used for recording of the data were wearing four tags (ankle left, ankle right, belt and chest). 
Each instance is a localization data for one of the tags. The tag can be identified by one of the attributes.


Attribute Information:

Instance example: A01,020-000-033-111,633790226057226795,27.05.2009 14:03:25:723,4.292500972747803,2.0738532543182373,1.36650812625885,walking 

1) Sequence Name {A01,A02,A03,A04,A05,B01,B02,B03,B04,B05,C01,C02,C03,C04,C05,D01,D02,D03,D04,D05,E01,E02,E03,E04,E05} (Nominal) 
- A, B, C, D, E = 5 people 
2) Tag identificator {010-000-024-033,020-000-033-111,020-000-032-221,010-000-030-096} (Nominal) 
- ANKLE_LEFT = 010-000-024-033 
- ANKLE_RIGHT = 010-000-030-096 
- CHEST = 020-000-033-111 
- BELT = 020-000-032-221 
3) timestamp (Numeric) all unique 
4) date FORMAT = dd.MM.yyyy HH:mm:ss:SSS (Date) 
5) x coordinate of the tag (Numeric) 
6) y coordinate of the tag (Numeric) 
7) z coordinate of the tag (Numeric) 
8) activity {walking,falling,'lying down',lying,'sitting down',sitting,'standing up from lying','on all fours','sitting on the ground','standing up from sitting','standing up from sitting on the ground'} (Nominal) 

Relevant Papers:

B. Kaluza, V. Mirchevska, E. Dovgan, M. Lustrek, M. Gams, An Agent-based Approach to Care in Independent Living, International Joint Conference on Ambient Intelligence (AmI-10), Malaga, Spain, In press"
1484,lsvt,"**Author**: Athanasios Tsanas

**Source**: UCI 

**Please cite**: A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: Objective automatic assessment of rehabilitative speech treatment in Parkinsons disease, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014   

Dataset title

laLSVT Voice Rehabilitation Data Set 

Source:

The dataset was created by Athanasios Tsanas (tsanasthanasis '@' gmail.com) of the University of Oxford.

Abstract: 
126 samples from 14 participants, 309 features. Aim: assess whether voice rehabilitation treatment lead to phonations considered 'acceptable' or 'unacceptable' (binary class classification problem).


Data Set Information:

The original paper demonstrated that it is possible to correctly replicate the experts' binary assessment with approximately 90% accuracy using both 10-fold cross-validation and leave-one-subject-out validation. We experimented with both random forests and support vector machines, using standard approaches for optimizing the SVM's hyperparameters. It will be interesting if researchers can improve on this finding using advanced machine learning tools. 

Details for the dataset can be found on the following paper. 
A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: â€œObjective automatic assessment of rehabilitative speech treatment in Parkinsonâ€™s diseaseâ€, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014 

A freely available preprint is availabe from the first author's website.


Attribute Information:

Each attribute (feature) corresponds to the application of a speech signal processing algorithm which aims to characterise objectively the signal. These algorithms include standard perturbation analysis methods, wavelet-based features, fundamental frequency-based features, and tools used to mine nonlinear time-series. Because of the extensive number of attributes we refer the interested readers to the relevant papers for further details.


Relevant Papers:

The dataset was introduced in: 
A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: â€œObjective automatic assessment of rehabilitative speech treatment in Parkinsonâ€™s diseaseâ€, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014 

Further details about the speech signal processing algorithms can be found in: 

A. Tsanas, Accurate telemonitoring of Parkinsonâ€™s disease symptom severity using nonlinear speech signal processing and statistical machine learning, D.Phil. (Ph.D.) thesis, University of Oxford, UK, 2012 

A. Tsanas, M.A. Little, P.E. McSharry, L.O. Ramig: â€œNonlinear speech analysis algorithms mapped to a standard metric achieve clinically useful quantification of average Parkinsonâ€™s disease symptom severityâ€, Journal of the Royal Society Interface, Vol. 8, pp. 842-855, 2011 

A. Tsanas, M.A. Little, P.E. McSharry, L.O. Ramig: â€œNew nonlinear markers and insights into speech signal degradation for effective tracking of Parkinsonâ€™s disease symptom severityâ€, International Symposium on Nonlinear Theory and its Applications (NOLTA), pp. 457-460, Krakow, Poland, 5-8 September 2010 

Preprints are available on the first author's website."
1485,madelon,"**Author**: Isabelle Guyon  
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/madelon)  
**Please cite**: Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge.

#### Abstract: 

MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear.

#### Source:

Isabelle Guyon 
Clopinet 
955 Creston Road 
Berkeley, CA 90708 
isabelle '@' clopinet.com 

#### Data Set Information:

MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five-dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). It was added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. 

This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. The original data was split into training, validation and test set. Target values are provided only for two first sets (not for the test set). So, this dataset version contains all the examples from training and validation partitions. 

There is no attribute information provided to avoid biasing the feature selection process.

#### Relevant Papers:

The best challenge entrants wrote papers collected in the book: 
Isabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer.

Isabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438–1444. 

Isabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report."
1486,nomao,"**Author**: Nomao Labs

**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Nomao)

**Please cite**: Laurent Candillier and Vincent Lemaire. Design and Analysis of the Nomao Challenge - Active Learning in the Real-World. In: Proceedings of the ALRA : Active Learning in Real-world Applications, Workshop ECML-PKDD 2012, Friday, September 28, 2012, Bristol, UK.

1. Data set title:
Nomao Data Set 


2. Abstract: 
Nomao collects data about places (name, phone, localization...) from many sources. Deduplication consists in detecting what data refer to the same place. Instances in the dataset compare 2 spots.

3. Data Set Characteristics:  

- Univariate
- Area: Computer
- Attribute Characteristics: Real
- Associated Tasks: Classification
- Missing Values?: Yes


4. Source:

(a) Original owner of database (name / phone / snail address / email address) 
Nomao / 00 33 5 62 48 33 90 / 1 avenue Jean Rieux, 31500 Toulouse / challenge '@' nomao.com 
(b) Donor of database (name / phone / snail address / email address) 
Laurent Candillier / - / 1 avenue Jean Rieux, 31500 Toulouse / laurent '@' nomao.com


5. Data Set Information:

The dataset has been enriched during the Nomao Challenge: organized along with the ALRA workshop (Active Learning in Real-world Applications): held at the ECML-PKDD 2012 conference.

5.1. Number of Instances

34,465 instances, mix of continuous and nominal, labeled by human expert.

First 29,104 instances have been labeled with ""human prior"".
See the corresponding article described in section ""3. Past Usage"" for more details.

Next 917 instances have been labeled using the active learning method called ""marg"".
Next 964 instances refer to the active method called ""wmarg"".
Next 995 instances refer to the active method called ""wmarg5"".
Next 1,985 instances refer to the active method called ""rand"" (random selection).

Last instances have been labeled during the corresponding challenge.
More details can be found in http://www.nomao.com/labs/challenge
Next 163 instances refer to the active method called ""baseline"".
Next 167 instances refer to the active method called ""nomao"".
And last 170 instances refer to the active method called ""tsun"".

5.2. Number of Attributes 

120 attributes: 89 continuous, 31 nominal (including the attributes 'label' and 'id'). 

The features are separated by comma.

5.3. Attribute Information: 

Missing data are allowed, represented by question marks '?'.

Labels are +1 if the concerned spots must be merged, -1 if they do not refer to the same entity.

1 id: name is composed of the names of the spots that are compared, separated by a sharp (#).   
2 clean_name_intersect_min: continuous.   
3 clean_name_intersect_max: continuous.   
4 clean_name_levenshtein_sim: continuous.   
5 clean_name_trigram_sim: continuous.   
6 clean_name_levenshtein_term: continuous.   
7 clean_name_trigram_term: continuous.   
8 clean_name_including: n,s,m.   
9 clean_name_equality: n,s,m.   
10 city_intersect_min: continuous.   
11 city_intersect_max: continuous.   
12 city_levenshtein_sim: continuous.   
13 city_trigram_sim: continuous.   
14 city_levenshtein_term: continuous.   
15 city_trigram_term: continuous.   
16 city_including: n,s,m.   
17 city_equality: n,s,m.   
18 zip_intersect_min: continuous.   
19 zip_intersect_max: continuous.   
20 zip_levenshtein_sim: continuous.   
21 zip_trigram_sim: continuous.   
22 zip_levenshtein_term: continuous.   
23 zip_trigram_term: continuous.   
24 zip_including: n,s,m.   
25 zip_equality: n,s,m.   
26 street_intersect_min: continuous.   
27 street_intersect_max: continuous.   
28 street_levenshtein_sim: continuous.   
29 street_trigram_sim: continuous.   
30 street_levenshtein_term: continuous.   
31 street_trigram_term: continuous.   
32 street_including: n,s,m.   
33 street_equality: n,s,m.   
34 website_intersect_min: continuous.   
35 website_intersect_max: continuous.   
36 website_levenshtein_sim: continuous.   
37 website_trigram_sim: continuous.   
38 website_levenshtein_term: continuous.   
39 website_trigram_term: continuous.   
40 website_including: n,s,m.   
41 website_equality: n,s,m.   
42 countryname_intersect_min: continuous.   
43 countryname_intersect_max: continuous.   
44 countryname_levenshtein_sim: continuous.   
45 countryname_trigram_sim: continuous.   
46 countryname_levenshtein_term: continuous.   
47 countryname_trigram_term: continuous.   
48 countryname_including: n,s,m.   
49 countryname_equality: n,s,m.   
50 geocoderlocalityname_intersect_min: continuous.   
51 geocoderlocalityname_intersect_max: continuous.   
52 geocoderlocalityname_levenshtein_sim: continuous.   
53 geocoderlocalityname_trigram_sim: continuous.   
54 geocoderlocalityname_levenshtein_term: continuous.   
55 geocoderlocalityname_trigram_term: continuous.   
56 geocoderlocalityname_including: n,s,m.   
57 geocoderlocalityname_equality: n,s,m.   
58 geocoderinputaddress_intersect_min: continuous.   
59 geocoderinputaddress_intersect_max: continuous.   
60 geocoderinputaddress_levenshtein_sim: continuous.   
61 geocoderinputaddress_trigram_sim: continuous.   
62 geocoderinputaddress_levenshtein_term: continuous.   
63 geocoderinputaddress_trigram_term: continuous.   
64 geocoderinputaddress_including: n,s,m.   
65 geocoderinputaddress_equality: n,s,m.   
66 geocoderoutputaddress_intersect_min: continuous.   
67 geocoderoutputaddress_intersect_max: continuous.   
68 geocoderoutputaddress_levenshtein_sim: continuous.   
69 geocoderoutputaddress_trigram_sim: continuous.   
70 geocoderoutputaddress_levenshtein_term: continuous.   
71 geocoderoutputaddress_trigram_term: continuous.   
72 geocoderoutputaddress_including: n,s,m.   
73 geocoderoutputaddress_equality: n,s,m.   
74 geocoderpostalcodenumber_intersect_min: continuous.   
75 geocoderpostalcodenumber_intersect_max: continuous.   
76 geocoderpostalcodenumber_levenshtein_sim: continuous.   
77 geocoderpostalcodenumber_trigram_sim: continuous.   
78 geocoderpostalcodenumber_levenshtein_term: continuous.   
79 geocoderpostalcodenumber_trigram_term: continuous.   
80 geocoderpostalcodenumber_including: n,s,m.   
81 geocoderpostalcodenumber_equality: n,s,m.   
82 geocodercountrynamecode_intersect_min: continuous.   
83 geocodercountrynamecode_intersect_max: continuous.   
84 geocodercountrynamecode_levenshtein_sim: continuous.   
85 geocodercountrynamecode_trigram_sim: continuous.   
86 geocodercountrynamecode_levenshtein_term: continuous.   
87 geocodercountrynamecode_trigram_term: continuous.   
88 geocodercountrynamecode_including: n,s,m.   
89 geocodercountrynamecode_equality: n,s,m.   
90 phone_diff: continuous.   
91 phone_levenshtein: continuous.   
92 phone_trigram: continuous.   
93 phone_equality: n,s,m.   
94 fax_diff: continuous.   
95 fax_levenshtein: continuous.   
96 fax_trigram: continuous.   
97 fax_equality: n,s,m.   
98 street_number_diff: continuous.   
99 street_number_levenshtein: continuous.   
100 street_number_trigram: continuous.   
101 street_number_equality: n,s,m.   
102 geocode_coordinates_long_diff: continuous.   
103 geocode_coordinates_long_levenshtein: continuous.   
104 geocode_coordinates_long_trigram: continuous.   
105 geocode_coordinates_long_equality: n,s,m.   
106 geocode_coordinates_lat_diff: continuous.   
107 geocode_coordinates_lat_levenshtein: continuous.   
108 geocode_coordinates_lat_trigram: continuous.   
109 geocode_coordinates_lat_equality: n,s,m.   
110 coordinates_long_diff: continuous.   
111 coordinates_long_levenshtein: continuous.   
112 coordinates_long_trigram: continuous.   
113 coordinates_long_equality: n,s,m.   
114 coordinates_lat_diff: continuous.   
115 coordinates_lat_levenshtein: continuous.   
116 coordinates_lat_trigram: continuous.   
117 coordinates_lat_equality: n,s,m.   
118 geocode_coordinates_diff: continuous.   
119 coordinates_diff: continuous.   
120 label: +1,-1.

Relevant Papers: Laurent Candillier and Vincent Lemaire. Design and Analysis of the Nomao Challenge - Active Learning in the Real-World. In: Proceedings of the ALRA : Active Learning in Real-world Applications, Workshop ECML-PKDD 2012, Friday, September 28, 2012, Bristol, UK."
1487,ozone-level-8hr,"**Author**: Kun Zhang, Wei Fan, XiaoJing Yuan

**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ozone+level+detection)

**Please cite**:   

Forecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008. 


1 . Abstract: 
Two ground ozone level data sets are included in this collection. One is the eight hour peak set (eighthr.data), the other is the one hour peak set (onehr.data). Those data were collected from 1998 to 2004 at the Houston, Galveston and Brazoria area.

2. Source:

Kun Zhang, zhang.kun05 '@' gmail.com, Department of Computer Science, Xavier University of Lousiana 
Wei Fan, wei.fan '@' gmail.com, IBM T.J.Watson Research 
XiaoJing Yuan, xyuan '@' uh.edu, Engineering Technology Department, College of Technology, University of Houston 


3. Data Set Information:

All the attribute start with T means the temperature measured at different time throughout the day; and those starts with WS indicate the wind speed at various time. 

WSR_PK: continuous. peek wind speed -- resultant (meaning average of wind vector) 
WSR_AV: continuous. average wind speed 
T_PK: continuous. Peak T 
T_AV: continuous. Average T 
T85: continuous. T at 850 hpa level (or about 1500 m height) 
RH85: continuous. Relative Humidity at 850 hpa 
U85: continuous. (U wind - east-west direction wind at 850 hpa) 
V85: continuous. V wind - N-S direction wind at 850 
HT85: continuous. Geopotential height at 850 hpa, it is about the same as height at low altitude 
T70: continuous. T at 700 hpa level (roughly 3100 m height) 

RH70: continuous. 
U70: continuous. 
V70: continuous. 
HT70: continuous. 

T50: continuous. T at 500 hpa level (roughly at 5500 m height) 

RH50: continuous. 
U50: continuous. 
V50: continuous. 
HT50: continuous. 

KI: continuous. K-Index [Web Link] 
TT: continuous. T-Totals [Web Link] 
SLP: continuous. Sea level pressure 
SLP_: continuous. SLP change from previous day 

Precp: continuous. -- precipitation


4. Attribute Information:

The following are specifications for several most important attributes that are highly valued by Texas Commission on Environmental Quality (TCEQ). More details can be found in the two relevant papers. 

O 3 - Local ozone peak prediction 
Upwind - Upwind ozone background level 
EmFactor - Precursor emissions related factor 
Tmax - Maximum temperature in degrees F 
Tb - Base temperature where net ozone production begins (50 F) 
SRd - Solar radiation total for the day 
WSa - Wind speed near sunrise (using 09-12 UTC forecast mode) 
WSp - Wind speed mid-day (using 15-21 UTC forecast mode) 


5. Relevant Papers:

Forecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008. 

It Discusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods. 
A shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in: 
Forecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764"
1488,parkinsons,"**Author**:   
**Source**: UCI
**Please cite**: 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. BioMedical Engineering OnLine 2007, 6:23 (26 June 2007) 

* Abstract: 

Oxford Parkinson's Disease Detection Dataset

* Source:

The dataset was created by Max Little of the University of Oxford, in collaboration with the National Centre for Voice and Speech, Denver, Colorado, who recorded the speech signals. The original study published the feature extraction methods for general voice disorders.

* Data Set Information:
This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (""name"" column). The main aim of the data is to discriminate healthy people from those with PD, according to ""status"" column which is set to 0 for healthy and 1 for PD. 

Further details are contained in the following reference -- if you use this dataset, please cite: 
Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).


* Attribute Information:

Matrix column entries (attributes): 
name - ASCII subject name and recording number 
MDVP:Fo(Hz) - Average vocal fundamental frequency 
MDVP:Fhi(Hz) - Maximum vocal fundamental frequency 
MDVP:Flo(Hz) - Minimum vocal fundamental frequency 
MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency 
MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude 
NHR,HNR - Two measures of ratio of noise to tonal components in the voice 
status - Health status of the subject (one) - Parkinson's, (zero) - healthy 
RPDE,D2 - Two nonlinear dynamical complexity measures 
DFA - Signal fractal scaling exponent 
spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation"
1489,phoneme,"**Author**: Dominique Van Cappel, THOMSON-SINTRA  
**Source**: [KEEL](http://sci2s.ugr.es/keel/dataset.php?cod=105#sub2), [ELENA](https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/databases/REAL/phoneme/) - 1993  
**Please cite**: None  

The aim of this dataset is to distinguish between nasal (class 0) and oral sounds (class 1). Five different attributes were chosen to characterize each vowel: they are the amplitudes of the five first harmonics AHi, normalised by the total energy Ene (integrated on all the frequencies): AHi/Ene. The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.  

### Source

The current dataset was formatted by the KEEL repository, but originally hosted by the [ELENA Project](https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/elena.htm#stuff). The dataset originates from the European ESPRIT 5516 project: ROARS. The aim of this project was the development and the implementation of a real time analytical system for French and Spanish speech recognition.  

### Relevant information

Most of the already existing speech recognition systems are global systems (typically Hidden Markov Models and Time Delay Neural Networks) which recognizes signals and do not really use the speech
specificities.  On the contrary, analytical systems take into account the articulatory process leading to the different phonemes of a given language, the idea being to deduce the presence of each of the
phonetic features from the acoustic observation.

The main difficulty of analytical systems is to obtain acoustical parameters sufficiantly reliable. These acoustical measurements must :

   - contain all the information relative to the concerned phonetic feature.
   - being speaker independent.
   - being context independent.
   - being more or less robust to noise.

The primary acoustical observation is always voluminous (spectrum x N different observation moments) and classification cannot been processed directly.

In ROARS, the initial database is provided by cochlear spectra, which may be seen as the output of a filters bank having a constant DeltaF/F0, where the central frequencies are distributed on a
logarithmic scale (MEL type) to simulate the frequency answer of the auditory nerves.  The filters outputs are taken every 2 or 8 msec (integration on 4 or 16 msec) depending on the type of phoneme
observed (stationary or transitory).  

The aim of the present database is to distinguish between nasal and
oral vowels. There are thus two different classes:

- Class 0 : Nasals  
- Class 1 : Orals        

This database contains vowels coming from 1809 isolated syllables (for example: pa, ta, pan,...). Five different attributes were chosen to characterize each vowel: they are the amplitudes of the five first harmonics AHi, normalised by the total energy Ene (integrated on all the frequencies): AHi/Ene. Each harmonic is signed: positive when it corresponds to a local maximum of the spectrum and negative otherwise.

Three observation moments have been kept for each vowel to obtain 5427 different instances: 

 - the observation corresponding to the maximum total energy Ene. 
   
 - the observations taken 8 msec before and 8 msec after the observation corresponding to this maximum total energy.

From these 5427 initial values, 23 instances for which the amplitude of the 5 first harmonics was zero were removed, leading to the 5404 instances of the present database. The patterns are presented in a random order.

### Past Usage  

Alinat, P., Periodic Progress Report 4, ROARS Project ESPRIT II- Number 5516, February 1993, Thomson report TS. ASM 93/S/EGS/NC/079  
    
Guerin-Dugue, A. and others, Deliverable R3-B4-P - Task B4: Benchmarks, Technical report, Elena-NervesII ""Enhanced Learning for Evolutive Neural Architecture"", ESPRIT-Basic Research Project  Number 6891, June 1995  

Verleysen, M. and Voz, J.L. and Thissen, P. and Legat, J.D., A statistical Neural Network for high-dimensional vector classification, ICNN'95 - IEEE International Conference on Neural Networks, November 1995, Perth, Western Australia.  
    
Voz J.L., Verleysen M., Thissen P. and Legat J.D., Suboptimal Bayesian classification by vector quantization with small clusters. ESANN95-European Symposium on Artificial Neural Networks, April 1995, M. Verleysen editor, D facto publications, Brussels, Belgium.  
    
Voz J.L., Verleysen M., Thissen P. and Legat J.D., A practical view of  suboptimal Bayesian classification, IWANN95-Proceedings of the International Workshop on Artificial Neural Networks, June 1995, Mira, Cabestany, Prieto editors, Springer-Verlag Lecture Notes in Computer Sciences, Malaga, Spain"
1490,planning-relax,"**Author**: Rajen Bhatt  

**Source**: UCI 

**Please cite**: Rajen Bhatt, 'Planning-Relax Dataset for Automatic Classification of EEG Signals', UCI Machine Learning Repository


* Title:

Planning Relax Data Set 


* Abstract: 

The dataset concerns with the classification of two mental stages from recorded EEG signals: Planning (during imagination of motor act) and Relax state.

* Data Set Characteristics:  

Univariate
Number of Instances: 182
Area: Computer
Attribute Characteristics: Real
Number of Attributes: 13
Associated Tasks: Classification
Missing Values? N/A

* Source:

Rajen Bhatt, rajen.bhatt '@' gmail.com, IIT Delhi


* Data Set Information:

EEG record contains many regular oscillations, which are believed to reflect synchronized rhythmic activity in a group of neurons. Most activity related EEG patterns occur within the following frequency bands. Delta (0.5 â€“ 4 Hz.), Theta (4 â€“ 8 Hz), Alpha (8 â€“ 13 Hz), Beta (13 â€“ 22 Hz), and Gamma (30 â€“ 40 Hz). The waves with the frequency of 7 â€“ 13 Hz over motor processing areas are called mu rhythm and reflect idling activity in motor areas. It is more pronounced when the subjects are at rest and at least a second before subjects initiate voluntary movement, the mu activity over the hemisphere contralateral to the region moved shows a decrease in amplitude and is called Event Related Desynchronization (ERD). 
For the current study, EEG data was collected for 5 times on various days from a healthy right-handed subject of 25 years of age. The data was recorded on a Medelec Profile Digital EEG machine. The settings of high frequency filter 50 Hz, low frequency filter 1.6 Hz, notch filter 50 Hz, sensitivity 70 micro volts/mm, and a sampling rate of 256 Hz were used for the basic signal processing. 
Eight EEG electrodes (C3, C4, P3, P4, F3, F4, T3, and T4) were placed according to the international standard 10-20 system of electrode placement. Bipolar and unipolar EEG was recorded from eight Ag/AgCI scalp electrodes, which were placed 2.5 cm anterior and posterior to the central electrodes C3 and C4 (left and right side of the hemisphere). A1 and A2 are reference electrodes. The reference electrodes are placed on the left and right ears and the ground electrode on the forehead. EOG (Electrooculogram) being a noise artifact, was derived from two electrodes, placed on the outer cantus of left and right eye in order to detect eye movement. These EOG signals are then used to eliminate eye movement artifacts. 
The subject was asked to lie down comfortably in a relaxed position with eyes closed and advised to minimize eye movements. The EEG was recorded for the relaxed state for 5 minutes. Following this, an audio beep of 60 db and 0.91 sec. duration was given at the start and end of a 5 second epoch where the subject was asked to mentally plan lifting of the right hand thumb. This activity is collected as a 5 second epoch data corresponding to â€˜movement imageryâ€™ state. After a gap of 5 minutes, the same cue is given to repeat the experiment. The whole experiment lasts for approximately 30 minutes, collecting data for 5 trials of 5 second epoch each for normal relaxed state and 5 trials of 5 second epoch each for movement imagery. No actual movement is performed during the session. All data sets were visually checked for artifacts before final selection.


* Attribute Information:

Wavelet transform has been applied for feature extraction for EEG classification. However, wavelet transforms pyramidal algorithm work only on approximation coefficients. So it can not identify 7-13 Hz frequency band. We have extended the methodology by applying wavelet packet analysis, which also decompose detail coefficients. Wavelet packet analysis has been used for signal decomposition with equal frequency bandwidth at each level of decomposition, which leads to an equal number of the approximation and detail coefficients. By applying wavelet packet analysis on the original signal, we have obtained twelve wavelet coefficients in the 7-13 Hz frequency band at the 6th level node (6,2). The signal is reconstructed at node (6,2) and its FFT plot gave the frequency band 7-13 Hz as the most discriminating, in conjunction with the wavelet Daubechies#6 (db6).


* Relevant Papers:

1. Rajen B. Bhatt and M. Gopal, 2008, â€œFRCT: Fuzzy-Rough Classification Treesâ€, Pattern Analysis and Applications, 11(1), pp. 73-88. 
2. Shweta Sahu and Rajen B. Bhatt, â€œAutomatic classification of Electroencephalography Signals using Wavelet Packet Analysis and Fuzzy Decision Treesâ€, in Proc. of 28th National Systems Conference (NSC-2004), Dec. 16-18, Vellore, India. 
3. Rajen Bhatt, 'Fuzzy-Rough Approach to Pattern Classification:Hybrid Algorithms and Optimization', Ph.D. Thesis, IIT Delhi, 2006."
1491,one-hundred-plants-margin,"**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) - 2010   
**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.     

### Description

One-hundred plant species leaves dataset (Class = Margin).
 
### Sources
```
   (a) Original owners of colour Leaves Samples:

 James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  
 The colour images are not included.  
 The Leaves were collected in the Royal Botanic Gardens, Kew, UK.  
 email: james.cope@kingston.ac.uk  
   
   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.  
 Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk  
```

### Dataset Information

The original data directory contains the binary images (masks) of the leaf samples (colour images not included).
There are three features for each image: Shape, Margin and Texture.
For each feature, a 64 element vector is given per leaf sample.
These vectors are taken as a contiguous descriptor (for shape) or histograms (for texture and margin).
So, there are three different files, one for each feature problem:  
 * 'data_Sha_64.txt' -> prediction based on shape
 * 'data_Tex_64.txt' -> prediction based on texture
 * 'data_Mar_64.txt' -> prediction based on margin [**dataset provided here**] 

Each row has a 64-element feature vector followed by the Class label.
There is a total of 1600 samples with 16 samples per leaf class (100 classes), and no missing values.

### Attributes Information

Three 64 element feature vectors per sample.

### Relevant Papers

Charles Mallah, James Cope, James Orwell. 
Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. 
Signal Processing, Pattern Recognition and Applications, in press.

J. Cope, P. Remagnino, S. Barman, and P. Wilkin.
Plant texture classification using gabor co-occurrences.
Advances in Visual Computing,
pages 699-677, 2010.

T. Beghin, J. Cope, P. Remagnino, and S. Barman.
Shape and texture based plant leaf classification. 
In: Advanced Concepts for Intelligent Vision Systems,
pages 345-353. Springer, 2010."
1492,one-hundred-plants-shape,"**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) - 2010   
**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.     

### Description

One-hundred plant species leaves dataset (Class = Shape).
 
### Sources
```
   (a) Original owners of colour Leaves Samples:

 James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  
 The colour images are not included.  
 The Leaves were collected in the Royal Botanic Gardens, Kew, UK.  
 email: james.cope@kingston.ac.uk  
   
   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.  
 Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk  
```

### Dataset Information

The original data directory contains the binary images (masks) of the leaf samples (colour images not included).
There are three features for each image: Shape, Margin and Texture.
For each feature, a 64 element vector is given per leaf sample.
These vectors are taken as a contiguous descriptor (for shape) or histograms (for texture and margin).
So, there are three different files, one for each feature problem:  
 * 'data_Sha_64.txt' -> prediction based on shape [**dataset provided here**]
 * 'data_Tex_64.txt' -> prediction based on texture
 * 'data_Mar_64.txt' -> prediction based on margin  

Each row has a 64-element feature vector followed by the Class label.
There is a total of 1600 samples with 16 samples per leaf class (100 classes), and no missing values.

### Attributes Information

Three 64 element feature vectors per sample.

### Relevant Papers

Charles Mallah, James Cope, James Orwell. 
Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. 
Signal Processing, Pattern Recognition and Applications, in press.

J. Cope, P. Remagnino, S. Barman, and P. Wilkin.
Plant texture classification using gabor co-occurrences.
Advances in Visual Computing,
pages 699-677, 2010.

T. Beghin, J. Cope, P. Remagnino, and S. Barman.
Shape and texture based plant leaf classification. 
In: Advanced Concepts for Intelligent Vision Systems,
pages 345-353. Springer, 2010."
1493,one-hundred-plants-texture,"**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) - 2010   
**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.     

### Description

One-hundred plant species leaves dataset (Class = Texture).
 
### Sources
```
   (a) Original owners of colour Leaves Samples:

 James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  
 The colour images are not included.  
 The Leaves were collected in the Royal Botanic Gardens, Kew, UK.  
 email: james.cope@kingston.ac.uk  
   
   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.  
 Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk  
```

### Dataset Information

The original data directory contains the binary images (masks) of the leaf samples (colour images not included).
There are three features for each image: Shape, Margin and Texture.
For each feature, a 64 element vector is given per leaf sample.
These vectors are taken as a contiguous descriptor (for shape) or histograms (for texture and margin).
So, there are three different files, one for each feature problem:  
 * 'data_Sha_64.txt' -> prediction based on shape
 * 'data_Tex_64.txt' -> prediction based on texture [**dataset provided here**] 
 * 'data_Mar_64.txt' -> prediction based on margin 

Each row has a 64-element feature vector followed by the Class label.
There is a total of 1600 samples with 16 samples per leaf class (100 classes), and no missing values.

### Attributes Information

Three 64 element feature vectors per sample.

### Relevant Papers

Charles Mallah, James Cope, James Orwell. 
Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. 
Signal Processing, Pattern Recognition and Applications, in press.

J. Cope, P. Remagnino, S. Barman, and P. Wilkin.
Plant texture classification using gabor co-occurrences.
Advances in Visual Computing,
pages 699-677, 2010.

T. Beghin, J. Cope, P. Remagnino, and S. Barman.
Shape and texture based plant leaf classification. 
In: Advanced Concepts for Intelligent Vision Systems,
pages 345-353. Springer, 2010."
1494,qsar-biodeg,"**Author**: Kamel Mansouri, Tine Ringsted, Davide Ballabio  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation)  
**Please cite**: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878 


QSAR biodegradation Data Set 

* Abstract: 

Data set containing values for 41 attributes (molecular descriptors) used to classify 1055 chemicals into 2 classes (ready and not ready biodegradable).


* Source:

Kamel Mansouri, Tine Ringsted, Davide Ballabio (davide.ballabio '@' unimib.it), Roberto Todeschini, Viviana Consonni, Milano Chemometrics and QSAR Research Group (http://michem.disat.unimib.it/chm/), UniversitÃ  degli Studi Milano â€“ Bicocca, Milano (Italy)


* Data Set Information:

The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group (UniversitÃ  degli Studi Milano â€“ Bicocca, Milano, Italy). The research leading to these results has received funding from the European Communityâ€™s Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project. 
The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.


* Attribute Information:

41 molecular descriptors and 1 experimental class: 
1) SpMax_L: Leading eigenvalue from Laplace matrix 
2) J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity 
3) nHM: Number of heavy atoms 
4) F01[N-N]: Frequency of N-N at topological distance 1 
5) F04[C-N]: Frequency of C-N at topological distance 4 
6) NssssC: Number of atoms of type ssssC 
7) nCb-: Number of substituted benzene C(sp2) 
8) C%: Percentage of C atoms 
9) nCp: Number of terminal primary C(sp3) 
10) nO: Number of oxygen atoms 
11) F03[C-N]: Frequency of C-N at topological distance 3 
12) SdssC: Sum of dssC E-states 
13) HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass 
14) LOC: Lopping centric index 
15) SM6_L: Spectral moment of order 6 from Laplace matrix 
16) F03[C-O]: Frequency of C - O at topological distance 3 
17) Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom) 
18) Mi: Mean first ionization potential (scaled on Carbon atom) 
19) nN-N: Number of N hydrazines 
20) nArNO2: Number of nitro groups (aromatic) 
21) nCRX3: Number of CRX3 
22) SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability 
23) nCIR: Number of circuits 
24) B01[C-Br]: Presence/absence of C - Br at topological distance 1 
25) B03[C-Cl]: Presence/absence of C - Cl at topological distance 3 
26) N-073: Ar2NH / Ar3N / Ar2N-Al / R..N..R 
27) SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index) 
28) Psi_i_1d: Intrinsic state pseudoconnectivity index - type 1d 
29) B04[C-Br]: Presence/absence of C - Br at topological distance 4 
30) SdO: Sum of dO E-states 
31) TI2_L: Second Mohar index from Laplace matrix 
32) nCrt: Number of ring tertiary C(sp3) 
33) C-026: R--CX--R 
34) F02[C-N]: Frequency of C - N at topological distance 2 
35) nHDon: Number of donor atoms for H-bonds (N and O) 
36) SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass 
37) Psi_i_A: Intrinsic state pseudoconnectivity index - type S average 
38) nN: Number of Nitrogen atoms 
39) SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass 
40) nArCOOR: Number of esters (aromatic) 
41) nX: Number of halogen atoms 
42) experimental class: ready biodegradable (RB) and not ready biodegradable (NRB)


* Relevant Papers:

Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878"
1495,qualitative-bankruptcy,"**Author**:  A. Martin, J. Uthayakumar, M. Nadarajan, V. Prasanna Venkatesan   
**Source**: UCI   
**Please cite**:    

* Abstract: 

Predict the Bankruptcy from Qualitative parameters from experts.

* Source:

Source Information
-- Creator : Mr.A.Martin(jayamartin '@' yahoo.com)
Mr.J.Uthayakumar (uthayakumar17691 '@' gmail.com)
Mr.M.Nadarajan(nadaraj.muthuvel '@' gmail.com)
-- Guided By : Dr.V.Prasanna Venkatesan
-- Institution : Sri Manakula Vinayagar Engineering College and Pondicherry University
-- Country : India
-- Date : February 2014


* Data Set Information:

The parameters which we used for collecting the dataset is referred from the paper 'The discovery of expert' decision rules from qualitative bankruptcy data using genetic algorithms' by Myoung-Jong Kim*, Ingoo Han.


* Attribute Information: 
(P=Positive,A-Average,N-negative,B-Bankruptcy,NB-Non-Bankruptcy) 

1. Industrial Risk: {P,A,N} 
2. Management Risk: {P,A,N} 
3. Financial Flexibility: {P,A,N} 
4. Credibility: {P,A,N} 
5. Competitiveness: {P,A,N} 
6. Operating Risk: {P,A,N} 
7. Class: {B,NB}


* Relevant Papers:

The parameters which we used for collecting the dataset is referred from the paper 'The discovery of expertsâ€™ decision rules from qualitative bankruptcy data using genetic algorithms' by Myoung-Jong Kim*, Ingoo Han."
1496,ringnorm,"**Author**: Michael Revow     
**Source**: http://www.cs.toronto.edu/~delve/data/ringnorm/desc.html   
**Please cite**:     

1: Abstract: 

This is a 20 dimensional, 2 class classification problem. Each class is drawn from a multivariate normal distribution. Class 1 has mean zero and covariance 4 times the identity. Class 2 has mean (a,a,..a) and unit covariance. a = 2/sqrt(20). 

2: Data set description.

This is an implementation of Leo Breiman's ringnorm example[1]. It is a 20 dimensional, 2 class classification example. Each class is drawn from a multivariate normal distribution. Class 1 has mean zero and covariance 4 times the identity. Class 2 has mean (a,a,..a) and unit covariance. a = 2/sqrt(20). Breiman reports the theoretical expected misclassification rate as 1.3%. He used 300 training examples with CART and found an error of 21.4%.


- Type.          Classification 
- Origin.  Laboratory
- Instances.  7400
- Features.  20
- Classes.  2 
- Missing values. No

3: Attributes information

@relation ring
@attribute A1 real [-6879.0, 6285.0]
@attribute A2 real [-7141.0, 6921.0]
@attribute A3 real [-7734.0, 7611.0]
@attribute A4 real [-6627.0, 7149.0]
@attribute A5 real [-7184.0, 6383.0]
@attribute A6 real [-6946.0, 6743.0]
@attribute A7 real [-7781.0, 6285.0]
@attribute A8 real [-6882.0, 6357.0]
@attribute A9 real [-7184.0, 7487.0]
@attribute A10 real [-7232.0, 6757.0]
@attribute A11 real [-7803.0, 7208.0]
@attribute A12 real [-7395.0, 6791.0]
@attribute A13 real [-7096.0, 6403.0]
@attribute A14 real [-7472.0, 7261.0]
@attribute A15 real [-7342.0, 7372.0]
@attribute A16 real [-7121.0, 6905.0]
@attribute A17 real [-7163.0, 7175.0]
@attribute A18 real [-8778.0, 6896.0]
@attribute A19 real [-7554.0, 5726.0]
@attribute A20 real [-6722.0, 7627.0]
@attribute Class {0, 1}
@inputs A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20
@outputs Class"
1497,wall-robot-navigation,"**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Wall-Following+Robot+Navigation+Data) - 2010  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)

**Wall-Following Robot Navigation Data Data Set**  
The data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.

The data consists of raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second.

The class labels are:  
1. Move-Forward,  
2. Slight-Right-Turn,  
3. Sharp-Right-Turn,  
4. Slight-Left-Turn  

It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). 

The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. 

### Attribute Information:

1. US1: ultrasound sensor at the front of the robot (reference angle: 180°) 
2. US2: ultrasound reading (reference angle: -165°)
3. US3: ultrasound reading (reference angle: -150°)
4. US4: ultrasound reading (reference angle: -135°)
5. US5: ultrasound reading (reference angle: -120°)
6. US6: ultrasound reading (reference angle: -105°)
7. US7: ultrasound reading (reference angle: -90°)
8. US8: ultrasound reading (reference angle: -75°) 
9. US9: ultrasound reading (reference angle: -60°) 
10. US10: ultrasound reading (reference angle: -45°)
11. US11: ultrasound reading (reference angle: -30°) 
12. US12: ultrasound reading (reference angle: -15°)
13. US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0°) 
14. US14: ultrasound reading (reference angle: 15°)
15. US15: ultrasound reading (reference angle: 30°)
16. US16: ultrasound reading (reference angle: 45°)
17. US17: ultrasound reading (reference angle: 60°)
18. US18: ultrasound reading (reference angle: 75°)
19. US19: ultrasound reading (reference angle: 90°)
20. US20: ultrasound reading (reference angle: 105°)
21. US21: ultrasound reading (reference angle: 120°)
22. US22: ultrasound reading (reference angle: 135°)
23. US23: ultrasound reading (reference angle: 150°)
24. US24: ultrasound reading (reference angle: 165°)


### Relevant Papers

Ananda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), 'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation Tasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009), pages 1-6"
1498,sa-heart,"**Author**:   
**Source**: http://statweb.stanford.edu/~tibs/ElemStatLearn/data.html   
**Please cite**:   

* Title:

South Africa Heart Disease Dataset

* Description

A retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases the measurements were made after these treatments. These data are taken from a larger dataset, described in  Rousseauw et al, 1983, South African Medical
Journal. 

* Attributes:

sbp  systolic blood pressure   
tobacco  cumulative tobacco (kg)   
ldl  low densiity lipoprotein cholesterol   
adiposity  
famhist  family history of heart disease (Present, Absent)   
typea  type-A behavior   
obesity   
alcohol  current alcohol consumption   
age  age at onset   
chd  response, coronary heart disease"
1499,seeds,"**Author**: M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak  
**Source**: UCI     
**Please cite**:  Contributors gratefully acknowledge support of their work by the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.   

* Title:

seeds Data Set 

* Abstract: 

Measurements of geometrical properties of kernels belonging to three different varieties of wheat. A soft X-ray technique and GRAINS package were used to construct all seven, real-valued attributes.

* Source:

MaÅ‚gorzata Charytanowicz, Jerzy Niewczas 
Institute of Mathematics and Computer Science, 
The John Paul II Catholic University of Lublin, KonstantynÃ³w 1 H, 
PL 20-708 Lublin, Poland 
e-mail: {mchmat,jniewczas}@kul.lublin.pl 

Piotr Kulczycki, Piotr A. Kowalski, Szymon Lukasik, Slawomir Zak 
Department of Automatic Control and Information Technology, 
Cracow University of Technology, Warszawska 24, PL 31-155 Cracow, Poland 
and 
Systems Research Institute, Polish Academy of Sciences, Newelska 6, 
PL 01-447 Warsaw, Poland 
e-mail: {kulczycki,pakowal,slukasik,slzak}@ibspan.waw.pl


* Data Set Information:

The examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected for the experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin. The data set can be used for the tasks of classification and cluster analysis.

* Attribute Information:

To construct the data, seven geometric parameters of wheat kernels were measured: 
1. area A, 
2. perimeter P, 
3. compactness C = 4*pi*A/P^2, 
4. length of kernel, 
5. width of kernel, 
6. asymmetry coefficient 
7. length of kernel groove. 
All of these parameters were real-valued continuous.


* Relevant Papers:

M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak, 'A Complete Gradient Clustering Algorithm for Features Analysis of X-ray Images', in: Information Technologies in Biomedicine, Ewa Pietka, Jacek Kawa (eds.), Springer-Verlag, Berlin-Heidelberg, 2010, pp. 15-24."
1500,seismic-bumps,"**Author**: Sikora M., Wrobel L.     
**Source**: UCI   
**Please cite**:  Sikora M., Wrobel L.: Application of rule induction algorithms for analysis of data collected by seismic hazard monitoring systems in coal mines. Archives of Mining Sciences, 55(1), 2010, 91-114.  

* Title: 

seismic-bumps Data Set 

* Abstract: 

The data describe the problem of high energy (higher than 10^4 J) seismic bumps forecasting in a coal mine. Data come from two of longwalls located in a Polish coal mine.

* Source:

Marek Sikora^{1,2} (marek.sikora '@' polsl.pl), Lukasz Wrobel^{1} (lukasz.wrobel '@' polsl.pl) 
(1) Institute of Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland 
(2) Institute of Innovative Technologies EMAG, 40-189 Katowice, Poland


* Data Set Information:

Mining activity was and is always connected with the occurrence of dangers which are commonly called mining hazards. A special case of such threat is a seismic hazard which frequently occurs in many underground mines. Seismic hazard is the hardest detectable and predictable of natural hazards and in this respect it is comparable to an earthquake. More and more advanced seismic and seismoacoustic monitoring systems allow a better understanding rock mass processes and definition of seismic hazard 
prediction methods. Accuracy of so far created methods is however far from perfect. Complexity of seismic processes and big disproportion between the number of low-energy seismic events and the number of high-energy phenomena (e.g. > 10^4J) causes the statistical techniques to be insufficient to predict seismic hazard. Therefore, it is essential to search for new opportunities of better hazard prediction, also using machine learning methods. In seismic hazard assessment data clustering techniques can be 
applied (Lesniak A., Isakow Z.: Space-time clustering of seismic events and hazard assessment in the Zabrze-Bielszowice coal mine, Poland. Int. Journal of Rock Mechanics and Mining Sciences, 46(5), 2009, 918-928), and for prediction of seismic tremors artificial neural networks are used (Kabiesz, J.: Effect of the form of data on the quality of mine tremors hazard forecasting using neural networks. Geotechnical and Geological Engineering, 24(5), 2005, 1131-1147). In the majority of applications, the results obtained by mentioned methods are reported in the form of two states which are interpreted as 'hazardous' and 'non-hazardous'. Unbalanced distribution of positive ('hazardous state') and negative ('non-hazardous state') examples is a serious problem in seismic hazard prediction. Currently used methods are still insufficient to achieve good sensitivity and specificity of predictions. In the paper 
(Bukowska M.: The probability of rockburst occurrence in the Upper Silesian Coal Basin area dependent on natural mining conditions. Journal of Mining Sciences, 42(6), 2006, 570-577) a number of factors having an effect on seismic hazard occurrence was proposed, among other factors, the occurrence of tremors with energy > 10^4J was listed. The task of seismic prediction can be defined in different ways, but the main aim of all seismic hazard assessment methods is to predict (with given precision relating to time and 
date) of increased seismic activity which can cause a rockburst. In the data set each row contains a summary statement about seismic activity in the rock mass within one shift (8 hours). If decision attribute has the value 1, then in the next shift any seismic bump with an energy higher than 10^4 J was registered. That task of hazards prediction bases on the relationship between the energy of recorded tremors and seismoacoustic activity with the possibility of rockburst occurrence. Hence, such hazard prognosis is not connected with accurate rockburst prediction. Moreover, with the information about the possibility of hazardous situation occurrence, an appropriate supervision service can reduce a risk of rockburst (e.g. by distressing shooting) or withdraw workers from the threatened area. Good prediction of increased seismic activity is therefore a matter of great practical importance. The presented data set is characterized by unbalanced distribution of positive and negative examples. In the data set there 
are only 170 positive examples representing class 1. 


* Attribute Information:

1. seismic: result of shift seismic hazard assessment in the mine working obtained by the seismic 
method (a - lack of hazard, b - low hazard, c - high hazard, d - danger state); 
2. seismoacoustic: result of shift seismic hazard assessment in the mine working obtained by the 
seismoacoustic method; 
3. shift: information about type of a shift (W - coal-getting, N -preparation shift); 
4. genergy: seismic energy recorded within previous shift by the most active geophone (GMax) out of 
geophones monitoring the longwall; 
5. gpuls: a number of pulses recorded within previous shift by GMax; 
6. gdenergy: a deviation of energy recorded within previous shift by GMax from average energy recorded 
during eight previous shifts; 
7. gdpuls: a deviation of a number of pulses recorded within previous shift by GMax from average number 
of pulses recorded during eight previous shifts; 
8. ghazard: result of shift seismic hazard assessment in the mine working obtained by the 
seismoacoustic method based on registration coming form GMax only; 
9. nbumps: the number of seismic bumps recorded within previous shift; 
10. nbumps2: the number of seismic bumps (in energy range [10^2,10^3)) registered within previous shift; 
11. nbumps3: the number of seismic bumps (in energy range [10^3,10^4)) registered within previous shift; 
12. nbumps4: the number of seismic bumps (in energy range [10^4,10^5)) registered within previous shift; 
13. nbumps5: the number of seismic bumps (in energy range [10^5,10^6)) registered within the last shift; 
14. nbumps6: the number of seismic bumps (in energy range [10^6,10^7)) registered within previous shift; 
15. nbumps7: the number of seismic bumps (in energy range [10^7,10^8)) registered within previous shift; 
16. nbumps89: the number of seismic bumps (in energy range [10^8,10^10)) registered within previous shift; 
17. energy: total energy of seismic bumps registered within previous shift; 
18. maxenergy: the maximum energy of the seismic bumps registered within previous shift; 
19. class: the decision attribute - '1' means that high energy seismic bump occurred in the next shift 
('hazardous state'), '0' means that no high energy seismic bumps occurred in the next shift 
('non-hazardous state')."
1501,semeion,"**Author**: Semeion Research Center of Sciences of Communication     
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit)     
**Please cite**: Semeion Research Center of Sciences of Communication, via Sersale 117, 00128 Rome, Italy 
Tattile Via Gaetano Donizetti, 1-3-5,25030 Mairano (Brescia), Italy.    

### Dataset Description

Semeion Handwritten Digit Data Set, where 1593 handwritten digits from around 80 persons were scanned and documented. The each of the 256 variables V1 - V256 describe one of the pixels and their corresponding values. 

### Sources

The dataset was created by Tactile Srl, Brescia, Italy (http://www.tattile.it) and donated in 1994 to Semeion Research Center of Sciences of Communication, Rome, Italy (http://www.semeion.it), for machine learning research. 

For any questions, e-mail Massimo Buscema (m.buscema '@' semeion.it) or Stefano Terzi (s.terzi '@' semeion.it)

### DataSet Information

A total of 1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values. Then each pixel of each image was scaled into a boolean (1/0) value using a fixed threshold. 

Each person wrote in a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). 

The best validation protocol for this dataset seems to be a 5x2CV, 50% Tune (Train +Test) and completely blind 50% Validation

### Attribute Information

This dataset consists of 1593 records (rows) and 256 attributes (columns). 
Each record represents a handwritten digit, originally scanned with a resolution of 256 grays scale (28). 
Each pixel of the each original scanned image was first stretched, and after scaled between 0 and 1 (setting to 0 every pixel whose value was under the value 127 of the grey scale (127 included) and setting to 1 each pixel whose original value in the grey scale was over 127). 
Finally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes).

### Relevant Papers

M Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse 33(2)1998, pp 439-461."
1502,skin-segmentation,"**Author**: Rajen Bhatt, Abhinav Dhall  
**Source**: UCI   
**Please cite**: Rajen Bhatt, Abhinav Dhall, 'Skin Segmentation Dataset', UCI Machine Learning Repository   

* Title:

Skin Segmentation Data Set 

* Abstract: 

The Skin Segmentation dataset is constructed over B, G, R color space. Skin and Nonskin dataset is generated using skin textures from face images of diversity of age, gender, and race people.

* Source:

Rajen Bhatt, Abhinav Dhall, rajen.bhatt '@' gmail.com, IIT Delhi.

* Data Set Information:

The skin dataset is collected by randomly sampling B,G,R values from face images of various age groups (young, middle, and old), race groups (white, black, and asian), and genders obtained from FERET database and PAL database. Total learning sample size is 245057; out of which 50859 is the skin samples and 194198 is non-skin samples. Color FERET Image Database: [Web Link], PAL Face Database from Productive Aging Laboratory, The University of Texas at Dallas: [Web Link]. 


* Attribute Information:

This dataset is of the dimension 245057 * 4 where first three columns are B,G,R (x1,x2, and x3 features) values and fourth column is of the class labels (decision variable y).


* Relevant Papers:

1. Rajen B. Bhatt, Gaurav Sharma, Abhinav Dhall, Santanu Chaudhury, â€œEfficient skin region segmentation using low complexity fuzzy decision tree modelâ€, IEEE-INDICON 2009, Dec 16-18, Ahmedabad, India, pp. 1-4. 
2. Abhinav Dhall, Gaurav Sharma, Rajen Bhatt, Ghulam Mohiuddin Khan, â€œAdaptive Digital Makeupâ€, in Proc. of International Symposium on Visual Computing (ISVC) 2009, Nov. 30 â€“ Dec. 02, Las Vegas, Nevada, USA, Lecture Notes in Computer Science, Vol. 5876, pp. 728-736."
1503,spoken-arabic-digit,"**Author**: Data Collected by the Laboratory of Automatic and Signals, University of Badji-Mokhtar Annaba, Algeria.    
**Source**: UCI    
**Please cite**:   


* Title of Database: Spoken Arabic Digit

* Abstract: 

This dataset contains time series of mel-frequency cepstrum coefficients (MFCCs) corresponding to spoken Arabic digits. Includes data from 44 males and 44 females native Arabic speakers.

* Source:

Data Collected by the Laboratory of Automatic and Signals, 
University of Badji-Mokhtar 
Annaba, Algeria. 

Direction: Prof.Mouldi Bedda 
Participants: H.Dahmani, C.Snani, MC.Amara Korba, S.Atoui 
Adapted and preprocessed by : 
Nacereddine Hammami and Mouldi Bedda 
Faculty of Engineering, 
Al-Jouf University 
Sakaka, Al-Jouf 
Kingdom of Saudi Arabia 
e-mail: nacereddine.hammami '@' gmail.com 
mouldi_bedda '@' yahoo.fr 
Date: October, 2008


* Data Set Information:

Dataset from 8800 (10 digits x 10 repetitions x 88 speakers) time series of 13 Frequency Cepstral 
Coefficients (MFCCs) had taken from 44 males and 44 females Arabic native speakers 
between the ages 18 and 40 to represent ten spoken Arabic digit.


* Attribute Information:

Each line on the data base represents 13 MFCCs coefficients in the increasing order separated by spaces. This corresponds to one analysis frame. The 13 Mel Frequency Cepstral Coefficients (MFCCs) are computed with the following conditions; Sampling rate: 11025 Hz, 16 bits Window applied: hamming Filter pre-emphasized: 1-0.97Z^(-1)


* Relevant Papers:

[1] N. Hammami, M. Bedda ,""Improved Tree model for Arabic Speech Recognition"", Proc. IEEE 
ICCSIT10 Conference, 2010. 
[2] N. Hammami, M. Sellami ,""Tree distribution classifier for automatic spoken Arabic digit 
recognition"", Proc. IEEE ICITST09 Conference, 2009 , PP 1-4."
1504,steel-plates-fault,"**Author**: Semeion, Research Center of Sciences of Communication, Rome, Italy.     
**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/steel+plates+faults)     
**Please cite**: Dataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy.  

**Steel Plates Faults Data Set**  
A dataset of steel plates' faults, classified into 7 different types. The goal was to train machine learning for automatic pattern recognition.

The dataset consists of 27 features describing each fault (location, size, ...) and 7 binary features indicating the type of fault (on of 7: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults). The latter is commonly used as a binary classification target ('common' or 'other' fault.)

### Attribute Information  
* V1: X_Minimum  
* V2: X_Maximum  
* V3: Y_Minimum  
* V4: Y_Maximum  
* V5: Pixels_Areas  
* V6: X_Perimeter  
* V7: Y_Perimeter  
* V8: Sum_of_Luminosity  
* V9: Minimum_of_Luminosity  
* V10: Maximum_of_Luminosity  
* V11: Length_of_Conveyer  
* V12: TypeOfSteel_A300  
* V13: TypeOfSteel_A400  
* V14: Steel_Plate_Thickness  
* V15: Edges_Index  
* V16: Empty_Index  
* V17: Square_Index  
* V18: Outside_X_Index  
* V19: Edges_X_Index  
* V20: Edges_Y_Index  
* V21: Outside_Global_Index  
* V22: LogOfAreas  
* V23: Log_X_Index  
* V24: Log_Y_Index  
* V25: Orientation_Index  
* V26: Luminosity_Index  
* V27: SigmoidOfAreas  
* V28: Pastry  
* V29: Z_Scratch  
* V30: K_Scatch  
* V31: Stains  
* V32: Dirtiness  
* V33: Bumps  
* Class: Other_Faults  

### Relevant Papers  
1.M Buscema, S Terzi, W Tastle, A New Meta-Classifier,in NAFIPS 2010, Toronto (CANADA),26-28 July 2010, 978-1-4244-7858-6/10 Â©2010 IEEE  
2.M Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse, 33(2), 439-461,1998"
1506,thoracic-surgery,"**Author**:   
**Source**: UCI    
**Please cite**: Zikeba, M., Tomczak, J. M., Lubicz, M., & Swikatek, J. (2013). Boosted SVM for extracting rules from imbalanced data in application to prediction of the post-operative life expectancy in the lung cancer patients. Applied Soft Computing.   

  
* Title: 
Thoracic Surgery Data Data Set 

* Abstract: 
The data is dedicated to classification problem related to the post-operative life expectancy in the lung cancer patients: class 1 - death within one year after surgery, class 2 - survival.

* Source:
Creators: Marek Lubicz (1), Konrad Pawelczyk (2), Adam Rzechonek (2), Jerzy Kolodziej (2) 
-- (1) Wroclaw University of Technology, wybrzeze Wyspianskiego 27, 50-370, Wroclaw, Poland 
-- (2) Wroclaw Medical University, wybrzeze L. Pasteura 1, 50-367 Wroclaw, Poland 

Donor: Maciej Zieba (maciej.zieba '@' pwr.wroc.pl), Jakub M. Tomczak (jakub.tomczak '@' pwr.wroc.pl), (+48) 71 320 44 53 

* Data Set Information:

The data was collected retrospectively at Wroclaw Thoracic Surgery Centre for patients who underwent major lung resections for primary lung cancer in the years 2007â€“2011. The Centre is associated with the Department of Thoracic Surgery of the Medical University of Wroclaw and Lower-Silesian Centre for Pulmonary Diseases, Poland, while the research database constitutes a part of the National Lung Cancer Registry, administered by the Institute of Tuberculosis and Pulmonary Diseases in Warsaw, Poland.


* Attribute Information:

1. DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1) 
2. PRE4: Forced vital capacity - FVC (numeric) 
3. PRE5: Volume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric) 
4. PRE6: Performance status - Zubrod scale (PRZ2,PRZ1,PRZ0) 
5. PRE7: Pain before surgery (T,F) 
6. PRE8: Haemoptysis before surgery (T,F) 
7. PRE9: Dyspnoea before surgery (T,F) 
8. PRE10: Cough before surgery (T,F) 
9. PRE11: Weakness before surgery (T,F) 
10. PRE14: T in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13) 
11. PRE17: Type 2 DM - diabetes mellitus (T,F) 
12. PRE19: MI up to 6 months (T,F) 
13. PRE25: PAD - peripheral arterial diseases (T,F) 
14. PRE30: Smoking (T,F) 
15. PRE32: Asthma (T,F) 
16. AGE: Age at surgery (numeric) 
17. Risk1Y: 1 year survival period - (T)rue value if died (T,F) 

Class Distribution: the class value (Risk1Y) is binary valued."
1507,twonorm,"**Author**: Michael Revow     
**Source**: http://www.cs.toronto.edu/~delve/data/twonorm/desc.html  
**Please cite**:     

* Twonorm dataset

This is an implementation of Leo Breiman's twonorm example[1]. It is a 20 dimensional, 2 class classification example. Each class is drawn from a multivariate normal distribution with unit variance. Class 1 has mean (a,a,..a) while Class 2 has mean (-a,-a,..-a). Where a = 2/sqrt(20). Breiman reports the theoretical expected misclassification rate as 2.3%. He used 300 training examples with CART and found an error of 22.1%."
1508,user-knowledge,"**Author**:   
**Source**: UCI    
**Please cite**:  H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, Knowledge Based Systems, vol. 37, pp. 283-295, 2013.   

* Title:  

User Knowledge Modeling Data Set 

* Abstract: 

It is the real dataset about the students' knowledge status about the subject of Electrical DC Machines. The dataset had been obtained from Ph.D. Thesis.

* Source:

-- Creators: Hamdi Tolga Kahraman (htolgakahraman '@' yahoo.com) 
-- Institution: Faculty of Technology, Department of Software Engineering, Karadeniz Technical University, Trabzon, Turkiye 
-- Creators: Ilhami Colak (icolak '@' gazi.edu.tr) 
-- Institution: Faculty of Technology, Department of Electrical and Electronics Engineering, Gazi University, Ankara, Turkiye 
-- Creators: Seref Sagiroglu (ss '@' gazi.edu.tr) 
-- Institution: Faculty of Technology, Department of Computer Engineering, Gazi University, Ankara, Turkiye 

-- Donor: undergraduate students of Department of Electrical Education of Gazi University in the 2009 semester 
-- Date: October, 2009


* Data Set Information:

-- The users' knowledge class were classified by the authors 
using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm. See article for more details on how the users' data was collected and evaluated by the user modeling server. 

H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, Knowledge Based Systems, vol. 37, pp. 283-295, 2013.


* Attribute Information:

STG (The degree of study time for goal object materails), (input value) 
SCG (The degree of repetition number of user for goal object materails) (input value) 
STR (The degree of study time of user for related objects with goal object) (input value) 
LPR (The exam performance of user for related objects with goal object) (input value) 
PEG (The exam performance of user for goal objects) (input value) 
UNS (The knowledge level of user) (target value)


* Relevant Papers:

1. H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, 
Knowledge Based Systems, vol. 37, pp. 283-295, 2013. 
2. Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156."
1509,walking-activity,"**Author**: P. Casale, O. Pujol, P. Radeva.    
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/User+Identification+From+Walking+Activity)  
**Please cite**: Casale, P. Pujol, O. and Radeva, P. 'Personalization and user verification in wearable systems using biometric walking patterns' Personal and Ubiquitous Computing, 16(5), 563-580, 2012

**User Identification From Walking Activity Data Set**  
The dataset collects data from an Android smartphone positioned in the chest pocket. Accelerometer Data are collected from 22 participants walking in the wild over a predefined path. The dataset is intended for Activity Recognition research purposes. It provides challenges for identification and authentication of people using motion patterns. 

**Note: the original per-user datasets were joined into one dataset**

### Attribute Information  
Time-step, x acceleration, y acceleration, z acceleration  
Target: User ID."
1510,wdbc,"**Author**: William H. Wolberg, W. Nick Street, Olvi L. Mangasarian    
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)), [University of Wisconsin](http://pages.cs.wisc.edu/~olvi/uwmp/cancer.html) - 1995  
**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)     

**Breast Cancer Wisconsin (Diagnostic) Data Set (WDBC).** Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The target feature records the prognosis (benign (1) or malignant (2)). [Original data available here](ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/) 

Current dataset was adapted to ARFF format from the UCI version. Sample code ID's were removed.  

! Note that there is also a related Breast Cancer Wisconsin (Original) Data Set with a different set of features, better known as [breast-w](https://www.openml.org/d/15).


### Feature description  

Ten real-valued features are computed for each of 3 cell nuclei, yielding a total of 30 descriptive features. See the papers below for more details on how they were computed. The 10 features (in order) are:  

a) radius (mean of distances from center to points on the perimeter)  
b) texture (standard deviation of gray-scale values)  
c) perimeter  
d) area  
e) smoothness (local variation in radius lengths)  
f) compactness (perimeter^2 / area - 1.0)  
g) concavity (severity of concave portions of the contour)  
h) concave points (number of concave portions of the contour)  
i) symmetry  
j) fractal dimension (""coastline approximation"" - 1)  

### Relevant Papers   

W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. 

O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995."
1511,wholesale-customers,"**Author**: Margarida G. M. S. Cardoso      
**Source**: UCI     
**Please cite**: Abreu, N. (2011). Analise do perfil do cliente Recheio e desenvolvimento de um sistema promocional. Mestrado em Marketing, ISCTE-IUL, Lisbon.  

* Title:   
Wholesale customers Data Set 

* Abstract:   
The data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories

* Source:  
Margarida G. M. S. Cardoso, margarida.cardoso '@' iscte.pt, ISCTE-IUL, Lisbon, Portugal

* Attribute Information:

1) FRESH: annual spending (m.u.) on fresh products (Continuous); 
2) MILK: annual spending (m.u.) on milk products (Continuous); 
3) GROCERY: annual spending (m.u.)on grocery products (Continuous); 
4) FROZEN: annual spending (m.u.)on frozen products (Continuous) 
5) DETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) 
6) DELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); 
7) CHANNEL: customers' Channel - Horeca (Hotel/Restaurant/Café) or Retail channel (Nominal) 
8) REGION: customers' Region - Lisbon, Porto or Other (Nominal) 

Descriptive Statistics: 

(Minimum, Maximum, Mean, Std. Deviation) 
FRESH ( 3, 112151, 12000.30, 12647.329) 
MILK (55, 73498, 5796.27, 7380.377) 
GROCERY (3, 92780, 7951.28, 9503.163) 
FROZEN (25, 60869, 3071.93, 4854.673) 
DETERGENTS_PAPER (3, 40827, 2881.49, 4767.854) 
DELICATESSEN (3, 47943, 1524.87, 2820.106) 

REGION Frequency 
Lisbon 77 
Oporto 47 
Other Region 316 
Total 440 

CHANNEL Frequency 
Horeca 298 
Retail 142 
Total 440 


* Relevant Papers:

Cardoso, Margarida G.M.S. (2013). Logical discriminant models â€“ Chapter 8 in Quantitative Modeling in Marketing and Management Edited by Luiz Moutinho and Kun-Huang Huarng. World Scientific. p. 223-253. ISBN 978-9814407717 

Jean-Patrick Baudry, Margarida Cardoso, Gilles Celeux, Maria JosÃ© Amorim, Ana Sousa Ferreira (2012). Enhancing the selection of a model-based clustering with external qualitative variables. RESEARCH REPORT NÂ° 8124, October 2012, Project-Team SELECT. INRIA Saclay - ÃŽle-de-France, Projet select, UniversitÃ© Paris-Sud 11"
1512,heart-long-beach,"**Author**: V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.   
**Source**: UCI     
**Please cite**: V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:Robert Detrano, M.D., Ph.D.   

* Donor: 

David W. Aha (aha '@' ics.uci.edu) (714) 856-8779


* Data Set Information:

This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to 
this date. The ""goal"" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0). 

The names and social security numbers of the patients were recently removed from the database, replaced with dummy values. 

One file has been ""processed"", that one containing the Cleveland database. All four unprocessed files also exist in this directory. 

To see Test Costs (donated by Peter Turney), please see the folder ""Costs""


* Attribute Information:

Only 14 attributes used:    
1. #3 (age)   
2. #4 (sex)   
3. #9 (cp)   
4. #10 (trestbps)   
5. #12 (chol)   
6. #16 (fbs)    
7. #19 (restecg)   
8. #32 (thalach)    
9. #38 (exang)   
10. #40 (oldpeak)   
11. #41 (slope)   
12. #44 (ca)   
13. #51 (thal)   
14. #58 (num) (the predicted attribute)   

Complete attribute documentation:     
1 id: patient identification number    
2 ccf: social security number (I replaced this with a dummy value of 0)     
3 age: age in years    
4 sex: sex (1 = male; 0 = female)    
5 painloc: chest pain location (1 = substernal; 0 = otherwise)    
6 painexer (1 = provoked by exertion; 0 = otherwise)    
7 relrest (1 = relieved after rest; 0 = otherwise)   
8 pncaden (sum of 5, 6, and 7)    
9 cp: chest pain type    
-- Value 1: typical angina    
-- Value 2: atypical angina    
-- Value 3: non-anginal pain    
-- Value 4: asymptomatic    
10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)     
11 htn    
12 chol: serum cholestoral in mg/dl     
13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)    
14 cigs (cigarettes per day)    
15 years (number of years as a smoker)    
16 fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)     
17 dm (1 = history of diabetes; 0 = no such history)    
18 famhist: family history of coronary artery disease (1 = yes; 0 = no)    
19 restecg: resting electrocardiographic results    
-- Value 0: normal    
-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)    
-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria    
20 ekgmo (month of exercise ECG reading)    
21 ekgday(day of exercise ECG reading)    
22 ekgyr (year of exercise ECG reading)    
23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)    
24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)    
25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)    
26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)    
27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)    
28 proto: exercise protocol    
1 = Bruce    
2 = Kottus    
3 = McHenry    
4 = fast Balke    
5 = Balke    
6 = Noughton    
7 = bike 150 kpa min/min (Not sure if ""kpa min/min"" is what was written!)    
8 = bike 125 kpa min/min    
9 = bike 100 kpa min/min    
10 = bike 75 kpa min/min    
11 = bike 50 kpa min/min    
12 = arm ergometer    
29 thaldur: duration of exercise test in minutes    
30 thaltime: time when ST measure depression was noted    
31 met: mets achieved   
32 thalach: maximum heart rate achieved    
33 thalrest: resting heart rate    
34 tpeakbps: peak exercise blood pressure (first of 2 parts)    
35 tpeakbpd: peak exercise blood pressure (second of 2 parts)    
36 dummy    
37 trestbpd: resting blood pressure    
38 exang: exercise induced angina (1 = yes; 0 = no)    
39 xhypo: (1 = yes; 0 = no)    
40 oldpeak = ST depression induced by exercise relative to rest    
41 slope: the slope of the peak exercise ST segment    
-- Value 1: upsloping    
-- Value 2: flat    
-- Value 3: downsloping    
42 rldv5: height at rest    
43 rldv5e: height at peak exercise    
44 ca: number of major vessels (0-3) colored by flourosopy    
45 restckm: irrelevant    
46 exerckm: irrelevant    
47 restef: rest raidonuclid (sp?) ejection fraction    
48 restwm: rest wall (sp?) motion abnormality    
0 = none   
1 = mild or moderate   
2 = moderate or severe    
3 = akinesis or dyskmem (sp?)    
49 exeref: exercise radinalid (sp?) ejection fraction    
50 exerwm: exercise wall (sp?) motion    
51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect    
52 thalsev: not used   
53 thalpul: not used   
54 earlobe: not used   
55 cmo: month of cardiac cath (sp?) (perhaps ""call"")   
56 cday: day of cardiac cath (sp?)   
57 cyr: year of cardiac cath (sp?)   
58 num: diagnosis of heart disease (angiographic disease status)   
-- Value 0: < 50% diameter narrowing   
-- Value 1: > 50% diameter narrowing   
(in any major vessel: attributes 59 through 68 are vessels)   
59 lmt   
60 ladprox   
61 laddist   
62 diag   
63 cxmain   
64 ramus   
65 om1   
66 om2   
67 rcaprox   
68 rcadist   
69 lvx1: not used   
70 lvx2: not used   
71 lvx3: not used   
72 lvx4: not used   
73 lvf: not used   
74 cathef: not used   
75 junk: not used   
76 name: last name of patient (I replaced this with the dummy string ""name"")  


* Relevant Papers:

Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J., Sandhu, S., Guppy, K., Lee, S., & Froelicher, V. (1989). International application of a new probability algorithm for the diagnosis of coronary artery disease. American Journal of Cardiology, 64,304--310. 

David W. Aha & Dennis Kibler. ""Instance-based prediction of heart-disease presence with the Cleveland database."" 

Gennari, J.H., Langley, P, & Fisher, D. (1989). Models of incremental concept formation. Artificial Intelligence, 40, 11--61."
1513,heart-switzerland,"**Author**: University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.    
**Source**: UCI     
**Please cite**: University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.   

* Donor: 

David W. Aha (aha '@' ics.uci.edu) (714) 856-8779


* Data Set Information:

This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to 
this date. The ""goal"" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0). 

The names and social security numbers of the patients were recently removed from the database, replaced with dummy values. 

One file has been ""processed"", that one containing the Cleveland database. All four unprocessed files also exist in this directory. 

To see Test Costs (donated by Peter Turney), please see the folder ""Costs""


* Attribute Information:

Only 14 attributes used:    
1. #3 (age)   
2. #4 (sex)   
3. #9 (cp)   
4. #10 (trestbps)   
5. #12 (chol)   
6. #16 (fbs)    
7. #19 (restecg)   
8. #32 (thalach)    
9. #38 (exang)   
10. #40 (oldpeak)   
11. #41 (slope)   
12. #44 (ca)   
13. #51 (thal)   
14. #58 (num) (the predicted attribute)   

Complete attribute documentation:     
1 id: patient identification number    
2 ccf: social security number (I replaced this with a dummy value of 0)     
3 age: age in years    
4 sex: sex (1 = male; 0 = female)    
5 painloc: chest pain location (1 = substernal; 0 = otherwise)    
6 painexer (1 = provoked by exertion; 0 = otherwise)    
7 relrest (1 = relieved after rest; 0 = otherwise)   
8 pncaden (sum of 5, 6, and 7)    
9 cp: chest pain type    
-- Value 1: typical angina    
-- Value 2: atypical angina    
-- Value 3: non-anginal pain    
-- Value 4: asymptomatic    
10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)     
11 htn    
12 chol: serum cholestoral in mg/dl     
13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)    
14 cigs (cigarettes per day)    
15 years (number of years as a smoker)    
16 fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)     
17 dm (1 = history of diabetes; 0 = no such history)    
18 famhist: family history of coronary artery disease (1 = yes; 0 = no)    
19 restecg: resting electrocardiographic results    
-- Value 0: normal    
-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)    
-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria    
20 ekgmo (month of exercise ECG reading)    
21 ekgday(day of exercise ECG reading)    
22 ekgyr (year of exercise ECG reading)    
23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)    
24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)    
25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)    
26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)    
27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)    
28 proto: exercise protocol    
1 = Bruce    
2 = Kottus    
3 = McHenry    
4 = fast Balke    
5 = Balke    
6 = Noughton    
7 = bike 150 kpa min/min (Not sure if ""kpa min/min"" is what was written!)    
8 = bike 125 kpa min/min    
9 = bike 100 kpa min/min    
10 = bike 75 kpa min/min    
11 = bike 50 kpa min/min    
12 = arm ergometer    
29 thaldur: duration of exercise test in minutes    
30 thaltime: time when ST measure depression was noted    
31 met: mets achieved   
32 thalach: maximum heart rate achieved    
33 thalrest: resting heart rate    
34 tpeakbps: peak exercise blood pressure (first of 2 parts)    
35 tpeakbpd: peak exercise blood pressure (second of 2 parts)    
36 dummy    
37 trestbpd: resting blood pressure    
38 exang: exercise induced angina (1 = yes; 0 = no)    
39 xhypo: (1 = yes; 0 = no)    
40 oldpeak = ST depression induced by exercise relative to rest    
41 slope: the slope of the peak exercise ST segment    
-- Value 1: upsloping    
-- Value 2: flat    
-- Value 3: downsloping    
42 rldv5: height at rest    
43 rldv5e: height at peak exercise    
44 ca: number of major vessels (0-3) colored by flourosopy    
45 restckm: irrelevant    
46 exerckm: irrelevant    
47 restef: rest raidonuclid (sp?) ejection fraction    
48 restwm: rest wall (sp?) motion abnormality    
0 = none   
1 = mild or moderate   
2 = moderate or severe    
3 = akinesis or dyskmem (sp?)    
49 exeref: exercise radinalid (sp?) ejection fraction    
50 exerwm: exercise wall (sp?) motion    
51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect    
52 thalsev: not used   
53 thalpul: not used   
54 earlobe: not used   
55 cmo: month of cardiac cath (sp?) (perhaps ""call"")   
56 cday: day of cardiac cath (sp?)   
57 cyr: year of cardiac cath (sp?)   
58 num: diagnosis of heart disease (angiographic disease status)   
-- Value 0: < 50% diameter narrowing   
-- Value 1: > 50% diameter narrowing   
(in any major vessel: attributes 59 through 68 are vessels)   
59 lmt   
60 ladprox   
61 laddist   
62 diag   
63 cxmain   
64 ramus   
65 om1   
66 om2   
67 rcaprox   
68 rcadist   
69 lvx1: not used   
70 lvx2: not used   
71 lvx3: not used   
72 lvx4: not used   
73 lvf: not used   
74 cathef: not used   
75 junk: not used   
76 name: last name of patient (I replaced this with the dummy string ""name"")  


* Relevant Papers:

Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J., Sandhu, S., Guppy, K., Lee, S., & Froelicher, V. (1989). International application of a new probability algorithm for the diagnosis of coronary artery disease. American Journal of Cardiology, 64,304--310. 

David W. Aha & Dennis Kibler. ""Instance-based prediction of heart-disease presence with the Cleveland database."" 

Gennari, J.H., Langley, P, & Fisher, D. (1989). Models of incremental concept formation. Artificial Intelligence, 40, 11--61."
1514,micro-mass,"**Author**: Pierre Mahé, Jean-Baptiste Veyrieras  
**Source**: UCI    
**Please cite**:   

* Dataset Title: MicroMass - Mixed (mixed spectra version)   

* Abstract:   
A dataset to explore machine learning approaches for the identification of microorganisms from mass-spectrometry data.  

* Source:

Pierre Mahé, pierre.mahe '@' biomerieux.com, bioMérieux
Jean-Baptiste Veyrieras, jean-baptiste.veyrieras '@' biomerieux.com, bioMérieux

* Data Set Information:

This MALDI-TOF dataset consists in:
A) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours, before a portion of colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. 
B) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:
* 4 mixtures, labelled A, B, C and D, involved species that belong to the same genus,  
* 2 mixtures, labelled E and F, involved species that belong to distinct genera, but to the same Gram type,  
* 4 mixtures, labelled G, H, I and J, involved species that belong to distinct Gram types.  
Each mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.

* Relevant Papers:

Mahé et al. (2014). Automatic identification of mixed bacterial species fingerprints in a MALDI-TOF mass-spectrum. Bioinformatics.

Vervier et al., A benchmark of support vector machines strategies for microbial identification by mass-spectrometry data, submitted"
1515,micro-mass,"**Author**: Pierre Mahé, Jean-Baptiste Veyrieras  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MicroMass) - 2014  
**Please cite**:   

### Description

MicroMass (pure spectra version) is a dataset to explore machine learning approaches for the identification of microorganisms from mass-spectrometry data.  

### Source
```
Pierre Mahé, pierre.mahe '@' biomerieux.com, bioMérieux
Jean-Baptiste Veyrieras, jean-baptiste.veyrieras '@' biomerieux.com, bioMérieux
```

### Data Set Information

This MALDI-TOF dataset consists in:

a) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours before a portion of the colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. 

b) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:
* 4 mixtures, labeled A, B, C and D, involved species that belong to the same genus,  
* 2 mixtures, labeled E and F, involved species that belong to distinct genera, but to the same Gram type,  
* 4 mixtures, labeled G, H, I and J, involved species that belong to distinct Gram types.  
Each mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.

### Relevant Papers

Mahé et al. (2014). Automatic identification of mixed bacterial species fingerprints in a MALDI-TOF mass-spectrum. Bioinformatics.

Vervier et al., A benchmark of support vector machines strategies for microbial identification by mass-spectrometry data, submitted"
1516,robot-failures-lp1,"**Author**: Luis Seabra Lope, Luis M. Camarinha-Matos    
**Source**: UCI   
**Please cite**:   

* Dataset Title:   
Robot Execution Failures Data Set 

* Abstract:   
This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals


* Source:  

Original Owner and Donor

Luis Seabra Lopes and Luis M. Camarinha-Matos, Universidade Nova de Lisboa, Monte da Caparica, Portugal 


* Data Set Information:

The donation includes 5 datasets, each of them defining a different learning problem: 

* LP1 (This Dataset): failures in approach to grasp position   
* LP2: failures in transfer of a part   
* LP3: position of part after a transfer failure   
* LP4: failures in approach to ungrasp position   
* LP5: failures in motion with part   

In order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].


* Attribute Information:

All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. 

Each example is described as follows: 

class    
Fx1 Fy1 Fz1 Tx1 Ty1 Tz1    
Fx2 Fy2 Fz2 Tx2 Ty2 Tz2    
......    
Fx15 Fy15 Fz15 Tx15 Ty15 Tz15   

where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features.


* Relevant Papers:

Seabra Lopes, L. (1997) ""Robot Learning at the Task Level: a Study in the Assembly Domain"", Ph.D. thesis, Universidade Nova de Lisboa, Portugal. 

Seabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, ""Feature Extraction, Construction and Selection. A Data Mining Perspective"", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers. 

Camarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, ""IEEE Transactions on Robotics and Automation"", 12 (2), 202-219."
1517,robot-failures-lp2,"**Author**: Luis Seabra Lope, Luis M. Camarinha-Matos    
**Source**: UCI   
**Please cite**:   

* Dataset Title:   
Robot Execution Failures Data Set 

* Abstract:   
This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals


* Source:  

Original Owner and Donor

Luis Seabra Lopes and Luis M. Camarinha-Matos, Universidade Nova de Lisboa, Monte da Caparica, Portugal 


* Data Set Information:

The donation includes 5 datasets, each of them defining a different learning problem: 

* LP1: failures in approach to grasp position   
* LP2 (This dataset): failures in transfer of a part   
* LP3: position of part after a transfer failure   
* LP4: failures in approach to ungrasp position   
* LP5: failures in motion with part   

In order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].


* Attribute Information:

All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. 

Each example is described as follows: 

class    
Fx1 Fy1 Fz1 Tx1 Ty1 Tz1    
Fx2 Fy2 Fz2 Tx2 Ty2 Tz2    
......    
Fx15 Fy15 Fz15 Tx15 Ty15 Tz15   

where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features.


* Relevant Papers:

Seabra Lopes, L. (1997) ""Robot Learning at the Task Level: a Study in the Assembly Domain"", Ph.D. thesis, Universidade Nova de Lisboa, Portugal. 

Seabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, ""Feature Extraction, Construction and Selection. A Data Mining Perspective"", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers. 

Camarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, ""IEEE Transactions on Robotics and Automation"", 12 (2), 202-219."
1518,robot-failures-lp3,"**Author**: Luis Seabra Lope, Luis M. Camarinha-Matos    
**Source**: UCI   
**Please cite**:   

* Dataset Title:   
Robot Execution Failures Data Set 

* Abstract:   
This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals


* Source:  

Original Owner and Donor

Luis Seabra Lopes and Luis M. Camarinha-Matos, Universidade Nova de Lisboa, Monte da Caparica, Portugal 


* Data Set Information:

The donation includes 5 datasets, each of them defining a different learning problem: 

* LP1: failures in approach to grasp position   
* LP2: failures in transfer of a part   
* LP3 (This dataset): position of part after a transfer failure   
* LP4: failures in approach to ungrasp position   
* LP5: failures in motion with part   

In order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].


* Attribute Information:

All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. 

Each example is described as follows: 

class    
Fx1 Fy1 Fz1 Tx1 Ty1 Tz1    
Fx2 Fy2 Fz2 Tx2 Ty2 Tz2    
......    
Fx15 Fy15 Fz15 Tx15 Ty15 Tz15   

where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features.


* Relevant Papers:

Seabra Lopes, L. (1997) ""Robot Learning at the Task Level: a Study in the Assembly Domain"", Ph.D. thesis, Universidade Nova de Lisboa, Portugal. 

Seabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, ""Feature Extraction, Construction and Selection. A Data Mining Perspective"", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers. 

Camarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, ""IEEE Transactions on Robotics and Automation"", 12 (2), 202-219."
1519,robot-failures-lp4,"**Author**: Luis Seabra Lope, Luis M. Camarinha-Matos    
**Source**: UCI   
**Please cite**:   

* Dataset Title:   
Robot Execution Failures Data Set 

* Abstract:   
This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals


* Source:  

Original Owner and Donor

Luis Seabra Lopes and Luis M. Camarinha-Matos, Universidade Nova de Lisboa, Monte da Caparica, Portugal 


* Data Set Information:

The donation includes 5 datasets, each of them defining a different learning problem: 

* LP1: failures in approach to grasp position   
* LP2: failures in transfer of a part   
* LP3: position of part after a transfer failure   
* LP4 (This dataset): failures in approach to ungrasp position   
* LP5: failures in motion with part   

In order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].


* Attribute Information:

All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. 

Each example is described as follows: 

class    
Fx1 Fy1 Fz1 Tx1 Ty1 Tz1    
Fx2 Fy2 Fz2 Tx2 Ty2 Tz2    
......    
Fx15 Fy15 Fz15 Tx15 Ty15 Tz15   

where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features.


* Relevant Papers:

Seabra Lopes, L. (1997) ""Robot Learning at the Task Level: a Study in the Assembly Domain"", Ph.D. thesis, Universidade Nova de Lisboa, Portugal. 

Seabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, ""Feature Extraction, Construction and Selection. A Data Mining Perspective"", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers. 

Camarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, ""IEEE Transactions on Robotics and Automation"", 12 (2), 202-219."
1520,robot-failures-lp5,"**Author**: Luis Seabra Lope, Luis M. Camarinha-Matos    
**Source**: UCI   
**Please cite**:   

* Dataset Title:   
Robot Execution Failures Data Set 

* Abstract:   
This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals


* Source:  

Original Owner and Donor

Luis Seabra Lopes and Luis M. Camarinha-Matos, Universidade Nova de Lisboa, Monte da Caparica, Portugal 


* Data Set Information:

The donation includes 5 datasets, each of them defining a different learning problem: 

* LP1: failures in approach to grasp position   
* LP2: failures in transfer of a part   
* LP3: position of part after a transfer failure   
* LP4: failures in approach to ungrasp position   
* LP5 (This dataset): failures in motion with part   

In order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].


* Attribute Information:

All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. 

Each example is described as follows: 

class    
Fx1 Fy1 Fz1 Tx1 Ty1 Tz1    
Fx2 Fy2 Fz2 Tx2 Ty2 Tz2    
......    
Fx15 Fy15 Fz15 Tx15 Ty15 Tz15   

where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features.


* Relevant Papers:

Seabra Lopes, L. (1997) ""Robot Learning at the Task Level: a Study in the Assembly Domain"", Ph.D. thesis, Universidade Nova de Lisboa, Portugal. 

Seabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, ""Feature Extraction, Construction and Selection. A Data Mining Perspective"", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers. 

Camarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, ""IEEE Transactions on Robotics and Automation"", 12 (2), 202-219."
1523,vertebra-column,"**Author**: Guilherme de Alencar Barreto, Ajalmar R. da Rocha Neto, Henrique Antonio Fonseca da Mota Filho       
**Source**: UCI  
**Please cite**:   

* Dataset Title: Vertebra Column - 3 classes

* Abstract:   
Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).

* Source:

Guilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar R. da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of Ceará, Fortaleza, Ceará, Brazil. 

Henrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, Ceará, Brazil.


Data Set Information:

Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre Médico-Chirurgical de Réadaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.


Attribute Information:

Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).


* Relevant Papers:

(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40â€“47. 

(2) Rocha Neto, A. R. & Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496. 

(3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Optionâ€, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595."
1524,vertebra-column,"**Author**: Guilherme de Alencar Barreto, Ajalmar R. da Rocha Neto, Henrique Antonio Fonseca da Mota Filho       
**Source**: [original](http://www.openml.org/d/1523) - UCI   
**Please cite**:   

* Dataset Title: Vertebra Column - 2 classes

* Abstract:   
Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).

* Source:

Guilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar R. da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of Ceará, Fortaleza, Ceará, Brazil. 

Henrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, Ceará, Brazil.


* Data Set Information:

Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre Médico-Chirurgical de Réadaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.


* Attribute Information:

Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).


* Relevant Papers:

(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40â€“47. 

(2) Rocha Neto, A. R. & Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496. 

(3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Optionâ€, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595."
1525,wall-robot-navigation,"**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     
**Source**: [original](http://www.openml.org/d/1497) - UCI  
**Please cite**:   

* Dataset Title: 

Wall-Following Robot Navigation Data Data Set (version with 2 Attributes)

* Abstract:  

The data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.

* Source:

(a) Creators: Ananda Freire, Marcus Veloso and Guilherme Barreto 
Department of Teleinformatics Engineering 
Federal University of CearÃ¡ 
Fortaleza, CearÃ¡, Brazil 

(b) Donors of database: Ananda Freire (anandalf '@' gmail.com) 
Guilherme Barreto (guilherme '@' deti.ufc.br)

* Data Set Information:

The provided file contain the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second. 

It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). 

The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. 

If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network. 

* Attribute Information:

Number of Attributes: sensor_readings_2.data: 2 numeric attributes and the class. 

For Each Attribute: 
-- File sensor_readings_2.data: 
1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real) 
2. SD_left: minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real) 
3. Class: {Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn}     


* Relevant Papers:

Ananda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), 
'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation 
Tasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009), 
ValparaÃ­so-Chile, pages 1-6, DOI: 10.1109/LARS.2009.5418323"
1526,wall-robot-navigation,"**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     
**Source**: [original](http://www.openml.org/d/1497) - UCI     
**Please cite**:   

* Dataset Title: 

Wall-Following Robot Navigation Data Data Set (version with 4 Attributes)

* Abstract:  

The data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.

* Source:

(a) Creators: Ananda Freire, Marcus Veloso and Guilherme Barreto 
Department of Teleinformatics Engineering 
Federal University of CearÃ¡ 
Fortaleza, CearÃ¡, Brazil 

(b) Donors of database: Ananda Freire (anandalf '@' gmail.com) 
Guilherme Barreto (guilherme '@' deti.ufc.br)

* Data Set Information:

The provided file contain the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second. 

It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). 

The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. 

If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network. 

* Attribute Information:

Number of Attributes: sensor_readings_24.data: 24 numeric attributes and the class. 

For Each Attribute: 
-- File sensor_readings_4.data: 
1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real) 
2. SD_left: minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real) 
3. SD_right: minimum sensor reading within a 60 degree arc located at the right of the robot - (numeric: real) 
4. SD_back: minimum sensor reading within a 60 degree arc located at the back of the robot - (numeric: real) 
5. Class: {Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn}   


* Relevant Papers:

Ananda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), 
'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation 
Tasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009), 
ValparaÃ­so-Chile, pages 1-6, DOI: 10.1109/LARS.2009.5418323"
1527,volcanoes-a1,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: A1        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 
[Web Link] 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 
[Web Link] 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 
[Web Link] 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995). 
[Web Link]"
1528,volcanoes-a2,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: A2        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1529,volcanoes-a3,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: A3       

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1530,volcanoes-a4,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: A4       

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1531,volcanoes-b1,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: B1        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1532,volcanoes-b2,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: B2        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1533,volcanoes-b3,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: B3        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1534,volcanoes-b4,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: B4        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1535,volcanoes-b5,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: B5        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1536,volcanoes-b6,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: B6        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1537,volcanoes-c1,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: C1        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1538,volcanoes-d1,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: D1        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1539,volcanoes-d2,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: D2        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1540,volcanoes-d3,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: D3        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1541,volcanoes-d4,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: D4        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1542,volcanoes-e1,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: E1         

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1543,volcanoes-e2,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: E2        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1544,volcanoes-e3,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: E3        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1545,volcanoes-e4,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: E4        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1546,volcanoes-e5,"**Author**: Michael C. Burl 
**Source**: UCI  
**Please cite**:   

* Dataset Title:  
Volcanoes on Venus - JARtool experiment Data Set  
Experiment: E5        

* Source:

Michael C. Burl 
MS 126-347, JPL 
4800 Oak Grove Drive 
Pasadena, CA 91109 
(818) 393-5345 
Michael.C.Burl '@' jpl.nasa.gov 
http://www-aig.jpl.nasa.gov/mls/home/burl/


* Data Set Information:  

The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. 

There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. 

In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. 

There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. 

* Attribute Information:

The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.


* Relevant Papers:

G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991). 

R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). 

M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998). 

P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995)."
1547,autoUniv-au1-1000,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au1-1000   

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1548,autoUniv-au4-2500,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au4-2500    

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1549,autoUniv-au6-750,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au6-250-drift-au6-cd1-500     

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1551,autoUniv-au6-400,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au6-cd1-400    

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1552,autoUniv-au7-1100,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au7-300-drift-au7-cpd1-800 

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1553,autoUniv-au7-700,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au7-700     

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1554,autoUniv-au7-500,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au7-cpd1-500    

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1555,autoUniv-au6-1000,"**Author**: Ray. J. Hickey   
**Source**: UCI  
**Please cite**:   

* Dataset Title:  

AutoUniv Dataset  
data problem: autoUniv-au6-1000    

* Abstract:   

AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.

* Source:  

AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com 
AutoUniv web-site: http://sites.google.com/site/autouniv/.


* Data Set Information:

The user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. 

AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).


* Attribute Information: 

Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .


* Relevant Papers:

Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. 
[Web Link]#proc . 

Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469. 

Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768."
1556,acute-inflammations,"**Author**: Jacek Czerniak     
**Source**: [original](http://www.openml.org/d/1455) - UCI    
**Please cite**:  J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive diagnosis of urinary system diseases, Artificial Intelligence and Security in Computing Systems, ACS'2002 9th International Conference Proceedings, Kluwer Academic Publishers,2003, pp. 41-51.  

* Abstract: 

The data was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of the urinary system. This is a class-balanced version of acute-inflammations dataset."
1557,abalone,"**Author**:   
**Source**: [original](http://www.openml.org/d/183) - UCI    
**Please cite**:   

* Abstract: 

A 3-class version of abalone dataset.

* Sources:  

(a) Original owners of database: Marine Resources Division Marine Research Laboratories - Taroona Department of Primary Industry and Fisheries, Tasmania GPO Box 619F, Hobart, Tasmania 7001, Australia (contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)

(b) Donor of database: Sam Waugh (Sam.Waugh@cs.utas.edu.au) Department of Computer Science, University of Tasmania GPO Box 252C, Hobart, Tasmania 7001, Australia"
1558,bank-marketing,"**Author**: Paulo Cortez, Sérgio Moro   
**Source**: [original] (http://www.openml.org/d/1461) - UCI    
**Please cite**: S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.       

* Dataset:   
Reduced version (10 % of the examples) of bank-marketing dataset."
1559,breast-tissue,"**Author**: JP Marques de Sá, J Jossinet  
**Source**: [original](http://www.openml.org/d/1465) - UCI   
**Please cite**:     

A 4-class version of breast-tissue dataset."
1560,cardiotocography,"**Author**: J. P. Marques de Sá, J. Bernardes, D. Ayers de Campos.  
**Source**: [original](http://www.openml.org/d/1466) - UCI   
**Please cite**:     

A 3-class version of Cardiotocography dataset."
1561,dbworld-bodies-stemmed,"**Author**: Michele Filannino   
**Source**: UCI  
**Please cite**:   

* Dataset:  
DBworld e-mails data set
Task: dbworld-bodies-stemmed


* Source:

Michele Filannino, PhD 
University of Manchester 
Centre for Doctoral Training 
Email: filannim_AT_cs.man.ac.uk


* Data Set Information:

I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.


* Attribute Information:

Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).

* Relevant Papers:

Michele Filannino, 'DBWorld e-mail classification using a very small corpus', Project of Machine Learning course, University of Manchester, 2011."
1562,dbworld-bodies,"**Author**: Michele Filannino   
**Source**: UCI  
**Please cite**:   

* Dataset:  
DBworld e-mails data set  
Task: dbworld-bodies


* Source:

Michele Filannino, PhD 
University of Manchester 
Centre for Doctoral Training 
Email: filannim_AT_cs.man.ac.uk


* Data Set Information:

I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.


* Attribute Information:

Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).

* Relevant Papers:

Michele Filannino, 'DBWorld e-mail classification using a very small corpus', Project of Machine Learning course, University of Manchester, 2011."
1563,dbworld-subjects-stemmed,"**Author**: Michele Filannino   
**Source**: UCI  
**Please cite**:   

* Dataset:  
DBworld e-mails data set  
Task: dbworld-subjects-stemmed


* Source:

Michele Filannino, PhD 
University of Manchester 
Centre for Doctoral Training 
Email: filannim_AT_cs.man.ac.uk


* Data Set Information:

I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.


* Attribute Information:

Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).

* Relevant Papers:

Michele Filannino, 'DBWorld e-mail classification using a very small corpus', Project of Machine Learning course, University of Manchester, 2011."
1564,dbworld-subjects,"**Author**: Michele Filannino   
**Source**: UCI  
**Please cite**:   

* Dataset:  
DBworld e-mails data set   
Task: dbworld-subjects   


* Source:

Michele Filannino, PhD 
University of Manchester 
Centre for Doctoral Training 
Email: filannim_AT_cs.man.ac.uk


* Data Set Information:

I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.


* Attribute Information:

Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).

* Relevant Papers:

Michele Filannino, 'DBWorld e-mail classification using a very small corpus', Project of Machine Learning course, University of Manchester, 2011."
1565,heart-h,"**Author**: Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.     
**Source**: [original](http://www.openml.org/d/51) - UCI      
**Please cite**: Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.       

* Dataset:
This is a reprocessed version of heart-h (hungarian), the heart disease reprocessed hungarian dataset from UCI."
1566,hill-valley,"**Author**: Lee Graham, Franz Oppacher
**Source**: [original](http://www.openml.org/d/1479) - UCI   
**Please cite**:   

* Dataset:
Hill valley dataset. A noiseless version of the data set."
1567,poker-hand,"**Author**: Robert Cattral, Franz Oppacher    
**Source**: UCI    
**Please cite**:   

* Abstract: 
Purpose is to predict poker hands

* Source - Creators:   
Robert Cattral (cattral '@' gmail.com)
Franz Oppacher (oppacher '@' scs.carleton.ca) 
Carleton University, Department of Computer Science 
Intelligent Systems Research Unit 
1125 Colonel By Drive, Ottawa, Ontario, Canada, K1S5B6


* Data Set Information:

Each record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the ""Poker Hand"". The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit).


* Attribute Information:

1) S1 ""Suit of card #1""    
Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}    

2) C1 ""Rank of card #1""    
Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)    

3) S2 ""Suit of card #2""    
Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}    

4) C2 ""Rank of card #2""   
Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   

5) S3 ""Suit of card #3""   
Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}   

6) C3 ""Rank of card #3""   
Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   

7) S4 ""Suit of card #4""   
Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}   

8) C4 ""Rank of card #4""   
Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   

9) S5 ""Suit of card #5""   
Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}   

10) C5 ""Rank of card 5""   
Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   

11) CLASS ""Poker Hand""   
Ordinal (0-9)   

0: Nothing in hand; not a recognized poker hand    
1: One pair; one pair of equal ranks within five cards   
2: Two pairs; two pairs of equal ranks within five cards   
3: Three of a kind; three equal ranks within five cards   
4: Straight; five cards, sequentially ranked with no gaps   
5: Flush; five cards with the same suit   
6: Full house; pair + different rank three of a kind   
7: Four of a kind; four equal ranks within five cards   
8: Straight flush; straight + flush   
9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush   


* Relevant Papers:

R. Cattral, F. Oppacher, D. Deugo. Evolutionary Data Mining with Automatic Rule Generalization. Recent Advances in Computers, Computing and Communications, pp.296-300, WSEAS Press, 2002. 
Note: This was a slightly different dataset that had more classes, and was considerably more difficult."
1568,nursery,"**Author**: Vladislav Rajkovic et al.     
**Source**: [original](http://www.openml.org/d/26) - UCI   
**Please cite**:   

* Title: Nursery Database  

* Abstract: 4-class version of the original Nursery dataset"
1569,poker-hand,"**Author**: Robert Cattral, Franz Oppacher    
**Source**: [original](http://www.openml.org/d/1567) - UCI    
**Please cite**:   

* Abstract:
9-class version of poker-hand dataset, it was removed the minority class."
1571,fourclass_scale,"**Author**: Tin Kam Ho and Eugene M. Kleinberg.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository.

Preprocessing: transform to two-class"
1572,german.numer,
1574,heart,"**Author**: Laboratory of Artificial Intelligence and Computer Science of the University of Porto (LIACC)  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository.

Preprocessing: scaled to [-1,1]"
1575,ijcnn,"**Author**: Danil Prokhorov.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**: Danil Prokhorov.
IJCNN 2001 neural network competition. 
Slide presentation in IJCNN'01, Ford Research Laboratory, 2001.
http://www.geocities.com/ijcnn/nnc_ijcnn01.pdf .  

#Dataset from the LIBSVM data repository.

Preprocessing:  We use winner's transformation"
1577,rcv1.binary,
1578,real-sim,"**Author**: A. McCallum  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository.

Preprocessing: Vikas Sindhwani for the SVMlin project."
1579,splice,"**Author**: Delve Datasets  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository.

Preprocessing: scaled to [-1,1]"
1581,w1a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1582,w2a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1583,w3a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1584,w4a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1585,w5a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1586,w6a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1587,w7a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1588,w8a,"**Author**: John C. Platt.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository."
1589,svmguide3,"**Author**: Chih-Wei Hsu"",""Chih-Chung Chang"",""and Chih-Jen Lin.  
libSVM"",""AAD group  
**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  
**Please cite**:   

#Dataset from the LIBSVM data repository.

Preprocessing: Original data: someone from Germany working with the car industry."
1590,adult,"**Author**: Ronny Kohavi and Barry Becker  
**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Adult) - 1996  
**Please cite**: Ron Kohavi, ""Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  

Prediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))

This is the original version from the UCI repository, with training and test sets merged.

### Variable description

Variables are all self-explanatory except __fnlwgt__. This is a proxy for the demographic background of the people: ""People with similar demographic characteristics should have similar weights"". This similarity-statement is not transferable across the 51 different states.

Description from the donor of the database: 

The weights on the CPS files are controlled to independent estimates of the civilian noninstitutional population of the US.  These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are:
1.  A single cell estimate of the population 16+ for each state.
2.  Controls for Hispanic Origin by age and sex.
3.  Controls by Race, age and sex.

We use all three sets of controls in our weighting program and ""rake"" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating ""weighted tallies"" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state.


### Relevant papers  

Ronny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.  
e-mail: ronnyk '@' live.com for questions."
